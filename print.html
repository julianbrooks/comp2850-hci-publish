<!DOCTYPE HTML>
<html lang="en" class="navy sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>COMP2850 ‚Ä¢ Human-Computer Interaction</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="HCI module covering server-first architecture, accessibility, privacy by design, and evaluation (Weeks 6-11)">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="css/admonish.css">
        <link rel="stylesheet" href="css/custom.css">
        <link rel="stylesheet" href="css/retro-theme.css">
        <link rel="stylesheet" href="./mdbook-admonish.css">


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "navy";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>‚Üê</kbd> or <kbd>‚Üí</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('navy')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">COMP2850 ‚Ä¢ Human-Computer Interaction</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="comp2850--human-computer-interaction"><a class="header" href="#comp2850--human-computer-interaction">COMP2850 ‚Ä¢ Human-Computer Interaction</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/University-Leeds-green" alt="University of Leeds" />
<img src="https://img.shields.io/badge/Year-2025%2F26-orange" alt="Academic Year" /></p>
<hr />
<h2 id="welcome"><a class="header" href="#welcome">Welcome</a></h2>
<p>This is the <strong>HCI (Human-Computer Interaction)</strong> component of <strong>COMP2850</strong>, running from <strong>Week 6 to Week 11</strong>. You‚Äôll build <strong>inclusive web interfaces</strong> using <strong>HTML as your UI layer</strong> (no React/Vue/Angular). We follow the <strong><a href="https://hypermedia.systems/">hypermedia systems</a></strong> approach‚Äîdynamic, accessible UIs built with server-rendered HTML and progressive enhancement.</p>
<p><strong>Core approaches</strong>:</p>
<ul>
<li><strong><a href="references/htmx-patterns.html">Hypermedia-driven interfaces (HTMX)</a></strong> - Dynamic HTML UIs without JavaScript frameworks</li>
<li><strong><a href="references/accessibility-testing.html">Accessibility-first design</a></strong> - WCAG 2.2 AA compliance, screen reader testing, keyboard navigation</li>
<li><strong><a href="references/htmx-patterns.html">Progressive enhancement</a></strong> - No-JS baseline, HTMX enhancements layered on top</li>
<li><strong><a href="references/server-first.html">Server-rendered HTML</a></strong> - Kotlin/Ktor + Pebble templates generate complete pages</li>
<li><strong><a href="references/privacy-by-design.html">Privacy by design</a></strong> - UK GDPR compliance, anonymous instrumentation</li>
<li><strong><a href="references/evaluation-guide.html">Evidence-based iteration</a></strong> - Task-based evaluation, metrics analysis, data-driven redesign</li>
</ul>
<p><strong>New to these terms?</strong> See the <strong><a href="references/glossary.html">Glossary</a></strong> for definitions of HTMX, AJAX, ARIA, WCAG, and 80+ other terms.</p>
<hr />
<h2 id="module-structure-for-semester-1"><a class="header" href="#module-structure-for-semester-1">Module Structure for Semester 1</a></h2>
<h3 id="weeks-1-5-object-oriented-programming-oop"><a class="header" href="#weeks-1-5-object-oriented-programming-oop">Weeks 1-5: Object-Oriented Programming (OOP)</a></h3>
<p>Foundation in Kotlin, classes, inheritance, interfaces. See <a href="https://python33r.github.io/comp2850-kotlin/index.html">OOP mdBook</a>.</p>
<h3 id="weeks-6-11-human-computer-interaction-hci"><a class="header" href="#weeks-6-11-human-computer-interaction-hci">Weeks 6-11: Human-Computer Interaction (HCI)</a></h3>
<p><strong><a href="wk06/wk6-lab1-html-css-htmx.html">Week 6</a></strong> ‚Äî Intro: Server-first foundations + needs-finding</p>
<p><strong><a href="wk07/wk7-lab1-ethics-inline-edit.html">Week 7</a></strong> ‚Äî Ethics in practice + accessibility audit</p>
<p><strong><a href="wk08/wk8-lab1-prototyping-constraints.html">Week 8</a></strong> ‚Äî Prototyping, constraints, no-JS parity</p>
<p><strong><a href="wk09/wk9-lab1-eval-plan-instrumentation.html">Week 9</a></strong> ‚Äî Evaluation planning + instrumentation</p>
<p><strong><a href="wk10/wk10-lab1-analysis-prioritisation.html">Week 10</a></strong> ‚Äî Analysis, prioritisation, redesign</p>
<p><strong><a href="wk11/wk11-lab1-studio-crit.html">Week 11</a></strong> ‚Äî Studio critique + portfolio wrap-up</p>
<h3 id="semester-flow-weeks-6-11"><a class="header" href="#semester-flow-weeks-6-11">Semester Flow (Weeks 6-11)</a></h3>
<pre class="mermaid">graph LR
  W6[Week 6&lt;br/&gt;Server-first&lt;br/&gt;Needs-finding]
  W7[Week 7&lt;br/&gt;Ethics&lt;br/&gt;Accessibility]
  W8[Week 8&lt;br/&gt;Prototyping&lt;br/&gt;Constraints]
  W9[Week 9&lt;br/&gt;Evaluation&lt;br/&gt;Pilots]
  W10[Week 10&lt;br/&gt;Analysis&lt;br/&gt;Redesign]
  W11[Week 11&lt;br/&gt;Studio Crit&lt;br/&gt;Portfolio]

  W6 --&gt; W7
  W7 --&gt; W8
  W8 --&gt; W9
  W9 --&gt; W10
  W10 --&gt; W11
</pre>
<p><small>See <a href="references/process-visuals.html#semester-flow">Process Visuals</a> for captions and alternative formats.</small></p>
<hr />
<h2 id="assessment"><a class="header" href="#assessment">Assessment</a></h2>
<p>One combined evidence-based assessment covers all 13 HCI Learning Outcomes:</p>
<h3 id="combined-assessment-evaluation-redesign--verification"><a class="header" href="#combined-assessment-evaluation-redesign--verification">Combined Assessment: Evaluation, Redesign &amp; Verification</a></h3>
<ul>
<li><strong>Launch</strong>: Week 9 Lab 1</li>
<li><strong>Deadline</strong>: End of Week 10</li>
<li><strong>Week 11</strong>: Optional refinement &amp; early marking</li>
<li>Design and execute task-based peer pilots (n=4+), analyse quantitative and qualitative data, implement inclusive redesign based on findings, verify via regression testing (30+ checks) and re-pilots (n=2+), synthesise evidence chains and analyse societal impacts</li>
<li><strong>Learning Outcomes</strong>: All 13 LO (LO1-LO13)</li>
</ul>
<p><strong>See <a href="assessment/combined-assessment-FINAL.html">Combined Assessment Specification</a></strong> for full details, <strong><a href="assessment/submission-template.html">Submission Template</a></strong> for structure, <strong><a href="assessment/student-faq.html">Student FAQ</a></strong> for common questions, and <strong><a href="assessment/rubric.html">Marking Rubric</a></strong> for criteria.</p>
<hr />
<h2 id="key-principles"><a class="header" href="#key-principles">Key Principles</a></h2>
<h3 id="1-people-centred-language"><a class="header" href="#1-people-centred-language">1. People-Centred Language</a></h3>
<p>We use ‚Äú<strong>person navigating with a screen reader</strong>‚Äù (not ‚Äúblind user‚Äù), ‚Äú<strong>person navigating by keyboard</strong>‚Äù (not
‚Äúdisabled user‚Äù), or ‚Äúparticipant‚Äù in evaluation contexts.<br />
<strong>Why this matters:</strong><br />
Disability arises from barriers in the environment‚Äîinaccessible design, missing features,
exclusionary assumptions‚Äînot from individual impairment.<br />
People-first language centres the person, not a diagnostic label.</p>
<h3 id="2-privacy-by-design"><a class="header" href="#2-privacy-by-design">2. Privacy by Design</a></h3>
<p>No personal data collected. Anonymous session IDs only. UK GDPR compliant (Data Protection Act 2018).</p>
<h3 id="3-progressive-enhancement"><a class="header" href="#3-progressive-enhancement">3. Progressive Enhancement</a></h3>
<p>Start with semantic HTML. Add JavaScript sparingly. Ensure all features work without JS.</p>
<h3 id="4-evidence-led-design"><a class="header" href="#4-evidence-led-design">4. Evidence-Led Design</a></h3>
<p>Every claim must be backed by data (pilot metrics, quotes, WCAG audits). No assumptions.</p>
<hr />
<h2 id="tools--technologies"><a class="header" href="#tools--technologies">Tools &amp; Technologies</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Tool</th><th>Purpose</th></tr></thead><tbody>
<tr><td><strong>HTMX</strong></td><td>Dynamic updates without full page reload</td></tr>
<tr><td><strong>Kotlin/Ktor</strong></td><td>Server-side routing, template rendering</td></tr>
<tr><td><strong>Pebble</strong></td><td>HTML templating (server-rendered)</td></tr>
<tr><td><strong>axe DevTools</strong></td><td>Accessibility auditing (WCAG 2.2)</td></tr>
<tr><td><strong>NVDA / VoiceOver</strong></td><td>Screen reader testing</td></tr>
<tr><td><strong>Colour Contrast Analyser</strong></td><td>WCAG 1.4.3 compliance</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="module-aims"><a class="header" href="#module-aims">Module Aims</a></h2>
<p>This module aims to enable you to:</p>
<ol>
<li>Apply HCI principles to design inclusive interfaces</li>
<li>Evaluate accessibility and ethics in interactive systems</li>
<li>Implement server-first architecture with progressive enhancement</li>
<li>Communicate design decisions with evidence</li>
</ol>
<p>These aims are achieved through <strong>13 specific Learning Outcomes</strong> detailed across Weeks 6-11. See the <strong><a href="references/learning-outcomes.html">Learning Outcomes Reference</a></strong> for mappings to weeks, labs, and assessment tasks.</p>
<hr />
<h2 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h2>
<ol>
<li><strong>Read Week 6 Lab 1</strong>: <a href="wk06/wk6-lab1-html-css-htmx.html">Server-first foundations with HTMX</a></li>
<li><strong>Clone starter pack</strong>: <code>git clone [repo URL]</code> (see Minerva for link)</li>
<li><strong>Install/setup tools</strong>: JDK 21+, Gradle 8+, axe DevTools, IntelliJ IDEA (or) VSCode (or) Codespaces - choose one</li>
<li><strong>Attend lab sessions</strong>: Bragg 2.05 Main Lab (check your timetable for days/times)</li>
<li><strong>Independent Study</strong>: We expect you to manage your time and complete all module requirements</li>
</ol>
<hr />
<h2 id="support"><a class="header" href="#support">Support</a></h2>
<ul>
<li><strong>Lab sessions</strong>: Staff on hand for questions (2-hour taught labs &amp; open lab sessions with TA‚Äôs available)</li>
<li><strong>Office hours</strong>: Contact teaching team for availability</li>
<li><strong>Discussion board</strong>: MS Teams COMP2850 forum for all module peer/staff questions</li>
<li><strong>Personal issues</strong>: Contact via Teams DM or email module staff directly</li>
<li><strong>Bugs in course materials</strong>: If you spot errors, typos, or mismatches in the mdBook content, contact Julian Brooks (author of the HCI materials) at <a href="mailto:j.brooks2@leeds.ac.uk">j.brooks2@leeds.ac.uk</a></li>
</ul>
<hr />
<h2 id="references"><a class="header" href="#references">References</a></h2>
<ul>
<li><strong>HTMX</strong>: <a href="https://hypermedia.systems/">hypermedia.systems</a> (Carson Gross et al., 2023)</li>
<li><strong>WCAG 2.2</strong>: <a href="https://www.w3.org/WAI/WCAG22/quickref/">W3C Quick Reference</a></li>
<li><strong>GOV.UK Design System</strong>: <a href="https://design-system.service.gov.uk/">Patterns &amp; Components</a></li>
<li><strong>Privacy by Design</strong>: <a href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/">ICO Guidance</a></li>
</ul>
<hr />
<p><strong>Module Lead</strong>: [Amy Brereton]
<strong>Teaching Team</strong>: [Ban Adil Naji Al-Jassani, Amy Brereton, Julian Brooks, Nick Efford, Will Kingdon, Ping Lu, David
Ofili, Jonathan Pickering, Xiao Wang]
<strong>Academic Year</strong>: 25/26
<strong>Department</strong>: School of Computer Science, University of Leeds</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-6--lab-1-server-first-foundations-with-htmx"><a class="header" href="#week-6--lab-1-server-first-foundations-with-htmx">Week 6 ‚Ä¢ Lab 1: Server-First Foundations with HTMX</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-6-orange" alt="Week 6" />
<img src="https://img.shields.io/badge/Lab-1-green" alt="Lab 1" />
<img src="https://img.shields.io/badge/Status-Draft-yellow" alt="Status" /></p>
<hr />
<h2 id="terminology-note"><a class="header" href="#terminology-note">Terminology Note</a></h2>
<p>Throughout COMP2850 we use <strong>people-centred language</strong> (e.g., ‚Äúperson using a screen reader‚Äù) rather than deficit-based terms (e.g., ‚Äúblind user‚Äù). This reflects contemporary inclusive-design practice and acknowledges that disability arises from environmental barriers, not individual impairment.</p>
<hr />
<h2 id="pre-reading"><a class="header" href="#pre-reading">Pre-reading</a></h2>
<p><strong>Essential</strong></p>
<ul>
<li><a href="https://hypermedia.systems/">Gross, Stepinski &amp; Ak≈üim≈üek (2023). <em>Hypermedia Systems</em>, Ch. 1-3</a></li>
<li><a href="https://htmx.org/docs/">HTMX Documentation: Core Concepts</a></li>
<li><a href="https://www.gov.uk/service-manual/technology/using-progressive-enhancement">GOV.UK Service Manual: Progressive Enhancement</a></li>
</ul>
<p><strong>Recommended</strong></p>
<ul>
<li><a href="https://www.w3.org/WAI/WCAG22/quickref/">W3C (2024). WCAG 2.2 Quick Reference</a></li>
<li><a href="https://developer.mozilla.org/en-US/docs/Glossary/Semantics#semantic_elements">MDN: Semantic HTML</a></li>
<li><a href="wk06/../references/privacy-by-design.html">Privacy by Design</a> (module-specific ethics guidance)</li>
</ul>
<blockquote>
<p><strong>Starter code</strong>: Clone the <a href="wk06/../../resources/code-resources.html#week-6">starter repository</a> or download the zip before the lab.</p>
</blockquote>
<h2 id="introduction"><a class="header" href="#introduction">Introduction</a></h2>
<h3 id="context"><a class="header" href="#context">Context</a></h3>
<p>This lab marks the beginning of the <strong>HCI component</strong> of COMP2850 (Weeks 6-11). For the first five weeks you built foundational Kotlin/OOP skills. Now you‚Äôll apply those skills to a real-world HCI challenge: building inclusive, accessible web applications using <strong>server-first architecture</strong> with <strong>progressive enhancement</strong>.</p>
<p>Modern web development often defaults to client-heavy JavaScript frameworks (React, Vue, Angular). While powerful, these approaches can create accessibility barriers:</p>
<ul>
<li>Screen readers struggle with dynamically-rendered content</li>
<li>Keyboard navigation breaks when focus management is incorrect</li>
<li>Customers with JavaScript disabled (corporate firewalls, data-saving modes) lose functionality</li>
<li>Development complexity increases, making accessibility fixes expensive to retrofit</li>
</ul>
<p><strong>Server-first architecture</strong> inverts this model: the server renders complete, semantic HTML that works <em>without</em> JavaScript. We then add HTMX as a <strong>progressive enhancement layer</strong> to improve interactivity without sacrificing the baseline experience.</p>
<h3 id="why-this-matters"><a class="header" href="#why-this-matters">Why This Matters</a></h3>
<p><strong>Professionally</strong>, server-first patterns are gaining traction in industry:</p>
<ul>
<li><strong>GOV.UK</strong> (UK government digital services) mandates progressive enhancement</li>
<li><strong>Basecamp</strong> (project management, 3M+ customers) uses server-rendered HTML + Turbo (similar to HTMX)</li>
<li><strong>GitHub</strong> serves primarily server-rendered HTML with JavaScript enhancements</li>
<li><strong>Stack Overflow</strong> is 90% server-rendered for performance and accessibility</li>
</ul>
<p><strong>Academically</strong>, this lab introduces core HCI concepts:</p>
<ul>
<li><strong>Inclusion by design</strong>: building accessibility into the foundation, not retrofitting it</li>
<li><strong>Progressive enhancement</strong>: layering capabilities so everyone gets a baseline experience</li>
<li><strong>Server-side rendering (SSR)</strong>: generating HTML on the server vs. client-side rendering (CSR)</li>
<li><strong>Hypermedia-driven architecture</strong>: using HTML as the engine of application state (HATEOAS)</li>
</ul>
<h2 id="learning-focus"><a class="header" href="#learning-focus">Learning Focus</a></h2>
<h3 id="lab-objectives"><a class="header" href="#lab-objectives">Lab Objectives</a></h3>
<p>By the end of this session, you will have:</p>
<ul>
<li>Implemented server-first routes using Ktor and Pebble templates</li>
<li>Enhanced a form with HTMX while maintaining no-JS functionality</li>
<li>Created accessible HTML with semantic structure, ARIA live regions, and skip links</li>
<li>Verified keyboard navigation, screen reader announcements, and no-JS parity</li>
</ul>
<h3 id="learning-outcomes-addressed"><a class="header" href="#learning-outcomes-addressed">Learning Outcomes Addressed</a></h3>
<p>This lab contributes to the following module Learning Outcomes (<a href="wk06/../references/learning-outcomes.html">full definitions</a>):</p>
<ul>
<li><strong>LO5</strong>: Create interface prototypes ‚Äî evidenced by functional HTMX task list</li>
<li><strong>LO7</strong>: Analyse design constraints ‚Äî evidenced by no-JS parity verification</li>
<li><strong>LO9</strong>: Apply inclusive design ‚Äî evidenced by semantic HTML + ARIA implementation</li>
<li><strong>LO13</strong>: Integrate HCI with SE ‚Äî evidenced by server-first architecture patterns</li>
</ul>
<hr />
<h2 id="key-concepts"><a class="header" href="#key-concepts">Key Concepts</a></h2>
<h3 id="1-server-first-architecture"><a class="header" href="#1-server-first-architecture">1. Server-First Architecture</a></h3>
<p><strong>Server-first</strong> (also called ‚Äúserver-side rendering‚Äù or SSR) means the server generates complete HTML pages and sends them to the browser. The browser displays them immediately without waiting for JavaScript to run.</p>
<p><strong>Example</strong>:</p>
<pre><code>Customer requests /tasks
‚Üí Server queries database
‚Üí Server renders tasks/index.peb template with data
‚Üí Server sends complete HTML to browser
‚Üí Browser displays page (works even if JS is disabled)
</code></pre>
<p><strong>Contrast with client-side rendering (CSR)</strong>:</p>
<pre><code>Customer requests /tasks
‚Üí Server sends empty HTML + JavaScript bundle
‚Üí Browser downloads and executes JS
‚Üí JS makes API call to /api/tasks
‚Üí JS renders HTML and inserts into DOM
‚ùå If JS fails to load, page is blank
</code></pre>
<p><strong>Benefits</strong>:</p>
<ul>
<li>‚úÖ Faster initial page load (no JS parsing delay)</li>
<li>‚úÖ Works without JavaScript (resilience)</li>
<li>‚úÖ Search engines can index content (SEO)</li>
<li>‚úÖ Screen readers receive semantic HTML immediately</li>
</ul>
<h3 id="2-progressive-enhancement"><a class="header" href="#2-progressive-enhancement">2. Progressive Enhancement</a></h3>
<p><strong>Progressive enhancement</strong> is a design philosophy: start with a baseline experience that works for everyone, then add enhancements for browsers that support them.</p>
<p><strong>Layers</strong>:</p>
<ol>
<li><strong>HTML</strong> (content layer): semantic markup, accessible by default</li>
<li><strong>CSS</strong> (presentation layer): styling, gracefully degrades if not supported</li>
<li><strong>JavaScript</strong> (behaviour layer): dynamic interactions, optional</li>
</ol>
<p><strong>Example (COMP2850 task manager)</strong>:</p>
<ul>
<li><strong>Baseline</strong>: Form POSTs to <code>/tasks</code>, server validates, redirects (PRG pattern)</li>
<li><strong>Enhancement</strong>: HTMX intercepts POST, swaps HTML fragment, no page reload</li>
</ul>
<p><strong>Key principle</strong>: JavaScript failure (network error, blocked script, unsupported browser) should not break core functionality.</p>
<h3 id="3-htmx-fundamentals"><a class="header" href="#3-htmx-fundamentals">3. HTMX Fundamentals</a></h3>
<p><strong>HTMX</strong> extends HTML with attributes that trigger AJAX requests and update the DOM. Instead of writing JavaScript, you declare behaviour in HTML.</p>
<p><strong>Core attributes</strong>:</p>
<div class="table-wrapper"><table><thead><tr><th>Attribute</th><th>Purpose</th><th>Example</th></tr></thead><tbody>
<tr><td><code>hx-get</code></td><td>HTTP GET request</td><td><code>&lt;button hx-get="/tasks/1"&gt;Load&lt;/button&gt;</code></td></tr>
<tr><td><code>hx-post</code></td><td>HTTP POST request</td><td><code>&lt;form hx-post="/tasks"&gt;</code></td></tr>
<tr><td><code>hx-target</code></td><td>Where to insert response</td><td><code>hx-target="#task-list"</code></td></tr>
<tr><td><code>hx-swap</code></td><td>How to insert response</td><td><code>hx-swap="beforeend"</code> (append), <code>hx-swap="outerHTML"</code> (replace)</td></tr>
<tr><td><code>hx-swap-oob</code></td><td>Out-of-band swap (update element not in target)</td><td><code>&lt;div id="status" hx-swap-oob="true"&gt;</code></td></tr>
</tbody></table>
</div>
<p><strong>How HTMX works</strong>:</p>
<ol>
<li>Customer triggers event (click, submit)</li>
<li>HTMX makes AJAX request to server</li>
<li>Server returns HTML fragment (not JSON)</li>
<li>HTMX swaps fragment into target element</li>
<li>Screen reader live regions announce changes</li>
</ol>
<p><strong>Why this helps accessibility</strong>:</p>
<ul>
<li>Server controls HTML structure (consistent semantics)</li>
<li>No manual DOM manipulation (reduces ARIA errors)</li>
<li>Live regions work automatically (if server includes them)</li>
</ul>
<h3 id="4-post-redirect-get-prg-pattern"><a class="header" href="#4-post-redirect-get-prg-pattern">4. Post-Redirect-Get (PRG) Pattern</a></h3>
<p><strong>Problem</strong>: If a person submits a form with POST and then refreshes the page, the browser re-submits the form
(duplicate submission).</p>
<p><strong>Solution</strong>: After processing a POST, return a redirect (HTTP 303) to a GET URL.</p>
<p><strong>Flow</strong>:</p>
<pre><code>1. Customer submits form ‚Üí POST /tasks (title="Buy milk")
2. Server validates, saves to database
3. Server returns: HTTP 303 See Other, Location: /tasks
4. Browser follows redirect ‚Üí GET /tasks
5. Server renders updated task list
6. Customer sees new task; refresh = safe GET (no duplicate)
</code></pre>
<p><strong>In Ktor</strong>:</p>
<pre><code class="language-kotlin">post("/tasks") {
    val title = call.receiveParameters()["title"].orEmpty().trim()
    if (title.isNotBlank()) {
        repo.add(title)
    }
    call.respondRedirect("/tasks") // PRG redirect
}
</code></pre>
<h3 id="5-aria-live-regions"><a class="header" href="#5-aria-live-regions">5. ARIA Live Regions</a></h3>
<p><strong>ARIA</strong> (Accessible Rich Internet Applications) provides attributes that help screen readers understand dynamic content.</p>
<p><strong>Live regions</strong> announce changes without moving focus. Essential for AJAX-updated content.</p>
<p><strong>Key attributes</strong>:</p>
<div class="table-wrapper"><table><thead><tr><th>Attribute</th><th>Purpose</th><th>Example</th></tr></thead><tbody>
<tr><td><code>role="status"</code></td><td>Announces non-critical updates</td><td><code>&lt;div role="status" aria-live="polite"&gt;Task added&lt;/div&gt;</code></td></tr>
<tr><td><code>role="alert"</code></td><td>Announces critical errors</td><td><code>&lt;div role="alert"&gt;Title is required&lt;/div&gt;</code></td></tr>
<tr><td><code>aria-live="polite"</code></td><td>Waits for customer to finish before announcing</td><td>Status messages</td></tr>
<tr><td><code>aria-live="assertive"</code></td><td>Interrupts to announce immediately</td><td>Error messages</td></tr>
</tbody></table>
</div>
<p><strong>Example (COMP2850 pattern)</strong>:</p>
<pre><code class="language-html">&lt;!-- In base.peb --&gt;
&lt;div id="status" role="status" aria-live="polite" class="visually-hidden"&gt;&lt;/div&gt;

&lt;!-- Server response (HTMX OOB swap) --&gt;
&lt;div id="status" hx-swap-oob="true"&gt;Task "Buy milk" added&lt;/div&gt;
</code></pre>
<p><strong>How it works</strong>:</p>
<ol>
<li>HTMX request completes</li>
<li>Server returns fragment + status div with <code>hx-swap-oob="true"</code></li>
<li>HTMX swaps main content <em>and</em> status div (out-of-band)</li>
<li>Screen reader detects status div change, announces ‚ÄúTask ‚ÄòBuy milk‚Äô added‚Äù</li>
</ol>
<hr />
<h2 id="activity-1-project-setup--scaffold-inspection"><a class="header" href="#activity-1-project-setup--scaffold-inspection">Activity 1: Project Setup &amp; Scaffold Inspection</a></h2>
<p><strong>Time</strong>: 15 minutes
<strong>Materials</strong>: Starter pack (Gradle project with Ktor + Pebble)</p>
<blockquote>
<p>Keep the <a href="wk06/../references/pebble-cheatsheet.html">Pebble Cheatsheet</a> handy for syntax reminders.</p>
</blockquote>
<h3 id="step-1-clone-starter-pack"><a class="header" href="#step-1-clone-starter-pack">Step 1: Clone Starter Pack</a></h3>
<pre><code class="language-bash"># Clone starter repository (URL provided on Minerva)
git clone [REPO_URL]/comp2850-hci-starter.git
cd comp2850-hci-starter

# Or open in Codespaces: Click "Code" ‚Üí "Create codespace on main"
</code></pre>
<h3 id="step-2-verify-dependencies"><a class="header" href="#step-2-verify-dependencies">Step 2: Verify Dependencies</a></h3>
<p>Open <code>build.gradle.kts</code> and confirm these dependencies:</p>
<pre><code class="language-kotlin">dependencies {
    implementation("io.ktor:ktor-server-core:2.3.12")
    implementation("io.ktor:ktor-server-netty:2.3.12")
    implementation("io.pebbletemplates:pebble:3.2.2")
    implementation("ch.qos.logback:logback-classic:1.5.6")
}
</code></pre>
<p><strong>What these do</strong>:</p>
<ul>
<li><strong>Ktor</strong>: Kotlin web framework (routes, HTTP handling)</li>
<li><strong>Pebble</strong>: Template engine (renders HTML with data)</li>
<li><strong>Logback</strong>: Logging (debug server behaviour)</li>
</ul>
<h3 id="step-3-run-the-server"><a class="header" href="#step-3-run-the-server">Step 3: Run the Server</a></h3>
<pre><code class="language-bash">./gradlew run

# Windows
gradlew.bat run
</code></pre>
<p><strong>Expected output</strong>:</p>
<pre><code>Application started in 0.5s
Listening on http://0.0.0.0:8080
</code></pre>
<p><strong>Visit</strong>: http://localhost:8080/tasks</p>
<p>You should see placeholder text: ‚ÄúTask manager coming soon‚Ä¶‚Äù This confirms the server works.</p>
<h3 id="step-4-inspect-directory-structure"><a class="header" href="#step-4-inspect-directory-structure">Step 4: Inspect Directory Structure</a></h3>
<pre><code>comp2850-hci-starter/
‚îú‚îÄ‚îÄ src/main/kotlin/
‚îÇ   ‚îú‚îÄ‚îÄ Main.kt               # Server entry point
‚îÇ   ‚îú‚îÄ‚îÄ model/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Task.kt           # Data model
‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ TaskRoutes.kt     # CRUD operations
‚îÇ   ‚îú‚îÄ‚îÄ storage/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ TaskStore.kt      # CSV persistence
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îî‚îÄ‚îÄ SessionUtils.kt   # Anonymous sessions
‚îú‚îÄ‚îÄ src/main/resources/
‚îÇ   ‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ _layout/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ base.peb      # Accessible base layout
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tasks/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ index.peb     # Full page view
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ _list.peb     # Task list partial
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ _item.peb     # Single task partial
‚îÇ   ‚îî‚îÄ‚îÄ static/
‚îÇ       ‚îú‚îÄ‚îÄ css/custom.css    # WCAG styles
‚îÇ       ‚îî‚îÄ‚îÄ js/htmx-1.9.12.min.js
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ tasks.csv             # File-based storage
‚îú‚îÄ‚îÄ build.gradle.kts          # Dependencies
‚îî‚îÄ‚îÄ README.md                 # Comprehensive guide
</code></pre>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ Server runs without errors</li>
<li>‚úÖ http://localhost:8080/tasks loads (even if placeholder)</li>
<li>‚úÖ You can see <code>base.peb</code> and <code>tasks/index.peb</code> in your IDE</li>
</ul>
<hr />
<h2 id="activity-2-build-accessible-base-layout"><a class="header" href="#activity-2-build-accessible-base-layout">Activity 2: Build Accessible Base Layout</a></h2>
<p><strong>Time</strong>: 30 minutes
<strong>Materials</strong>: <code>src/main/resources/templates/base.peb</code></p>
<h3 id="step-1-create-semantic-html-structure"><a class="header" href="#step-1-create-semantic-html-structure">Step 1: Create Semantic HTML Structure</a></h3>
<p>Replace the contents of <code>base.peb</code> with:</p>
<pre><code class="language-html">&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
  &lt;meta charset="UTF-8"&gt;
  &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt;
  &lt;title&gt;{{ title | default("COMP2850 Task Manager") }}&lt;/title&gt;
  &lt;link rel="stylesheet" href="https://unpkg.com/@picocss/pico@2/css/pico.min.css"&gt;
  &lt;style&gt;
    /* Visually hidden but accessible to screen readers */
    .visually-hidden {
      position: absolute !important;
      clip: rect(1px, 1px, 1px, 1px);
      padding: 0 !important;
      border: 0 !important;
      height: 1px !important;
      width: 1px !important;
      overflow: hidden;
      white-space: nowrap;
    }

    /* Skip link (keyboard only) */
    .skip-link {
      position: absolute;
      left: -10000px;
      width: 1px;
      height: 1px;
      overflow: hidden;
    }
    .skip-link:focus {
      position: static;
      width: auto;
      height: auto;
      background: #1976d2;
      color: white;
      padding: 0.5rem 1rem;
      text-decoration: none;
      font-weight: bold;
    }

    /* ARIA live region styling */
    #status:not(:empty) {
      background: #e3f2fd;
      border-left: 4px solid #1976d2;
      padding: 1rem;
      margin: 1rem 0;
    }
  &lt;/style&gt;
  &lt;script src="https://unpkg.com/htmx.org@2.0.0"&gt;&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
  &lt;a href="#main" class="skip-link"&gt;Skip to main content&lt;/a&gt;

  &lt;main class="container" id="main"&gt;
    &lt;div id="status" role="status" aria-live="polite" class="visually-hidden"&gt;&lt;/div&gt;
    {% block content %}{% endblock %}
  &lt;/main&gt;

  &lt;footer class="container"&gt;
    &lt;p&gt;&lt;small&gt;COMP2850 HCI ‚Ä¢ University of Leeds ‚Ä¢ 2024/25&lt;/small&gt;&lt;/p&gt;
  &lt;/footer&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<h3 id="step-2-understanding-the-accessibility-features"><a class="header" href="#step-2-understanding-the-accessibility-features">Step 2: Understanding the Accessibility Features</a></h3>
<p><strong>Skip link</strong> (line 35-36):</p>
<ul>
<li>Allows keyboard/SR to jump past repeated navigation</li>
<li>Hidden until focused (keyboard Tab reveals it)</li>
<li><strong>WCAG 2.4.1 (Bypass Blocks, A)</strong>: Mechanism to bypass repeated content</li>
</ul>
<p><strong>Live region</strong> (line 39):</p>
<ul>
<li><code>role="status"</code>: Announces updates without stealing focus</li>
<li><code>aria-live="polite"</code>: Waits for customer to pause before announcing</li>
<li><code>.visually-hidden</code>: Hidden visually but announced by SR</li>
<li><strong>WCAG 4.1.3 (Status Messages, AA)</strong>: Status messages programmatically announced</li>
</ul>
<p><strong>Semantic HTML</strong>:</p>
<ul>
<li><code>&lt;main&gt;</code>: Primary content landmark</li>
<li><code>&lt;footer&gt;</code>: Site information landmark</li>
<li><code>lang="en"</code>: Tells SR which language to use</li>
<li><strong>WCAG 1.3.1 (Info and Relationships, A)</strong>: Structure conveyed programmatically</li>
</ul>
<h3 id="step-3-test-the-base-layout"><a class="header" href="#step-3-test-the-base-layout">Step 3: Test the Base Layout</a></h3>
<p>Reload http://localhost:8080/tasks. You should still see placeholder text, but now:</p>
<ol>
<li><strong>Tab once</strong>: Skip link appears with blue background</li>
<li><strong>Press Enter on skip link</strong>: Focus jumps to <code>#main</code> (no effect yet, but will matter when we add navigation)</li>
<li><strong>Inspect with DevTools</strong>:
<ul>
<li>Open Elements panel</li>
<li>Find <code>&lt;div id="status"&gt;</code> with <code>role="status"</code> and <code>aria-live="polite"</code></li>
<li>Confirm <code>.visually-hidden</code> class applied</li>
</ul>
</li>
</ol>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ Skip link appears on keyboard focus</li>
<li>‚úÖ Live region exists in DOM (empty for now)</li>
<li>‚úÖ Pico.css loaded (page has default styling)</li>
</ul>
<hr />
<h2 id="activity-3-implement-server-side-routes--repository"><a class="header" href="#activity-3-implement-server-side-routes--repository">Activity 3: Implement Server-Side Routes &amp; Repository</a></h2>
<p><strong>Time</strong>: 35 minutes
<strong>Materials</strong>: <code>src/main/kotlin/routes/TaskRoutes.kt</code>, <code>data/tasks.csv</code></p>
<h3 id="step-1-create-a-simple-repository"><a class="header" href="#step-1-create-a-simple-repository">Step 1: Create a Simple Repository</a></h3>
<p>Create <code>src/main/kotlin/data/TaskRepository.kt</code>:</p>
<pre><code class="language-kotlin">package data

import java.io.File
import java.util.concurrent.atomic.AtomicInteger

data class Task(val id: Int, var title: String)

object TaskRepository {
    private val file = File("data/tasks.csv")
    private val tasks = mutableListOf&lt;Task&gt;()
    private val idCounter = AtomicInteger(1)

    init {
        file.parentFile?.mkdirs()
        if (!file.exists()) {
            file.writeText("id,title\n")
        } else {
            file.readLines().drop(1).forEach { line -&gt;
                val parts = line.split(",", limit = 2)
                if (parts.size == 2) {
                    val id = parts[0].toIntOrNull() ?: return@forEach
                    tasks.add(Task(id, parts[1]))
                    idCounter.set(maxOf(idCounter.get(), id + 1))
                }
            }
        }
    }

    fun all(): List&lt;Task&gt; = tasks.toList()

    fun add(title: String): Task {
        val task = Task(idCounter.getAndIncrement(), title)
        tasks.add(task)
        persist()
        return task
    }

    fun delete(id: Int): Boolean {
        val removed = tasks.removeIf { it.id == id }
        if (removed) persist()
        return removed
    }

    private fun persist() {
        file.writeText("id,title\n" + tasks.joinToString("\n") { "${it.id},${it.title}" })
    }
}
</code></pre>
<p><strong>Why CSV?</strong></p>
<ul>
<li>Simple, inspectable, no database setup required</li>
<li>Good for learning (focus on HCI, not DB configuration)</li>
<li>Production apps would use PostgreSQL/MongoDB</li>
</ul>
<h3 id="step-2-create-baseline-routes-no-htmx-yet"><a class="header" href="#step-2-create-baseline-routes-no-htmx-yet">Step 2: Create Baseline Routes (No HTMX Yet)</a></h3>
<p>Edit <code>src/main/kotlin/routes/TaskRoutes.kt</code>:</p>
<pre><code class="language-kotlin">package routes

import data.TaskRepository
import io.ktor.http.*
import io.ktor.server.application.*
import io.ktor.server.request.*
import io.ktor.server.response.*
import io.ktor.server.routing.*
import io.pebbletemplates.pebble.PebbleEngine
import java.io.StringWriter

fun Route.taskRoutes() {
    val pebble = PebbleEngine.Builder().build()

    get("/tasks") {
        val model = mapOf(
            "title" to "Tasks",
            "tasks" to TaskRepository.all()
        )
        val template = pebble.getTemplate("templates/tasks/index.peb")
        val writer = StringWriter()
        template.evaluate(writer, model)
        call.respondText(writer.toString(), ContentType.Text.Html)
    }

    post("/tasks") {
        val title = call.receiveParameters()["title"].orEmpty().trim()
        if (title.isNotBlank()) {
            TaskRepository.add(title)
        }
        call.respondRedirect("/tasks") // PRG pattern
    }

    post("/tasks/{id}/delete") {
        val id = call.parameters["id"]?.toIntOrNull()
        id?.let { TaskRepository.delete(it) }
        call.respondRedirect("/tasks") // PRG pattern
    }
}
</code></pre>
<p><strong>Update <code>Application.kt</code></strong> (or wherever routing is configured):</p>
<pre><code class="language-kotlin">import io.ktor.server.application.*
import io.ktor.server.routing.*
import routes.taskRoutes

fun Application.configureRouting() {
    routing {
        taskRoutes()
    }
}
</code></pre>
<h3 id="step-3-create-task-list-template"><a class="header" href="#step-3-create-task-list-template">Step 3: Create Task List Template</a></h3>
<blockquote>
<p><strong>üí° Pebble Template Syntax Primer</strong></p>
<p>Pebble uses three types of delimiters:</p>
<div class="table-wrapper"><table><thead><tr><th>Syntax</th><th>Purpose</th><th>Example</th></tr></thead><tbody>
<tr><td><code>{{ variable }}</code></td><td><strong>Output</strong> - Print variable values</td><td><code>{{ task.title }}</code> outputs ‚ÄúBuy milk‚Äù</td></tr>
<tr><td><code>{% statement %}</code></td><td><strong>Logic</strong> - Control structures (if, for, extends)</td><td><code>{% for task in tasks %}...{% endfor %}</code></td></tr>
<tr><td><code>{# comment #}</code></td><td><strong>Comments</strong> - Not rendered in HTML</td><td><code>{# TODO: Add pagination #}</code></td></tr>
</tbody></table>
</div>
<p><strong>Common statements</strong>:</p>
<ul>
<li><code>{% extends "base.peb" %}</code> - Inherit from parent template</li>
<li><code>{% block content %}...{% endblock %}</code> - Define/override content sections</li>
<li><code>{% for item in list %}...{% endfor %}</code> - Loop over collections</li>
<li><code>{% if condition %}...{% endif %}</code> - Conditional rendering</li>
<li><code>{% else %}</code> - Inside <code>{% for %}</code>, shown if list is empty</li>
</ul>
<p><strong>Filters</strong> (pipe syntax):</p>
<ul>
<li><code>{{ tasks | length }}</code> - Get list size (outputs: <code>3</code>)</li>
<li><code>{{ title | escape }}</code> - HTML-escape (auto-enabled in Pebble)</li>
<li><code>{{ price | default(0) }}</code> - Fallback value if null</li>
</ul>
<p><strong>Reference</strong>: <a href="https://pebbletemplates.io/">Pebble Documentation</a> ‚Ä¢ <a href="wk06/../references/pebble-intro.html">Pebble Intro</a></p>
</blockquote>
<p>Edit <code>src/main/resources/templates/tasks/index.peb</code>:</p>
<pre><code class="language-html">{% extends "base.peb" %}

{% block content %}
&lt;h1&gt;Tasks&lt;/h1&gt;

&lt;section aria-labelledby="add-heading"&gt;
  &lt;h2 id="add-heading"&gt;Add a new task&lt;/h2&gt;
  &lt;form action="/tasks" method="post"&gt;
    &lt;label for="title"&gt;Title&lt;/label&gt;
    &lt;input type="text" id="title" name="title" required
           placeholder="e.g., Buy milk" aria-describedby="title-hint"&gt;
    &lt;small id="title-hint"&gt;Keep it short and specific.&lt;/small&gt;
    &lt;button type="submit"&gt;Add Task&lt;/button&gt;
  &lt;/form&gt;
&lt;/section&gt;

&lt;section aria-labelledby="list-heading"&gt;
  &lt;h2 id="list-heading"&gt;Current tasks ({{ tasks | length }})&lt;/h2&gt;
  &lt;ul id="task-list"&gt;
    {% for task in tasks %}
      &lt;li id="task-{{ task.id }}"&gt;
        &lt;span&gt;{{ task.title }}&lt;/span&gt;
        &lt;form action="/tasks/{{ task.id }}/delete" method="post" style="display: inline;"&gt;
          &lt;button type="submit" aria-label="Delete task: {{ task.title }}"&gt;Delete&lt;/button&gt;
        &lt;/form&gt;
      &lt;/li&gt;
    {% else %}
      &lt;li&gt;No tasks yet. Add one above!&lt;/li&gt;
    {% endfor %}
  &lt;/ul&gt;
&lt;/section&gt;
{% endblock %}
</code></pre>
<p><strong>Accessibility features</strong>:</p>
<ul>
<li><code>aria-labelledby</code>: Links sections to headings (SR announces ‚ÄúAdd a new task, region‚Äù)</li>
<li><code>aria-describedby</code>: Links input to hint (SR announces ‚ÄúTitle, edit text, Keep it short and specific‚Äù)</li>
<li><code>aria-label</code> on Delete button: SR announces ‚ÄúDelete task: Buy milk‚Äù (context-specific)</li>
<li>Semantic <code>&lt;section&gt;</code>, <code>&lt;h2&gt;</code>, <code>&lt;ul&gt;</code> structure</li>
</ul>
<h3 id="step-4-test-no-js-baseline"><a class="header" href="#step-4-test-no-js-baseline">Step 4: Test No-JS Baseline</a></h3>
<ol>
<li>
<p><strong>Disable JavaScript</strong> in browser:</p>
<ul>
<li>Chrome: DevTools (F12) ‚Üí Settings (‚öôÔ∏è) ‚Üí Debugger ‚Üí ‚ÄúDisable JavaScript‚Äù</li>
<li>Firefox: about:config ‚Üí javascript.enabled ‚Üí false</li>
</ul>
</li>
<li>
<p><strong>Reload http://localhost:8080/tasks</strong></p>
</li>
<li>
<p><strong>Add a task</strong>:</p>
<ul>
<li>Type ‚ÄúBuy milk‚Äù in Title field</li>
<li>Click ‚ÄúAdd Task‚Äù</li>
<li><strong>Expected</strong>: Page reloads, ‚ÄúBuy milk‚Äù appears in list</li>
</ul>
</li>
<li>
<p><strong>Delete a task</strong>:</p>
<ul>
<li>Click ‚ÄúDelete‚Äù next to ‚ÄúBuy milk‚Äù</li>
<li><strong>Expected</strong>: Page reloads, task removed</li>
</ul>
</li>
</ol>
<p><strong>If this works, you have a fully functional, accessible baseline without any JavaScript.</strong></p>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ Adding tasks works (no-JS)</li>
<li>‚úÖ Deleting tasks works (no-JS)</li>
<li>‚úÖ Page reloads on each action (PRG pattern)</li>
<li>‚úÖ Screen reader announces labels correctly (test with NVDA/VoiceOver if available)</li>
</ul>
<hr />
<h2 id="activity-4-add-htmx-progressive-enhancement"><a class="header" href="#activity-4-add-htmx-progressive-enhancement">Activity 4: Add HTMX Progressive Enhancement</a></h2>
<p><strong>Time</strong>: 40 minutes
<strong>Materials</strong>: Updated routes and templates</p>
<h3 id="step-1-detect-htmx-requests"><a class="header" href="#step-1-detect-htmx-requests">Step 1: Detect HTMX Requests</a></h3>
<p>Add helper function to <code>TaskRoutes.kt</code>:</p>
<pre><code class="language-kotlin">fun ApplicationCall.isHtmx(): Boolean =
    request.headers["HX-Request"]?.equals("true", ignoreCase = true) == true
</code></pre>
<p><strong>How it works</strong>: HTMX adds <code>HX-Request: true</code> header to all AJAX requests. Server checks this to decide whether to return full page or fragment.</p>
<h3 id="step-2-update-post-tasks-route"><a class="header" href="#step-2-update-post-tasks-route">Step 2: Update POST /tasks Route</a></h3>
<p>Replace <code>post("/tasks")</code> route with:</p>
<pre><code class="language-kotlin">post("/tasks") {
    val title = call.receiveParameters()["title"].orEmpty().trim()

    // Validation
    if (title.isBlank()) {
        if (call.isHtmx()) {
            val error = """&lt;div id="status" hx-swap-oob="true" role="alert" aria-live="assertive"&gt;
                Title is required. Please enter at least one character.
            &lt;/div&gt;"""
            return@post call.respondText(error, ContentType.Text.Html, HttpStatusCode.BadRequest)
        } else {
            // No-JS path: redirect with error flag (handle in GET if needed)
            return@post call.respondRedirect("/tasks?error=required")
        }
    }

    val task = TaskRepository.add(title)

    if (call.isHtmx()) {
        // Return HTML fragment for new task
        val fragment = """&lt;li id="task-${task.id}"&gt;
            &lt;span&gt;${task.title}&lt;/span&gt;
            &lt;form action="/tasks/${task.id}/delete" method="post" style="display: inline;"
                  hx-post="/tasks/${task.id}/delete"
                  hx-target="#task-${task.id}"
                  hx-swap="outerHTML"&gt;
              &lt;button type="submit" aria-label="Delete task: ${task.title}"&gt;Delete&lt;/button&gt;
            &lt;/form&gt;
        &lt;/li&gt;"""

        val status = """&lt;div id="status" hx-swap-oob="true"&gt;Task "${task.title}" added successfully.&lt;/div&gt;"""

        return@post call.respondText(fragment + status, ContentType.Text.Html, HttpStatusCode.Created)
    }

    call.respondRedirect("/tasks") // No-JS fallback
}
</code></pre>
<p><strong>Key pattern</strong>:</p>
<ul>
<li><strong>HTMX path</strong>: Returns <code>&lt;li&gt;</code> fragment + OOB status message</li>
<li><strong>No-JS path</strong>: Redirects to <code>/tasks</code> (page reload)</li>
<li>Both paths end up in the same state (DRY principle)</li>
</ul>
<h3 id="step-3-update-post-tasksiddelete-route"><a class="header" href="#step-3-update-post-tasksiddelete-route">Step 3: Update POST /tasks/{id}/delete Route</a></h3>
<pre><code class="language-kotlin">post("/tasks/{id}/delete") {
    val id = call.parameters["id"]?.toIntOrNull()
    val removed = id?.let { TaskRepository.delete(it) } ?: false

    if (call.isHtmx()) {
        val message = if (removed) "Task deleted." else "Could not delete task."
        val status = """&lt;div id="status" hx-swap-oob="true"&gt;$message&lt;/div&gt;"""
        // Return empty content to trigger outerHTML swap (removes the &lt;li&gt;)
        return@post call.respondText(status, ContentType.Text.Html)
    }

    call.respondRedirect("/tasks")
}
</code></pre>
<h3 id="step-4-add-htmx-attributes-to-template"><a class="header" href="#step-4-add-htmx-attributes-to-template">Step 4: Add HTMX Attributes to Template</a></h3>
<p>Update <code>tasks/index.peb</code>:</p>
<pre><code class="language-html">{% extends "base.peb" %}

{% block content %}
&lt;h1&gt;Tasks&lt;/h1&gt;

&lt;section aria-labelledby="add-heading"&gt;
  &lt;h2 id="add-heading"&gt;Add a new task&lt;/h2&gt;
  &lt;form action="/tasks" method="post"
        hx-post="/tasks"
        hx-target="#task-list"
        hx-swap="beforeend"&gt;
    &lt;label for="title"&gt;Title&lt;/label&gt;
    &lt;input type="text" id="title" name="title" required
           placeholder="e.g., Buy milk" aria-describedby="title-hint"&gt;
    &lt;small id="title-hint"&gt;Keep it short and specific.&lt;/small&gt;
    &lt;button type="submit"&gt;Add Task&lt;/button&gt;
  &lt;/form&gt;
&lt;/section&gt;

&lt;section aria-labelledby="list-heading"&gt;
  &lt;h2 id="list-heading"&gt;Current tasks ({{ tasks | length }})&lt;/h2&gt;
  &lt;ul id="task-list"&gt;
    {% for task in tasks %}
      &lt;li id="task-{{ task.id }}"&gt;
        &lt;span&gt;{{ task.title }}&lt;/span&gt;
        &lt;form action="/tasks/{{ task.id }}/delete" method="post" style="display: inline;"
              hx-post="/tasks/{{ task.id }}/delete"
              hx-target="#task-{{ task.id }}"
              hx-swap="outerHTML"&gt;
          &lt;button type="submit" aria-label="Delete task: {{ task.title }}"&gt;Delete&lt;/button&gt;
        &lt;/form&gt;
      &lt;/li&gt;
    {% else %}
      &lt;li&gt;No tasks yet. Add one above!&lt;/li&gt;
    {% endfor %}
  &lt;/ul&gt;
&lt;/section&gt;
{% endblock %}
</code></pre>
<p><strong>HTMX attributes explained</strong>:</p>
<ul>
<li>
<p><strong>Add form</strong>:</p>
<ul>
<li><code>hx-post="/tasks"</code>: AJAX POST on submit</li>
<li><code>hx-target="#task-list"</code>: Insert response into task list</li>
<li><code>hx-swap="beforeend"</code>: Append (not replace)</li>
</ul>
</li>
<li>
<p><strong>Delete form</strong>:</p>
<ul>
<li><code>hx-post="/tasks/{id}/delete"</code>: AJAX POST</li>
<li><code>hx-target="#task-{{ task.id }}"</code>: Target the specific <code>&lt;li&gt;</code></li>
<li><code>hx-swap="outerHTML"</code>: Replace entire <code>&lt;li&gt;</code> (removes it if response is empty)</li>
</ul>
</li>
</ul>
<h3 id="step-5-test-htmx-enhancement"><a class="header" href="#step-5-test-htmx-enhancement">Step 5: Test HTMX Enhancement</a></h3>
<ol>
<li>
<p><strong>Re-enable JavaScript</strong> in browser</p>
</li>
<li>
<p><strong>Reload http://localhost:8080/tasks</strong></p>
</li>
<li>
<p><strong>Add a task</strong>:</p>
<ul>
<li>Type ‚ÄúBuy oat milk‚Äù</li>
<li>Click ‚ÄúAdd Task‚Äù</li>
<li><strong>Expected</strong>: Task appears instantly, NO page reload</li>
<li><strong>Check DevTools Network tab</strong>: See AJAX POST to <code>/tasks</code></li>
</ul>
</li>
<li>
<p><strong>Check live region announcement</strong>:</p>
<ul>
<li>Open browser console</li>
<li>Type: <code>document.getElementById('status').textContent</code></li>
<li><strong>Expected</strong>: ‚ÄúTask ‚ÄòBuy oat milk‚Äô added successfully.‚Äù</li>
<li><strong>With screen reader</strong>: Should announce this message</li>
</ul>
</li>
<li>
<p><strong>Delete a task</strong>:</p>
<ul>
<li>Click ‚ÄúDelete‚Äù next to ‚ÄúBuy oat milk‚Äù</li>
<li><strong>Expected</strong>: Task removed instantly, NO page reload</li>
</ul>
</li>
<li>
<p><strong>Verify no-JS still works</strong>:</p>
<ul>
<li>Disable JavaScript again</li>
<li>Repeat add/delete tests</li>
<li><strong>Expected</strong>: Both still work (page reloads)</li>
</ul>
</li>
</ol>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ HTMX path: instant updates, no reload</li>
<li>‚úÖ No-JS path: still works with redirects</li>
<li>‚úÖ Live region updates (inspect with DevTools)</li>
<li>‚úÖ Network tab shows AJAX requests (JS enabled) vs. full page loads (JS disabled)</li>
</ul>
<hr />
<h2 id="activity-5-accessibility-verification"><a class="header" href="#activity-5-accessibility-verification">Activity 5: Accessibility Verification</a></h2>
<p><strong>Time</strong>: 25 minutes
<strong>Materials</strong>: Keyboard, screen reader (NVDA/VoiceOver), browser DevTools</p>
<h3 id="test-1-keyboard-navigation"><a class="header" href="#test-1-keyboard-navigation">Test 1: Keyboard Navigation</a></h3>
<p><strong>Enable JavaScript</strong>, reload page, then:</p>
<ol>
<li>
<p><strong>Tab through page</strong>:</p>
<ul>
<li>Tab 1: Skip link appears ‚Üí Press Enter ‚Üí Focus jumps to main</li>
<li>Tab 2: Title input</li>
<li>Tab 3: Add Task button</li>
<li>Tab 4: First Delete button</li>
<li>Continue tabbing through all Delete buttons</li>
</ul>
</li>
<li>
<p><strong>Check focus indicators</strong>:</p>
<ul>
<li>Pico.css provides default focus outlines</li>
<li>Ensure you can always see which element has focus</li>
</ul>
</li>
<li>
<p><strong>Submit form with keyboard</strong>:</p>
<ul>
<li>Focus Title input, type ‚ÄúTest task‚Äù</li>
<li>Press Enter (submits form)</li>
<li><strong>Expected</strong>: Task added via HTMX (no reload)</li>
</ul>
</li>
</ol>
<p><strong>Result</strong>: ‚úÖ All interactive elements keyboard-accessible</p>
<h3 id="test-2-screen-reader-testing"><a class="header" href="#test-2-screen-reader-testing">Test 2: Screen Reader Testing</a></h3>
<p><strong>Tools</strong>:</p>
<ul>
<li><strong>Windows</strong>: NVDA (free, https://www.nvaccess.org/)</li>
<li><strong>macOS</strong>: VoiceOver (built-in, Cmd+F5)</li>
<li><strong>Linux</strong>: Orca (pre-installed on RHEL labs)</li>
</ul>
<p><strong>Test with NVDA</strong> (Windows):</p>
<ol>
<li>Start NVDA (Ctrl+Alt+N)</li>
<li>Navigate to http://localhost:8080/tasks</li>
<li><strong>Listen for</strong>:
<ul>
<li>‚ÄúTasks, heading level 1‚Äù</li>
<li>‚ÄúAdd a new task, heading level 2‚Äù</li>
<li>‚ÄúTitle, edit, Keep it short and specific‚Äù (input + hint)</li>
</ul>
</li>
<li><strong>Type</strong> ‚ÄúNVDA test task‚Äù and press Enter</li>
<li><strong>Listen for</strong>: ‚ÄúTask ‚ÄòNVDA test task‚Äô added successfully‚Äù (from live region)</li>
<li><strong>Tab to Delete button</strong>:
<ul>
<li><strong>Expected</strong>: ‚ÄúDelete task: NVDA test task, button‚Äù</li>
</ul>
</li>
<li><strong>Press Space</strong> (activates Delete)</li>
<li><strong>Listen for</strong>: ‚ÄúTask deleted‚Äù (from live region)</li>
</ol>
<p><strong>Result</strong>: ‚úÖ Screen reader announces labels, hints, and status messages</p>
<h3 id="test-3-no-js-parity"><a class="header" href="#test-3-no-js-parity">Test 3: No-JS Parity</a></h3>
<ol>
<li><strong>Disable JavaScript</strong> (DevTools ‚Üí Settings ‚Üí Disable JavaScript)</li>
<li><strong>Reload page</strong></li>
<li><strong>Add task</strong>: ‚ÄúNo-JS test‚Äù
<ul>
<li><strong>Expected</strong>: Page reloads, task appears</li>
</ul>
</li>
<li><strong>Delete task</strong>:
<ul>
<li><strong>Expected</strong>: Page reloads, task removed</li>
</ul>
</li>
<li><strong>Compare with JS-enabled</strong>:
<ul>
<li>Functionality identical (only UX differs: reload vs. instant)</li>
</ul>
</li>
</ol>
<p><strong>Result</strong>: ‚úÖ No-JS parity achieved</p>
<h3 id="test-4-wcag-quick-check"><a class="header" href="#test-4-wcag-quick-check">Test 4: WCAG Quick Check</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Criterion</th><th>Test</th><th>Result</th></tr></thead><tbody>
<tr><td><strong>1.3.1 Info and Relationships (A)</strong></td><td>Inspect HTML: <code>&lt;label for="title"&gt;</code> links to <code>&lt;input id="title"&gt;</code></td><td>‚òê Pass</td></tr>
<tr><td><strong>2.1.1 Keyboard (A)</strong></td><td>All features accessible via Tab, Enter, Space</td><td>‚òê Pass</td></tr>
<tr><td><strong>2.4.1 Bypass Blocks (A)</strong></td><td>Skip link appears on focus, jumps to main</td><td>‚òê Pass</td></tr>
<tr><td><strong>3.2.2 On Input (A)</strong></td><td>Changing input doesn‚Äôt auto-submit (only explicit button press)</td><td>‚òê Pass</td></tr>
<tr><td><strong>3.3.2 Labels or Instructions (A)</strong></td><td>All inputs have <code>&lt;label&gt;</code> and hint text</td><td>‚òê Pass</td></tr>
<tr><td><strong>4.1.3 Status Messages (AA)</strong></td><td>Live region announces add/delete confirmations</td><td>‚òê Pass</td></tr>
</tbody></table>
</div>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ All WCAG tests pass</li>
<li>‚úÖ Keyboard and SR can complete all tasks</li>
<li>‚úÖ No-JS path works identically</li>
</ul>
<hr />
<h2 id="reflection-questions"><a class="header" href="#reflection-questions">Reflection Questions</a></h2>
<ol>
<li>
<p><strong>Server-first vs. client-first</strong>: How would this lab differ if we used React instead of server-rendered HTML + HTMX? What would be harder? What would be easier?</p>
</li>
<li>
<p><strong>Progressive enhancement</strong>: Imagine a person on a slow 3G connection where HTMX fails to load. How does our
implementation handle this gracefully?</p>
</li>
<li>
<p><strong>Live regions</strong>: Why do we use <code>aria-live="polite"</code> for success messages but <code>aria-live="assertive"</code> for errors? When would you choose one over the other?</p>
</li>
<li>
<p><strong>HTMX trade-offs</strong>: What are the limitations of HTMX compared to a full JavaScript framework? When might HTMX <em>not</em> be appropriate?</p>
</li>
</ol>
<hr />
<h2 id="further-reading"><a class="header" href="#further-reading">Further Reading</a></h2>
<p><strong>Server-first architecture</strong></p>
<ul>
<li>Gross, C., Stepinski, A., &amp; Ak≈üim≈üek, D. (2023). <em>Hypermedia Systems</em>. <a href="https://hypermedia.systems/">https://hypermedia.systems/</a></li>
</ul>
<p><strong>Progressive enhancement</strong></p>
<ul>
<li>GOV.UK Service Manual. ‚ÄúUsing Progressive Enhancement.‚Äù <a href="https://www.gov.uk/service-manual/technology/using-progressive-enhancement">https://www.gov.uk/service-manual/technology/using-progressive-enhancement</a></li>
<li>Champeon, S. (2003). ‚ÄúProgressive Enhancement and the Future of Web Design.‚Äù SXSW presentation.</li>
</ul>
<p><strong>HTMX &amp; hypermedia</strong></p>
<ul>
<li>HTMX Documentation. <a href="https://htmx.org/docs/">https://htmx.org/docs/</a></li>
</ul>
<p><strong>WCAG &amp; accessibility</strong></p>
<ul>
<li>W3C (2024). <em>Web Content Accessibility Guidelines (WCAG) 2.2</em>. <a href="https://www.w3.org/WAI/WCAG22/quickref/">https://www.w3.org/WAI/WCAG22/quickref/</a></li>
<li>Pickering, H. (2016). <em>Inclusive Design Patterns</em>. Smashing Magazine.</li>
</ul>
<hr />
<h2 id="glossary-summary"><a class="header" href="#glossary-summary">Glossary Summary</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Term</th><th>Definition</th><th>Example/Context</th></tr></thead><tbody>
<tr><td><strong>Server-first</strong></td><td>Architecture where server generates complete HTML pages</td><td>Ktor renders <code>tasks/index.peb</code> ‚Üí sends full HTML to browser</td></tr>
<tr><td><strong>Progressive enhancement</strong></td><td>Building baseline (HTML) first, adding optional layers (CSS, JS)</td><td>Form works with POST/redirect; HTMX adds instant updates</td></tr>
<tr><td><strong>HTMX</strong></td><td>Library that adds AJAX capabilities via HTML attributes</td><td><code>&lt;form hx-post="/tasks" hx-target="#list"&gt;</code></td></tr>
<tr><td><strong>PRG (Post-Redirect-Get)</strong></td><td>Pattern to prevent duplicate form submissions</td><td>POST /tasks ‚Üí 303 Redirect ‚Üí GET /tasks</td></tr>
<tr><td><strong>ARIA live region</strong></td><td>Element that announces dynamic changes to screen readers</td><td><code>&lt;div role="status" aria-live="polite"&gt;</code></td></tr>
<tr><td><strong>Out-of-band (OOB) swap</strong></td><td>HTMX updating an element outside the main target</td><td><code>&lt;div id="status" hx-swap-oob="true"&gt;</code></td></tr>
<tr><td><strong>Semantic HTML</strong></td><td>Using tags that convey meaning (not just structure)</td><td><code>&lt;main&gt;</code>, <code>&lt;section&gt;</code>, <code>&lt;label&gt;</code>, <code>&lt;button&gt;</code> (not <code>&lt;div onclick&gt;</code>)</td></tr>
<tr><td><strong>Skip link</strong></td><td>Link to jump past repeated content (navigation)</td><td><code>&lt;a href="#main"&gt;Skip to content&lt;/a&gt;</code></td></tr>
<tr><td><strong>WCAG 2.2 AA</strong></td><td>Web accessibility standard (Level AA = target for most orgs)</td><td>GOV.UK, universities, large companies must comply</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="git-commit-best-practices"><a class="header" href="#git-commit-best-practices">Git Commit Best Practices</a></h2>
<p>Good commit messages are essential for your <strong>portfolio assessment</strong> and <strong>professional practice</strong>. Your commits tell the story of your development process.</p>
<h3 id="conventional-commit-format"><a class="header" href="#conventional-commit-format">Conventional Commit Format</a></h3>
<p>Use this structure for clear, searchable commits:</p>
<pre><code>&lt;type&gt;(&lt;scope&gt;): &lt;short description&gt;

[Optional longer explanation]
</code></pre>
<p><strong>Examples</strong>:</p>
<pre><code class="language-bash"># Good ‚úÖ
git commit -m "feat(tasks): add HTMX progressive enhancement to delete button"
git commit -m "fix(a11y): add aria-label to delete buttons for screen readers"
git commit -m "docs(readme): add setup instructions for Codespaces"
git commit -m "refactor(templates): extract task item to partial template"

# Bad ‚ùå
git commit -m "stuff"
git commit -m "fixed it"
git commit -m "update"
git commit -m "changes"
</code></pre>
<h3 id="common-types"><a class="header" href="#common-types">Common Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>When to Use</th><th>Example</th></tr></thead><tbody>
<tr><td><code>feat</code></td><td>New feature or capability</td><td><code>feat(tasks): add search by title</code></td></tr>
<tr><td><code>fix</code></td><td>Bug fix</td><td><code>fix(validation): prevent blank task titles</code></td></tr>
<tr><td><code>refactor</code></td><td>Code restructure (no behaviour change)</td><td><code>refactor(store): move CSV logic to TaskStore class</code></td></tr>
<tr><td><code>docs</code></td><td>Documentation only</td><td><code>docs(readme): add IntelliJ setup guide</code></td></tr>
<tr><td><code>style</code></td><td>Formatting, CSS, no code change</td><td><code>style(tasks): improve focus indicator contrast</code></td></tr>
<tr><td><code>test</code></td><td>Adding or fixing tests</td><td><code>test(store): add TaskStore CRUD tests</code></td></tr>
<tr><td><code>chore</code></td><td>Build, dependencies, tooling</td><td><code>chore(deps): update Ktor to 2.3.11</code></td></tr>
</tbody></table>
</div>
<h3 id="scope-optional-but-helpful"><a class="header" href="#scope-optional-but-helpful">Scope (Optional but Helpful)</a></h3>
<p>Scope = which part of the codebase changed:</p>
<ul>
<li><code>(tasks)</code> = Task management feature</li>
<li><code>(a11y)</code> = Accessibility improvements</li>
<li><code>(htmx)</code> = HTMX enhancements</li>
<li><code>(templates)</code> = Pebble template changes</li>
<li><code>(docs)</code> = Documentation</li>
<li><code>(store)</code> = Data storage/persistence</li>
</ul>
<h3 id="why-this-matters-1"><a class="header" href="#why-this-matters-1">Why This Matters</a></h3>
<p><strong>For portfolio assessment</strong>:</p>
<ul>
<li>Demonstrates professional development practices</li>
<li>Shows your understanding of changes (not just ‚Äúwhat‚Äù but ‚Äúwhy‚Äù)</li>
<li>Makes it easy to find specific features when preparing evidence</li>
</ul>
<p><strong>For collaboration</strong>:</p>
<ul>
<li>Team members understand changes at a glance</li>
<li>Easy to search git history (<code>git log --grep="feat(a11y)"</code>)</li>
<li>Tools can auto-generate changelogs from commit messages</li>
</ul>
<h3 id="week-6-lab-1-example-commit"><a class="header" href="#week-6-lab-1-example-commit">Week 6 Lab 1 Example Commit</a></h3>
<p>For this lab, a good commit message would be:</p>
<pre><code class="language-bash">git add src/main/kotlin/ src/main/resources/templates/ build.gradle.kts
git commit -m "feat(scaffold): implement server-first task manager with HTMX

- Add Ktor server with Pebble templating
- Implement TaskStore with CSV persistence
- Add dual-mode CRUD routes (HTMX + no-JS)
- Include WCAG 2.2 AA accessibility baseline (skip link, ARIA live region)
- Add progressive enhancement with HTMX for add/delete
- Tested with keyboard navigation and NVDA screen reader

Addresses Week 6 Lab 1 requirements.
WCAG: 2.4.1 (skip link), 4.1.3 (status messages)"
</code></pre>
<p><strong>Quick version</strong> (for smaller changes):</p>
<pre><code class="language-bash">git commit -m "feat(wk6-lab1): server-first scaffold with HTMX and WCAG 2.2 AA"
</code></pre>
<hr />
<h2 id="lab-checklist"><a class="header" href="#lab-checklist">Lab Checklist</a></h2>
<p>Before leaving lab, confirm:</p>
<ul>
<li><input disabled="" type="checkbox"/>
<strong>Server runs</strong>: <code>./gradlew run</code> ‚Üí http://localhost:8080/tasks loads</li>
<li><input disabled="" type="checkbox"/>
<strong>No-JS works</strong>: Add/delete tasks with JS disabled (page reloads)</li>
<li><input disabled="" type="checkbox"/>
<strong>HTMX works</strong>: Add/delete tasks with JS enabled (no reloads)</li>
<li><input disabled="" type="checkbox"/>
<strong>Keyboard accessible</strong>: Tab through all controls, submit with Enter</li>
<li><input disabled="" type="checkbox"/>
<strong>Screen reader tested</strong>: Labels, hints, and status messages announced (NVDA/VoiceOver)</li>
<li><input disabled="" type="checkbox"/>
<strong>Live region updates</strong>: Inspect DevTools ‚Üí <code>#status</code> text changes after add/delete</li>
<li><input disabled="" type="checkbox"/>
<strong>Code committed</strong>: <code>git add .</code>, <code>git commit -m "wk6-lab1: server-first scaffold with HTMX"</code></li>
</ul>
<hr />
<h2 id="next-steps"><a class="header" href="#next-steps">Next Steps</a></h2>
<p>In <strong>Week 6 Lab 2</strong> you will:</p>
<ol>
<li>Conduct peer interviews (needs-finding)</li>
<li>Document consent protocol (ethics)</li>
<li>Build an inclusive backlog from research insights</li>
<li>Plan instrumentation for Week 9 evaluation</li>
</ol>
<p><strong>Preparation</strong>:</p>
<ul>
<li>Read <a href="wk06/../references/consent-pii-faq.html">Consent &amp; PII FAQ</a> and <a href="wk06/../references/privacy-by-design.html">Privacy by Design</a></li>
<li>Bring laptop with working scaffold (Lab 1 code)</li>
<li>Be ready to pair with a classmate for interviews</li>
</ul>
<hr />
<p><strong>Lab authored by</strong>: COMP2850 Teaching Team, University of Leeds
<strong>Last updated</strong>: 2025-01-14
<strong>Licence</strong>: Academic use only (not for redistribution)</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-6--lab-1--student-guide-understanding-server-first-architecture"><a class="header" href="#week-6--lab-1--student-guide-understanding-server-first-architecture">Week 6 ‚Ä¢ Lab 1 ‚Äî Student Guide: Understanding Server-First Architecture</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-6-orange" alt="Week 6" />
<img src="https://img.shields.io/badge/Lab-1-green" alt="Lab 1" />
<img src="https://img.shields.io/badge/Type-Student_Guide-purple" alt="Guide" /></p>
<blockquote>
<p><strong>Purpose</strong>: Week 6 Lab 1 is your first HCI lab. The starter repository already contains working code - your task is to <strong>understand how it works</strong>, verify the dual-mode architecture, and test accessibility features.</p>
</blockquote>
<hr />
<h2 id="your-starter-code"><a class="header" href="#your-starter-code">Your Starter Code</a></h2>
<p>The starter repository (<code>comp2850-hci-starter</code>) already includes:</p>
<p>‚úÖ <strong>Complete</strong>: <code>Main.kt</code>, base layout, HTMX library, CSS
‚úÖ <strong>Complete</strong>: <code>TaskRoutes.kt</code> with dual-mode CRUD (lines 67-142)
‚úÖ <strong>Complete</strong>: <code>TaskRepository.kt</code> with CSV persistence
‚úÖ <strong>Complete</strong>: <code>tasks/index.peb</code> template</p>
<p><strong>You don‚Äôt need to write code from scratch</strong> - it‚Äôs already there!</p>
<hr />
<h2 id="how-to-use-this-guide"><a class="header" href="#how-to-use-this-guide">How to Use This Guide</a></h2>
<p><strong>If you‚Äôve read the lab instructions:</strong> Follow the numbered activities in the mdbook.</p>
<p><strong>If you‚Äôre confused:</strong> Use this guide to understand the key patterns, then verify everything works.</p>
<hr />
<h2 id="understanding-the-code-15-minutes"><a class="header" href="#understanding-the-code-15-minutes">Understanding the Code (15 minutes)</a></h2>
<h3 id="1-server-first-pattern"><a class="header" href="#1-server-first-pattern">1. Server-First Pattern</a></h3>
<p><strong>Open</strong>: <code>src/main/kotlin/routes/TaskRoutes.kt</code></p>
<p><strong>Key function</strong>: <code>get("/tasks")</code> (lines 67-77)</p>
<p><strong>What it does</strong>:</p>
<ol>
<li>Gets all tasks from repository</li>
<li>Creates a model (map of data)</li>
<li>Renders <code>tasks/index.peb</code> template with data</li>
<li>Sends complete HTML to browser</li>
</ol>
<p><strong>Why this matters</strong>: The server sends ready-to-display HTML. If JavaScript fails, the page still works.</p>
<hr />
<h3 id="2-dual-mode-architecture"><a class="header" href="#2-dual-mode-architecture">2. Dual-Mode Architecture</a></h3>
<p><strong>Still in</strong>: <code>TaskRoutes.kt</code></p>
<p><strong>Key function</strong>: <code>post("/tasks")</code> (lines 83-122)</p>
<p><strong>The pattern</strong>:</p>
<pre><code class="language-kotlin">if (call.isHtmx()) {
    // HTMX path: return HTML fragment
    return@post call.respondText(fragment + status, ...)
}

// No-JS path: redirect to GET /tasks
call.respond(HttpStatusCode.SeeOther)
</code></pre>
<p><strong>What this means</strong>:</p>
<ul>
<li><strong>With JavaScript</strong>: HTMX intercepts form submit, server returns just the new task HTML, HTMX adds it to the list (smooth, no page reload)</li>
<li><strong>Without JavaScript</strong>: Form submits normally, server redirects browser back to <code>/tasks</code>, full page reloads (works but slower)</li>
</ul>
<p><strong>Why both?</strong>: Progressive enhancement - baseline functionality for everyone, enhanced experience for capable browsers.</p>
<hr />
<h3 id="3-htmx-attributes"><a class="header" href="#3-htmx-attributes">3. HTMX Attributes</a></h3>
<p><strong>Open</strong>: <code>src/main/resources/templates/tasks/index.peb</code></p>
<p><strong>Find the form</strong> (around line 9-18):</p>
<pre><code class="language-pebble">&lt;form action="/tasks" method="post"
      hx-post="/tasks"
      hx-target="#task-list"
      hx-swap="beforeend"&gt;
</code></pre>
<p><strong>What each attribute does</strong>:</p>
<ul>
<li><code>action="/tasks" method="post"</code> - Baseline HTML (works without JS)</li>
<li><code>hx-post="/tasks"</code> - HTMX intercepts, does AJAX instead</li>
<li><code>hx-target="#task-list"</code> - Where to put the response</li>
<li><code>hx-swap="beforeend"</code> - How to insert it (append to end of list)</li>
</ul>
<p><strong>The magic</strong>: If JavaScript is disabled, <code>hx-*</code> attributes are ignored and the form uses <code>action</code> instead. Both paths work!</p>
<hr />
<h3 id="4-out-of-band-status-updates"><a class="header" href="#4-out-of-band-status-updates">4. Out-of-Band Status Updates</a></h3>
<p><strong>Back in</strong>: <code>TaskRoutes.kt</code> line 114</p>
<pre><code class="language-kotlin">val status = """&lt;div id="status" hx-swap-oob="true"&gt;Task "${task.title}" added successfully.&lt;/div&gt;"""
</code></pre>
<p><strong>What <code>hx-swap-oob="true"</code> does</strong>:</p>
<ul>
<li>‚ÄúOOB‚Äù = Out Of Band</li>
<li>Response includes this <code>&lt;div&gt;</code> even though it‚Äôs not in the <code>hx-target</code></li>
<li>HTMX finds the element with <code>id="status"</code> anywhere on the page and updates it</li>
<li>Screen readers announce the change (because the div has <code>role="status"</code> in base layout)</li>
</ul>
<p><strong>Why this matters</strong>: Visual feedback + screen reader announcement with one server response.</p>
<hr />
<h2 id="verification-checklist"><a class="header" href="#verification-checklist">Verification Checklist</a></h2>
<p>Test that everything works correctly:</p>
<h3 id="dual-mode-testing"><a class="header" href="#dual-mode-testing">Dual-Mode Testing</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
<strong>Run the server</strong>: <code>./gradlew run</code> ‚Üí visit http://localhost:8080/tasks</li>
<li><input disabled="" type="checkbox"/>
<strong>Add task (with JS)</strong>: Type ‚ÄúBuy milk‚Äù ‚Üí click Add Task ‚Üí task appears without page reload</li>
<li><input disabled="" type="checkbox"/>
<strong>Delete task (with JS)</strong>: Click Delete ‚Üí task disappears without page reload</li>
<li><input disabled="" type="checkbox"/>
<strong>Disable JavaScript</strong>: DevTools ‚Üí Settings ‚Üí Disable JavaScript ‚Üí refresh page</li>
<li><input disabled="" type="checkbox"/>
<strong>Add task (no JS)</strong>: Type ‚ÄúPay bills‚Äù ‚Üí click Add Task ‚Üí page reloads, task appears</li>
<li><input disabled="" type="checkbox"/>
<strong>Delete task (no JS)</strong>: Click Delete ‚Üí page reloads, task gone</li>
</ul>
<p><strong>Expected</strong>: All 6 tests pass. Features work identically with/without JavaScript.</p>
<hr />
<h3 id="accessibility-testing"><a class="header" href="#accessibility-testing">Accessibility Testing</a></h3>
<ul>
<li>
<p><input disabled="" type="checkbox"/>
<strong>Keyboard navigation</strong>:</p>
<ul>
<li>Press Tab repeatedly ‚Üí focus moves through: skip link ‚Üí title input ‚Üí Add button ‚Üí delete buttons ‚Üí footer</li>
<li>All focus indicators visible (blue outline)</li>
<li>Press Enter on Add button ‚Üí form submits</li>
</ul>
</li>
<li>
<p><input disabled="" type="checkbox"/>
<strong>Skip link</strong>:</p>
<ul>
<li>Press Tab once ‚Üí ‚ÄúSkip to main content‚Äù appears</li>
<li>Press Enter ‚Üí focus jumps to main content (skips header)</li>
</ul>
</li>
<li>
<p><input disabled="" type="checkbox"/>
<strong>Screen reader</strong> (if available - NVDA/ORCA/VoiceOver):</p>
<ul>
<li>Navigate to form ‚Üí hears ‚ÄúTitle, edit text, Keep it short and specific‚Äù</li>
<li>Add task ‚Üí hears ‚ÄúTask ‚ÄòBuy milk‚Äô added successfully‚Äù</li>
<li>Navigate to delete button ‚Üí hears ‚ÄúDelete task: Buy milk, button‚Äù</li>
</ul>
</li>
<li>
<p><input disabled="" type="checkbox"/>
<strong>ARIA live region</strong>:</p>
<ul>
<li>Open DevTools ‚Üí Elements tab ‚Üí find <code>&lt;div id="status"&gt;</code></li>
<li>Add a task ‚Üí watch the status div text change</li>
<li>Confirm it has <code>role="status"</code> and <code>aria-live="polite"</code></li>
</ul>
</li>
</ul>
<hr />
<h3 id="browser-history"><a class="header" href="#browser-history">Browser History</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
<strong>Add task</strong> ‚Üí URL stays <code>/tasks</code> (not <code>/tasks?</code> or changed)</li>
<li><input disabled="" type="checkbox"/>
<strong>Press back button</strong> ‚Üí goes to previous page (not re-submits form)</li>
<li><input disabled="" type="checkbox"/>
<strong>Refresh page</strong> ‚Üí shows current task list (not ‚Äúconfirm resubmission‚Äù dialog)</li>
</ul>
<p><strong>Why this works</strong>: Post-Redirect-Get (PRG) pattern. After POST, server sends <code>303 See Other</code> redirect to <code>GET /tasks</code>.</p>
<hr />
<h2 id="common-issues--fixes"><a class="header" href="#common-issues--fixes">Common Issues &amp; Fixes</a></h2>
<h3 id="cannot-find-taskrepository"><a class="header" href="#cannot-find-taskrepository">‚ÄúCannot find TaskRepository‚Äù</a></h3>
<p><strong>Problem</strong>: Missing import or file not created
<strong>Fix</strong>: Check <code>src/main/kotlin/data/TaskRepository.kt</code> exists. If not, copy from lab instructions Activity 3 Step 1.</p>
<h3 id="tasks-dont-appear-after-adding"><a class="header" href="#tasks-dont-appear-after-adding">‚ÄúTasks don‚Äôt appear after adding‚Äù</a></h3>
<p><strong>Problem</strong>: HTMX target mismatch
<strong>Fix</strong>: In <code>index.peb</code>, confirm <code>&lt;ul id="task-list"&gt;</code> exists. HTMX needs this ID to know where to insert.</p>
<h3 id="page-reloads-even-with-javascript-enabled"><a class="header" href="#page-reloads-even-with-javascript-enabled">‚ÄúPage reloads even with JavaScript enabled‚Äù</a></h3>
<p><strong>Problem</strong>: HTMX library not loaded
<strong>Fix</strong>: Check browser console for errors. Confirm <code>static/js/htmx-1.9.12.min.js</code> exists and is linked in <code>base.peb</code>.</p>
<h3 id="status-message-not-announced-by-screen-reader"><a class="header" href="#status-message-not-announced-by-screen-reader">‚ÄúStatus message not announced by screen reader‚Äù</a></h3>
<p><strong>Problem</strong>: Live region not configured correctly
<strong>Fix</strong>: Check <code>_layout/base.peb</code> has <code>&lt;div id="status" role="status" aria-live="polite"&gt;</code> in header.</p>
<hr />
<h2 id="understanding-check"><a class="header" href="#understanding-check">Understanding Check</a></h2>
<p>Before moving to Lab 2, make sure you can answer:</p>
<ol>
<li>
<p><strong>What is server-first architecture?</strong>
<em>Expected: Server renders complete HTML and sends it to browser, not JSON for client-side rendering</em></p>
</li>
<li>
<p><strong>What is progressive enhancement?</strong>
<em>Expected: Build baseline HTML that works for everyone, then add JavaScript enhancements</em></p>
</li>
<li>
<p><strong>What does <code>hx-swap-oob</code> do?</strong>
<em>Expected: Updates an element outside the hx-target, useful for status messages</em></p>
</li>
<li>
<p><strong>Why do we need both <code>action</code> and <code>hx-post</code>?</strong>
<em>Expected: action for no-JS fallback, hx-post for HTMX enhancement - dual-mode pattern</em></p>
</li>
<li>
<p><strong>What is the PRG pattern?</strong>
<em>Expected: Post-Redirect-Get prevents duplicate form submissions on browser refresh</em></p>
</li>
</ol>
<hr />
<h2 id="commit--continue"><a class="header" href="#commit--continue">Commit &amp; Continue</a></h2>
<pre><code class="language-bash"># If you made any changes (comments, fixes):
git add .
git commit -m "feat(wk6-lab1): verify server-first scaffold with HTMX

- Tested dual-mode CRUD (HTMX + no-JS)
- Verified keyboard navigation and skip link
- Confirmed ARIA live region announces status changes
- Tested with JavaScript disabled - full parity achieved"

# If code was already complete:
git commit --allow-empty -m "docs(wk6-lab1): verified server-first architecture understanding"
</code></pre>
<p><strong>Next</strong>: Week 6 Lab 2 - Needs-finding, consent protocol, and backlog creation.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-6--lab-2-needs-finding-consent--inclusive-backlog"><a class="header" href="#week-6--lab-2-needs-finding-consent--inclusive-backlog">Week 6 ‚Ä¢ Lab 2: Needs-Finding, Consent &amp; Inclusive Backlog</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-6-orange" alt="Week 6" />
<img src="https://img.shields.io/badge/Lab-2-green" alt="Lab 2" />
<img src="https://img.shields.io/badge/Status-Draft-yellow" alt="Status" /></p>
<hr />
<h2 id="terminology-note-1"><a class="header" href="#terminology-note-1">Terminology Note</a></h2>
<p>Throughout COMP2850 we use <strong>people-centred language</strong> (e.g., ‚Äúperson using a screen reader‚Äù) rather than deficit-based terms (e.g., ‚Äúblind user‚Äù). This reflects contemporary inclusive-design practice and acknowledges that disability arises from environmental barriers, not individual impairment.</p>
<hr />
<h2 id="pre-reading-1"><a class="header" href="#pre-reading-1">Pre-reading</a></h2>
<p><strong>Essential</strong></p>
<ul>
<li>Clone/update your Week 6 starter repo (same baseline code) to ensure tasks work before research session</li>
<li><a href="https://hbr.org/2016/09/know-your-customers-jobs-to-be-done">Christensen, C. M., Hall, T., Dillon, K., &amp; Duncan, D. S. (2016). ‚ÄúKnow Your Customers‚Äô Jobs to Be Done‚Äù</a></li>
<li><a href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/">ICO (2024). ‚ÄúGuide to Data Protection by Design and Default‚Äù</a></li>
<li><a href="wk06/../references/consent-pii-faq.html">Consent &amp; PII FAQ</a> (module ethics guidance)</li>
<li><a href="wk06/../references/privacy-by-design.html">Privacy by Design</a> (UK GDPR compliance framework)</li>
<li><a href="wk06/../references/assistive-testing-checklist.html">Assistive Testing Checklist</a> (module testing guide for Weeks 6-11)</li>
</ul>
<p><strong>Recommended</strong></p>
<ul>
<li><a href="https://inclusive.microsoft.design/">Microsoft Inclusive Design Toolkit</a></li>
<li><a href="https://www.jpattonassociates.com/user-story-mapping/">Patton, J. (2014). <em>User Story Mapping</em>, Ch. 1-3</a></li>
<li><a href="https://www.nngroup.com/articles/interviewing-users/">Nielsen, J. (1993). ‚ÄúUsability Engineering‚Äù, Ch. 5: User Interviews</a></li>
</ul>
<hr />
<h2 id="introduction-1"><a class="header" href="#introduction-1">Introduction</a></h2>
<h3 id="context-1"><a class="header" href="#context-1">Context</a></h3>
<p>In <strong>Week 6 Lab 1</strong> you built a server-first task manager with progressive enhancement (HTMX). The scaffold is technically sound: it works without JavaScript, keyboard navigation is accessible, and ARIA live regions announce status messages.</p>
<p><strong>But we don‚Äôt yet know if it meets real people‚Äôs needs.</strong></p>
<p>This lab introduces <strong>needs-finding</strong>: a lightweight research activity to understand how people work with task managers, what frustrates them, and what inclusive features would help. You‚Äôll capture insights using <strong>job stories</strong> (a people-centred alternative to user stories), document an <strong>ethical consent protocol</strong> for peer interviews, and build an <strong>inclusive backlog</strong> that will drive your accessibility work in Weeks 7-10.</p>
<h3 id="why-this-matters-2"><a class="header" href="#why-this-matters-2">Why This Matters</a></h3>
<p><strong>Professionally</strong>, needs-finding prevents ‚Äúsolution looking for a problem‚Äù:</p>
<ul>
<li><strong>Basecamp</strong> (project management) conducts customer interviews every sprint</li>
<li><strong>GOV.UK</strong> runs user research sessions before building new services</li>
<li><strong>GitHub</strong> uses job stories to prioritise accessibility features</li>
</ul>
<p>Research shows that teams who ground design decisions in <strong>evidence</strong> (pilot data, interviews, observations) build more inclusive products than teams who rely on assumptions (Norman, 2013).</p>
<p><strong>Academically</strong>, this lab teaches:</p>
<ul>
<li><strong>Qualitative research methods</strong>: interviewing, note-taking, thematic coding</li>
<li><strong>Ethics in practice</strong>: informed consent, anonymisation, right to withdraw (UK GDPR)</li>
<li><strong>Jobs-to-Be-Done framework</strong>: understanding needs vs. specifying solutions</li>
<li><strong>Inclusive backlog management</strong>: prioritising features by severity √ó inclusion risk</li>
</ul>
<h2 id="learning-focus-1"><a class="header" href="#learning-focus-1">Learning Focus</a></h2>
<h3 id="lab-objectives-1"><a class="header" href="#lab-objectives-1">Lab Objectives</a></h3>
<p>By the end of this session, you will have:</p>
<ul>
<li>Conducted peer interviews using structured prompts and consent protocols</li>
<li>Written 5+ job stories from needs-finding activities that represent diverse needs</li>
<li>Designed and implemented a GDPR-compliant consent form</li>
<li>Created a prioritised backlog linking features to user needs with severity and inclusion-risk tagging</li>
</ul>
<h3 id="learning-outcomes-addressed-1"><a class="header" href="#learning-outcomes-addressed-1">Learning Outcomes Addressed</a></h3>
<p>This lab contributes to the following module Learning Outcomes (<a href="wk06/../references/learning-outcomes.html">full definitions</a>):</p>
<ul>
<li><strong>LO1</strong>: Differentiate people-centred methods ‚Äî evidenced by job story methodology</li>
<li><strong>LO2</strong>: Design and conduct needs-finding ‚Äî evidenced by structured interview + synthesis</li>
<li><strong>LO3</strong>: Analyse ethical implications ‚Äî evidenced by consent protocol and privacy audit</li>
<li><strong>LO13</strong>: Integrate HCI with SE ‚Äî evidenced by backlog with evidence chains</li>
</ul>
<hr />
<h2 id="key-concepts-1"><a class="header" href="#key-concepts-1">Key Concepts</a></h2>
<h3 id="1-needs-finding-vs-requirements-gathering"><a class="header" href="#1-needs-finding-vs-requirements-gathering">1. Needs-Finding vs. Requirements Gathering</a></h3>
<p><strong>Traditional requirements gathering</strong>:</p>
<blockquote>
<p>‚ÄúThe system shall allow users to filter tasks by status (complete/incomplete).‚Äù</p>
</blockquote>
<p><strong>Needs-finding</strong>:</p>
<blockquote>
<p>‚ÄúWhen I‚Äôm preparing for a crit, I want to focus only on deliverable tasks so I can check I haven‚Äôt missed anything, because I get anxious about deadlines.‚Äù</p>
</blockquote>
<p><strong>Difference</strong>:</p>
<ul>
<li><strong>Requirements</strong> specify <em>solutions</em> (‚Äúfilter by status‚Äù)</li>
<li><strong>Needs</strong> uncover <em>motivations</em> (‚Äúreduce anxiety about missed deadlines‚Äù)</li>
</ul>
<p><strong>Why this matters</strong>: Solutions can change (filter, search, tags, AI assistant), but needs stay constant. Understanding needs lets you pivot to better solutions as technology evolves.</p>
<h3 id="2-jobs-to-be-done-jtbd-framework"><a class="header" href="#2-jobs-to-be-done-jtbd-framework">2. Jobs-to-Be-Done (JTBD) Framework</a></h3>
<p><strong>Job story template</strong>:</p>
<pre><code>When [situation/context],
I want to [motivation/goal],
so I can [desired outcome],
because [underlying need/constraint].
</code></pre>
<p><strong>Example (COMP2850 context)</strong>:</p>
<pre><code>When I'm using a screen reader to check my task list,
I want confirmation messages announced immediately after I delete a task,
so I can know the action succeeded without navigating back to the list,
because re-scanning 20 items to confirm deletion is time-consuming and error-prone.
</code></pre>
<p><strong>Contrast with persona-based user story</strong>:</p>
<blockquote>
<p>‚ÄúAs a blind user, I want screen reader support so I can use the app.‚Äù</p>
</blockquote>
<p><strong>Problems with persona stories</strong>:</p>
<ul>
<li>Assumes all ‚Äúblind users‚Äù have same needs (heterogeneity ignored)</li>
<li>Focuses on disability label, not situational context</li>
<li>Doesn‚Äôt explain <em>why</em> the need exists</li>
</ul>
<p><strong>JTBD advantages</strong>:</p>
<ul>
<li>Situation-specific (works for temporary impairments: broken mouse, bright sunlight)</li>
<li>Explains motivation (builds empathy)</li>
<li>Actionable (clear what success looks like)</li>
</ul>
<h3 id="3-informed-consent-uk-gdpr"><a class="header" href="#3-informed-consent-uk-gdpr">3. Informed Consent (UK GDPR)</a></h3>
<p><strong>UK GDPR principles</strong> (Data Protection Act 2018):</p>
<ol>
<li><strong>Lawfulness, fairness, transparency</strong>: People must know what data you collect and why</li>
<li><strong>Purpose limitation</strong>: Only collect data needed for stated purpose</li>
<li><strong>Data minimisation</strong>: Collect as little as possible</li>
<li><strong>Accuracy</strong>: Keep data correct and up-to-date</li>
<li><strong>Storage limitation</strong>: Delete when no longer needed</li>
<li><strong>Integrity &amp; confidentiality</strong>: Protect from unauthorised access</li>
</ol>
<p><strong>Low-risk peer research</strong> (COMP2850 context):</p>
<ul>
<li><strong>No PII</strong>: Use pseudonyms (‚ÄúParticipant A‚Äù), not names</li>
<li><strong>Local storage</strong>: CSV files on your machine, not cloud services</li>
<li><strong>Opt-out</strong>: Participant can withdraw at any time</li>
<li><strong>No recordings</strong>: Text notes only (unless explicit consent for audio)</li>
<li><strong>Deletion plan</strong>: Delete at end of Semester 1 (or anonymise for portfolio)</li>
</ul>
<p><strong>Consent script elements</strong>:</p>
<ol>
<li>Purpose (‚ÄúWe‚Äôre researching task manager usability‚Äù)</li>
<li>What you‚Äôll do (‚Äú5-minute interview, taking notes‚Äù)</li>
<li>Data stored (‚ÄúPseudonymised notes in local Git repo‚Äù)</li>
<li>Rights (‚ÄúYou can stop at any time, request deletion‚Äù)</li>
<li>Contact (‚ÄúEmail <module> to opt out‚Äù)</li>
</ol>
<h3 id="4-inclusive-backlog-structure"><a class="header" href="#4-inclusive-backlog-structure">4. Inclusive Backlog Structure</a></h3>
<p><strong>Standard backlog</strong>:</p>
<pre><code>ID | Title | Priority | Effort
1  | Add filter | P1 | 3
</code></pre>
<p><strong>Inclusive backlog</strong> (COMP2850 format):</p>
<pre><code>ID | Title | Story Ref | Need | Type | Severity | Inclusion Risk | Evidence | Notes
1  | Filter remembers query | stories.md#S2 | Reduce cognitive load | Accessibility | High | Cognitive, SR | P2 notes L15 | Filter resets on reload; SR users lose context
</code></pre>
<p><strong>Why additional columns</strong>:</p>
<ul>
<li><strong>Story Ref</strong>: Traceable to research evidence</li>
<li><strong>Inclusion Risk</strong>: Tags who‚Äôs affected (SR, keyboard, low-vision, cognitive, motor)</li>
<li><strong>Evidence</strong>: Links to pilot notes, WCAG audits, screenshots</li>
<li><strong>Severity</strong>: Impact on task completion (High = blocks, Medium = hinders, Low = cosmetic)</li>
</ul>
<p><strong>Benefits</strong>:</p>
<ul>
<li>Transparent prioritisation (not just ‚Äúgut feel‚Äù)</li>
<li>Ensures diverse needs considered (not just mouse + sighted users)</li>
<li>Creates evidence chain for assessments (Task 1, Task 2, studio crit)</li>
</ul>
<h3 id="5-thematic-coding-light-touch"><a class="header" href="#5-thematic-coding-light-touch">5. Thematic Coding (Light Touch)</a></h3>
<p><strong>Thematic coding</strong> = systematically identifying patterns in qualitative data.</p>
<p><strong>Example process</strong>:</p>
<ol>
<li><strong>Read notes</strong>: Highlight key phrases</li>
<li><strong>Code observations</strong>: Tag with themes (e.g., <code>status_feedback</code>, <code>keyboard_nav</code>, <code>cognitive_load</code>)</li>
<li><strong>Group codes</strong>: Cluster similar tags</li>
<li><strong>Synthesise themes</strong>: ‚ÄúParticipants struggle to confirm actions succeeded‚Äù ‚Üí backlog item: ‚ÄúAdd persistent confirmation messages‚Äù</li>
</ol>
<p><strong>Tools</strong> (COMP2850 level):</p>
<ul>
<li>Markdown with inline tags: <code>[status_feedback] P2 said "I didn't know if it saved"</code></li>
<li>Spreadsheet with code column</li>
<li>Simple frequency count (how many times each theme appears)</li>
</ul>
<hr />
<h2 id="activity-1-setup--consent-protocol"><a class="header" href="#activity-1-setup--consent-protocol">Activity 1: Setup &amp; Consent Protocol</a></h2>
<p><strong>Time</strong>: 20 minutes
<strong>Materials</strong>: Git repo from Lab 1, consent script template</p>
<h3 id="step-1-create-research-directories"><a class="header" href="#step-1-create-research-directories">Step 1: Create Research Directories</a></h3>
<pre><code class="language-bash">cd comp2850-hci-starter  # Your project from Lab 1
mkdir -p research
mkdir -p backlog
mkdir -p wk06/instrumentation

# Create placeholder files
touch wk06/research/consent-protocol.md
touch wk06/research/stories.md
touch wk06/research/notes.md
touch backlog/backlog.csv
touch wk06/instrumentation/plan.md
</code></pre>
<h3 id="step-2-document-consent-protocol"><a class="header" href="#step-2-document-consent-protocol">Step 2: Document Consent Protocol</a></h3>
<p>Edit <code>wk06/research/consent-protocol.md</code>:</p>
<pre><code class="language-markdown"># Informed Consent Protocol ‚Äî Week 6 Peer Interviews

**Module**: COMP2850 Human-Computer Interaction
**Activity**: Low-risk needs-finding (peer interviews)
**Date**: [YYYY-MM-DD]
**Researcher**: [Your Name/Student ID]

---

## Purpose

We are conducting short peer interviews (5-10 minutes) to understand how people use task managers and identify accessibility improvements. This is part of our HCI coursework for Weeks 6-11.

## What You'll Do

I will ask you 3-5 questions about your experience with task management tools (e.g., "Tell me about a time you struggled to find a specific task"). I'll take brief notes. **No recordings** will be made unless you explicitly agree (and I'll ask again before starting).

## Data Collected

- **What I will collect**:
  - Pseudonymised notes (e.g., "Participant A said...")
  - Timestamps of interview
  - Contextual tags (e.g., "Uses keyboard only", "Prefers dark mode")

- **What I will NOT collect**:
  - Your name (unless you want credit in acknowledgements)
  - Student ID number
  - Email address
  - Any other personally identifiable information (PII)

## Data Storage

- **Where**: Local Git repository on my laptop (private repo, not shared publicly)
- **Who can access**: Me, my lab partner, module teaching staff (if requested for marking)
- **How long**: Until end of Semester 1 (January 2025), then deleted OR anonymised for portfolio

## Your Rights (UK GDPR / Data Protection Act 2018)

- **Right to withdraw**: You can stop at any time, no explanation needed
- **Right to access**: You can ask to see your data (I'll show you my notes)
- **Right to erasure**: You can request I delete your data (email me with interview date/pseudonym)
- **Right to complain**: Contact University Data Protection Officer if concerned: dpo@leeds.ac.uk

## Consent Confirmation

Before starting, I will ask:
- [ ] Have I explained the purpose clearly?
- [ ] Do you understand what data I'll collect?
- [ ] Do you know you can stop at any time?
- [ ] Do you consent to participate?

**Verbal consent is sufficient** for this low-risk activity. If you say "yes", I'll note:
- Date/time: [YYYY-MM-DD HH:MM]
- Pseudonym assigned: [e.g., "Participant A"]
- Consent confirmed: [Initials]

---

## Opt-Out Process

If you change your mind after the interview:
1. Email me at [your-university-email]
2. Include: interview date and pseudonym (if you remember it)
3. I will delete all notes related to your session within 48 hours
4. I will confirm deletion via email

---

## Contact

**Researcher**: [Your Name], [your-email@leeds.ac.uk]
**Module Lead**: Dr. [Name], [module-email]
**University Ethics**: Research Ethics, ethics@leeds.ac.uk

---

**Template source**: COMP2850 HCI, University of Leeds
**Reference**: ICO (2024). Guide to GDPR, &lt;https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/&gt;
</code></pre>
<h3 id="step-3-review-with-lab-partner"><a class="header" href="#step-3-review-with-lab-partner">Step 3: Review with Lab Partner</a></h3>
<p>Pair up with a classmate and:</p>
<ol>
<li>Read each other‚Äôs consent protocols</li>
<li>Check for <strong>missing elements</strong>:
<ul>
<li>‚úÖ Purpose clearly stated?</li>
<li>‚úÖ Data storage location specified?</li>
<li>‚úÖ Participant rights listed (withdraw, access, delete)?</li>
<li>‚úÖ Opt-out process described?</li>
</ul>
</li>
<li>Suggest improvements (clearer language, missing details)</li>
</ol>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ Consent protocol saved in <code>wk06/research/consent-protocol.md</code></li>
<li>‚úÖ Reviewed by peer (get their initials/signature in notes)</li>
<li>‚úÖ Ready to use for interviews</li>
</ul>
<hr />
<h2 id="activity-2-conduct-peer-interviews"><a class="header" href="#activity-2-conduct-peer-interviews">Activity 2: Conduct Peer Interviews</a></h2>
<p><strong>Time</strong>: 40 minutes (20 min each direction)
<strong>Materials</strong>: Interview prompts, note-taking template</p>
<h3 id="step-1-interview-prompts"><a class="header" href="#step-1-interview-prompts">Step 1: Interview Prompts</a></h3>
<p>Use these open-ended prompts (adapt as needed):</p>
<p><strong>General task management</strong>:</p>
<ol>
<li>‚ÄúTell me about the last time you used a to-do list or task manager. What were you trying to accomplish?‚Äù</li>
<li>‚ÄúWhat frustrates you most about managing tasks? Can you give me a specific example?‚Äù</li>
<li>‚ÄúHave you ever lost track of an important task? What happened?‚Äù</li>
</ol>
<p><strong>Accessibility &amp; interaction</strong>:
4. ‚ÄúDo you ever work without a mouse (e.g., trackpad broken, using laptop on train)? How does that change how you interact with apps?‚Äù
5. ‚ÄúHave you used a task manager with your eyes closed or in bright sunlight? What was hard?‚Äù
6. ‚ÄúIf you could add one feature to make task management less stressful, what would it be?‚Äù</p>
<p><strong>Follow-up probes</strong>:</p>
<ul>
<li>‚ÄúCan you tell me more about that?‚Äù</li>
<li>‚ÄúHow did that make you feel?‚Äù</li>
<li>‚ÄúWhat did you do to work around it?‚Äù</li>
</ul>
<h3 id="step-2-note-taking-template"><a class="header" href="#step-2-note-taking-template">Step 2: Note-Taking Template</a></h3>
<p>Create <code>wk06/research/notes.md</code>:</p>
<pre><code class="language-markdown"># Interview Notes ‚Äî Week 6

## Participant A
**Date**: [YYYY-MM-DD HH:MM]
**Context**: [e.g., Uses keyboard only, prefers dark mode, has ADHD]
**Consent**: ‚úÖ Confirmed verbally
**Duration**: [~10 minutes]

### Q1: Last time you used a task manager
**Response**: "I use Notion for uni work. Last week I had to find all tasks tagged 'COMP2850' to prepare for a deadline. It took ages because the filter kept resetting."

**Observations**:
- Mentioned filter UX issue (cognitive load)
- Time pressure context (deadline stress)
- Tag-based workflow (not just chronological)

**Themes**: `filter_persistence`, `cognitive_load`, `deadline_anxiety`

---

### Q2: What frustrates you?
**Response**: "When I submit a form and nothing happens‚Äîlike, did it save? I have to refresh the whole page to check."

**Observations**:
- Lack of confirmation feedback
- Low trust in interface
- Workaround = page reload (inefficient)

**Themes**: `status_feedback`, `confirmation`, `trust`

---

### Q3: Lost track of important task?
**Response**: "Yeah, I once forgot to submit coursework because it was buried in my list. I wish there was a way to pin urgent things."

**Observations**:
- List length issue (visibility)
- Prioritisation need
- Consequence = missed deadline (high impact)

**Themes**: `prioritisation`, `visibility`, `urgent_tasks`

---

### Q4: Work without a mouse?
**Response**: "My trackpad broke last month. I tried using Tab to navigate, but some buttons were impossible to reach. Had to borrow a friend's mouse."

**Observations**:
- Keyboard-only experience = friction
- Temporary impairment (broken hardware)
- Exclusion from features

**Themes**: `keyboard_nav`, `temporary_impairment`, `button_accessibility`

---

### Q5: Eyes closed / bright sunlight?
**Response**: "Haven't tried eyes closed, but in sunlight I can't read low-contrast text. I increase zoom but then the layout breaks."

**Observations**:
- Contrast issue (situational disability)
- Zoom breaks responsive design
- Environmental factor (sunlight)

**Themes**: `contrast`, `zoom`, `responsive_design`

---

### Q6: One feature to add?
**Response**: "A way to see progress‚Äîlike, 'You've completed 8 out of 12 tasks this week.' That would motivate me."

**Observations**:
- Motivation through feedback
- Progress visualisation
- Weekly scope (not just daily)

**Themes**: `progress_tracking`, `motivation`, `feedback`

---

## Summary (Participant A)
**Top pain points**:
1. Filter resets ‚Üí cognitive overload
2. No confirmation feedback ‚Üí uncertainty
3. Keyboard navigation gaps ‚Üí temporary exclusion
4. Contrast issues in bright light ‚Üí situational disability

**Job story ideas**:
- "When I'm filtering tasks, I want the selection to persist across page reloads so I don't lose my place."
- "When I submit a form, I want immediate confirmation so I know it worked without refreshing."
- "When my mouse breaks, I want full keyboard access so I can still complete tasks."
</code></pre>
<p><strong>Repeat for Participant B, C, etc.</strong></p>
<h3 id="step-3-swap-roles"><a class="header" href="#step-3-swap-roles">Step 3: Swap Roles</a></h3>
<ol>
<li><strong>Researcher ‚Üí Participant</strong>: Your partner interviews you (10 minutes)</li>
<li><strong>Participant ‚Üí Researcher</strong>: You interview your partner (10 minutes)</li>
</ol>
<p><strong>After both interviews</strong>:</p>
<ul>
<li>Compare notes</li>
<li>Identify overlapping themes (both mentioned confirmation feedback?)</li>
<li>Flag unique insights (only one person mentioned colour-blindness?)</li>
</ul>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ At least 2 interviews completed (ideally 3-4)</li>
<li>‚úÖ Notes saved in <code>wk06/research/notes.md</code></li>
<li>‚úÖ Themes tagged consistently (use same terms across interviews)</li>
</ul>
<hr />
<h2 id="activity-3-synthesise-job-stories"><a class="header" href="#activity-3-synthesise-job-stories">Activity 3: Synthesise Job Stories</a></h2>
<p><strong>Time</strong>: 25 minutes
<strong>Materials</strong>: Interview notes, job story template</p>
<h3 id="step-1-extract-situations--needs"><a class="header" href="#step-1-extract-situations--needs">Step 1: Extract Situations &amp; Needs</a></h3>
<p>Review <code>notes.md</code> and list <strong>situations</strong> where people struggled:</p>
<div class="table-wrapper"><table><thead><tr><th>Situation</th><th>Need</th><th>Evidence</th></tr></thead><tbody>
<tr><td>Filtering tasks for specific project</td><td>Filter persists across reloads</td><td>P-A notes L5</td></tr>
<tr><td>Submitting a form</td><td>Confirmation feedback</td><td>P-A notes L12, P-B notes L8</td></tr>
<tr><td>Using keyboard only (broken mouse)</td><td>Full keyboard access to all buttons</td><td>P-A notes L20</td></tr>
<tr><td>Bright sunlight</td><td>High-contrast text</td><td>P-A notes L28</td></tr>
<tr><td>Managing 20+ tasks</td><td>Visual progress indicator</td><td>P-A notes L35, P-B notes L15</td></tr>
</tbody></table>
</div>
<h3 id="step-2-write-job-stories"><a class="header" href="#step-2-write-job-stories">Step 2: Write Job Stories</a></h3>
<p>Create <code>wk06/research/stories.md</code>:</p>
<pre><code class="language-markdown"># Job Stories ‚Äî Week 6 Needs-Finding

## Story S1: Filter Persistence
**Situation**: When I'm filtering tasks by project tag (e.g., "COMP2850")
**Motivation**: I want the filter selection to persist across page reloads
**Outcome**: So I can pick up where I left off without re-selecting the filter
**Underlying need**: Because re-filtering 10+ times per session creates cognitive overload and wastes time

**Evidence**: Participant A (notes L5), Participant B (notes L3)
**Inclusion risk**: Cognitive, memory impairment, ADHD
**Type**: Job story (situation-specific)

---

## Story S2: Confirmation Feedback
**Situation**: When I submit a form (add task, edit task, delete task)
**Motivation**: I want immediate, explicit confirmation that the action succeeded
**Outcome**: So I can trust the interface without refreshing to verify
**Underlying need**: Because uncertainty about save status causes anxiety and inefficient workarounds (page reload)

**Evidence**: Participant A (notes L12), Participant B (notes L8)
**Inclusion risk**: Cognitive, screen reader (if confirmation not announced), low digital literacy
**Type**: Job story

---

## Story S3: Full Keyboard Access
**Situation**: When my mouse/trackpad is unavailable (broken hardware, RSI flare-up, preference)
**Motivation**: I want to access all features using only Tab, Enter, Space, and arrow keys
**Outcome**: So I can complete tasks without being excluded
**Underlying need**: Because reliance on pointing device excludes people with motor impairments or temporary injuries

**Evidence**: Participant A (notes L20)
**Inclusion risk**: Motor impairment, RSI, temporary disability, keyboard-only preference
**Type**: Job story
**WCAG**: 2.1.1 Keyboard (A), 2.1.3 Keyboard (No Exception, AAA)

---

## Story S4: High Contrast
**Situation**: When I'm working in bright sunlight or have low vision
**Motivation**: I want text to have sufficient contrast against background
**Outcome**: So I can read task titles and buttons without straining
**Underlying need**: Because low contrast creates situational disability (sunlight) or permanent exclusion (low vision)

**Evidence**: Participant A (notes L28)
**Inclusion risk**: Low vision, colour-blindness, situational (bright light)
**Type**: Job story
**WCAG**: 1.4.3 Contrast (Minimum, AA) ‚Äî 4.5:1 for normal text

---

## Story S5: Progress Visualisation
**Situation**: When I'm managing a long task list (15+ items)
**Motivation**: I want to see completion progress (e.g., "8/12 done this week")
**Outcome**: So I can feel motivated and track productivity
**Underlying need**: Because invisible progress reduces motivation and makes it hard to assess workload

**Evidence**: Participant A (notes L35), Participant B (notes L15)
**Inclusion risk**: Cognitive, ADHD (executive function support)
**Type**: Job story

---

## Story S6: Persistent Error Messages (No-JS)
**Situation**: When JavaScript is disabled (corporate firewall, data-saving mode) and I submit invalid data
**Motivation**: I want error messages to persist after page reload
**Outcome**: So I can understand what went wrong and correct it
**Underlying need**: Because ephemeral error messages (lost on redirect) require perfect memory or multiple submission attempts

**Evidence**: Inferred from Lab 1 no-JS testing; no explicit interview mention (add if time)
**Inclusion risk**: Cognitive, screen reader (needs page-level error summary)
**Type**: Pain point (internally identified)
**WCAG**: 3.3.1 Error Identification (A), 3.3.3 Error Suggestion (AA)
</code></pre>
<h3 id="step-3-map-stories-to-wcag"><a class="header" href="#step-3-map-stories-to-wcag">Step 3: Map Stories to WCAG</a></h3>
<p>For each story, check if it relates to a WCAG criterion:</p>
<div class="table-wrapper"><table><thead><tr><th>Story</th><th>WCAG Criterion</th><th>Level</th></tr></thead><tbody>
<tr><td>S3 (Keyboard access)</td><td>2.1.1 Keyboard</td><td>A</td></tr>
<tr><td>S4 (Contrast)</td><td>1.4.3 Contrast (Minimum)</td><td>AA</td></tr>
<tr><td>S6 (Error messages)</td><td>3.3.1 Error Identification</td><td>A</td></tr>
</tbody></table>
</div>
<p><strong>Why this matters</strong>: When you build the backlog, you can justify priority with ‚ÄúThis is a WCAG Level A failure‚Äù vs. ‚ÄúThis is a nice-to-have.‚Äù</p>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ 5-6 job stories written</li>
<li>‚úÖ Each story cites evidence (participant + line number)</li>
<li>‚úÖ Inclusion risk tags added (SR, keyboard, cognitive, etc.)</li>
<li>‚úÖ At least 2 stories map to WCAG criteria</li>
</ul>
<hr />
<h2 id="activity-4-build-inclusive-backlog"><a class="header" href="#activity-4-build-inclusive-backlog">Activity 4: Build Inclusive Backlog</a></h2>
<p><strong>Time</strong>: 30 minutes
<strong>Materials</strong>: Job stories, <code>backlog.csv</code> template</p>
<h3 id="step-1-create-csv-headers"><a class="header" href="#step-1-create-csv-headers">Step 1: Create CSV Headers</a></h3>
<p>Edit <code>backlog/backlog.csv</code>:</p>
<pre><code class="language-csv">id,title,story_ref,story_type,need,type,severity,inclusion_risk,evidence,notes,candidate_fix
</code></pre>
<p><strong>Column definitions</strong>:</p>
<ul>
<li><strong>id</strong>: Unique number (1, 2, 3‚Ä¶)</li>
<li><strong>title</strong>: Short summary (&lt; 10 words)</li>
<li><strong>story_ref</strong>: Link to <code>stories.md#S1</code> or <code>notes.md#L15</code></li>
<li><strong>story_type</strong>: ‚ÄúJob story‚Äù, ‚ÄúPain point‚Äù, ‚ÄúWCAG violation‚Äù, ‚ÄúResearch insight‚Äù</li>
<li><strong>need</strong>: High-level category (‚ÄúConfirmation feedback‚Äù, ‚ÄúKeyboard access‚Äù)</li>
<li><strong>type</strong>: ‚ÄúAccessibility‚Äù, ‚ÄúUsability‚Äù, ‚ÄúPerformance‚Äù, ‚ÄúTech debt‚Äù</li>
<li><strong>severity</strong>: High (blocks task), Medium (hinders), Low (cosmetic)</li>
<li><strong>inclusion_risk</strong>: Comma-separated tags (SR, Keyboard, Cognitive, Motor, Low vision)</li>
<li><strong>evidence</strong>: Path to notes, screenshot, WCAG reference</li>
<li><strong>notes</strong>: Free-form (root cause, affected flows)</li>
<li><strong>candidate_fix</strong>: <code>true</code> if planning to fix in Week 7 (pick 1-2)</li>
</ul>
<h3 id="step-2-populate-backlog-rows"><a class="header" href="#step-2-populate-backlog-rows">Step 2: Populate Backlog Rows</a></h3>
<p>Example entries:</p>
<pre><code class="language-csv">id,title,story_ref,story_type,need,type,severity,inclusion_risk,evidence,notes,candidate_fix
1,Filter selection resets on page reload,stories.md#S1,Job story,Reduce cognitive load,Usability,Medium,"Cognitive,Memory","P-A notes L5",Current implementation doesn't persist filter state in session or URL,false
2,No confirmation after form submission,stories.md#S2,Job story,Trust &amp; feedback,Accessibility,High,"Cognitive,SR,Low digital literacy","P-A notes L12; P-B notes L8",HTMX shows status in live region (good) but no-JS path gives no feedback (PRG redirect with no message),true
3,Delete button not keyboard-accessible,stories.md#S3,Job story,Full keyboard access,Accessibility,High,"Keyboard,Motor","P-A notes L20; WCAG 2.1.1","Inline form works but focus order unclear; test with Tab-only navigation",true
4,Text contrast below 4.5:1 in default theme,stories.md#S4,Job story,Visibility,Accessibility,Medium,"Low vision,Colour-blind,Situational","P-A notes L28; WCAG 1.4.3",Pico.css default gray (#6c757d) on white = 4.2:1 (fails AA); needs adjustment,false
5,No progress indicator for completed tasks,stories.md#S5,Job story,Motivation &amp; feedback,Usability,Low,Cognitive,"P-A notes L35; P-B notes L15",Nice-to-have; defer to Semester 2 backlog,false
6,Error messages not persistent in no-JS path,stories.md#S6,Pain point,Error recovery,Accessibility,High,"Cognitive,SR","Internal testing; WCAG 3.3.1",PRG redirect loses error context; need error summary on target page,true
7,Skip link not tested with screen reader,Internal audit,WCAG check,Bypass blocks,Accessibility,Medium,SR,"WCAG 2.4.1",Lab 1 tested keyboard focus but not SR announcement; verify with NVDA,false
8,Live region uses polite (should be assertive for errors),Internal audit,WCAG check,Error announcement,Accessibility,High,SR,"WCAG 4.1.3",Errors need aria-live=assertive so SR interrupts to announce; success messages stay polite,false
</code></pre>
<h3 id="step-3-prioritise-with-severity--inclusion"><a class="header" href="#step-3-prioritise-with-severity--inclusion">Step 3: Prioritise with Severity √ó Inclusion</a></h3>
<p><strong>Severity scoring</strong>:</p>
<ul>
<li><strong>High (3 points)</strong>: Blocks task completion or excludes a group</li>
<li><strong>Medium (2 points)</strong>: Makes task harder but workaround exists</li>
<li><strong>Low (1 point)</strong>: Cosmetic or enhancement</li>
</ul>
<p><strong>Inclusion weight</strong>:</p>
<ul>
<li><strong>Multiple groups affected</strong>: +1 point (e.g., SR + Keyboard + Cognitive = +1)</li>
<li><strong>WCAG Level A failure</strong>: +2 points</li>
<li><strong>WCAG Level AA failure</strong>: +1 point</li>
</ul>
<p><strong>Example calculation</strong> (Item #2):</p>
<ul>
<li>Severity: High (3)</li>
<li>Inclusion: SR + Cognitive + Low digital literacy (3 groups) = +1</li>
<li>WCAG: 4.1.3 (AA) = +1</li>
<li><strong>Total priority</strong>: 3 + 1 + 1 = 5 ‚Üí <strong>Fix in Week 7</strong></li>
</ul>
<p><strong>Example calculation</strong> (Item #5):</p>
<ul>
<li>Severity: Low (1)</li>
<li>Inclusion: Cognitive only (1 group) = 0</li>
<li>WCAG: N/A = 0</li>
<li><strong>Total priority</strong>: 1 ‚Üí <strong>Defer to Semester 2</strong></li>
</ul>
<h3 id="step-4-select-candidate-fixes"><a class="header" href="#step-4-select-candidate-fixes">Step 4: Select Candidate Fixes</a></h3>
<p>Mark 1-2 items with <code>candidate_fix=true</code>. These are the issues you‚Äôll fix in <strong>Week 7 Lab 2</strong>. Criteria:</p>
<ul>
<li>High severity + high inclusion risk</li>
<li>Fixable in 1-2 hours (scoped for lab time)</li>
<li>Clear WCAG criterion to verify against</li>
</ul>
<p><strong>Recommended first fixes</strong>:</p>
<ol>
<li>Item #2 (No confirmation in no-JS) ‚Üí Add error summary</li>
<li>Item #3 (Keyboard access) ‚Üí Verify Tab order, add aria-labels</li>
<li>Item #8 (Live region assertive for errors) ‚Üí Change <code>aria-live</code> attribute</li>
</ol>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ At least 8 backlog items (mix of research + WCAG audit)</li>
<li>‚úÖ Severity and inclusion risk assigned to each</li>
<li>‚úÖ 1-2 items marked as candidate fixes</li>
<li>‚úÖ Evidence column links to notes or WCAG reference</li>
</ul>
<hr />
<h2 id="activity-5-instrumentation-planning-teaser"><a class="header" href="#activity-5-instrumentation-planning-teaser">Activity 5: Instrumentation Planning (Teaser)</a></h2>
<p><strong>Time</strong>: 15 minutes
<strong>Materials</strong>: <code>wk06/instrumentation/plan.md</code></p>
<p>In <strong>Week 9</strong> you‚Äôll run task-based pilots and collect metrics (time-on-task, error rate, completion rate). Today you‚Äôll sketch what data to capture.</p>
<h3 id="step-1-identify-events-to-log"><a class="header" href="#step-1-identify-events-to-log">Step 1: Identify Events to Log</a></h3>
<p>Based on your backlog, list key events:</p>
<div class="table-wrapper"><table><thead><tr><th>Event</th><th>Why Log It</th><th>Fields to Capture</th></tr></thead><tbody>
<tr><td><code>task_created</code></td><td>Measure add task completion time</td><td><code>ts_iso</code>, <code>session_id</code>, <code>title_length</code>, <code>js_mode</code></td></tr>
<tr><td><code>task_deleted</code></td><td>Measure delete task completion time</td><td><code>ts_iso</code>, <code>session_id</code>, <code>task_id</code>, <code>js_mode</code></td></tr>
<tr><td><code>validation_error</code></td><td>Count errors (usability metric)</td><td><code>ts_iso</code>, <code>session_id</code>, <code>field</code>, <code>error_type</code>, <code>js_mode</code></td></tr>
<tr><td><code>filter_applied</code></td><td>Track filter usage (S1 story)</td><td><code>ts_iso</code>, <code>session_id</code>, <code>filter_value</code>, <code>result_count</code></td></tr>
</tbody></table>
</div>
<h3 id="step-2-draft-instrumentation-plan"><a class="header" href="#step-2-draft-instrumentation-plan">Step 2: Draft Instrumentation Plan</a></h3>
<p>Edit <code>wk06/instrumentation/plan.md</code>:</p>
<pre><code class="language-markdown"># Instrumentation Plan ‚Äî Week 6

**Purpose**: Capture objective metrics for Week 9 task-based pilots and Week 10 analysis.

---

## Events to Log

### 1. Task Created
**Trigger**: POST /tasks (success)
**Fields**:
- `ts_iso`: ISO 8601 timestamp (e.g., 2025-01-15T14:23:45Z)
- `session_id`: Anonymous 6-char hex (e.g., `P1_a3f7`)
- `request_id`: Unique per request (for tracing)
- `task_code`: `T3_add` (pilot task identifier)
- `step`: `submit`
- `outcome`: `success` | `validation_error`
- `ms`: Time from request start to response (server-side)
- `http_status`: 200 (success) | 400 (validation error)
- `js_mode`: `js-on` | `js-off`

**Why**: Measure task completion time, compare HTMX vs. no-JS.

---

### 2. Validation Error
**Trigger**: POST /tasks (blank title)
**Fields**: Same as Task Created, but `outcome=validation_error`, `http_status=400`

**Why**: Count errors as usability metric; high error rate = poor UX.

---

### 3. Task Deleted
**Trigger**: POST /tasks/{id}/delete (success)
**Fields**: Same structure as Task Created, but `task_code=T4_delete`

**Why**: Measure delete task time; verify live region announcement.

---

## Data Storage

- **Format**: CSV (human-readable, easy to analyse in Excel/Google Sheets)
- **Location**: `data/metrics.csv` (local file, not cloud)
- **Schema**:
  ```csv
  ts_iso,session_id,request_id,task_code,step,outcome,ms,http_status,js_mode
</code></pre>
<p><strong>Example rows</strong>:</p>
<pre><code class="language-csv">2025-01-15T14:23:45Z,P1_a3f7,req_001,T3_add,submit,success,120,200,js-on
2025-01-15T14:24:10Z,P1_a3f7,req_002,T4_delete,submit,success,85,200,js-on
2025-01-15T14:25:00Z,P2_b8c4,req_003,T3_add,submit,validation_error,0,400,js-off
</code></pre>
<hr />
<h2 id="ethics--privacy"><a class="header" href="#ethics--privacy">Ethics &amp; Privacy</a></h2>
<ul>
<li><strong>No PII</strong>: Session IDs are random hex (not linked to names/emails)</li>
<li><strong>Anonymisation</strong>: Use <code>P1</code>, <code>P2</code> pseudonyms (consistent with interview notes)</li>
<li><strong>Consent</strong>: Covered by Week 6 consent protocol (low-risk research)</li>
<li><strong>Retention</strong>: Delete after Semester 1 or anonymise for portfolio</li>
</ul>
<hr />
<h2 id="implementation-week-9"><a class="header" href="#implementation-week-9">Implementation (Week 9)</a></h2>
<p>Create <code>src/main/kotlin/utils/Logger.kt</code>:</p>
<pre><code class="language-kotlin">object Logger {
    private val file = File("data/metrics.csv").apply {
        parentFile?.mkdirs()
        if (!exists()) writeText("ts_iso,session_id,request_id,task_code,step,outcome,ms,http_status,js_mode\n")
    }

    @Synchronized
    fun write(session: String, req: String, task: String, step: String, outcome: String, ms: Long, status: Int, js: String) {
        val ts = DateTimeFormatter.ISO_INSTANT.format(Instant.now())
        file.appendText("$ts,$session,$req,$task,$step,$outcome,$ms,$status,$js\n")
    }
}
</code></pre>
<hr />
<p><strong>Next steps</strong>: In Week 9 Lab 1, integrate Logger into routes and test with manual pilots.</p>
<pre><code>
**Stop and check**:
- ‚úÖ Instrumentation plan saved
- ‚úÖ Events identified (at least 3)
- ‚úÖ CSV schema defined
- ‚úÖ Ethics considerations documented

---

## Reflection Questions

1. **Job stories vs. requirements**: Look at your backlog. How would the items differ if you'd written traditional requirements ("The system shall...") instead of job stories?

2. **Consent trade-offs**: Our protocol uses pseudonyms and no recordings. What insights might we *miss* by not recording audio? When would recordings be justified?

3. **Inclusion risk tagging**: Review your backlog. Did you find issues that affect *only* screen reader users, or do most issues affect multiple groups? What does this tell you about inclusive design?

4. **Evidence chains**: Pick one backlog item. Can you trace it from interview notes ‚Üí job story ‚Üí backlog ‚Üí (future) fix ‚Üí verification? What's missing in your chain?

---

## Further Reading

**Jobs-to-Be-Done**
- Christensen, C. M., Hall, T., Dillon, K., &amp; Duncan, D. S. (2016). "Know Your Customers' Jobs to Be Done." *Harvard Business Review*. &lt;https://hbr.org/2016/09/know-your-customers-jobs-to-be-done&gt;
- Christensen, C. M., Hall, T., Dillon, K., &amp; Duncan, D. S. (2016). *Competing Against Luck*. HarperCollins.

**Qualitative research methods**
- Lazar, J., Feng, J. H., &amp; Hochheiser, H. (2017). *Research Methods in Human-Computer Interaction* (2nd ed.). Morgan Kaufmann. (Ch. 9: Interviews &amp; Focus Groups)
- Braun, V., &amp; Clarke, V. (2006). "Using thematic analysis in psychology." *Qualitative Research in Psychology*, 3(2), 77-101.

**Ethics &amp; GDPR**
- ICO (2024). *Guide to the UK GDPR*. &lt;https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/&gt;
- BCS (2022). *Code of Conduct*. &lt;https://www.bcs.org/membership-and-registrations/become-a-member/bcs-code-of-conduct/&gt;

**Inclusive design**
- Microsoft (2024). *Inclusive Design Toolkit*. &lt;https://inclusive.microsoft.design/&gt;
- Holmes, K. (2018). *Mismatch: How Inclusion Shapes Design*. MIT Press.

---

## Glossary Summary

| Term | Definition | Example/Context |
|------|------------|-----------------|
| **Needs-finding** | Research to understand people's motivations, not just feature requests | Interviews reveal "I want confirmation" (need) vs. "Add a popup" (solution) |
| **Job story** | Situation-specific story format: When/I want/So I can/Because | "When filtering, I want persistence so I don't lose context because re-filtering is tedious" |
| **Informed consent** | Explaining research purpose, data use, and participant rights before collecting data | Consent script explains what you'll note, where it's stored, how to opt out |
| **Pseudonym** | Fake name to protect identity | "Participant A" instead of "Alice Smith" |
| **PII (Personally Identifiable Information)** | Data that can identify an individual (name, email, student ID) | Names = PII; random session IDs ‚â† PII |
| **UK GDPR** | Data protection law (Data Protection Act 2018) | Right to access, delete, withdraw consent |
| **Inclusive backlog** | Backlog with severity + inclusion risk tags | "High severity, affects SR + Keyboard users" |
| **Thematic coding** | Identifying patterns in qualitative data | Tag interview notes with `confirmation`, `keyboard_nav` themes |
| **Severity** | Impact on task completion (High/Medium/Low) | High = blocks completion; Low = cosmetic |
| **Inclusion risk** | Who's affected (SR, Keyboard, Cognitive, Motor, Low vision) | SR + Cognitive = multiple groups at risk |

---

## Lab Checklist

Before leaving lab, confirm:

- [ ] **Consent protocol written**: `wk06/research/consent-protocol.md` complete with opt-out process
- [ ] **Interviews completed**: At least 2 peer interviews (ideally 3-4)
- [ ] **Notes saved**: `wk06/research/notes.md` with themes tagged
- [ ] **Job stories written**: 5-6 stories in `wk06/research/stories.md` with evidence links
- [ ] **Backlog populated**: 8+ items in `backlog/backlog.csv` with severity + inclusion risk
- [ ] **Candidate fixes selected**: 1-2 items marked `candidate_fix=true`
- [ ] **Instrumentation plan drafted**: `wk06/instrumentation/plan.md` outlines metrics for Week 9
- [ ] **Code committed**: `git add wk06/`, `git commit -m "wk6-lab2: needs-finding + consent + backlog"`

---

## Next Steps

In **Week 7 Lab 1** you will:
1. Review ethics guidance from guest speaker
2. Implement accessible inline edit (dual-path HTMX + no-JS)
3. Add validation with `aria-describedby` and `role="alert"`
4. Test with screen reader (NVDA/VoiceOver)

**Preparation**:
- Ensure scaffold from Lab 1 still runs (`./gradlew run`)
- Review backlog items marked `candidate_fix=true`
- Install NVDA (Windows) or enable VoiceOver (macOS) for testing

---

**Lab authored by**: COMP2850 Teaching Team, University of Leeds
**Last updated**: 2025-01-14
**Licence**: Academic use only (not for redistribution)</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-6--lab-2--student-guide-needs-finding--research-ethics"><a class="header" href="#week-6--lab-2--student-guide-needs-finding--research-ethics">Week 6 ‚Ä¢ Lab 2 ‚Äî Student Guide: Needs-Finding &amp; Research Ethics</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-6-orange" alt="Week 6" />
<img src="https://img.shields.io/badge/Lab-2-green" alt="Lab 2" />
<img src="https://img.shields.io/badge/Type-Student_Guide-purple" alt="Guide" /></p>
<blockquote>
<p><strong>Purpose</strong>: Week 6 Lab 2 is about understanding real people‚Äôs needs through peer interviews, documenting ethical consent, and building an inclusive backlog. This is research work, not coding.</p>
</blockquote>
<hr />
<h2 id="what-youll-create"><a class="header" href="#what-youll-create">What You‚Äôll Create</a></h2>
<p>By the end of this lab:</p>
<ul>
<li>‚úÖ <code>wk06/research/consent-protocol.md</code> - Ethical consent documentation</li>
<li>‚úÖ <code>wk06/research/notes.md</code> - Interview notes (2-3 participants)</li>
<li>‚úÖ <code>wk06/research/stories.md</code> - 5-6 job stories</li>
<li>‚úÖ <code>backlog/backlog.csv</code> - Prioritised inclusive backlog (8+ items)</li>
<li>‚úÖ <code>wk06/instrumentation/plan.md</code> - Sketch of Week 9 metrics</li>
</ul>
<hr />
<h2 id="quick-start-create-files"><a class="header" href="#quick-start-create-files">Quick Start: Create Files</a></h2>
<pre><code class="language-bash">cd your-repo
mkdir -p wk06/research backlog wk06/instrumentation
touch wk06/research/consent-protocol.md
touch wk06/research/notes.md
touch wk06/research/stories.md
touch backlog/backlog.csv
touch wk06/instrumentation/plan.md
</code></pre>
<hr />
<h2 id="part-1-consent-protocol-10-minutes"><a class="header" href="#part-1-consent-protocol-10-minutes">Part 1: Consent Protocol (10 minutes)</a></h2>
<p><strong>Copy this template</strong> into <code>wk06/research/consent-protocol.md</code>:</p>
<details>
<summary>Click to expand: Consent Protocol Template</summary>
<pre><code class="language-markdown"># Informed Consent Protocol ‚Äî Week 6 Peer Interviews

**Module**: COMP2850 Human-Computer Interaction
**Activity**: Low-risk needs-finding (peer interviews)
**Date**: [YYYY-MM-DD]
**Researcher**: [Your Name/Student ID]

---

## Purpose

Short peer interviews (5-10 minutes) to understand task manager needs and identify accessibility improvements for COMP2850 coursework (Weeks 6-11).

## What You'll Do

I'll ask 3-5 questions about task management experiences. Brief notes only. **No recordings** unless you explicitly agree.

## Data Collected

**Will collect**:
- Pseudonymised notes ("Participant A said...")
- Interview timestamp
- Context tags ("Uses keyboard only", "Prefers dark mode")

**Will NOT collect**:
- Your name (unless you want acknowledgement credit)
- Student ID, email, or any personally identifiable information (PII)

## Data Storage

- **Where**: Private Git repository on my laptop (not shared publicly)
- **Access**: Me, lab partner, teaching staff (if requested for marking)
- **Duration**: Until end of Semester 1 (January 2025), then deleted OR anonymised for portfolio

## Your Rights (UK GDPR / Data Protection Act 2018)

- **Withdraw**: Stop anytime, no explanation needed
- **Access**: Ask to see your data (I'll show notes)
- **Erasure**: Request deletion (email me with date/pseudonym)
- **Complain**: University Data Protection Officer: dpo@leeds.ac.uk

## Consent Confirmation

Before starting, I will ask:
- [ ] Purpose explained clearly?
- [ ] Understand what data I'll collect?
- [ ] Know you can stop anytime?
- [ ] Consent to participate?

**Verbal consent sufficient**. If yes, I'll note:
- Date/time: [YYYY-MM-DD HH:MM]
- Pseudonym: [e.g., "Participant A"]
- Consent confirmed: [Initials]

---

## Opt-Out Process

If you change your mind:
1. Email: [your-university-email]
2. Include: interview date + pseudonym
3. I'll delete notes within 48 hours
4. Confirm deletion via email

---

## Contact

**Researcher**: [Your Name], [your-email@leeds.ac.uk]
**Module Lead**: Dr. [Name], [module-email]
**University Ethics**: ethics@leeds.ac.uk

---

**Template source**: COMP2850 HCI, University of Leeds
**Reference**: ICO (2024). Guide to GDPR, &lt;https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/&gt;
</code></pre>
</details>
<p><strong>Checklist</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Filled in your name, date, email</li>
<li><input disabled="" type="checkbox"/>
Peer-reviewed by lab partner (get initials)</li>
<li><input disabled="" type="checkbox"/>
Saved in repo</li>
</ul>
<hr />
<h2 id="part-2-conduct-peer-interviews-40-minutes"><a class="header" href="#part-2-conduct-peer-interviews-40-minutes">Part 2: Conduct Peer Interviews (40 minutes)</a></h2>
<h3 id="interview-prompts"><a class="header" href="#interview-prompts">Interview Prompts</a></h3>
<p>Use these 6 open-ended questions:</p>
<ol>
<li>‚ÄúTell me about the last time you used a to-do list or task manager. What were you trying to accomplish?‚Äù</li>
<li>‚ÄúWhat frustrates you most about managing tasks? Give me a specific example.‚Äù</li>
<li>‚ÄúHave you ever lost track of an important task? What happened?‚Äù</li>
<li>‚ÄúDo you ever work without a mouse (trackpad broken, on train)? How does that change how you interact with apps?‚Äù</li>
<li>‚ÄúHave you used a task manager with your eyes closed or in bright sunlight? What was hard?‚Äù</li>
<li>‚ÄúIf you could add one feature to make task management less stressful, what would it be?‚Äù</li>
</ol>
<p><strong>Follow-up probes</strong>:</p>
<ul>
<li>‚ÄúTell me more about that‚Äù</li>
<li>‚ÄúHow did that make you feel?‚Äù</li>
<li>‚ÄúWhat did you do to work around it?‚Äù</li>
</ul>
<h3 id="note-taking-template"><a class="header" href="#note-taking-template">Note-Taking Template</a></h3>
<p><strong>Copy into</strong> <code>wk06/research/notes.md</code>:</p>
<details>
<summary>Click to expand: Notes Template</summary>
<pre><code class="language-markdown"># Interview Notes ‚Äî Week 6

## Participant A
**Date**: [YYYY-MM-DD HH:MM]
**Context**: [e.g., Uses keyboard only, ADHD, prefers dark mode]
**Consent**: ‚úÖ Confirmed verbally
**Duration**: ~10 minutes

---

### Q1: Last time using task manager?
**Response**: [Quote or paraphrase]

**Observations**: [What stood out? Frustration? Workaround?]

**Themes**: `[tag1]`, `[tag2]`

---

### Q2: Biggest frustration?
**Response**: [Quote]

**Observations**:

**Themes**:

---

[Repeat for Q3-Q6]

---

## Summary (Participant A)
**Top pain points**:
1. [Issue with evidence]
2. [Issue with evidence]

**Job story ideas**:
- "When [situation], I want [motivation] so [outcome]."
</code></pre>
</details>
<p><strong>Tips</strong>:</p>
<ul>
<li>Write direct quotes when possible</li>
<li>Tag themes consistently (<code>keyboard</code>, <code>confirmation</code>, <code>contrast</code>)</li>
<li>Note non-verbal cues (frustration, confusion)</li>
</ul>
<p><strong>Swap roles</strong>: Interview 2-3 people, take turns being researcher/participant.</p>
<p><strong>Checklist</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Completed 2-3 interviews</li>
<li><input disabled="" type="checkbox"/>
Notes saved with themes tagged</li>
<li><input disabled="" type="checkbox"/>
Identified overlapping pain points</li>
</ul>
<hr />
<h2 id="part-3-write-job-stories-25-minutes"><a class="header" href="#part-3-write-job-stories-25-minutes">Part 3: Write Job Stories (25 minutes)</a></h2>
<p>Job stories connect situations to needs. Format:</p>
<pre><code>When [situation/context],
I want [motivation/capability],
So [outcome/benefit],
Because [underlying need].
</code></pre>
<p><strong>Copy into</strong> <code>wk06/research/stories.md</code>:</p>
<details>
<summary>Click to expand: Job Stories Template</summary>
<pre><code class="language-markdown"># Job Stories ‚Äî Week 6 Needs-Finding

## Story S1: [Short Title]
**Situation**: When I'm [doing specific task in specific context]
**Motivation**: I want [capability or feature]
**Outcome**: So I can [accomplish goal]
**Underlying need**: Because [why this matters, what pain it solves]

**Evidence**: Participant A (notes L5), Participant B (notes L3)
**Inclusion risk**: [e.g., Cognitive, Motor, Screen reader]
**Type**: Job story
**WCAG**: [If applicable, e.g., 2.1.1 Keyboard (A)]

---

## Story S2: Confirmation Feedback
**Situation**: When I submit a form (add/edit/delete task)
**Motivation**: I want immediate, explicit confirmation that the action succeeded
**Outcome**: So I can trust the interface without refreshing to verify
**Underlying need**: Because uncertainty about save status causes anxiety and inefficient workarounds

**Evidence**: [Your notes references]
**Inclusion risk**: Cognitive, Screen reader, Low digital literacy
**Type**: Job story
**WCAG**: 4.1.3 Status Messages (AA)

---

[Write 5-6 total stories based on your interviews]
</code></pre>
</details>
<p><strong>Map to WCAG</strong>:</p>
<ul>
<li>S1: Keyboard access ‚Üí 2.1.1 Keyboard (A)</li>
<li>S2: Confirmation ‚Üí 4.1.3 Status Messages (AA)</li>
<li>S3: Contrast ‚Üí 1.4.3 Contrast Minimum (AA)</li>
<li>S4: Error messages ‚Üí 3.3.1 Error Identification (A)</li>
</ul>
<p><strong>Checklist</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
5-6 job stories written</li>
<li><input disabled="" type="checkbox"/>
Each cites evidence (participant + line number)</li>
<li><input disabled="" type="checkbox"/>
Inclusion risk tags added</li>
<li><input disabled="" type="checkbox"/>
At least 2 map to WCAG criteria</li>
</ul>
<hr />
<h2 id="part-4-build-inclusive-backlog-30-minutes"><a class="header" href="#part-4-build-inclusive-backlog-30-minutes">Part 4: Build Inclusive Backlog (30 minutes)</a></h2>
<p><strong>Copy into</strong> <code>backlog/backlog.csv</code>:</p>
<details>
<summary>Click to expand: Backlog Template</summary>
<pre><code class="language-csv">id,title,story_ref,story_type,need,type,severity,inclusion_risk,evidence,notes,candidate_fix
1,Filter selection resets on page reload,stories.md#S1,Job story,Reduce cognitive load,Usability,Medium,"Cognitive,Memory","P-A notes L5",Doesn't persist filter state in session or URL,false
2,No confirmation after form submission,stories.md#S2,Job story,Trust &amp; feedback,Accessibility,High,"Cognitive,SR,Low digital literacy","P-A notes L12",HTMX good but no-JS gives no feedback (PRG redirect),true
3,Delete button not keyboard-accessible,stories.md#S3,Job story,Full keyboard access,Accessibility,High,"Keyboard,Motor","P-A notes L20; WCAG 2.1.1",Focus order unclear; needs Tab-only test,true
4,Text contrast below 4.5:1,stories.md#S4,Job story,Visibility,Accessibility,Medium,"Low vision,Colour-blind","P-A notes L28; WCAG 1.4.3",Pico.css gray = 4.2:1 (fails AA),false
5,No progress indicator,stories.md#S5,Job story,Motivation,Usability,Low,Cognitive,"P-A notes L35",Nice-to-have; defer,false
6,Error messages not persistent in no-JS,Internal,Pain point,Error recovery,Accessibility,High,"Cognitive,SR","WCAG 3.3.1",PRG redirect loses error context,true
7,Skip link not SR-tested,Internal audit,WCAG check,Bypass blocks,Accessibility,Medium,SR,"WCAG 2.4.1",Keyboard tested but not SR announcement,false
8,Live region polite (should be assertive for errors),Internal audit,WCAG check,Error announcement,Accessibility,High,SR,"WCAG 4.1.3",Errors need aria-live=assertive,false
</code></pre>
</details>
<p><strong>Column guide</strong>:</p>
<ul>
<li><strong>severity</strong>: High (blocks), Medium (hinders), Low (cosmetic)</li>
<li><strong>inclusion_risk</strong>: SR, Keyboard, Cognitive, Motor, Low vision, Colour-blind</li>
<li><strong>candidate_fix</strong>: Mark 1-2 items <code>true</code> to fix in Week 7 Lab 2</li>
</ul>
<p><strong>Prioritisation</strong>:</p>
<ul>
<li>High severity + multiple groups + WCAG Level A = fix first</li>
<li>Low severity + single group + no WCAG = defer</li>
</ul>
<p><strong>Checklist</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
8+ backlog items (mix of research + audit)</li>
<li><input disabled="" type="checkbox"/>
Severity and inclusion risk assigned</li>
<li><input disabled="" type="checkbox"/>
1-2 items marked <code>candidate_fix=true</code></li>
<li><input disabled="" type="checkbox"/>
Evidence column links to notes or WCAG</li>
</ul>
<hr />
<h2 id="part-5-instrumentation-sketch-15-minutes"><a class="header" href="#part-5-instrumentation-sketch-15-minutes">Part 5: Instrumentation Sketch (15 minutes)</a></h2>
<p><strong>Create</strong> <code>wk06/instrumentation/plan.md</code>:</p>
<pre><code class="language-markdown"># Week 9 Evaluation Planning Sketch

## Events to Log

Based on backlog priorities:
- Task creation (time, validation errors)
- Task deletion (confirmation shown?)
- Filter usage (reset frequency)
- Keyboard navigation (Tab presses per task)

## Metrics to Capture

- **Time-on-task**: How long to add/edit/delete?
- **Error rate**: How often do validation errors occur?
- **Completion rate**: Can people complete tasks without help?
- **Confidence ratings**: Post-task subjective feedback

## Test Scenarios

1. Add 3 tasks (test confirmation feedback)
2. Delete task with keyboard only (test accessibility)
3. Filter then page-reload (test filter persistence)

Details in Week 9 Lab 1.
</code></pre>
<p><strong>Checklist</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Listed 4-5 events to log</li>
<li><input disabled="" type="checkbox"/>
Identified 3-4 metrics</li>
<li><input disabled="" type="checkbox"/>
Sketched 2-3 test scenarios</li>
</ul>
<hr />
<h2 id="commit--continue-1"><a class="header" href="#commit--continue-1">Commit &amp; Continue</a></h2>
<pre><code class="language-bash">git add wk06/ backlog/
git commit -m "feat(wk6-lab2): needs-finding, consent protocol, inclusive backlog

- Conducted 2-3 peer interviews on task management needs
- Wrote 5-6 job stories with inclusion-risk tagging
- Built prioritised backlog (8+ items) mapping to WCAG criteria
- Documented GDPR-compliant consent protocol
- Sketched Week 9 instrumentation plan

Addresses Week 6 Lab 2 requirements. Ready for Week 7 accessibility fixes."
</code></pre>
<p><strong>Next</strong>: Week 7 Lab 1 - Ethics overlay and accessible inline edit.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-7--lab-1-ethics-in-practice--accessible-inline-edit"><a class="header" href="#week-7--lab-1-ethics-in-practice--accessible-inline-edit">Week 7 ‚Ä¢ Lab 1: Ethics in Practice &amp; Accessible Inline Edit</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-7-orange" alt="Week 7" />
<img src="https://img.shields.io/badge/Lab-1-green" alt="Lab 1" />
<img src="https://img.shields.io/badge/Status-Draft-yellow" alt="Status" /></p>
<hr />
<h2 id="terminology-note-2"><a class="header" href="#terminology-note-2">Terminology Note</a></h2>
<p>Throughout COMP2850 we use <strong>people-centred language</strong> (e.g., ‚Äúperson using a screen reader‚Äù) rather than deficit-based terms (e.g., ‚Äúblind user‚Äù). This reflects contemporary inclusive-design practice and acknowledges that disability arises from environmental barriers, not individual impairment.</p>
<hr />
<h2 id="pre-reading-2"><a class="header" href="#pre-reading-2">Pre-reading</a></h2>
<p><strong>Essential</strong></p>
<ul>
<li>Pull latest changes in your starter repository (Week 7 branch)</li>
<li><a href="https://www.w3.org/WAI/WCAG22/Understanding/error-identification.html">W3C (2024). WCAG 2.2: 3.3.1 Error Identification</a></li>
<li><a href="https://www.w3.org/WAI/WCAG22/Understanding/status-messages.html">W3C (2024). WCAG 2.2: 4.1.3 Status Messages</a></li>
<li><a href="https://htmx.org/examples/click-to-edit/">HTMX: Click to Edit Pattern</a></li>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/Accessibility/ARIA/ARIA_Live_Regions">MDN: ARIA Live Regions</a></li>
</ul>
<p><strong>Recommended</strong></p>
<ul>
<li><a href="https://design-system.service.gov.uk/components/error-message/">GOV.UK: Error Message Pattern</a></li>
<li><a href="wk07/../references/example-accessible-inline-edit.html">Example: Accessible Inline Edit</a> (worked example with code)</li>
<li><a href="wk07/../references/privacy-by-design.html">Privacy by Design</a> (ethics framework)</li>
</ul>
<hr />
<h2 id="introduction-2"><a class="header" href="#introduction-2">Introduction</a></h2>
<h3 id="context-2"><a class="header" href="#context-2">Context</a></h3>
<p>In <strong>Week 6</strong> you built a server-first task manager with add/delete functionality. The scaffold works without JavaScript, uses ARIA live regions for status announcements, and follows the PRG (Post-Redirect-Get) pattern.</p>
<p><strong>This week you‚Äôll add inline editing</strong>‚Äîone of the most challenging patterns to make accessible. Done poorly, inline edit breaks screen reader navigation, loses keyboard focus, and excludes people using assistive technology. Done well, it provides a seamless experience across HTMX, no-JS, keyboard, and screen reader interaction modes.</p>
<p>You‚Äôll also review <strong>ethics in practice</strong>: how consent, data minimisation, and privacy-by-design shape implementation decisions (not just policy documents).</p>
<h3 id="why-this-matters-3"><a class="header" href="#why-this-matters-3">Why This Matters</a></h3>
<p><strong>Professionally</strong>, inline edit is everywhere:</p>
<ul>
<li><strong>Trello</strong> (task management): click card title to edit</li>
<li><strong>Notion</strong> (knowledge base): click any block to edit</li>
<li><strong>GitHub</strong> (issue tracking): click issue title to edit</li>
</ul>
<p>All these examples face the same accessibility challenge: how do you swap view mode ‚Üî edit mode without losing context for people using screen readers?</p>
<p><strong>Academically</strong>, this lab demonstrates:</p>
<ul>
<li><strong>Dual-path architecture</strong>: Same feature, different implementation (HTMX vs. no-JS)</li>
<li><strong>Progressive disclosure</strong>: Edit form only appears when needed (not cluttering UI)</li>
<li><strong>ARIA best practices</strong>: <code>aria-describedby</code>, <code>role="alert"</code>, focus management</li>
</ul>
<h2 id="learning-focus-2"><a class="header" href="#learning-focus-2">Learning Focus</a></h2>
<h3 id="lab-objectives-2"><a class="header" href="#lab-objectives-2">Lab Objectives</a></h3>
<p>By the end of this session, you will have:</p>
<ul>
<li>Implemented a consent modal with GDPR-compliant controls</li>
<li>Built an inline-edit feature with accessible focus management and dual-path support (HTMX + no-JS)</li>
<li>Created accessible validation with ARIA error identification</li>
<li>Tested with keyboard and screen reader (NVDA/VoiceOver)</li>
<li>Documented ethical trade-offs in design decisions</li>
</ul>
<h3 id="learning-outcomes-addressed-2"><a class="header" href="#learning-outcomes-addressed-2">Learning Outcomes Addressed</a></h3>
<p>This lab contributes to the following module Learning Outcomes (<a href="wk07/../references/learning-outcomes.html">full definitions</a>):</p>
<ul>
<li><strong>LO3</strong>: Analyse ethical implications ‚Äî evidenced by consent modal implementation</li>
<li><strong>LO5</strong>: Create interface prototypes ‚Äî evidenced by inline-edit feature</li>
<li><strong>LO9</strong>: Apply inclusive design ‚Äî evidenced by keyboard navigation + ARIA patterns</li>
<li><strong>LO10</strong>: Critique societal impacts ‚Äî evidenced by ethics reflection</li>
</ul>
<hr />
<h2 id="key-concepts-2"><a class="header" href="#key-concepts-2">Key Concepts</a></h2>
<h3 id="1-inline-edit-pattern"><a class="header" href="#1-inline-edit-pattern">1. Inline Edit Pattern</a></h3>
<p><strong>Inline edit</strong> = editing content in place (not navigating to a separate edit page).</p>
<p><strong>View mode</strong> ‚Üí <strong>Edit mode</strong> ‚Üí <strong>View mode</strong></p>
<p><strong>Traditional approach</strong> (separate edit page):</p>
<pre><code>View: GET /tasks/1 ‚Üí shows task details
Edit: GET /tasks/1/edit ‚Üí shows edit form
Save: POST /tasks/1 ‚Üí validates, redirects to /tasks/1
</code></pre>
<p><strong>Inline edit approach</strong>:</p>
<pre><code>View: Renders view template (title as text)
Edit: Swaps view ‚Üí edit template (title as input)
Save: Swaps edit ‚Üí view template (updated title)
</code></pre>
<p><strong>Why inline edit is harder for accessibility</strong>:</p>
<ul>
<li>Focus moves between elements (button ‚Üí input ‚Üí button)</li>
<li>Screen reader must announce mode change</li>
<li>Cancel action must restore original state</li>
<li>Keyboard shortcuts conflict (Enter = submit vs. newline)</li>
</ul>
<h3 id="2-dual-path-implementation"><a class="header" href="#2-dual-path-implementation">2. Dual-Path Implementation</a></h3>
<p><strong>HTMX path</strong> (JavaScript enabled):</p>
<ol>
<li>Customer clicks ‚ÄúEdit‚Äù button</li>
<li><code>hx-get="/tasks/1/edit"</code> ‚Üí server returns edit form HTML fragment</li>
<li><code>hx-target="#task-1" hx-swap="outerHTML"</code> ‚Üí replaces <code>&lt;li&gt;</code> with form</li>
<li>Customer edits, clicks ‚ÄúSave‚Äù</li>
<li><code>hx-post="/tasks/1/edit"</code> ‚Üí server validates, returns updated view fragment</li>
<li>HTMX swaps form ‚Üí view mode</li>
<li>OOB status update announces ‚ÄúTask updated‚Äù</li>
</ol>
<p><strong>No-JS path</strong> (JavaScript disabled):</p>
<ol>
<li>Customer clicks ‚ÄúEdit‚Äù button</li>
<li>GET <code>/tasks/1/edit</code> ‚Üí full-page reload with edit form shown</li>
<li>Customer edits, clicks ‚ÄúSave‚Äù</li>
<li>POST <code>/tasks/1/edit</code> ‚Üí validates, redirects to <code>/tasks</code> (PRG)</li>
<li>Page reloads showing updated task</li>
</ol>
<p><strong>Key invariant</strong>: Both paths end in same state (task updated), just different UX (instant swap vs. page reload).</p>
<h3 id="3-aria-error-identification-wcag-331"><a class="header" href="#3-aria-error-identification-wcag-331">3. ARIA Error Identification (WCAG 3.3.1)</a></h3>
<p><strong>WCAG 3.3.1 (Level A)</strong>: If an input error is detected, the item in error is identified and described to the user in text.</p>
<p><strong>Requirements</strong>:</p>
<ol>
<li>Error must be <strong>identified</strong>: Label or instruction shows which field has error</li>
<li>Error must be <strong>described</strong>: Specific message (not just ‚ÄúInvalid‚Äù)</li>
<li>Error must be <strong>programmatically associated</strong>: Screen reader announces error with field</li>
</ol>
<p><strong>Implementation</strong>:</p>
<pre><code class="language-html">&lt;label for="title-1"&gt;Title&lt;/label&gt;
&lt;input id="title-1" name="title"
       aria-describedby="hint-1 error-1"&gt;
&lt;small id="hint-1"&gt;Keep it short and specific.&lt;/small&gt;
&lt;p id="error-1" role="alert"&gt;Title is required. Please enter at least one character.&lt;/p&gt;
</code></pre>
<p><strong>How it works</strong>:</p>
<ol>
<li>Input links to error via <code>aria-describedby="error-1"</code></li>
<li>Screen reader announces: ‚ÄúTitle, edit, Keep it short and specific, Title is required. Please enter at least one character.‚Äù</li>
<li><code>role="alert"</code> makes screen reader interrupt to announce error</li>
</ol>
<h3 id="4-focus-management"><a class="header" href="#4-focus-management">4. Focus Management</a></h3>
<p><strong>Problem</strong>: When HTMX swaps DOM elements, focus can be lost.</p>
<p><strong>Example</strong>:</p>
<pre><code>1. Customer focuses "Edit" button
2. Clicks Enter (activates button)
3. HTMX swaps &lt;li&gt; ‚Üí &lt;form&gt;
4. Focus lost (button no longer exists)
</code></pre>
<p><strong>Solutions</strong>:</p>
<ul>
<li><strong>HTMX attempts restoration</strong>: If swapped element has same <code>id</code>, HTMX tries to restore focus</li>
<li><strong>Manual focus</strong>: Use <code>hx-on::after-swap="document.getElementById('title-1').focus()"</code></li>
<li><strong>Tab order preserved</strong>: Ensure new elements appear in logical position</li>
</ul>
<p><strong>WCAG 2.4.3 (Focus Order, A)</strong>: If a web page can be navigated sequentially, focusable components receive focus in an order that preserves meaning and operability.</p>
<h3 id="5-status-messages-wcag-413"><a class="header" href="#5-status-messages-wcag-413">5. Status Messages (WCAG 4.1.3)</a></h3>
<p><strong>WCAG 4.1.3 (Level AA)</strong>: Status messages can be programmatically determined through role or properties such that they can be presented to the user by assistive technologies without receiving focus.</p>
<p><strong>Status message</strong> = information about the outcome of an action (success, error, progress).</p>
<p><strong>Implementation</strong>:</p>
<pre><code class="language-html">&lt;!-- In base.peb --&gt;
&lt;div id="status" role="status" aria-live="polite"&gt;&lt;/div&gt;

&lt;!-- Server response (HTMX OOB) --&gt;
&lt;div id="status" hx-swap-oob="true"&gt;Task "Buy milk" updated successfully.&lt;/div&gt;
</code></pre>
<p><strong>Why this matters</strong>: People using screen readers need confirmation that save succeeded, but moving focus to a status message disrupts workflow. Live regions solve this by announcing without focus change.</p>
<hr />
<h2 id="activity-1-ethics-refresher--data-boundaries"><a class="header" href="#activity-1-ethics-refresher--data-boundaries">Activity 1: Ethics Refresher &amp; Data Boundaries</a></h2>
<p><strong>Time</strong>: 20 minutes
<strong>Materials</strong>: Week 6 consent protocol, privacy-by-design guidance</p>
<h3 id="step-1-review-consent-protocol"><a class="header" href="#step-1-review-consent-protocol">Step 1: Review Consent Protocol</a></h3>
<p>Open <code>wk06/research/consent-protocol.md</code> from Week 6 Lab 2.</p>
<p><strong>Check</strong>:</p>
<ul>
<li>‚úÖ Purpose clearly stated?</li>
<li>‚úÖ Data storage location specified (local Git repo)?</li>
<li>‚úÖ Participant rights listed (withdraw, access, delete)?</li>
<li>‚úÖ Opt-out process described?</li>
</ul>
<p><strong>If missing any</strong>, update now before Week 7 interviews/testing.</p>
<h3 id="step-2-identify-data-boundaries"><a class="header" href="#step-2-identify-data-boundaries">Step 2: Identify Data Boundaries</a></h3>
<p>Create <code>wk07/ethics/data-boundaries.md</code>:</p>
<pre><code class="language-markdown"># Data Boundaries ‚Äî Week 7

## What We Collect (Allowed)
- **Pseudonymised session IDs**: Random 6-char hex (e.g., `P1_a3f7`)
- **Task metadata**: Title, completion status, timestamps
- **Interaction logs**: HTTP requests, response times, error codes
- **Accessibility testing notes**: "NVDA announced X", "Focus moved to Y"

## What We DO NOT Collect (Prohibited)
- ‚ùå Real names (use pseudonyms: Participant A, P1, etc.)
- ‚ùå Student ID numbers
- ‚ùå Email addresses
- ‚ùå IP addresses (Ktor logs disabled in production)
- ‚ùå Content of tasks beyond module examples (e.g., no personal to-do items)

## Storage &amp; Retention
- **Location**: Local CSV files (`data/tasks.csv`, `data/metrics.csv`)
- **Access**: Researcher, lab partner, module staff (on request)
- **Encryption**: Standard filesystem permissions (chmod 600)
- **Deletion**: End of Semester 1 (January 2025) OR anonymised for portfolio

## Privacy by Design Principles Applied
1. **Data minimisation**: Only collect session ID (not name)
2. **Purpose limitation**: Metrics used only for HCI evaluation (not sold/shared)
3. **Storage limitation**: Delete after assessment complete
4. **Integrity &amp; confidentiality**: Local storage (not cloud), Git repo private

## Ethics Risks Identified
| Risk | Mitigation |
|------|-----------|
| Task titles contain sensitive info | Provide example tasks ("Buy milk"); warn against personal content |
| Session IDs linked to participants | Use randomised IDs; don't store mapping |
| Git repo accidentally public | Verify `.git/config` remote is private; add `.gitignore` for `/data` |
| Screenshots include PII | Crop to relevant UI; blur names if visible |

---

**Reference**: ICO (2024). Guide to GDPR, &lt;https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/&gt;
</code></pre>
<h3 id="step-3-update-gitignore"><a class="header" href="#step-3-update-gitignore">Step 3: Update <code>.gitignore</code></a></h3>
<p>Ensure sensitive data isn‚Äôt committed:</p>
<pre><code class="language-bash"># Add to .gitignore
/data/tasks.csv
/data/metrics.csv
/wk*/research/*notes.md  # Interview notes with pseudonyms
*.log
</code></pre>
<p><strong>Rationale</strong>: Even with pseudonyms, raw interview notes could be re-identified in small cohorts. Keep them local, don‚Äôt push to remote.</p>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ Data boundaries documented</li>
<li>‚úÖ <code>.gitignore</code> updated to exclude sensitive files</li>
<li>‚úÖ Consent protocol from Week 6 still valid</li>
</ul>
<hr />
<h2 id="activity-2-implement-viewedit-templates"><a class="header" href="#activity-2-implement-viewedit-templates">Activity 2: Implement View/Edit Templates</a></h2>
<p><strong>Time</strong>: 30 minutes
<strong>Materials</strong>: <code>templates/tasks/</code>, Pebble template engine</p>
<blockquote>
<p><strong>üîÑ Refactoring Note: From Monolithic to Partials</strong></p>
<p>In <strong>Week 6</strong>, your <code>tasks/index.peb</code> rendered each task as a simple <code>&lt;li&gt;</code> with title + delete button:</p>
<pre><code class="language-html">{% for task in tasks %}
  &lt;li id="task-{{ task.id }}"&gt;
    &lt;span&gt;{{ task.title }}&lt;/span&gt;
    &lt;form action="/tasks/{{ task.id }}/delete" method="post"&gt;
      &lt;button type="submit"&gt;Delete&lt;/button&gt;
    &lt;/form&gt;
  &lt;/li&gt;
{% endfor %}
</code></pre>
<p>In <strong>Week 7</strong>, we introduce <strong>inline editing</strong>, which requires two states:</p>
<ul>
<li><strong>View mode</strong>: Display title with Edit/Delete buttons</li>
<li><strong>Edit mode</strong>: Show input field with Save/Cancel buttons</li>
</ul>
<p><strong>Refactoring strategy</strong>:</p>
<ol>
<li>Extract <code>&lt;li&gt;</code> markup into <strong>two partial templates</strong>:
<ul>
<li><code>_item.peb</code> - Read-only display (view mode)</li>
<li><code>_edit.peb</code> - Editable input (edit mode)</li>
</ul>
</li>
<li>Update <code>tasks/index.peb</code> to <code>{% include %}</code> the appropriate partial</li>
<li>HTMX will swap partials in-place (view ‚Üî edit) without full page reload</li>
</ol>
<p><strong>Before</strong> (Week 6):</p>
<pre><code>tasks/index.peb (full page)
  ‚îî‚îÄ‚îÄ &lt;li&gt; hardcoded for each task
</code></pre>
<p><strong>After</strong> (Week 7):</p>
<pre><code>tasks/index.peb (full page)
  ‚îî‚îÄ‚îÄ {% include "tasks/_item.peb" %}  ‚Üê Reusable view partial
  ‚îî‚îÄ‚îÄ {% include "tasks/_edit.peb" %}  ‚Üê Reusable edit partial
</code></pre>
<p><strong>Note</strong>: The underscore prefix (<code>_</code>) indicates these are <strong>partials</strong> (fragments included in other templates), not standalone pages. This is a widely-used convention (Rails, Jekyll, Sass) that Week 8 explains in detail.</p>
<pre><code>
This **separation of concerns** makes it easier to:
- Swap between states (HTMX swaps just the `&lt;li&gt;`, not the whole page)
- Test each mode independently
- Add more modes later (e.g., "completed" view with strikethrough)
</code></pre>
</blockquote>
<h3 id="step-1-understanding-the-existing-structure"><a class="header" href="#step-1-understanding-the-existing-structure">Step 1: Understanding the Existing Structure</a></h3>
<p>From Week 6, you already have <code>templates/tasks/_item.peb</code> which displays a task in <strong>view mode</strong>. In Week 7, we‚Äôll add an Edit button to <code>_item.peb</code> and create a new <code>_edit.peb</code> template for <strong>edit mode</strong>.</p>
<p>We‚Äôll create <strong>two modes</strong>: view (display title) and edit (input field).</p>
<h3 id="step-2-update-view-mode-partial"><a class="header" href="#step-2-update-view-mode-partial">Step 2: Update View Mode Partial</a></h3>
<p>The <code>_item.peb</code> template already exists from Week 6. We need to <strong>add an Edit button</strong> to it.</p>
<p>Update <code>templates/tasks/_item.peb</code> to add an Edit button before the Toggle button:</p>
<pre><code class="language-html">&lt;li id="task-{{ task.id }}" class="task-view"&gt;
  &lt;span class="task-title"&gt;{{ task.title }}&lt;/span&gt;

  &lt;form action="/tasks/{{ task.id }}/edit" method="get" style="display: inline;"
        hx-get="/tasks/{{ task.id }}/edit"
        hx-target="#task-{{ task.id }}"
        hx-swap="outerHTML"&gt;
    &lt;button type="submit" aria-label="Edit task: {{ task.title }}"&gt;Edit&lt;/button&gt;
  &lt;/form&gt;

  &lt;form action="/tasks/{{ task.id }}/delete" method="post" style="display: inline;"
        hx-post="/tasks/{{ task.id }}/delete"
        hx-target="#task-{{ task.id }}"
        hx-swap="outerHTML"&gt;
    &lt;button type="submit" aria-label="Delete task: {{ task.title }}"&gt;Delete&lt;/button&gt;
  &lt;/form&gt;
&lt;/li&gt;
</code></pre>
<p><strong>Accessibility features</strong>:</p>
<ul>
<li>Unique <code>id="task-{{ task.id }}"</code> for HTMX targeting</li>
<li><code>aria-label</code> on buttons provides context (‚ÄúEdit task: Buy milk‚Äù)</li>
<li>Semantic <code>&lt;li&gt;</code> structure (screen readers announce ‚ÄúList item 1 of 5‚Äù)</li>
</ul>
<h3 id="step-3-create-edit-mode-partial"><a class="header" href="#step-3-create-edit-mode-partial">Step 3: Create Edit Mode Partial</a></h3>
<p>Create a new file <code>templates/tasks/_edit.peb</code>:</p>
<pre><code class="language-html">&lt;li id="task-{{ task.id }}" class="task-edit"&gt;
  &lt;form action="/tasks/{{ task.id }}/edit" method="post"
        hx-post="/tasks/{{ task.id }}/edit"
        hx-target="#task-{{ task.id }}"
        hx-swap="outerHTML"&gt;

    &lt;label for="title-{{ task.id }}"&gt;Title&lt;/label&gt;
    &lt;input type="text"
           id="title-{{ task.id }}"
           name="title"
           value="{{ task.title }}"
           required
           autofocus
           aria-describedby="hint-{{ task.id }}{% if error %} error-{{ task.id }}{% endif %}"&gt;

    &lt;small id="hint-{{ task.id }}"&gt;Keep it short and specific.&lt;/small&gt;

    {% if error %}
      &lt;p id="error-{{ task.id }}" class="error" role="alert" aria-live="assertive"&gt;
        {{ error }}
      &lt;/p&gt;
    {% else %}
      &lt;p id="error-{{ task.id }}" class="visually-hidden" aria-live="assertive"&gt;&lt;/p&gt;
    {% endif %}

    &lt;button type="submit"&gt;Save&lt;/button&gt;
    &lt;a href="/tasks"
       hx-get="/tasks/{{ task.id }}/view"
       hx-target="#task-{{ task.id }}"
       hx-swap="outerHTML"
       role="button"&gt;Cancel&lt;/a&gt;
  &lt;/form&gt;
&lt;/li&gt;
</code></pre>
<p><strong>Accessibility features</strong>:</p>
<ul>
<li><code>autofocus</code>: Input receives focus when form appears (people using keyboards can start typing immediately)</li>
<li><code>aria-describedby</code>: Links input to hint and error (screen reader announces both)</li>
<li><code>role="alert" aria-live="assertive"</code>: Error interrupts screen reader to announce immediately</li>
<li>Error element always exists (even when hidden) so <code>aria-describedby</code> always points to valid ID</li>
<li>Cancel link has <code>role="button"</code> for semantic consistency</li>
</ul>
<h3 id="step-4-update-main-task-list-template"><a class="header" href="#step-4-update-main-task-list-template">Step 4: Update Main Task List Template</a></h3>
<p>Edit <code>templates/tasks/index.peb</code>:</p>
<pre><code class="language-html">{% extends "base.peb" %}

{% block content %}
&lt;h1&gt;Tasks&lt;/h1&gt;

&lt;section aria-labelledby="add-heading"&gt;
  &lt;h2 id="add-heading"&gt;Add a new task&lt;/h2&gt;
  &lt;form action="/tasks" method="post"
        hx-post="/tasks"
        hx-target="#task-list"
        hx-swap="beforeend"&gt;
    &lt;label for="title"&gt;Title&lt;/label&gt;
    &lt;input type="text" id="title" name="title" required
           placeholder="e.g., Buy milk" aria-describedby="title-hint"&gt;
    &lt;small id="title-hint"&gt;Keep it short and specific.&lt;/small&gt;
    &lt;button type="submit"&gt;Add Task&lt;/button&gt;
  &lt;/form&gt;
&lt;/section&gt;

&lt;section aria-labelledby="list-heading"&gt;
  &lt;h2 id="list-heading"&gt;Current tasks ({{ tasks | length }})&lt;/h2&gt;
  &lt;ul id="task-list"&gt;
    {% for task in tasks %}
      {% if editingId and editingId == task.id %}
        {% include "tasks/_edit.peb" with {"task": task, "error": errorMessage} %}
      {% else %}
        {% include "tasks/_item.peb" with {"task": task} %}
      {% endif %}
    {% empty %}
      &lt;li&gt;No tasks yet. Add one above!&lt;/li&gt;
    {% endfor %}
  &lt;/ul&gt;
&lt;/section&gt;
{% endblock %}
</code></pre>
<p><strong>Logic</strong>:</p>
<ul>
<li>If <code>editingId</code> matches current task, render edit mode</li>
<li>Otherwise, render view mode</li>
<li>This enables no-JS path (full-page render with one task in edit mode)</li>
</ul>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ <code>view.peb</code> created with Edit/Delete buttons</li>
<li>‚úÖ <code>edit.peb</code> created with input + Save/Cancel</li>
<li>‚úÖ <code>index.peb</code> uses conditional includes</li>
</ul>
<hr />
<h2 id="activity-3-implement-routes-dual-path"><a class="header" href="#activity-3-implement-routes-dual-path">Activity 3: Implement Routes (Dual-Path)</a></h2>
<p><strong>Time</strong>: 35 minutes
<strong>Materials</strong>: <code>src/main/kotlin/routes/Tasks.kt</code></p>
<h3 id="step-1-add-helper-to-detect-htmx"><a class="header" href="#step-1-add-helper-to-detect-htmx">Step 1: Add Helper to Detect HTMX</a></h3>
<p>Already exists from Week 6, but verify:</p>
<pre><code class="language-kotlin">fun ApplicationCall.isHtmx(): Boolean =
    request.headers["HX-Request"]?.equals("true", ignoreCase = true) == true
</code></pre>
<h3 id="step-2-add-get-tasksidedit-route"><a class="header" href="#step-2-add-get-tasksidedit-route">Step 2: Add GET /tasks/{id}/edit Route</a></h3>
<pre><code class="language-kotlin">get("/tasks/{id}/edit") {
    val id = call.parameters["id"]?.toIntOrNull() ?: return@get call.respond(HttpStatusCode.NotFound)
    val task = TaskRepository.find(id) ?: return@get call.respond(HttpStatusCode.NotFound)

    if (call.isHtmx()) {
        // HTMX path: return edit fragment
        val template = pebble.getTemplate("templates/tasks/_edit.peb")
        val model = mapOf("task" to task, "error" to null)
        val writer = StringWriter()
        template.evaluate(writer, model)
        call.respondText(writer.toString(), ContentType.Text.Html)
    } else {
        // No-JS path: full-page render with editingId
        val model = mapOf(
            "title" to "Tasks",
            "tasks" to TaskRepository.all(),
            "editingId" to id,
            "errorMessage" to null
        )
        val template = pebble.getTemplate("templates/tasks/index.peb")
        val writer = StringWriter()
        template.evaluate(writer, model)
        call.respondText(writer.toString(), ContentType.Text.Html)
    }
}
</code></pre>
<p><strong>Logic</strong>:</p>
<ul>
<li>HTMX: Returns <code>&lt;li&gt;</code> edit fragment (swaps in place)</li>
<li>No-JS: Returns full page with <code>editingId=1</code> (conditional rendering in template)</li>
</ul>
<h3 id="step-3-add-post-tasksidedit-route"><a class="header" href="#step-3-add-post-tasksidedit-route">Step 3: Add POST /tasks/{id}/edit Route</a></h3>
<pre><code class="language-kotlin">post("/tasks/{id}/edit") {
    val id = call.parameters["id"]?.toIntOrNull() ?: return@post call.respond(HttpStatusCode.NotFound)
    val task = TaskRepository.find(id) ?: return@post call.respond(HttpStatusCode.NotFound)

    val newTitle = call.receiveParameters()["title"].orEmpty().trim()

    // Validation
    if (newTitle.isBlank()) {
        if (call.isHtmx()) {
            // HTMX path: return edit fragment with error
            val template = pebble.getTemplate("templates/tasks/_edit.peb")
            val model = mapOf(
                "task" to task,
                "error" to "Title is required. Please enter at least one character."
            )
            val writer = StringWriter()
            template.evaluate(writer, model)
            return@post call.respondText(writer.toString(), ContentType.Text.Html, HttpStatusCode.BadRequest)
        } else {
            // No-JS path: redirect with error flag
            return@post call.respondRedirect("/tasks/${id}/edit?error=blank")
        }
    }

    // Update task
    task.title = newTitle
    TaskRepository.update(task)

    if (call.isHtmx()) {
        // HTMX path: return view fragment + OOB status
        val viewTemplate = pebble.getTemplate("templates/tasks/_item.peb")
        val viewWriter = StringWriter()
        viewTemplate.evaluate(viewWriter, mapOf("task" to task))

        val status = """&lt;div id="status" hx-swap-oob="true"&gt;Task "${task.title}" updated successfully.&lt;/div&gt;"""

        return@post call.respondText(viewWriter.toString() + status, ContentType.Text.Html)
    }

    // No-JS path: PRG redirect
    call.respondRedirect("/tasks")
}
</code></pre>
<p><strong>Validation paths</strong>:</p>
<ul>
<li><strong>HTMX + error</strong>: Returns edit fragment with error message, status 400</li>
<li><strong>No-JS + error</strong>: Redirects to <code>/tasks/{id}/edit?error=blank</code></li>
<li><strong>HTMX + success</strong>: Returns view fragment + OOB status</li>
<li><strong>No-JS + success</strong>: PRG redirect to <code>/tasks</code></li>
</ul>
<h3 id="step-4-handle-error-query-parameter-no-js"><a class="header" href="#step-4-handle-error-query-parameter-no-js">Step 4: Handle Error Query Parameter (No-JS)</a></h3>
<p>Update GET <code>/tasks/{id}/edit</code> to handle <code>?error=blank</code>:</p>
<pre><code class="language-kotlin">get("/tasks/{id}/edit") {
    val id = call.parameters["id"]?.toIntOrNull() ?: return@get call.respond(HttpStatusCode.NotFound)
    val task = TaskRepository.find(id) ?: return@get call.respond(HttpStatusCode.NotFound)
    val errorParam = call.request.queryParameters["error"]

    val errorMessage = when (errorParam) {
        "blank" -&gt; "Title is required. Please enter at least one character."
        else -&gt; null
    }

    if (call.isHtmx()) {
        val template = pebble.getTemplate("templates/tasks/_edit.peb")
        val model = mapOf("task" to task, "error" to errorMessage)
        val writer = StringWriter()
        template.evaluate(writer, model)
        call.respondText(writer.toString(), ContentType.Text.Html)
    } else {
        val model = mapOf(
            "title" to "Tasks",
            "tasks" to TaskRepository.all(),
            "editingId" to id,
            "errorMessage" to errorMessage
        )
        val template = pebble.getTemplate("templates/tasks/index.peb")
        val writer = StringWriter()
        template.evaluate(writer, model)
        call.respondText(writer.toString(), ContentType.Text.Html)
    }
}
</code></pre>
<h3 id="step-5-add-get-tasksidview-cancel-handler"><a class="header" href="#step-5-add-get-tasksidview-cancel-handler">Step 5: Add GET /tasks/{id}/view (Cancel Handler)</a></h3>
<pre><code class="language-kotlin">get("/tasks/{id}/view") {
    val id = call.parameters["id"]?.toIntOrNull() ?: return@get call.respond(HttpStatusCode.NotFound)
    val task = TaskRepository.find(id) ?: return@get call.respond(HttpStatusCode.NotFound)

    // HTMX path only (cancel is just a link to /tasks in no-JS)
    val template = pebble.getTemplate("templates/tasks/_item.peb")
    val model = mapOf("task" to task)
    val writer = StringWriter()
    template.evaluate(writer, model)
    call.respondText(writer.toString(), ContentType.Text.Html)
}
</code></pre>
<h3 id="step-6-add-taskrepository-methods"><a class="header" href="#step-6-add-taskrepository-methods">Step 6: Add TaskRepository Methods</a></h3>
<p>If not already present:</p>
<pre><code class="language-kotlin">object TaskRepository {
    // ... existing methods ...

    fun find(id: Int): Task? = tasks.find { it.id == id }

    fun update(task: Task) {
        tasks.find { it.id == task.id }?.let { it.title = task.title }
        persist()
    }
}
</code></pre>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ GET <code>/tasks/{id}/edit</code> returns edit fragment (HTMX) or full page (no-JS)</li>
<li>‚úÖ POST <code>/tasks/{id}/edit</code> validates, returns fragment/redirect</li>
<li>‚úÖ GET <code>/tasks/{id}/view</code> returns view fragment (cancel handler)</li>
<li>‚úÖ Error messages passed to templates</li>
</ul>
<hr />
<h2 id="activity-4-test-dual-path-functionality"><a class="header" href="#activity-4-test-dual-path-functionality">Activity 4: Test Dual-Path Functionality</a></h2>
<p><strong>Time</strong>: 25 minutes
<strong>Materials</strong>: Browser, keyboard, screen reader</p>
<h3 id="test-1-htmx-path-javascript-enabled"><a class="header" href="#test-1-htmx-path-javascript-enabled">Test 1: HTMX Path (JavaScript Enabled)</a></h3>
<ol>
<li><strong>Load http://localhost:8080/tasks</strong></li>
<li><strong>Add a task</strong>: ‚ÄúTest inline edit‚Äù</li>
<li><strong>Click ‚ÄúEdit‚Äù</strong>:
<ul>
<li><strong>Expected</strong>: Form appears in place (no page reload)</li>
<li><strong>Check Network tab</strong>: See GET <code>/tasks/1/edit</code> (AJAX)</li>
</ul>
</li>
<li><strong>Type new title</strong>: ‚ÄúUpdated title‚Äù</li>
<li><strong>Click ‚ÄúSave‚Äù</strong>:
<ul>
<li><strong>Expected</strong>: View mode appears (no page reload)</li>
<li><strong>Check DevTools</strong>: <code>#status</code> text = ‚ÄúTask ‚ÄòUpdated title‚Äô updated successfully.‚Äù</li>
</ul>
</li>
<li><strong>Click ‚ÄúCancel‚Äù</strong> (after editing again):
<ul>
<li><strong>Expected</strong>: Returns to view mode, original title preserved</li>
</ul>
</li>
</ol>
<p><strong>Result</strong>: ‚úÖ Inline edit works with HTMX</p>
<h3 id="test-2-validation-htmx"><a class="header" href="#test-2-validation-htmx">Test 2: Validation (HTMX)</a></h3>
<ol>
<li><strong>Click ‚ÄúEdit‚Äù</strong> on a task</li>
<li><strong>Delete all text</strong>, click ‚ÄúSave‚Äù</li>
<li><strong>Expected</strong>: Error message appears: ‚ÄúTitle is required‚Ä¶‚Äù</li>
<li><strong>Check error element</strong>:
<ul>
<li>Inspect <code>&lt;p id="error-1" role="alert"&gt;</code></li>
<li>Confirm <code>aria-live="assertive"</code></li>
</ul>
</li>
<li><strong>Type valid title</strong>, click ‚ÄúSave‚Äù</li>
<li><strong>Expected</strong>: Error disappears, save succeeds</li>
</ol>
<p><strong>Result</strong>: ‚úÖ Validation works (HTMX)</p>
<h3 id="test-3-no-js-path-javascript-disabled"><a class="header" href="#test-3-no-js-path-javascript-disabled">Test 3: No-JS Path (JavaScript Disabled)</a></h3>
<ol>
<li><strong>Disable JavaScript</strong> (DevTools ‚Üí Settings ‚Üí Disable JavaScript)</li>
<li><strong>Reload page</strong></li>
<li><strong>Click ‚ÄúEdit‚Äù</strong>:
<ul>
<li><strong>Expected</strong>: Full page reload, edit form shown</li>
</ul>
</li>
<li><strong>Type new title</strong>: ‚ÄúNo-JS test‚Äù</li>
<li><strong>Click ‚ÄúSave‚Äù</strong>:
<ul>
<li><strong>Expected</strong>: Page reloads, task updated</li>
</ul>
</li>
<li><strong>Click ‚ÄúEdit‚Äù</strong>, delete title, click ‚ÄúSave‚Äù**:
<ul>
<li><strong>Expected</strong>: Page reloads, error message shown</li>
</ul>
</li>
</ol>
<p><strong>Result</strong>: ‚úÖ No-JS path works</p>
<h3 id="test-4-keyboard-navigation"><a class="header" href="#test-4-keyboard-navigation">Test 4: Keyboard Navigation</a></h3>
<p><strong>Re-enable JavaScript</strong>, reload page:</p>
<ol>
<li><strong>Tab to ‚ÄúEdit‚Äù button</strong></li>
<li><strong>Press Enter</strong>:
<ul>
<li><strong>Expected</strong>: Form appears, focus in input field (autofocus)</li>
</ul>
</li>
<li><strong>Type new title</strong></li>
<li><strong>Tab to ‚ÄúSave‚Äù button</strong>, press Enter:
<ul>
<li><strong>Expected</strong>: Saves, returns to view mode</li>
</ul>
</li>
<li><strong>Tab to ‚ÄúEdit‚Äù</strong>, Enter, Tab to ‚ÄúCancel‚Äù**, Enter:
<ul>
<li><strong>Expected</strong>: Returns to view mode without saving</li>
</ul>
</li>
</ol>
<p><strong>Check focus indicators</strong>:</p>
<ul>
<li>‚úÖ All buttons have visible outline on focus</li>
<li>‚úÖ Input has visible outline</li>
<li>‚úÖ Focus order logical (Edit ‚Üí Title input ‚Üí Save ‚Üí Cancel)</li>
</ul>
<p><strong>Result</strong>: ‚úÖ Keyboard accessible</p>
<h3 id="test-5-screen-reader-nvdavoiceover"><a class="header" href="#test-5-screen-reader-nvdavoiceover">Test 5: Screen Reader (NVDA/VoiceOver)</a></h3>
<p><strong>Windows (NVDA)</strong>:</p>
<ol>
<li>Start NVDA (Ctrl+Alt+N)</li>
<li>Navigate to task list</li>
<li><strong>Tab to ‚ÄúEdit‚Äù button</strong>:
<ul>
<li><strong>Listen for</strong>: ‚ÄúEdit task: Test inline edit, button‚Äù</li>
</ul>
</li>
<li><strong>Press Enter</strong> (activates Edit)</li>
<li><strong>Listen for</strong>: ‚ÄúTitle, edit, Keep it short and specific, [current value]‚Äù</li>
<li><strong>Delete text, Tab to Save, Enter</strong></li>
<li><strong>Listen for</strong>: ‚ÄúTitle is required. Please enter at least one character, alert‚Äù</li>
<li><strong>Type valid title, Save</strong></li>
<li><strong>Listen for</strong>: ‚ÄúTask ‚ÄòValid title‚Äô updated successfully‚Äù</li>
</ol>
<p><strong>macOS (VoiceOver)</strong>:</p>
<ol>
<li>Enable VoiceOver (Cmd+F5)</li>
<li>Navigate with VoiceOver cursor (VO+Right Arrow)</li>
<li>Repeat NVDA steps, listen for equivalent announcements</li>
</ol>
<p><strong>Result</strong>: ‚úÖ Screen reader announces labels, errors, status</p>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ HTMX path: instant swaps</li>
<li>‚úÖ No-JS path: page reloads</li>
<li>‚úÖ Validation works both paths</li>
<li>‚úÖ Keyboard accessible</li>
<li>‚úÖ Screen reader announces correctly</li>
</ul>
<hr />
<h2 id="activity-5-evidence-collection"><a class="header" href="#activity-5-evidence-collection">Activity 5: Evidence Collection</a></h2>
<p><strong>Time</strong>: 15 minutes
<strong>Materials</strong>: Screenshots, testing notes</p>
<h3 id="step-1-capture-evidence"><a class="header" href="#step-1-capture-evidence">Step 1: Capture Evidence</a></h3>
<p>Create <code>wk07/evidence/</code> directory:</p>
<pre><code class="language-bash">mkdir -p wk07/evidence
</code></pre>
<p><strong>Screenshots to capture</strong>:</p>
<ol>
<li><strong>View mode</strong> (HTMX): Before clicking Edit</li>
<li><strong>Edit mode</strong> (HTMX): Form in place</li>
<li><strong>Validation error</strong> (HTMX): Error message with <code>role="alert"</code></li>
<li><strong>Status message</strong> (HTMX): DevTools showing <code>#status</code> content</li>
<li><strong>No-JS edit mode</strong>: Full page with form</li>
<li><strong>NVDA speech viewer</strong>: Showing error announcement</li>
</ol>
<p><strong>Example naming</strong>:</p>
<ul>
<li><code>01-view-mode-htmx.png</code></li>
<li><code>02-edit-mode-htmx.png</code></li>
<li><code>03-validation-error-htmx.png</code></li>
<li><code>04-status-oob-devtools.png</code></li>
<li><code>05-edit-mode-nojs.png</code></li>
<li><code>06-nvda-error-announcement.png</code></li>
</ul>
<h3 id="step-2-document-testing-notes"><a class="header" href="#step-2-document-testing-notes">Step 2: Document Testing Notes</a></h3>
<p>Create <code>wk07/evidence/testing-notes.md</code>:</p>
<pre><code class="language-markdown"># Testing Notes ‚Äî Week 7 Lab 1

## HTMX Path
**Date**: [YYYY-MM-DD]
**Browser**: Chrome 120.0
**JavaScript**: Enabled

### Test: Inline edit activation
- **Action**: Clicked "Edit" button
- **Result**: ‚úÖ Form appeared instantly (no page reload)
- **Network**: GET /tasks/1/edit (AJAX, 45ms)
- **Screenshot**: `01-view-mode-htmx.png`, `02-edit-mode-htmx.png`

### Test: Validation error
- **Action**: Deleted title, clicked "Save"
- **Result**: ‚úÖ Error shown: "Title is required..."
- **ARIA**: `&lt;p id="error-1" role="alert" aria-live="assertive"&gt;` confirmed in DevTools
- **Screenshot**: `03-validation-error-htmx.png`

### Test: Successful save
- **Action**: Entered valid title, clicked "Save"
- **Result**: ‚úÖ View mode restored, status = "Task 'New title' updated successfully."
- **Screenshot**: `04-status-oob-devtools.png`

---

## No-JS Path
**Date**: [YYYY-MM-DD]
**Browser**: Chrome 120.0
**JavaScript**: Disabled

### Test: Edit activation
- **Action**: Clicked "Edit" button
- **Result**: ‚úÖ Full page reload, form shown
- **URL**: http://localhost:8080/tasks/1/edit

### Test: Validation error
- **Action**: Deleted title, clicked "Save"
- **Result**: ‚úÖ Redirect to /tasks/1/edit?error=blank, error shown
- **Screenshot**: `05-edit-mode-nojs-error.png`

---

## Keyboard Testing
**Date**: [YYYY-MM-DD]
**Input**: Keyboard only (no mouse)

### Test: Tab navigation
- **Path**: Tab ‚Üí "Edit" ‚Üí Enter ‚Üí Title input (autofocus) ‚Üí Tab ‚Üí "Save" ‚Üí Enter
- **Result**: ‚úÖ Focus order logical, all buttons reachable
- **Focus indicators**: ‚úÖ Visible outline on all elements

---

## Screen Reader Testing
**Date**: [YYYY-MM-DD]
**Tool**: NVDA 2024.1 (Windows 11)

### Test: Edit button announcement
- **Navigated to**: "Edit" button
- **NVDA said**: "Edit task: Buy milk, button"
- **Result**: ‚úÖ Contextual label announced

### Test: Input field announcement
- **Activated**: Edit button (Enter)
- **NVDA said**: "Title, edit, Keep it short and specific, Buy milk"
- **Result**: ‚úÖ Label + hint + value announced

### Test: Error announcement
- **Action**: Deleted title, pressed Save
- **NVDA said**: "Title is required. Please enter at least one character, alert"
- **Result**: ‚úÖ Error announced immediately (assertive)

### Test: Status message announcement
- **Action**: Saved valid title
- **NVDA said**: "Task 'New title' updated successfully"
- **Result**: ‚úÖ Status announced (polite, didn't interrupt)

---

## Issues Found
None. All tests passed.

## WCAG Compliance Check
| Criterion | Status | Evidence |
|-----------|--------|----------|
| 2.1.1 Keyboard (A) | ‚úÖ Pass | All features accessible via Tab/Enter |
| 3.3.1 Error Identification (A) | ‚úÖ Pass | Error message explicit, aria-describedby links input |
| 4.1.3 Status Messages (AA) | ‚úÖ Pass | Live region announces success without focus change |
</code></pre>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ Screenshots saved in <code>wk07/evidence/</code></li>
<li>‚úÖ Testing notes documented</li>
<li>‚úÖ WCAG criteria mapped to evidence</li>
</ul>
<hr />
<h2 id="reflection-questions-1"><a class="header" href="#reflection-questions-1">Reflection Questions</a></h2>
<ol>
<li>
<p><strong>Dual-path trade-offs</strong>: The HTMX path returns HTML fragments; the no-JS path returns full pages. Which is easier to maintain? Which is easier to test?</p>
</li>
<li>
<p><strong>Focus management</strong>: HTMX tries to restore focus after swaps. Did you notice focus moving unexpectedly? How would you improve this?</p>
</li>
<li>
<p><strong>Error persistence</strong>: In the no-JS path, errors survive redirects via query parameters. Could you use session storage instead? What are the trade-offs?</p>
</li>
<li>
<p><strong>Screen reader experience</strong>: Compare the HTMX path (instant swap) vs. no-JS path (page reload). Which is better for people using screen readers? Why?</p>
</li>
</ol>
<hr />
<h2 id="further-reading-1"><a class="header" href="#further-reading-1">Further Reading</a></h2>
<p><strong>Inline edit patterns</strong></p>
<ul>
<li>HTMX Examples: Click to Edit. <a href="https://htmx.org/examples/click-to-edit/">https://htmx.org/examples/click-to-edit/</a></li>
<li>Nielsen Norman Group (2015). ‚ÄúIn-Place Editing‚Äù. <a href="https://www.nngroup.com/articles/in-place-editing/">https://www.nngroup.com/articles/in-place-editing/</a></li>
</ul>
<p><strong>WCAG Error Identification</strong></p>
<ul>
<li>W3C (2024). Understanding 3.3.1 Error Identification. <a href="https://www.w3.org/WAI/WCAG22/Understanding/error-identification.html">https://www.w3.org/WAI/WCAG22/Understanding/error-identification.html</a></li>
<li>GOV.UK Design System: Error Message Component. <a href="https://design-system.service.gov.uk/components/error-message/">https://design-system.service.gov.uk/components/error-message/</a></li>
</ul>
<p><strong>Focus management</strong></p>
<ul>
<li>Deque (2023). ‚ÄúFocus Management in ARIA‚Äù. <a href="https://www.deque.com/blog/give-focus-power/">https://www.deque.com/blog/give-focus-power/</a></li>
<li>WebAIM: Keyboard Accessibility. <a href="https://webaim.org/techniques/keyboard/">https://webaim.org/techniques/keyboard/</a></li>
</ul>
<hr />
<h2 id="glossary-summary-1"><a class="header" href="#glossary-summary-1">Glossary Summary</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Term</th><th>Definition</th><th>Example/Context</th></tr></thead><tbody>
<tr><td><strong>Inline edit</strong></td><td>Editing content in place (not separate page)</td><td>Click task title ‚Üí form appears ‚Üí save ‚Üí title updates</td></tr>
<tr><td><strong>Dual-path</strong></td><td>Same feature, different implementation (HTMX vs. no-JS)</td><td>HTMX = fragment swap; no-JS = full page reload</td></tr>
<tr><td><strong>aria-describedby</strong></td><td>Links input to descriptive text (hint/error)</td><td><code>&lt;input aria-describedby="hint-1 error-1"&gt;</code></td></tr>
<tr><td><strong>role=‚Äúalert‚Äù</strong></td><td>Announces content immediately to screen readers</td><td><code>&lt;p role="alert"&gt;Error message&lt;/p&gt;</code></td></tr>
<tr><td><strong>OOB swap</strong></td><td>HTMX updating element outside main target</td><td><code>&lt;div id="status" hx-swap-oob="true"&gt;</code></td></tr>
<tr><td><strong>Autofocus</strong></td><td>Input receives focus when rendered</td><td><code>&lt;input autofocus&gt;</code> (use sparingly, can disorient people using SR)</td></tr>
<tr><td><strong>Focus order</strong></td><td>Sequence of Tab navigation (WCAG 2.4.3)</td><td>Edit button ‚Üí Title input ‚Üí Save ‚Üí Cancel</td></tr>
<tr><td><strong>WCAG 3.3.1</strong></td><td>Error Identification (Level A)</td><td>Error must be identified + described + programmatically associated</td></tr>
<tr><td><strong>WCAG 4.1.3</strong></td><td>Status Messages (Level AA)</td><td>Status announced without focus change (live regions)</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="lab-checklist-1"><a class="header" href="#lab-checklist-1">Lab Checklist</a></h2>
<p>Before leaving lab, confirm:</p>
<ul>
<li><input disabled="" type="checkbox"/>
<strong>View/edit partials created</strong>: <code>templates/tasks/_item.peb</code> (updated with Edit button), <code>templates/tasks/_edit.peb</code> (new)</li>
<li><input disabled="" type="checkbox"/>
<strong>Routes implemented</strong>: GET/POST <code>/tasks/{id}/edit</code>, GET <code>/tasks/{id}/view</code></li>
<li><input disabled="" type="checkbox"/>
<strong>HTMX path works</strong>: Inline edit, validation, save (no page reload)</li>
<li><input disabled="" type="checkbox"/>
<strong>No-JS path works</strong>: Edit, validation, save (page reloads)</li>
<li><input disabled="" type="checkbox"/>
<strong>Keyboard accessible</strong>: Tab through all controls, submit with Enter</li>
<li><input disabled="" type="checkbox"/>
<strong>Screen reader tested</strong>: NVDA/VoiceOver announces labels, hints, errors, status</li>
<li><input disabled="" type="checkbox"/>
<strong>Evidence collected</strong>: Screenshots + testing notes in <code>wk07/evidence/</code></li>
<li><input disabled="" type="checkbox"/>
<strong>Code committed</strong>: <code>git add .</code>, <code>git commit -m "wk7-lab1: inline edit with dual-path + ARIA"</code></li>
</ul>
<hr />
<h2 id="next-steps-1"><a class="header" href="#next-steps-1">Next Steps</a></h2>
<p>In <strong>Week 7 Lab 2</strong> you will:</p>
<ol>
<li>Run structured accessibility audit (WCAG checklist, heuristics)</li>
<li>Log findings in inclusive backlog</li>
<li>Implement <strong>one priority fix</strong> from backlog (error summary, focus indicator, etc.)</li>
<li>Package evidence for Task 1 (Gradescope submission)</li>
</ol>
<p><strong>Preparation</strong>:</p>
<ul>
<li>Review backlog from Week 6 (<code>backlog/backlog.csv</code>)</li>
<li>Install axe DevTools browser extension</li>
<li>Bring inline edit code from Lab 1 (working state)</li>
</ul>
<hr />
<p><strong>Lab authored by</strong>: COMP2850 Teaching Team, University of Leeds
<strong>Last updated</strong>: 2025-01-14
<strong>Licence</strong>: Academic use only (not for redistribution)</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-7--lab-1--student-guide-ethics--inline-edit"><a class="header" href="#week-7--lab-1--student-guide-ethics--inline-edit">Week 7 ‚Ä¢ Lab 1 ‚Äî Student Guide: Ethics &amp; Inline Edit</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-7-orange" alt="Week 7" />
<img src="https://img.shields.io/badge/Lab-1-green" alt="Lab 1" />
<img src="https://img.shields.io/badge/Type-Student_Guide-purple" alt="Guide" /></p>
<blockquote>
<p><strong>Purpose</strong>: Week 7 Lab 1 adds inline editing with accessible focus management and ethics-by-design practices. If you‚Äôre struggling with the implementation, this guide provides working code and verification steps.</p>
</blockquote>
<hr />
<h2 id="deliverables"><a class="header" href="#deliverables">Deliverables</a></h2>
<p>By the end of this lab:</p>
<ul>
<li>‚úÖ <code>wk07/ethics/data-boundaries.md</code> - Privacy-by-design documentation</li>
<li>‚úÖ Updated <code>.gitignore</code> for sensitive data</li>
<li>‚úÖ <code>templates/tasks/_edit.peb</code> - Edit mode template</li>
<li>‚úÖ Updated <code>templates/tasks/_item.peb</code> - Added Edit button</li>
<li>‚úÖ Routes: <code>GET /tasks/{id}/edit</code>, <code>POST /tasks/{id}/edit</code>, <code>GET /tasks/{id}/view</code></li>
<li>‚úÖ Keyboard + screen reader testing verification</li>
</ul>
<hr />
<h2 id="part-1-ethics-setup-15-minutes"><a class="header" href="#part-1-ethics-setup-15-minutes">Part 1: Ethics Setup (15 minutes)</a></h2>
<h3 id="create-data-boundaries-doc"><a class="header" href="#create-data-boundaries-doc">Create Data Boundaries Doc</a></h3>
<p><strong>Create</strong> <code>wk07/ethics/data-boundaries.md</code>:</p>
<details>
<summary>Click to expand: Data Boundaries Template</summary>
<pre><code class="language-markdown"># Data Boundaries ‚Äî Week 7

## What We Collect (Allowed)
- **Pseudonymised session IDs**: Random 6-char hex (e.g., `P1_a3f7`)
- **Task metadata**: Title, completion status, timestamps
- **Interaction logs**: HTTP requests, response times, error codes
- **Accessibility testing notes**: "NVDA announced X", "Focus moved to Y"

## What We DO NOT Collect (Prohibited)
- ‚ùå Real names (use pseudonyms: Participant A, P1, etc.)
- ‚ùå Student ID numbers
- ‚ùå Email addresses
- ‚ùå IP addresses (Ktor logs disabled)
- ‚ùå Personal task content beyond module examples

## Storage &amp; Retention
- **Location**: Local CSV files (`data/tasks.csv`, `data/metrics.csv`)
- **Access**: Researcher, lab partner, module staff (on request)
- **Encryption**: Standard filesystem permissions (chmod 600)
- **Deletion**: End of Semester 1 (January 2025) OR anonymised for portfolio

## Privacy by Design Principles Applied
1. **Data minimisation**: Only collect session ID (not name)
2. **Purpose limitation**: Metrics for HCI evaluation only (not sold/shared)
3. **Storage limitation**: Delete after assessment complete
4. **Integrity &amp; confidentiality**: Local storage (not cloud), Git repo private

## Ethics Risks Identified
| Risk | Mitigation |
|------|-----------|
| Task titles contain sensitive info | Provide example tasks; warn against personal content |
| Session IDs linked to participants | Use randomised IDs; don't store mapping |
| Git repo accidentally public | Verify remote is private; add `.gitignore` for `/data` |
| Screenshots include PII | Crop to relevant UI; blur names |

---

**Reference**: ICO (2024). Guide to GDPR, &lt;https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/&gt;
</code></pre>
</details>
<h3 id="update-gitignore"><a class="header" href="#update-gitignore">Update <code>.gitignore</code></a></h3>
<p>Add these lines to exclude sensitive data:</p>
<pre><code class="language-bash"># Sensitive data
/data/tasks.csv
/data/metrics.csv
/wk*/research/*notes.md
*.log
</code></pre>
<p><strong>Rationale</strong>: Even with pseudonyms, interview notes could be re-identified. Keep local, don‚Äôt push.</p>
<p><strong>Checklist</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Data boundaries documented</li>
<li><input disabled="" type="checkbox"/>
<code>.gitignore</code> updated</li>
<li><input disabled="" type="checkbox"/>
Consent protocol from Week 6 still valid</li>
</ul>
<hr />
<h2 id="part-2-inline-edit-templates-optional-code"><a class="header" href="#part-2-inline-edit-templates-optional-code">Part 2: Inline Edit Templates (Optional Code)</a></h2>
<details>
<summary>Click to expand: Update <code>templates/tasks/_item.peb</code> (Add Edit button)</summary>
<pre><code class="language-pebble">&lt;li id="task-{{ task.id }}" class="task-view"&gt;
  &lt;span class="task-title"&gt;{{ task.title }}&lt;/span&gt;

  {# NEW: Edit button (dual-mode) #}
  &lt;form action="/tasks/{{ task.id }}/edit" method="get" style="display: inline;"
        hx-get="/tasks/{{ task.id }}/edit"
        hx-target="#task-{{ task.id }}"
        hx-swap="outerHTML"&gt;
    &lt;button type="submit" aria-label="Edit task: {{ task.title }}"&gt;Edit&lt;/button&gt;
  &lt;/form&gt;

  {# Existing: Delete button #}
  &lt;form action="/tasks/{{ task.id }}/delete" method="post" style="display: inline;"
        hx-post="/tasks/{{ task.id }}/delete"
        hx-target="#task-{{ task.id }}"
        hx-swap="outerHTML"&gt;
    &lt;button type="submit" aria-label="Delete task: {{ task.title }}"&gt;Delete&lt;/button&gt;
  &lt;/form&gt;
&lt;/li&gt;
</code></pre>
<p><strong>Key points</strong>:</p>
<ul>
<li><code>hx-get="/tasks/{id}/edit"</code> - HTMX path (returns edit form HTML)</li>
<li><code>action="/tasks/{id}/edit" method="get"</code> - No-JS path (full page with edit form)</li>
<li><code>hx-swap="outerHTML"</code> - Replaces entire <code>&lt;li&gt;</code> with edit form</li>
</ul>
</details>
<details>
<summary>Click to expand: Create <code>templates/tasks/_edit.peb</code> (new file)</summary>
<pre><code class="language-pebble">{# Edit mode partial - shown when person clicks "Edit" #}
{# WCAG 3.3.2: Provide labels for all form inputs #}

&lt;li id="task-{{ task.id }}" class="task-edit"&gt;
  &lt;form action="/tasks/{{ task.id }}/edit" method="post"
        hx-post="/tasks/{{ task.id }}/edit"
        hx-target="#task-{{ task.id }}"
        hx-swap="outerHTML"&gt;

    &lt;label for="title-{{ task.id }}" class="visually-hidden"&gt;Edit task title&lt;/label&gt;
    &lt;input type="text"
           id="title-{{ task.id }}"
           name="title"
           value="{{ task.title }}"
           required
           aria-describedby="hint-{{ task.id }}"
           autofocus&gt;
    &lt;small id="hint-{{ task.id }}"&gt;Press Enter to save, Esc to cancel.&lt;/small&gt;

    {# Save button #}
    &lt;button type="submit" aria-label="Save changes to: {{ task.title }}"&gt;Save&lt;/button&gt;

    {# Cancel button (dual-mode) #}
    &lt;a href="/tasks"
       hx-get="/tasks/{{ task.id }}/view"
       hx-target="#task-{{ task.id }}"
       hx-swap="outerHTML"
       role="button"
       aria-label="Cancel editing: {{ task.title }}"&gt;
      Cancel
    &lt;/a&gt;
  &lt;/form&gt;
&lt;/li&gt;
</code></pre>
<p><strong>Key accessibility features</strong>:</p>
<ul>
<li><code>autofocus</code> - Keyboard focus moves to input immediately</li>
<li><code>aria-describedby</code> - Links hint text to input for screen readers</li>
<li><code>visually-hidden</code> label - People using screen readers hear ‚ÄúEdit task title‚Äù without visual clutter</li>
<li>Dual-mode Cancel (HTMX swaps to view, no-JS goes to <code>/tasks</code>)</li>
</ul>
</details>
<hr />
<h2 id="part-3-inline-edit-routes-optional-code"><a class="header" href="#part-3-inline-edit-routes-optional-code">Part 3: Inline Edit Routes (Optional Code)</a></h2>
<details>
<summary>Click to expand: Add to <code>src/main/kotlin/routes/TaskRoutes.kt</code></summary>
<pre><code class="language-kotlin">/**
 * GET /tasks/{id}/edit - Show edit form
 * Dual-mode: HTMX returns _edit.peb fragment, no-JS returns full page
 */
get("/tasks/{id}/edit") {
    val id = call.parameters["id"]?.toIntOrNull()
    val task = id?.let { TaskRepository.get(it) }

    if (task == null) {
        call.respond(HttpStatusCode.NotFound, "Task not found")
        return@get
    }

    if (call.isHtmx()) {
        // HTMX: Return just the edit form fragment
        val html = call.renderTemplate("tasks/_edit.peb", mapOf("task" to task))
        call.respondText(html, ContentType.Text.Html)
    } else {
        // No-JS: Return full page with task in edit mode
        val html = call.renderTemplate("tasks/index.peb", mapOf(
            "title" to "Edit Task",
            "tasks" to TaskRepository.all(),
            "editingTaskId" to id
        ))
        call.respondText(html, ContentType.Text.Html)
    }
}

/**
 * POST /tasks/{id}/edit - Save edits
 * Dual-mode: HTMX returns _item.peb fragment, no-JS redirects to /tasks
 */
post("/tasks/{id}/edit") {
    val id = call.parameters["id"]?.toIntOrNull()
    val newTitle = call.receiveParameters()["title"]?.trim()

    if (id == null || newTitle.isNullOrBlank()) {
        call.respond(HttpStatusCode.BadRequest, "Invalid input")
        return@post
    }

    val updated = TaskRepository.update(id, newTitle)

    if (updated == null) {
        call.respond(HttpStatusCode.NotFound, "Task not found")
        return@post
    }

    if (call.isHtmx()) {
        // HTMX: Return updated view mode + status
        val item = call.renderTemplate("tasks/_item.peb", mapOf("task" to updated))
        val status = """&lt;div id="status" hx-swap-oob="true"&gt;Task updated to "${updated.title}".&lt;/div&gt;"""
        call.respondText(item + status, ContentType.Text.Html)
    } else {
        // No-JS: PRG redirect
        call.respondRedirect("/tasks")
    }
}

/**
 * GET /tasks/{id}/view - Cancel edit (HTMX only)
 * Returns task in view mode without saving changes
 */
get("/tasks/{id}/view") {
    val id = call.parameters["id"]?.toIntOrNull()
    val task = id?.let { TaskRepository.get(it) }

    if (task == null) {
        call.respond(HttpStatusCode.NotFound)
        return@get
    }

    val html = call.renderTemplate("tasks/_item.peb", mapOf("task" to task))
    call.respondText(html, ContentType.Text.Html)
}
</code></pre>
<p><strong>Note</strong>: You‚Äôll need to add <code>update()</code> method to <code>TaskRepository</code>:</p>
<pre><code class="language-kotlin">fun update(id: Int, newTitle: String): Task? {
    val task = tasks.find { it.id == id } ?: return null
    task.title = newTitle
    persist()
    return task
}
</code></pre>
</details>
<hr />
<h2 id="part-4-verification-checklist"><a class="header" href="#part-4-verification-checklist">Part 4: Verification Checklist</a></h2>
<h3 id="dual-mode-testing-1"><a class="header" href="#dual-mode-testing-1">Dual-Mode Testing</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
<strong>HTMX mode</strong>: Click Edit ‚Üí form appears in place ‚Üí type new title ‚Üí click Save ‚Üí view mode returns</li>
<li><input disabled="" type="checkbox"/>
<strong>HTMX cancel</strong>: Click Edit ‚Üí click Cancel ‚Üí returns to view mode without saving</li>
<li><input disabled="" type="checkbox"/>
<strong>No-JS mode</strong>: Disable JavaScript ‚Üí click Edit ‚Üí full page loads with edit form ‚Üí save ‚Üí redirects to <code>/tasks</code></li>
</ul>
<h3 id="keyboard-navigation"><a class="header" href="#keyboard-navigation">Keyboard Navigation</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
Click Edit ‚Üí focus moves to input field automatically (<code>autofocus</code>)</li>
<li><input disabled="" type="checkbox"/>
Type new title ‚Üí press Enter ‚Üí saves (form submission)</li>
<li><input disabled="" type="checkbox"/>
Click Edit ‚Üí press Tab ‚Üí reaches Save button ‚Üí press Enter ‚Üí saves</li>
<li><input disabled="" type="checkbox"/>
Click Edit ‚Üí press Tab ‚Üí reaches Cancel ‚Üí press Enter ‚Üí cancels</li>
</ul>
<h3 id="screen-reader-testing-if-available"><a class="header" href="#screen-reader-testing-if-available">Screen Reader Testing (if available)</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
Navigate to Edit button ‚Üí hears ‚ÄúEdit task: [title]‚Äù</li>
<li><input disabled="" type="checkbox"/>
Activate Edit ‚Üí hears ‚ÄúEdit task title, edit text‚Äù</li>
<li><input disabled="" type="checkbox"/>
Input has hint ‚Üí hears ‚ÄúPress Enter to save, Esc to cancel‚Äù</li>
<li><input disabled="" type="checkbox"/>
Save ‚Üí hears ‚ÄúTask updated to [new title]‚Äù (status message)</li>
</ul>
<h3 id="focus-management"><a class="header" href="#focus-management">Focus Management</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
After clicking Edit: focus is on input field</li>
<li><input disabled="" type="checkbox"/>
After saving: focus should be on the updated task (check with Tab)</li>
<li><input disabled="" type="checkbox"/>
After cancelling: focus should return to Edit button</li>
</ul>
<hr />
<h2 id="common-issues"><a class="header" href="#common-issues">Common Issues</a></h2>
<h3 id="focus-doesnt-move-to-input"><a class="header" href="#focus-doesnt-move-to-input">‚ÄúFocus doesn‚Äôt move to input‚Äù</a></h3>
<p><strong>Fix</strong>: Confirm <code>autofocus</code> attribute is on <code>&lt;input&gt;</code> in <code>_edit.peb</code></p>
<h3 id="cancel-button-doesnt-work-in-no-js-mode"><a class="header" href="#cancel-button-doesnt-work-in-no-js-mode">‚ÄúCancel button doesn‚Äôt work in no-JS mode‚Äù</a></h3>
<p><strong>Expected</strong>: No-JS cancel navigates to <code>/tasks</code>. HTMX cancel swaps to view mode. This is correct dual-mode behaviour.</p>
<h3 id="save-doesnt-update-the-title"><a class="header" href="#save-doesnt-update-the-title">‚ÄúSave doesn‚Äôt update the title‚Äù</a></h3>
<p><strong>Check</strong>: <code>TaskRepository.update()</code> method exists and calls <code>persist()</code> to save CSV</p>
<h3 id="screen-reader-doesnt-announce-hint"><a class="header" href="#screen-reader-doesnt-announce-hint">‚ÄúScreen reader doesn‚Äôt announce hint‚Äù</a></h3>
<p><strong>Fix</strong>: Verify <code>aria-describedby="hint-{{ task.id }}"</code> links to <code>&lt;small id="hint-{{ task.id }}"&gt;</code></p>
<hr />
<h2 id="commit--continue-2"><a class="header" href="#commit--continue-2">Commit &amp; Continue</a></h2>
<pre><code class="language-bash">git add wk07/ templates/ src/
git commit -m "feat(wk7-lab1): ethics documentation + inline edit with dual-path

- Added data boundaries and privacy-by-design documentation
- Implemented inline edit with view/edit mode partials
- Added dual-path routes (HTMX fragment + no-JS full page)
- Verified keyboard navigation and focus management
- Tested with screen reader (NVDA/VoiceOver)
- Updated .gitignore to exclude sensitive research data

Addresses Week 7 Lab 1 requirements."
</code></pre>
<p><strong>Next</strong>: Week 7 Lab 2 - Accessibility audit and inclusive fixes from backlog.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-7--lab-2-accessibility-audit-backlog--inclusive-fix"><a class="header" href="#week-7--lab-2-accessibility-audit-backlog--inclusive-fix">Week 7 ‚Ä¢ Lab 2: Accessibility Audit, Backlog &amp; Inclusive Fix</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-7-orange" alt="Week 7" />
<img src="https://img.shields.io/badge/Lab-2-green" alt="Lab 2" />
<img src="https://img.shields.io/badge/Status-Draft-yellow" alt="Status" /></p>
<hr />
<h2 id="terminology-note-3"><a class="header" href="#terminology-note-3">Terminology Note</a></h2>
<p>Throughout COMP2850 we use <strong>people-centred language</strong> (e.g., ‚Äúperson using a screen reader‚Äù) rather than deficit-based terms (e.g., ‚Äúblind user‚Äù). This reflects contemporary inclusive-design practice and acknowledges that disability arises from environmental barriers, not individual impairment.</p>
<hr />
<h2 id="pre-reading-3"><a class="header" href="#pre-reading-3">Pre-reading</a></h2>
<p><strong>Essential</strong></p>
<ul>
<li>Ensure your Week 7 starter repo clone is up to date (inline edit changes committed)</li>
<li><a href="https://www.w3.org/WAI/WCAG22/quickref/">W3C (2024). WCAG 2.2 Quick Reference</a></li>
<li><a href="https://www.deque.com/axe/devtools/">axe DevTools Documentation</a></li>
<li><a href="https://www.gov.uk/service-manual/helping-people-to-use-your-service/making-your-service-accessible-an-introduction">GOV.UK: Making Your Service Accessible</a></li>
</ul>
<p><strong>Recommended</strong></p>
<ul>
<li><a href="https://webaim.org/standards/wcag/checklist">WebAIM: WCAG 2 Checklist</a></li>
<li><a href="https://www.nngroup.com/articles/how-to-conduct-a-heuristic-evaluation/">Nielsen, J. (1994). ‚ÄúHeuristic Evaluation‚Äù</a></li>
<li><a href="https://www.cs.umd.edu/~ben/">Shneiderman et al. (2016). <em>Designing the User Interface</em>, Ch. 3: Guidelines</a></li>
</ul>
<hr />
<h2 id="introduction-3"><a class="header" href="#introduction-3">Introduction</a></h2>
<h3 id="context-3"><a class="header" href="#context-3">Context</a></h3>
<p>In <strong>Week 7 Lab 1</strong> you implemented accessible inline edit with dual-path support (HTMX + no-JS), ARIA error identification, and status message announcements. You tested with keyboard and screen reader (NVDA/VoiceOver) and collected evidence.</p>
<p><strong>Now you‚Äôll audit the entire application systematically</strong> using:</p>
<ol>
<li><strong>WCAG 2.2 AA checklist</strong> (technical compliance)</li>
<li><strong>Heuristics</strong> (Nielsen‚Äôs 10 Usability Heuristics + Shneiderman‚Äôs Golden Rules)</li>
<li><strong>Assistive technology testing</strong> (keyboard, screen reader, no-JS, zoom)</li>
</ol>
<p>You‚Äôll log findings in your inclusive backlog (from Week 6), prioritise using <em>severity √ó inclusion risk</em>, and
<strong>implement one high-priority fix end-to-end</strong> (code ‚Üí verification ‚Üí evidence).</p>
<p>This lab directly feeds <strong>Gradescope Task 1</strong> (evaluation &amp; findings) and sets up <strong>Task 2</strong> (redesign &amp; verification).</p>
<h3 id="why-this-matters-4"><a class="header" href="#why-this-matters-4">Why This Matters</a></h3>
<p><strong>Professionally</strong>, accessibility audits are standard practice:</p>
<ul>
<li><strong>GOV.UK</strong> mandates WCAG 2.2 AA compliance before launch</li>
<li><strong>BBC</strong> runs quarterly audits with people using assistive technologies</li>
<li><strong>Microsoft</strong> uses automated (axe) + manual (SR) testing in CI/CD pipeline</li>
</ul>
<p><strong>Academically</strong>, this lab teaches:</p>
<ul>
<li><strong>Systematic evaluation</strong>: Structured checklists reduce bias (vs. ad-hoc testing)</li>
<li><strong>Triangulation</strong>: Automated tools + manual testing + feedback from people</li>
<li><strong>Evidence-based prioritisation</strong>: Data (backlog scores) beats intuition</li>
</ul>
<h2 id="learning-focus-3"><a class="header" href="#learning-focus-3">Learning Focus</a></h2>
<h3 id="lab-objectives-3"><a class="header" href="#lab-objectives-3">Lab Objectives</a></h3>
<p>By the end of this session, you will have:</p>
<ul>
<li>Conducted a structured accessibility audit using WCAG 2.2 AA criteria</li>
<li>Run axe DevTools audit and documented 5+ WCAG violations</li>
<li>Mapped violations to WCAG 2.2 success criteria</li>
<li>Populated inclusive backlog with severity + inclusion risk scores</li>
<li>Implemented one priority accessibility fix with regression testing</li>
</ul>
<h3 id="learning-outcomes-addressed-3"><a class="header" href="#learning-outcomes-addressed-3">Learning Outcomes Addressed</a></h3>
<p>This lab contributes to the following module Learning Outcomes (<a href="wk07/../references/learning-outcomes.html">full definitions</a>):</p>
<ul>
<li><strong>LO4</strong>: Evaluate for accessibility ‚Äî evidenced by axe audit + WCAG mapping</li>
<li><strong>LO6</strong>: Apply iterative design ‚Äî evidenced by fix implementation</li>
<li><strong>LO9</strong>: Apply inclusive design ‚Äî evidenced by WCAG 2.2 AA compliance</li>
<li><strong>LO12</strong>: Demonstrate professionalism ‚Äî evidenced by documentation + testing</li>
</ul>
<hr />
<h2 id="key-concepts-3"><a class="header" href="#key-concepts-3">Key Concepts</a></h2>
<h3 id="1-accessibility-audit-levels"><a class="header" href="#1-accessibility-audit-levels">1. Accessibility Audit Levels</a></h3>
<p><strong>Level 1: Automated testing</strong> (20-30% of WCAG issues)</p>
<ul>
<li>Tools: axe DevTools, WAVE, Lighthouse</li>
<li>Fast, repeatable, catches low-hanging fruit</li>
<li><strong>Limitations</strong>: Can‚Äôt detect non-semantic HTML, focus order issues, SR announcements</li>
</ul>
<p><strong>Level 2: Manual testing</strong> (keyboard, screen reader)</p>
<ul>
<li>Catches 50-60% of issues</li>
<li>Time-consuming, requires expertise</li>
<li><strong>Essential for</strong>: Focus management, ARIA announcements, keyboard traps</li>
</ul>
<p><strong>Level 3: Testing with people</strong> (including disabled people)</p>
<ul>
<li>Catches 90%+ of issues</li>
<li>Gold standard, but expensive and slow</li>
<li><strong>Week 9</strong>: You‚Äôll run task-based pilots (mini evaluations with people)</li>
</ul>
<p><strong>COMP2850 approach</strong>: Levels 1 + 2 in Labs 7-8; Level 3 in Week 9.</p>
<blockquote>
<p><strong>‚ö†Ô∏è Critical</strong>: Automated tools alone miss 70-80% of accessibility issues. You MUST complete both automated (axe) AND manual (keyboard + screen reader) testing to discover all intentional errors in this lab. Students who skip manual testing will fail to identify critical ARIA issues that affect people using screen readers.</p>
</blockquote>
<h3 id="2-wcag-22-conformance-levels"><a class="header" href="#2-wcag-22-conformance-levels">2. WCAG 2.2 Conformance Levels</a></h3>
<p><strong>Level A</strong> (minimum, legal requirement in many jurisdictions):</p>
<ul>
<li>Examples: 1.3.1 Info and Relationships, 2.1.1 Keyboard, 3.3.1 Error Identification</li>
</ul>
<p><strong>Level AA</strong> (target for most organisations):</p>
<ul>
<li>Examples: 1.4.3 Contrast (Minimum), 2.4.7 Focus Visible, 4.1.3 Status Messages</li>
</ul>
<p><strong>Level AAA</strong> (enhanced, not always achievable):</p>
<ul>
<li>Examples: 1.4.6 Contrast (Enhanced, 7:1), 2.1.3 Keyboard (No Exception)</li>
</ul>
<p><strong>COMP2850 target</strong>: AA compliance (industry standard).</p>
<h3 id="3-severity-scoring-comp2850-framework"><a class="header" href="#3-severity-scoring-comp2850-framework">3. Severity Scoring (COMP2850 Framework)</a></h3>
<p><strong>High (3 points)</strong>:</p>
<ul>
<li>Blocks task completion entirely (e.g., form unsubmittable via keyboard)</li>
<li>Excludes entire group (e.g., no screen reader access)</li>
<li>WCAG Level A failure</li>
</ul>
<p><strong>Medium (2 points)</strong>:</p>
<ul>
<li>Makes task significantly harder (e.g., poor contrast, slow to navigate)</li>
<li>Affects multiple groups (e.g., keyboard + screen reader)</li>
<li>WCAG Level AA failure</li>
</ul>
<p><strong>Low (1 point)</strong>:</p>
<ul>
<li>Minor friction (e.g., missing hint text, suboptimal label)</li>
<li>Affects niche scenario (e.g., rare browser/AT combination)</li>
<li>WCAG AAA or best practice (not required)</li>
</ul>
<h3 id="4-inclusion-risk-tagging"><a class="header" href="#4-inclusion-risk-tagging">4. Inclusion Risk Tagging</a></h3>
<p><strong>Tags</strong> identify who‚Äôs affected:</p>
<ul>
<li><strong>SR</strong> (Screen reader): NVDA, JAWS, VoiceOver, TalkBack</li>
<li><strong>Keyboard</strong>: People using keyboards only, motor impairments, RSI</li>
<li><strong>Cognitive</strong>: ADHD, dyslexia, memory impairments</li>
<li><strong>Low vision</strong>: People using magnification, high contrast needs</li>
<li><strong>Motor</strong>: Tremor, limited dexterity, people using switches</li>
<li><strong>Hearing</strong>: Caption/transcript needs (not applicable to this project yet)</li>
<li><strong>Situational</strong>: Bright light, broken mouse, noisy environment</li>
</ul>
<p><strong>Example</strong>: ‚ÄúDelete button lacks keyboard access‚Äù = <strong>Keyboard + Motor</strong> tags.</p>
<h3 id="5-nielsens-10-usability-heuristics-applied-to-accessibility"><a class="header" href="#5-nielsens-10-usability-heuristics-applied-to-accessibility">5. Nielsen‚Äôs 10 Usability Heuristics (Applied to Accessibility)</a></h3>
<ol>
<li><strong>Visibility of system status</strong>: Screen readers announce state changes</li>
<li><strong>Match between system and real world</strong>: Plain language (not jargon)</li>
<li><strong>User control and freedom</strong>: Undo, cancel actions</li>
<li><strong>Consistency and standards</strong>: Follow ARIA patterns, GOV.UK conventions</li>
<li><strong>Error prevention</strong>: Validation before submission</li>
<li><strong>Recognition rather than recall</strong>: Labels visible (not just placeholders)</li>
<li><strong>Flexibility and efficiency of use</strong>: Keyboard shortcuts for experienced people</li>
<li><strong>Aesthetic and minimalist design</strong>: No clutter (easier for people using SR/people with cognitive disabilities)</li>
<li><strong>Help people recognise, diagnose, and recover from errors</strong>: Specific error messages</li>
<li><strong>Help and documentation</strong>: Context-sensitive help text</li>
</ol>
<hr />
<h2 id="activity-1-automated-audit-with-axe-devtools"><a class="header" href="#activity-1-automated-audit-with-axe-devtools">Activity 1: Automated Audit with axe DevTools</a></h2>
<p><strong>Time</strong>: 20 minutes
<strong>Materials</strong>: Chrome/Firefox with axe DevTools extension</p>
<h3 id="step-1-install-axe-devtools"><a class="header" href="#step-1-install-axe-devtools">Step 1: Install axe DevTools</a></h3>
<p><strong>Chrome</strong>:</p>
<ol>
<li>Visit <a href="https://chrome.google.com/webstore">Chrome Web Store</a></li>
<li>Search ‚Äúaxe DevTools‚Äù</li>
<li>Install extension</li>
</ol>
<p><strong>Firefox</strong>:</p>
<ol>
<li>Visit <a href="https://addons.mozilla.org/">Firefox Add-ons</a></li>
<li>Search ‚Äúaxe DevTools‚Äù</li>
<li>Install add-on</li>
</ol>
<h3 id="step-2-run-automated-scan"><a class="header" href="#step-2-run-automated-scan">Step 2: Run Automated Scan</a></h3>
<ol>
<li><strong>Open http://localhost:8080/tasks</strong> (ensure server running)</li>
<li><strong>Open DevTools</strong> (F12)</li>
<li><strong>Navigate to ‚Äúaxe DevTools‚Äù tab</strong></li>
<li><strong>Click ‚ÄúScan ALL of my page‚Äù</strong></li>
<li><strong>Wait 5-10 seconds</strong> for results</li>
</ol>
<h3 id="step-3-review-findings"><a class="header" href="#step-3-review-findings">Step 3: Review Findings</a></h3>
<p>axe categorises issues:</p>
<div class="table-wrapper"><table><thead><tr><th>Category</th><th>Severity</th><th>Action</th></tr></thead><tbody>
<tr><td><strong>Critical</strong></td><td>Blocks access (Level A failures)</td><td>Must fix</td></tr>
<tr><td><strong>Serious</strong></td><td>Major barriers (Level A/AA failures)</td><td>Should fix</td></tr>
<tr><td><strong>Moderate</strong></td><td>Noticeable issues (Level AA/AAA)</td><td>Consider fixing</td></tr>
<tr><td><strong>Minor</strong></td><td>Best practice violations</td><td>Low priority</td></tr>
</tbody></table>
</div>
<h3 id="step-4-document-automated-findings"><a class="header" href="#step-4-document-automated-findings">Step 4: Document Automated Findings</a></h3>
<p>Create <code>wk07/audit/axe-report.md</code>:</p>
<pre><code class="language-markdown"># axe DevTools Audit Report ‚Äî Week 7

**Date**: [YYYY-MM-DD]
**URL**: http://localhost:8080/tasks
**Tool**: axe DevTools 4.x
**Scope**: Full page scan (add form + task list)

---

## Summary
- **Critical**: 0
- **Serious**: 2
- **Moderate**: 1
- **Minor**: 3
- **Total**: 6 issues

---

## Critical Issues
None detected.

---

## Serious Issues

### Issue 1: Form label missing (Serious)
**Element**: `&lt;input id="title" name="title"&gt;`
**Rule**: `label` (WCAG 1.3.1, 4.1.2)
**Description**: Form element does not have an associated label.
**Impact**: Screen readers don't know what the input is for.
**Fix**: Ensure `&lt;label for="title"&gt;Title&lt;/label&gt;` exists and is visible (not visually-hidden).
**Status**: ‚ùå **FALSE POSITIVE** ‚Äî Label exists in template. Possible axe bug or dynamic rendering issue. Verify manually.

### Issue 2: Insufficient color contrast (Serious)
**Element**: `&lt;button type="submit"&gt;Delete&lt;/button&gt;`
**Rule**: `color-contrast` (WCAG 1.4.3)
**Description**: Text color #6c757d on white background = 4.2:1 (fails AA 4.5:1)
**Impact**: People with low vision struggle to read button text.
**Fix**: Change button color to #495057 (darker gray, 7:1 contrast).
**Status**: ‚úÖ **CONFIRMED** ‚Äî Add to backlog as High severity.

---

## Moderate Issues

### Issue 3: Skip link not keyboard-accessible (Moderate)
**Element**: `&lt;a href="#main" class="skip-link"&gt;`
**Rule**: `skip-link` (best practice)
**Description**: Skip link exists but positioned off-screen; unclear if focus visible.
**Impact**: Keyboards may not discover skip link.
**Fix**: Ensure `:focus` pseudo-class makes skip link visible (already implemented in CSS, but verify).
**Status**: ‚úÖ **VERIFIED** ‚Äî Tab reveals skip link. No action needed.

---

## Minor Issues

### Issue 4-6: [Document remaining minor issues]
[Low priority, defer to Semester 2]

---

## Actions
1. **False positive (Issue 1)**: Verify label exists with manual inspection
2. **High priority (Issue 2)**: Fix contrast ratio ‚Üí Add to backlog
3. **Verified (Issue 3)**: No action needed

---

**Next step**: Manual testing to catch issues axe misses (focus order, SR announcements, keyboard traps).
</code></pre>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ axe scan completed</li>
<li>‚úÖ Findings documented in <code>axe-report.md</code></li>
<li>‚úÖ At least 1 serious issue identified (contrast, label, etc.)</li>
</ul>
<hr />
<h2 id="activity-2-manual-wcag-checklist"><a class="header" href="#activity-2-manual-wcag-checklist">Activity 2: Manual WCAG Checklist</a></h2>
<p><strong>Time</strong>: 30 minutes
<strong>Materials</strong>: WCAG 2.2 Quick Reference, keyboard, screen reader</p>
<h3 id="step-1-create-wcag-checklist-template"><a class="header" href="#step-1-create-wcag-checklist-template">Step 1: Create WCAG Checklist Template</a></h3>
<p>Create <code>wk07/audit/wcag-checklist.md</code>:</p>
<pre><code class="language-markdown"># WCAG 2.2 AA Checklist ‚Äî Week 7

**Date**: [YYYY-MM-DD]
**Scope**: Task manager (add, edit, delete flows)
**Tester**: [Your Name]

---

## Perceivable (Principle 1)

### 1.1 Text Alternatives
| Criterion | Level | Status | Evidence | Notes |
|-----------|-------|--------|----------|-------|
| 1.1.1 Non-text Content | A | N/A | No images yet | Will add in Week 8 |

### 1.3 Adaptable
| Criterion | Level | Status | Evidence | Notes |
|-----------|-------|--------|----------|-------|
| 1.3.1 Info and Relationships | A | ‚úÖ Pass | `&lt;label for="title"&gt;` links to input | Semantic HTML (`&lt;main&gt;`, `&lt;section&gt;`, `&lt;ul&gt;`) |
| 1.3.2 Meaningful Sequence | A | ‚úÖ Pass | Tab order: skip link ‚Üí add form ‚Üí task list | Logical reading order |

### 1.4 Distinguishable
| Criterion | Level | Status | Evidence | Notes |
|-----------|-------|--------|----------|-------|
| 1.4.3 Contrast (Minimum) | AA | ‚ùå Fail | Delete button #6c757d = 4.2:1 | Needs 4.5:1 (AA) |
| 1.4.11 Non-text Contrast | AA | ‚úÖ Pass | Focus outline 3px solid #1976d2 | Sufficient contrast |

---

## Operable (Principle 2)

### 2.1 Keyboard Accessible
| Criterion | Level | Status | Evidence | Notes |
|-----------|-------|--------|----------|-------|
| 2.1.1 Keyboard | A | ‚úÖ Pass | All features accessible via Tab/Enter/Space | Tested: add, edit, delete, cancel |
| 2.1.2 No Keyboard Trap | A | ‚úÖ Pass | No traps detected | Can Tab out of all forms |

### 2.4 Navigable
| Criterion | Level | Status | Evidence | Notes |
|-----------|-------|--------|----------|-------|
| 2.4.1 Bypass Blocks | A | ‚úÖ Pass | Skip link appears on Tab, jumps to #main | Tested with keyboard |
| 2.4.3 Focus Order | A | ‚úÖ Pass | Tab order: Edit ‚Üí Title ‚Üí Save ‚Üí Cancel | Logical sequence |
| 2.4.7 Focus Visible | AA | ‚ö†Ô∏è Partial | Pico.css default outline visible, but faint | Consider custom outline (3px solid) |

---

## Understandable (Principle 3)

### 3.2 Predictable
| Criterion | Level | Status | Evidence | Notes |
|-----------|-------|--------|----------|-------|
| 3.2.1 On Focus | A | ‚úÖ Pass | No context change on focus | Only explicit button clicks trigger actions |
| 3.2.2 On Input | A | ‚úÖ Pass | No auto-submit on input change | Form submits only on button click |

### 3.3 Input Assistance
| Criterion | Level | Status | Evidence | Notes |
|-----------|-------|--------|----------|-------|
| 3.3.1 Error Identification | A | ‚úÖ Pass | Error: "Title is required. Please enter at least one character." | Specific, actionable |
| 3.3.2 Labels or Instructions | A | ‚úÖ Pass | All inputs have `&lt;label&gt;` + hint text | `aria-describedby` links to hint |
| 3.3.3 Error Suggestion | AA | ‚úÖ Pass | Error message includes correction hint | "Please enter at least one character" |

---

## Robust (Principle 4)

### 4.1 Compatible
| Criterion | Level | Status | Evidence | Notes |
|-----------|-------|--------|----------|-------|
| 4.1.2 Name, Role, Value | A | ‚úÖ Pass | All buttons have accessible names | `aria-label="Edit task: Buy milk"` |
| 4.1.3 Status Messages | AA | ‚úÖ Pass | `&lt;div role="status" aria-live="polite"&gt;` | Tested with NVDA |

---

## Summary
- **Total criteria evaluated**: 18
- **Pass**: 15
- **Fail**: 1 (1.4.3 Contrast)
- **Partial**: 1 (2.4.7 Focus Visible)
- **N/A**: 1

---

## High-Priority Failures
1. **1.4.3 Contrast (Minimum, AA)**: Delete button text fails 4.5:1 ratio
   - **Action**: Change Pico.css button color or add custom CSS

2. **2.4.7 Focus Visible (AA, Partial)**: Default outline may be too faint
   - **Action**: Add custom `:focus` styles (3px solid #1976d2)

---

**Next**: Add these findings to backlog with severity scores.
</code></pre>
<h3 id="step-2-test-each-criterion"><a class="header" href="#step-2-test-each-criterion">Step 2: Test Each Criterion</a></h3>
<p><strong>Keyboard testing</strong> (2.1.1, 2.1.2, 2.4.3):</p>
<ol>
<li>Tab through entire page</li>
<li>Activate all buttons with Enter/Space</li>
<li>Check for keyboard traps (can you Tab out of forms?)</li>
</ol>
<p><strong>Screen reader testing</strong> (4.1.2, 4.1.3):</p>
<ol>
<li>Start NVDA/VoiceOver</li>
<li>Navigate to each form field (listen for labels + hints)</li>
<li>Trigger error (listen for <code>role="alert"</code> announcement)</li>
<li>Save successfully (listen for status message)</li>
</ol>
<p><strong>Contrast testing</strong> (1.4.3):</p>
<ol>
<li>Open DevTools ‚Üí Inspect element</li>
<li>Check computed color values</li>
<li>Use <a href="https://webaim.org/resources/contrastchecker/">WebAIM Contrast Checker</a>
<ul>
<li>Foreground: #6c757d</li>
<li>Background: #ffffff</li>
<li><strong>Result</strong>: 4.2:1 (fails AA)</li>
</ul>
</li>
</ol>
<p><strong>Focus visible testing</strong> (2.4.7):</p>
<ol>
<li>Tab to each interactive element</li>
<li>Can you clearly see which element has focus?</li>
<li>Take screenshot of focus indicator</li>
</ol>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ WCAG checklist completed (at least 15 criteria)</li>
<li>‚úÖ Pass/Fail status recorded</li>
<li>‚úÖ Evidence cited (screenshot, manual test, tool output)</li>
</ul>
<hr />
<h2 id="activity-3-heuristic-evaluation"><a class="header" href="#activity-3-heuristic-evaluation">Activity 3: Heuristic Evaluation</a></h2>
<p><strong>Time</strong>: 20 minutes
<strong>Materials</strong>: Nielsen‚Äôs heuristics, Shneiderman‚Äôs Golden Rules</p>
<h3 id="step-1-apply-nielsens-heuristics"><a class="header" href="#step-1-apply-nielsens-heuristics">Step 1: Apply Nielsen‚Äôs Heuristics</a></h3>
<p>Create <code>wk07/audit/heuristics.md</code>:</p>
<pre><code class="language-markdown"># Heuristic Evaluation ‚Äî Week 7

**Evaluator**: [Your Name]
**Date**: [YYYY-MM-DD]
**Method**: Nielsen's 10 Usability Heuristics + Shneiderman's Golden Rules

---

## Nielsen's Heuristics

### 1. Visibility of System Status
**Rating**: 4/5 (Good)
**Evidence**:
- ‚úÖ Status messages announce add/delete/edit actions
- ‚úÖ ARIA live region updates (`role="status"`)
- ‚ö†Ô∏è No loading indicator for HTMX requests (instant for now, but could be slow on poor network)

**Accessibility implication**: Screen readers get confirmation via live region (WCAG 4.1.3).

**Issue identified**: None (meets WCAG). Enhancement: Add `hx-indicator` for slow requests.

---

### 2. Match Between System and Real World
**Rating**: 5/5 (Excellent)
**Evidence**:
- ‚úÖ Plain language: "Add Task", "Edit", "Delete" (not technical jargon)
- ‚úÖ Confirmation messages in natural language: "Task 'Buy milk' added successfully"

**Accessibility implication**: Simple language benefits cognitive disabilities, low digital literacy.

**Issue identified**: None.

---

### 3. Customer Control and Freedom
**Rating**: 4/5 (Good)
**Evidence**:
- ‚úÖ Cancel button in edit mode (escape hatch)
- ‚ùå No undo for delete (permanent action)

**Accessibility implication**: People with motor impairments may accidentally trigger delete.

**Issue identified**: **Medium severity** ‚Äî Add confirmation dialog or undo feature for delete.

---

### 4. Consistency and Standards
**Rating**: 5/5 (Excellent)
**Evidence**:
- ‚úÖ Semantic HTML (`&lt;button&gt;`, not `&lt;div onclick&gt;`)
- ‚úÖ Follows ARIA patterns (errors use `role="alert"`)
- ‚úÖ Consistent with GOV.UK patterns (error summary, hints)

**Accessibility implication**: Consistency reduces learning curve for AT.

**Issue identified**: None.

---

### 5. Error Prevention
**Rating**: 3/5 (Fair)
**Evidence**:
- ‚úÖ Client-side `required` attribute prevents blank submission
- ‚ö†Ô∏è Server-side validation catches blank titles (good), but no prevention of accidental delete

**Accessibility implication**: BenefitS from preventing errors before they happen.

**Issue identified**: **Medium severity** ‚Äî Delete button too easy to trigger accidentally (no confirmation).

---

### 6. Recognition Rather Than Recall
**Rating**: 4/5 (Good)
**Evidence**:
- ‚úÖ Labels always visible (not just placeholders)
- ‚úÖ Hint text persists below input (`aria-describedby`)
- ‚ö†Ô∏è Error message only appears after submission (could preview validation on blur)

**Accessibility implication**: Persistent labels help cognitive disabilities, memory impairments.

**Issue identified**: None (meets WCAG). Enhancement: Live validation on blur.

---

### 7. Flexibility and Efficiency of Use
**Rating**: 3/5 (Fair)
**Evidence**:
- ‚úÖ Keyboard shortcuts work (Enter submits, Escape cancels in some browsers)
- ‚ùå No custom shortcuts (e.g., Ctrl+E to edit first task)

**Accessibility implication**: Experienced people using keyboards could benefit from shortcuts.

**Issue identified**: **Low severity** ‚Äî Add keyboard shortcuts (defer to Semester 2).

---

### 8. Aesthetic and Minimalist Design
**Rating**: 5/5 (Excellent)
**Evidence**:
- ‚úÖ No clutter (only essential fields shown)
- ‚úÖ Edit form appears inline (progressive disclosure)
- ‚úÖ Status messages dismiss automatically (don't accumulate)

**Accessibility implication**: Minimalism reduces cognitive load, SR navigation time.

**Issue identified**: None.

---

### 9. Help People Recognise, Diagnose, and Recover from Errors
**Rating**: 5/5 (Excellent)
**Evidence**:
- ‚úÖ Error message specific: "Title is required. Please enter at least one character."
- ‚úÖ Error programmatically associated (`aria-describedby`, `role="alert"`)
- ‚úÖ Recovery path clear (fix input, resubmit)

**Accessibility implication**: Meets WCAG 3.3.1 (Error Identification, A) and 3.3.3 (Error Suggestion, AA).

**Issue identified**: None.

---

### 10. Help and Documentation
**Rating**: 2/5 (Poor)
**Evidence**:
- ‚ùå No help text beyond inline hints
- ‚ùå No "What is this?" links for fields

**Accessibility implication**: People with cognitive disabilities, people using the interface for the first time may struggle without documentation.

**Issue identified**: **Low severity** ‚Äî Add help tooltips or links to docs (defer to Semester 2).

---

## Summary of Issues

| Heuristic | Issue | Severity | Inclusion Risk |
|-----------|-------|----------|----------------|
| 3 (Control &amp; Freedom) | No undo for delete | Medium | Motor, Cognitive |
| 5 (Error Prevention) | Delete lacks confirmation | Medium | Motor, Cognitive |
| 7 (Flexibility) | No keyboard shortcuts | Low | Keyboard (experienced people) |
| 10 (Help) | No help documentation | Low | Cognitive, Low digital literacy |

---

**Next**: Add these to backlog.
</code></pre>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ Heuristic evaluation completed (10 heuristics)</li>
<li>‚úÖ Ratings assigned (1-5 scale)</li>
<li>‚úÖ Issues identified with severity</li>
</ul>
<hr />
<h2 id="activity-4-update-inclusive-backlog"><a class="header" href="#activity-4-update-inclusive-backlog">Activity 4: Update Inclusive Backlog</a></h2>
<p><strong>Time</strong>: 25 minutes
<strong>Materials</strong>: <code>backlog/backlog.csv</code>, audit findings</p>
<h3 id="step-1-consolidate-findings"><a class="header" href="#step-1-consolidate-findings">Step 1: Consolidate Findings</a></h3>
<p>Merge findings from:</p>
<ul>
<li>axe DevTools (<code>axe-report.md</code>)</li>
<li>WCAG checklist (<code>wcag-checklist.md</code>)</li>
<li>Heuristics (<code>heuristics.md</code>)</li>
<li>Week 6 needs-finding interviews</li>
</ul>
<h3 id="step-2-add-new-backlog-items"><a class="header" href="#step-2-add-new-backlog-items">Step 2: Add New Backlog Items</a></h3>
<p>Edit <code>backlog/backlog.csv</code>:</p>
<pre><code class="language-csv">id,title,story_ref,story_type,need,type,severity,inclusion_risk,evidence,notes,candidate_fix
9,Delete button text contrast 4.2:1 (fails AA),wk07/audit/axe-report.md#Issue2,WCAG violation,Visibility,Accessibility,High,"Low vision,Situational","axe: color-contrast; WCAG 1.4.3","Pico.css default gray #6c757d on white = 4.2:1; needs 4.5:1",true
10,Focus outline too faint (Pico.css default),wk07/audit/wcag-checklist.md#2.4.7,WCAG partial,Visibility,Accessibility,Medium,Keyboard,"Manual test: outline visible but faint","Add custom :focus { outline: 3px solid #1976d2; }",true
11,No confirmation for delete action,wk07/audit/heuristics.md#H3,Heuristic violation,Error prevention,Usability,Medium,"Motor,Cognitive","Nielsen H3 + H5","Accidental clicks cause permanent deletion; add confirmation dialog",false
12,No undo feature for delete,wk07/audit/heuristics.md#H3,Heuristic violation,Customer control,Usability,Low,"Motor,
Cognitive","Nielsen H3","Defer to Semester 2; requires state management",false
13,No help documentation or tooltips,wk07/audit/heuristics.md#H10,Heuristic violation,Learning support,Usability,Low,Cognitive,"Nielsen H10","Defer to Semester 2; low priority",false
</code></pre>
<h3 id="step-3-prioritise-with-scoring"><a class="header" href="#step-3-prioritise-with-scoring">Step 3: Prioritise with Scoring</a></h3>
<p><strong>Formula</strong>: <code>Priority = (Severity √ó 2) + (Inclusion Weight) + (WCAG Bonus)</code></p>
<ul>
<li><strong>Severity</strong>: High=3, Medium=2, Low=1 (√ó2 weighting)</li>
<li><strong>Inclusion Weight</strong>: +1 per group affected (max +3)</li>
<li><strong>WCAG Bonus</strong>: Level A failure=+2, Level AA failure=+1</li>
</ul>
<p><strong>Example (Item 9: Contrast)</strong>:</p>
<ul>
<li>Severity: High (3) √ó 2 = 6</li>
<li>Inclusion: Low vision + Situational = +2</li>
<li>WCAG: Level AA (1.4.3) = +1</li>
<li><strong>Total</strong>: 6 + 2 + 1 = <strong>9 (highest priority)</strong></li>
</ul>
<p><strong>Example (Item 11: Delete confirmation)</strong>:</p>
<ul>
<li>Severity: Medium (2) √ó 2 = 4</li>
<li>Inclusion: Motor + Cognitive = +2</li>
<li>WCAG: N/A = 0</li>
<li><strong>Total</strong>: 4 + 2 + 0 = <strong>6 (medium priority)</strong></li>
</ul>
<h3 id="step-4-select-candidate-fix"><a class="header" href="#step-4-select-candidate-fix">Step 4: Select Candidate Fix</a></h3>
<p>Mark <strong>1-2 items</strong> with <code>candidate_fix=true</code>. Criteria:</p>
<ul>
<li>Highest priority score</li>
<li>Fixable in 30-40 minutes (lab time constraint)</li>
<li>Clear success criteria (WCAG pass = verifiable)</li>
</ul>
<p><strong>Recommended fixes</strong>:</p>
<ol>
<li><strong>Item 9</strong> (Contrast): Change button color in CSS (10 min fix)</li>
<li><strong>Item 10</strong> (Focus outline): Add custom <code>:focus</code> styles (15 min fix)</li>
</ol>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ Backlog updated with 5+ new items from audits</li>
<li>‚úÖ Priority scores calculated</li>
<li>‚úÖ 1-2 items marked <code>candidate_fix=true</code></li>
</ul>
<hr />
<h2 id="activity-5-implement-one-priority-fix"><a class="header" href="#activity-5-implement-one-priority-fix">Activity 5: Implement One Priority Fix</a></h2>
<p><strong>Time</strong>: 35 minutes
<strong>Materials</strong>: Backlog, code editor</p>
<h3 id="step-1-choose-fix-target"><a class="header" href="#step-1-choose-fix-target">Step 1: Choose Fix Target</a></h3>
<p><strong>Selected</strong>: Item 9 (Delete button contrast)</p>
<p><strong>Why</strong>: Highest priority (WCAG AA failure), quick fix, measurable success.</p>
<h3 id="step-2-create-fix-plan"><a class="header" href="#step-2-create-fix-plan">Step 2: Create Fix Plan</a></h3>
<p>Create <code>wk07/fixes/fix09-contrast.md</code>:</p>
<pre><code class="language-markdown"># Fix 09: Delete Button Contrast (WCAG 1.4.3)

**Backlog ID**: 9
**WCAG Criterion**: 1.4.3 Contrast (Minimum, Level AA)
**Priority**: 9 (highest)

---

## Problem Statement
Delete button text color (#6c757d) on white background (#ffffff) = 4.2:1 contrast ratio.
**Fails**: WCAG AA requires 4.5:1 for normal text.

**Evidence**:
- axe DevTools: color-contrast (Serious)
- WebAIM Contrast Checker: 4.2:1 (Fail AA)
- Screenshot: `wk07/evidence/contrast-before.png`

---

## Target State
Contrast ratio ‚â• 4.5:1 (AA) or ‚â• 7:1 (AAA).

---

## Solution
Override Pico.css button color with darker gray or custom color.

**Option A**: Darker gray (#495057 = 7:1 contrast, passes AAA)
**Option B**: Custom blue (#1976d2 = 5.2:1 contrast, passes AA)

**Chosen**: Option A (darker gray) for consistency with Pico theme.

---

## Implementation

### Before (Current CSS)
Pico.css default:
```css
button {
  color: #6c757d; /* 4.2:1 contrast */
}
</code></pre>
<h3 id="after-custom-css"><a class="header" href="#after-custom-css">After (Custom CSS)</a></h3>
<p>Add to <code>base.peb</code> <code>&lt;style&gt;</code>:</p>
<pre><code class="language-css">button[type="submit"],
button {
  color: #495057 !important; /* 7:1 contrast (AAA) */
}
</code></pre>
<hr />
<h2 id="verification"><a class="header" href="#verification">Verification</a></h2>
<h3 id="step-1-visual-inspection"><a class="header" href="#step-1-visual-inspection">Step 1: Visual Inspection</a></h3>
<ul>
<li>Load http://localhost:8080/tasks</li>
<li>Inspect ‚ÄúDelete‚Äù button</li>
<li>Confirm text appears darker</li>
</ul>
<h3 id="step-2-contrast-check"><a class="header" href="#step-2-contrast-check">Step 2: Contrast Check</a></h3>
<ul>
<li>Use WebAIM Contrast Checker</li>
<li>Foreground: #495057</li>
<li>Background: #ffffff</li>
<li><strong>Expected</strong>: 7:1 (Pass AAA)</li>
</ul>
<h3 id="step-3-re-run-axe"><a class="header" href="#step-3-re-run-axe">Step 3: Re-run axe</a></h3>
<ul>
<li>Open axe DevTools</li>
<li>Scan page</li>
<li><strong>Expected</strong>: color-contrast issue resolved</li>
</ul>
<h3 id="step-4-screenshot"><a class="header" href="#step-4-screenshot">Step 4: Screenshot</a></h3>
<ul>
<li>Save <code>wk07/evidence/contrast-after.png</code></li>
<li>Show button with new color</li>
</ul>
<hr />
<h2 id="evidence"><a class="header" href="#evidence">Evidence</a></h2>
<ul>
<li>Before: <code>wk07/evidence/contrast-before.png</code></li>
<li>After: <code>wk07/evidence/contrast-after.png</code></li>
<li>axe report: <code>wk07/evidence/axe-after.png</code> (0 serious issues)</li>
</ul>
<hr />
<h2 id="commit"><a class="header" href="#commit">Commit</a></h2>
<p><code>git commit -m "Fix #9: Increase button contrast to 7:1 (WCAG 1.4.3 AAA)"</code></p>
<pre><code>
### Step 3: Implement Fix

**Edit `src/main/resources/templates/base.peb`**:

Add inside `&lt;style&gt;` block:

```css
/* Override Pico.css button color for WCAG 1.4.3 AA compliance */
button[type="submit"],
button {
  color: #495057 !important; /* 7:1 contrast (passes AAA) */
}
</code></pre>
<p><strong>Reload page</strong>, inspect button:</p>
<ul>
<li><strong>Before</strong>: #6c757d (light gray)</li>
<li><strong>After</strong>: #495057 (dark gray)</li>
</ul>
<h3 id="step-4-verify-fix"><a class="header" href="#step-4-verify-fix">Step 4: Verify Fix</a></h3>
<p><strong>1. Visual check</strong>:</p>
<pre><code class="language-bash"># Reload http://localhost:8080/tasks
# Confirm button text darker
</code></pre>
<p><strong>2. Contrast calculator</strong>:</p>
<ul>
<li>Visit <a href="https://webaim.org/resources/contrastchecker/">WebAIM Contrast Checker</a></li>
<li>Foreground: #495057</li>
<li>Background: #ffffff</li>
<li><strong>Result</strong>: 7.0:1 (Pass AAA) ‚úÖ</li>
</ul>
<p><strong>3. Re-run axe</strong>:</p>
<ul>
<li>Open axe DevTools</li>
<li>Scan page</li>
<li><strong>Expected</strong>: 0 serious issues (contrast resolved)</li>
</ul>
<p><strong>4. Screenshot</strong>:</p>
<pre><code class="language-bash"># Save screenshot to wk07/evidence/contrast-after.png
</code></pre>
<h3 id="step-5-document-verification"><a class="header" href="#step-5-document-verification">Step 5: Document Verification</a></h3>
<p>Create <code>wk07/fixes/verification.md</code>:</p>
<pre><code class="language-markdown"># Verification Log ‚Äî Fix 09

**Date**: [YYYY-MM-DD]
**Fix**: Delete button contrast (WCAG 1.4.3)

---

## Before State
- **Color**: #6c757d (Pico.css default)
- **Contrast**: 4.2:1 (Fail AA)
- **axe**: 1 serious issue (color-contrast)

## After State
- **Color**: #495057 (custom override)
- **Contrast**: 7.0:1 (Pass AAA)
- **axe**: 0 serious issues

---

## Tests Performed

### Test 1: Contrast Calculation
**Tool**: WebAIM Contrast Checker
**Foreground**: #495057
**Background**: #ffffff
**Result**: ‚úÖ 7.0:1 (Pass AAA)

### Test 2: Visual Inspection
**Action**: Loaded http://localhost:8080/tasks, inspected "Delete" button
**Result**: ‚úÖ Text noticeably darker, easier to read

### Test 3: Automated Re-scan
**Tool**: axe DevTools 4.x
**Result**: ‚úÖ 0 critical, 0 serious (contrast issue resolved)

### Test 4: Regression Check
**Action**: Tested add, edit, delete flows
**Result**: ‚úÖ No regressions, all features work

---

## Evidence
- Before screenshot: `wk07/evidence/contrast-before.png`
- After screenshot: `wk07/evidence/contrast-after.png`
- Contrast checker result: `wk07/evidence/webaim-contrast-7-1.png`
- axe report (after): `wk07/evidence/axe-after.png`

---

## WCAG Compliance
**Criterion**: 1.4.3 Contrast (Minimum, Level AA)
**Status**: ‚úÖ Pass (7.0:1 exceeds 4.5:1 requirement)

**Bonus**: Also passes AAA (7:1 threshold)

---

## Commit
SHA: [abc123f]
Message: "Fix #9: Increase button contrast to 7:1 (WCAG 1.4.3 AAA)"
Files changed: `base.peb` (+3 lines)
</code></pre>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ Fix implemented (CSS change)</li>
<li>‚úÖ Contrast verified (7:1, Pass AAA)</li>
<li>‚úÖ axe re-scan shows 0 serious issues</li>
<li>‚úÖ Evidence collected (screenshots, verification log)</li>
</ul>
<hr />
<h2 id="reflection-questions-2"><a class="header" href="#reflection-questions-2">Reflection Questions</a></h2>
<ol>
<li>
<p><strong>Automated vs. manual testing</strong>: axe found the contrast issue, but did it catch the focus outline being faint? Why do we need both automated and manual testing?</p>
</li>
<li>
<p><strong>Prioritisation</strong>: You had 5 new backlog items. How did the scoring formula (severity √ó inclusion √ó WCAG) change
which one you fixed first? Would your decision differ if time wasn‚Äôt limited?</p>
</li>
<li>
<p><strong>Evidence chains</strong>: Trace the evidence chain for your fix: audit finding ‚Üí backlog item ‚Üí fix implementation ‚Üí verification. What would happen if you skipped any step?</p>
</li>
<li>
<p><strong>Regression risk</strong>: After fixing contrast, did you verify all buttons still work? Why is regression testing important?</p>
</li>
</ol>
<hr />
<h2 id="further-reading-2"><a class="header" href="#further-reading-2">Further Reading</a></h2>
<p><strong>WCAG 2.2 &amp; auditing</strong></p>
<ul>
<li>W3C (2024). <em>WCAG 2.2 Quick Reference</em>. <a href="https://www.w3.org/WAI/WCAG22/quickref/">https://www.w3.org/WAI/WCAG22/quickref/</a></li>
<li>Deque (2024). <em>axe DevTools Documentation</em>. <a href="https://www.deque.com/axe/devtools/">https://www.deque.com/axe/devtools/</a></li>
<li>WebAIM (2024). <em>WCAG 2 Checklist</em>. <a href="https://webaim.org/standards/wcag/checklist">https://webaim.org/standards/wcag/checklist</a></li>
</ul>
<p><strong>Heuristic evaluation</strong></p>
<ul>
<li>Nielsen, J. (1994). ‚ÄúHeuristic Evaluation.‚Äù <em>Usability Inspection Methods</em>, 25-62.</li>
<li>Shneiderman, B. et al. (2016). <em>Designing the User Interface</em> (6th ed.), Ch. 3.</li>
</ul>
<p><strong>Inclusive backlogs</strong></p>
<ul>
<li>Cohn, M. (2004). <em>User Stories Applied</em>. Addison-Wesley.</li>
<li>Microsoft (2024). <em>Inclusive Design Toolkit</em>. <a href="https://inclusive.microsoft.design/">https://inclusive.microsoft.design/</a></li>
</ul>
<hr />
<h2 id="glossary-summary-2"><a class="header" href="#glossary-summary-2">Glossary Summary</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Term</th><th>Definition</th><th>Example/Context</th></tr></thead><tbody>
<tr><td><strong>Accessibility audit</strong></td><td>Systematic evaluation against WCAG criteria</td><td>axe scan + manual keyboard/SR testing</td></tr>
<tr><td><strong>Automated testing</strong></td><td>Tools that scan code for issues (20-30% coverage)</td><td>axe DevTools, WAVE, Lighthouse</td></tr>
<tr><td><strong>Manual testing</strong></td><td>Human evaluation (keyboard, SR, heuristics)</td><td>Tab through page, listen with NVDA</td></tr>
<tr><td><strong>Severity</strong></td><td>Impact on task completion (High/Medium/Low)</td><td>High = blocks; Medium = hinders; Low = cosmetic</td></tr>
<tr><td><strong>Inclusion risk</strong></td><td>Who‚Äôs affected (SR, Keyboard, Cognitive, etc.)</td><td>‚ÄúAffects people using SR + keyboards‚Äù</td></tr>
<tr><td><strong>Heuristic evaluation</strong></td><td>Expert review using usability principles</td><td>Nielsen‚Äôs 10 Heuristics, Shneiderman‚Äôs Golden Rules</td></tr>
<tr><td><strong>Contrast ratio</strong></td><td>Luminance difference (text vs. background)</td><td>4.5:1 (AA), 7:1 (AAA)</td></tr>
<tr><td><strong>Regression testing</strong></td><td>Verifying fixes don‚Äôt break existing features</td><td>After contrast fix, confirm buttons still work</td></tr>
<tr><td><strong>Evidence chain</strong></td><td>Traceable path: audit ‚Üí backlog ‚Üí fix ‚Üí verification</td><td>Finding ‚Üí Item #9 ‚Üí CSS change ‚Üí 7:1 verified</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="lab-checklist-2"><a class="header" href="#lab-checklist-2">Lab Checklist</a></h2>
<p>Before leaving lab, confirm:</p>
<ul>
<li><input disabled="" type="checkbox"/>
<strong>Automated audit completed</strong>: axe DevTools scan, report saved</li>
<li><input disabled="" type="checkbox"/>
<strong>WCAG checklist filled</strong>: At least 15 criteria evaluated (Pass/Fail/N/A)</li>
<li><input disabled="" type="checkbox"/>
<strong>Heuristic evaluation done</strong>: Nielsen‚Äôs 10 applied, issues logged</li>
<li><input disabled="" type="checkbox"/>
<strong>Backlog updated</strong>: 5+ new items added with severity + inclusion risk</li>
<li><input disabled="" type="checkbox"/>
<strong>One fix implemented</strong>: Code changed, committed</li>
<li><input disabled="" type="checkbox"/>
<strong>Fix verified</strong>: Contrast/tool re-scan shows success</li>
<li><input disabled="" type="checkbox"/>
<strong>Evidence collected</strong>: Before/after screenshots, verification log</li>
<li><input disabled="" type="checkbox"/>
<strong>Code committed</strong>: <code>git add .</code>, <code>git commit -m "wk7-lab2: audit + fix #9 (contrast)"</code></li>
</ul>
<hr />
<h2 id="next-steps-2"><a class="header" href="#next-steps-2">Next Steps</a></h2>
<p>In <strong>Week 8 Lab 1</strong> you will:</p>
<ol>
<li>Add partials and pagination to task list (Pebble template patterns)</li>
<li>Implement filtering with constraint-based design</li>
<li>Test dual-path filtering (HTMX + no-JS)</li>
</ol>
<p>In <strong>Week 8 Lab 2</strong> you will:</p>
<ol>
<li>Verify routing parity (HTMX vs. no-JS)</li>
<li>Document trade-offs (performance, complexity, accessibility)</li>
<li>Run no-JS verification script</li>
</ol>
<p><strong>Preparation</strong>:</p>
<ul>
<li>Ensure backlog up-to-date with Week 7 findings</li>
<li>Have working task manager (add, edit, delete functional)</li>
<li>Review audit evidence (you‚Äôll reference it in Task 1)</li>
</ul>
<hr />
<p><strong>Lab authored by</strong>: COMP2850 Teaching Team, University of Leeds
<strong>Last updated</strong>: 2025-01-14
<strong>Licence</strong>: Academic use only (not for redistribution)</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-7--lab-2--student-guide-accessibility-audit--inclusive-fix"><a class="header" href="#week-7--lab-2--student-guide-accessibility-audit--inclusive-fix">Week 7 ‚Ä¢ Lab 2 ‚Äî Student Guide: Accessibility Audit &amp; Inclusive Fix</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-7-orange" alt="Week 7" />
<img src="https://img.shields.io/badge/Lab-2-green" alt="Lab 2" />
<img src="https://img.shields.io/badge/Type-Student_Guide-purple" alt="Guide" /></p>
<blockquote>
<p><strong>Purpose</strong>: Week 7 Lab 2 is about systematically auditing your application for accessibility issues, documenting them in your backlog, and implementing one high-priority fix.</p>
</blockquote>
<hr />
<h2 id="deliverables-1"><a class="header" href="#deliverables-1">Deliverables</a></h2>
<p>By the end of this lab:</p>
<ul>
<li>‚úÖ <code>wk07/audit/axe-report.md</code> - Automated accessibility audit</li>
<li>‚úÖ <code>wk07/audit/manual-wcag-checklist.md</code> - Manual WCAG 2.2 AA verification</li>
<li>‚úÖ Updated <code>backlog/backlog.csv</code> - All findings logged with severity + inclusion risk</li>
<li>‚úÖ One accessibility fix implemented and verified</li>
<li>‚úÖ <code>wk07/evidence/</code> - Screenshots showing before/after fix</li>
</ul>
<hr />
<h2 id="part-1-run-axe-devtools-audit-20-minutes"><a class="header" href="#part-1-run-axe-devtools-audit-20-minutes">Part 1: Run axe DevTools Audit (20 minutes)</a></h2>
<h3 id="install-axe-devtools"><a class="header" href="#install-axe-devtools">Install axe DevTools</a></h3>
<ol>
<li>Open Chrome/Edge/Firefox</li>
<li>Install <a href="https://www.deque.com/axe/devtools/">axe DevTools Extension</a></li>
<li>Open DevTools (F12) ‚Üí find ‚Äúaxe DevTools‚Äù tab</li>
</ol>
<h3 id="run-automated-scan"><a class="header" href="#run-automated-scan">Run Automated Scan</a></h3>
<ol>
<li>Start your server: <code>./gradlew run</code></li>
<li>Navigate to http://localhost:8080/tasks</li>
<li>Click ‚ÄúScan ALL of my page‚Äù in axe DevTools tab</li>
<li>Review results</li>
</ol>
<h3 id="document-findings"><a class="header" href="#document-findings">Document Findings</a></h3>
<p><strong>Create</strong> <code>wk07/audit/axe-report.md</code>:</p>
<details>
<summary>Click to expand: axe Report Template</summary>
<pre><code class="language-markdown"># axe DevTools Audit Report ‚Äî Week 7

**Date**: [YYYY-MM-DD]
**Page scanned**: http://localhost:8080/tasks
**axe version**: [e.g., 4.8.2]

---

## Summary

- **Violations**: [e.g., 5]
- **Needs review**: [e.g., 2]
- **Passed**: [e.g., 43]

---

## Violations Found

### 1. Color Contrast (Serious)
**WCAG**: 1.4.3 Contrast (Minimum) - Level AA
**Issue**: Button text (#6c757d) on white background = 4.2:1 (needs 4.5:1)
**Element**: `&lt;button&gt;Delete&lt;/button&gt;` in task list
**Impact**: Low vision, colour-blind people struggle to read
**Fix**: Change button colour to #5a6268 (meets 4.53:1)

---

### 2. Missing Form Labels (Critical)
**WCAG**: 3.3.2 Labels or Instructions - Level A
**Issue**: Input field has no associated `&lt;label&gt;`
**Element**: `&lt;input id="title" name="title"&gt;`
**Impact**: People using screen readers don't know what the field is for
**Fix**: Add `&lt;label for="title"&gt;Task title&lt;/label&gt;`

---

[Add all violations found - typically 5-8]

---

## Needs Review (Manual Check Required)

### 1. Link Purpose (Best Practice)
**WCAG**: 2.4.4 Link Purpose (In Context) - Level A
**Issue**: Link text is "here" (not descriptive)
**Element**: `&lt;a href="/docs"&gt;Click here&lt;/a&gt;`
**Manual check**: Review if context makes purpose clear

---

## Passed Checks (Sample)

- ‚úÖ HTML lang attribute
- ‚úÖ Unique IDs
- ‚úÖ Valid ARIA attributes
- ‚úÖ Landmark roles
- ‚úÖ Skip link present

---

## Priority Fixes (Week 7)

Based on severity + inclusion risk:
1. **Missing form labels** (Critical, WCAG A) - FIX NOW
2. **Color contrast** (Serious, WCAG AA) - FIX NOW
3. **Link purpose** (Best practice) - Defer to Week 10
</code></pre>
</details>
<p><strong>Checklist</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
axe scan run on <code>/tasks</code> page</li>
<li><input disabled="" type="checkbox"/>
All violations documented with WCAG reference</li>
<li><input disabled="" type="checkbox"/>
Priority fixes identified</li>
</ul>
<hr />
<h2 id="part-2-manual-wcag-checklist-25-minutes"><a class="header" href="#part-2-manual-wcag-checklist-25-minutes">Part 2: Manual WCAG Checklist (25 minutes)</a></h2>
<p>axe catches ~30% of issues. Manual testing is essential.</p>
<p><strong>Create</strong> <code>wk07/audit/manual-wcag-checklist.md</code>:</p>
<details>
<summary>Click to expand: Manual WCAG Checklist Template</summary>
<pre><code class="language-markdown"># Manual WCAG 2.2 AA Checklist ‚Äî Week 7

**Date**: [YYYY-MM-DD]
**Tester**: [Your name]
**Assistive tech**: [e.g., NVDA 2024.1, Chrome 120]

---

## Principle 1: Perceivable

### 1.4.3 Contrast (Minimum) - Level AA
- [ ] **Text**: All text 4.5:1 contrast minimum
- [ ] **Large text**: 18pt+ or 14pt bold - 3:1 minimum
- [ ] **UI components**: Buttons, inputs, borders - 3:1 minimum

**Test method**: Use Chrome DevTools Color Picker or [WebAIM Contrast Checker](https://webaim.org/resources/contrastchecker/)

**Findings**: [List any contrast failures with ratios]

---

### 1.4.10 Reflow - Level AA
- [ ] **Zoom to 400%**: Content reflows without horizontal scroll
- [ ] **Viewport 320px wide**: No loss of content or functionality

**Test method**: Chrome DevTools ‚Üí Responsive mode ‚Üí 320√ó568 ‚Üí Zoom to 400%

**Findings**: [Any overflow or broken layouts?]

---

## Principle 2: Operable

### 2.1.1 Keyboard - Level A
- [ ] **All interactive elements** reachable via Tab
- [ ] **Focus order** matches visual order
- [ ] **No keyboard traps** (can Tab out of all elements)

**Test method**: Unplug mouse, use Tab/Shift+Tab/Enter/Space only

**Findings**: [List any unreachable elements]

---

### 2.4.1 Bypass Blocks - Level A
- [ ] **Skip link** present and functional
- [ ] **Landmarks** (nav, main, aside) for screen reader navigation

**Test method**: Press Tab once ‚Üí "Skip to main content" appears ‚Üí Enter ‚Üí focus jumps

**Findings**: [Skip link working? Landmarks present?]

---

### 2.4.3 Focus Order - Level A
- [ ] **Logical sequence**: Tab follows reading order
- [ ] **No unexpected jumps**: Focus doesn't skip sections

**Test method**: Tab through entire page, note order

**Findings**: [Any illogical jumps?]

---

### 2.4.7 Focus Visible - Level AA
- [ ] **All focusable elements** show clear visual indicator
- [ ] **Indicator visible** against all backgrounds

**Test method**: Tab through page, confirm blue outline visible

**Findings**: [Any invisible focus states?]

---

## Principle 3: Understandable

### 3.3.1 Error Identification - Level A
- [ ] **Error messages** identify what's wrong in text
- [ ] **Errors associated** with fields (`aria-describedby`, `aria-invalid`)

**Test method**: Submit empty form, check error display

**Findings**: [Errors clearly identified?]

---

### 3.3.2 Labels or Instructions - Level A
- [ ] **All inputs** have `&lt;label&gt;` or `aria-label`
- [ ] **Labels descriptive** ("Task title" not "Title")

**Test method**: Check all `&lt;input&gt;`, `&lt;select&gt;`, `&lt;textarea&gt;` have labels

**Findings**: [Any missing labels?]

---

## Principle 4: Robust

### 4.1.3 Status Messages - Level AA
- [ ] **ARIA live regions** for dynamic updates
- [ ] **Success/error messages** announced by screen reader

**Test method**: NVDA on ‚Üí add task ‚Üí confirm "Task added" announced

**Findings**: [Status messages announced?]

---

## Summary

**Total checks**: 10
**Passed**: [e.g., 7]
**Failed**: [e.g., 3]

**Critical failures** (Level A):
- [List Level A failures - these MUST be fixed]

**Important failures** (Level AA):
- [List Level AA failures - should be fixed]
</code></pre>
</details>
<p><strong>Checklist</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Manual keyboard testing complete</li>
<li><input disabled="" type="checkbox"/>
Screen reader testing done (if available)</li>
<li><input disabled="" type="checkbox"/>
All WCAG A/AA criteria checked</li>
<li><input disabled="" type="checkbox"/>
Failures documented with test method</li>
</ul>
<hr />
<h2 id="part-3-update-backlog-20-minutes"><a class="header" href="#part-3-update-backlog-20-minutes">Part 3: Update Backlog (20 minutes)</a></h2>
<p>Add all audit findings to <code>backlog/backlog.csv</code>:</p>
<pre><code class="language-csv">id,title,story_ref,story_type,need,type,severity,inclusion_risk,evidence,notes,candidate_fix
9,Missing label on title input,audit#2,WCAG violation,Form accessibility,Accessibility,Critical,"SR,Keyboard","axe-report.md; WCAG 3.3.2 (A)",No &lt;label&gt; associated with input - SR announces "edit text" with no context,true
10,Button contrast 4.2:1 (fails AA),audit#1,WCAG violation,Visibility,Accessibility,High,"Low vision,Colour-blind","axe-report.md; WCAG 1.4.3 (AA)",Pico.css default gray fails minimum contrast,true
11,Focus indicator low contrast,manual#7,WCAG violation,Keyboard navigation,Accessibility,Medium,Keyboard,"manual-wcag-checklist.md; WCAG 2.4.7 (AA)",Blue outline barely visible on light backgrounds,false
12,No error message in no-JS path,manual#3,WCAG violation,Error handling,Accessibility,High,"Cognitive,SR","manual-wcag-checklist.md; WCAG 3.3.1 (A)",PRG redirect loses validation context,true
</code></pre>
<p><strong>Prioritisation formula</strong>:</p>
<ul>
<li><strong>Critical/High severity</strong> + <strong>WCAG Level A</strong> = Fix immediately</li>
<li><strong>Medium severity</strong> + <strong>WCAG Level AA</strong> = Fix if time permits</li>
<li><strong>Low severity</strong> + <strong>no WCAG</strong> = Defer to Week 10</li>
</ul>
<p><strong>Checklist</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
All axe violations logged</li>
<li><input disabled="" type="checkbox"/>
All manual test failures logged</li>
<li><input disabled="" type="checkbox"/>
Severity and inclusion risk assigned</li>
<li><input disabled="" type="checkbox"/>
1-2 marked <code>candidate_fix=true</code></li>
</ul>
<hr />
<h2 id="part-4-implement-one-fix-40-minutes"><a class="header" href="#part-4-implement-one-fix-40-minutes">Part 4: Implement One Fix (40 minutes)</a></h2>
<p>Choose one high-priority fix from your backlog. Example: <strong>Missing form label</strong>.</p>
<h3 id="before-violation"><a class="header" href="#before-violation">Before (Violation)</a></h3>
<pre><code class="language-html">&lt;input id="title" name="title" required&gt;
</code></pre>
<p><strong>Issue</strong>: Screen reader announces ‚Äúedit text‚Äù with no context.</p>
<h3 id="after-fixed"><a class="header" href="#after-fixed">After (Fixed)</a></h3>
<pre><code class="language-html">&lt;label for="title"&gt;Task title&lt;/label&gt;
&lt;input id="title" name="title" required aria-describedby="title-hint"&gt;
&lt;small id="title-hint"&gt;Keep it short and specific.&lt;/small&gt;
</code></pre>
<p><strong>What changed</strong>:</p>
<ul>
<li>Added <code>&lt;label&gt;</code> linked via <code>for="title"</code></li>
<li>Added hint text with <code>aria-describedby</code></li>
<li>Screen reader now announces: ‚ÄúTask title, edit text, Keep it short and specific‚Äù</li>
</ul>
<h3 id="verification-1"><a class="header" href="#verification-1">Verification</a></h3>
<ol>
<li><strong>Re-run axe</strong>: Violation should disappear</li>
<li><strong>Screen reader test</strong>: NVDA should announce label + hint</li>
<li><strong>Take screenshot</strong>: Save to <code>wk07/evidence/fix-missing-label-after.png</code></li>
</ol>
<hr />
<h2 id="part-5-evidence-capture-15-minutes"><a class="header" href="#part-5-evidence-capture-15-minutes">Part 5: Evidence Capture (15 minutes)</a></h2>
<p>Create <code>wk07/evidence/</code> folder:</p>
<pre><code class="language-bash">mkdir -p wk07/evidence
</code></pre>
<p><strong>Capture</strong>:</p>
<ol>
<li><strong>Before screenshot</strong>: axe DevTools showing violation</li>
<li><strong>After screenshot</strong>: axe DevTools showing pass</li>
<li><strong>Screen reader output</strong>: Text file with NVDA announcements</li>
</ol>
<p><strong>Example evidence</strong>:</p>
<pre><code>wk07/evidence/
‚îú‚îÄ‚îÄ axe-before-missing-label.png
‚îú‚îÄ‚îÄ axe-after-missing-label.png
‚îú‚îÄ‚îÄ nvda-announcement-after.txt
‚îî‚îÄ‚îÄ contrast-checker-button-fix.png
</code></pre>
<p><strong>Checklist</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Before/after screenshots captured</li>
<li><input disabled="" type="checkbox"/>
axe re-scan shows violation resolved</li>
<li><input disabled="" type="checkbox"/>
Evidence files saved in <code>wk07/evidence/</code></li>
</ul>
<hr />
<h2 id="commit--continue-3"><a class="header" href="#commit--continue-3">Commit &amp; Continue</a></h2>
<pre><code class="language-bash">git add wk07/ backlog/ templates/ src/
git commit -m "fix(wk7-lab2): accessibility audit and priority fixes

- Ran axe DevTools scan, found 5 WCAG violations
- Completed manual WCAG 2.2 AA checklist (keyboard, SR, contrast)
- Updated backlog with 8 new accessibility issues
- Fixed missing form label (WCAG 3.3.2 Level A)
- Fixed button contrast to 4.53:1 (WCAG 1.4.3 Level AA)
- Verified fixes with axe re-scan and NVDA testing
- Captured before/after evidence in wk07/evidence/

Addresses Week 7 Lab 2 requirements. Ready for Week 8 prototyping."
</code></pre>
<p><strong>Next</strong>: Week 8 Lab 1 - Pagination, filtering, and template partials.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-8--lab-1--prototyping-with-constraints-partials-pagination-filtering"><a class="header" href="#week-8--lab-1--prototyping-with-constraints-partials-pagination-filtering">Week 8 ‚Ä¢ Lab 1 ‚Äî Prototyping with Constraints: Partials, Pagination, Filtering</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-8-orange" alt="Week 8" />
<img src="https://img.shields.io/badge/Lab-1-green" alt="Lab 1" />
<img src="https://img.shields.io/badge/Status-Draft-yellow" alt="Status" /></p>
<blockquote>
<p>We keep saying ‚Äúserver-first for everyone, HTMX for enhancement.‚Äù Scaling that pattern to dozens or hundreds of tasks introduces new constraints. Today you will factor templates, add filtering and pagination, and document the trade-offs you are making.</p>
</blockquote>
<hr />
<h2 id="why-this-lab-matters"><a class="header" href="#why-this-lab-matters">Why this lab matters</a></h2>
<ul>
<li>Template partials reduce duplication and keep accessibility fixes in one place.</li>
<li>Pagination and filtering control cognitive load and network cost when lists grow.</li>
<li>History (<code>hx-push-url</code>) and live status updates maintain web affordances (back button, result count) for all participants.</li>
<li>Documented trade-offs help you justify design decisions in critiques and assessments.</li>
</ul>
<p>This lab feeds directly into Week 8 Lab 2 (no-JS parity verification) and sets up metrics collection in Week 9.</p>
<hr />
<h2 id="pre-lab-reading-15-min"><a class="header" href="#pre-lab-reading-15-min">Pre-lab reading (15 min)</a></h2>
<ul>
<li><a href="https://htmx.org/examples/active-search/">HTMX Examples ‚Äî Active Search</a></li>
<li><a href="https://htmx.org/attributes/hx-push-url/">HTMX reference: <code>hx-push-url</code></a> and <a href="https://htmx.org/attributes/hx-trigger/"><code>hx-trigger</code></a></li>
<li><a href="https://pebbletemplates.io/wiki/tag/extends/">Pebble template inheritance</a> and include syntax</li>
</ul>
<p>Keep the <a href="wk08/../references/pebble-cheatsheet.html">Pebble Cheatsheet</a> and <a href="wk08/../references/htmx-patterns.html">HTMX Patterns</a> open for reference.</p>
<hr />
<h2 id="before-you-start-week-8-architecture-migration"><a class="header" href="#before-you-start-week-8-architecture-migration">Before You Start: Week 8 Architecture Migration</a></h2>
<h3 id="overview-week-7--week-8-transition"><a class="header" href="#overview-week-7--week-8-transition">Overview: Week 7 ‚Üí Week 8 Transition</a></h3>
<p>Week 8 introduces a <strong>production-ready architecture</strong> with String UUID IDs and improved data storage. You will migrate from Week 7‚Äôs simple <code>TaskRepository</code> object to Week 8‚Äôs <code>TaskStore</code> class.</p>
<p><strong>Why this change?</strong></p>
<ul>
<li><strong>Scalability</strong>: String UUIDs avoid ID conflicts in distributed systems</li>
<li><strong>Security</strong>: Sequential Int IDs leak information (total tasks, creation order)</li>
<li><strong>Production patterns</strong>: UUIDs are standard in REST APIs, databases, and microservices</li>
<li><strong>Data richness</strong>: Week 8 Task model adds <code>completed</code>, <code>createdAt</code> for evaluation metrics (Week 9)</li>
</ul>
<h3 id="architecture-comparison"><a class="header" href="#architecture-comparison">Architecture Comparison</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Aspect</th><th><strong>Week 7</strong> (Simple)</th><th><strong>Week 8</strong> (Production-Ready)</th></tr></thead><tbody>
<tr><td><strong>Task ID Type</strong></td><td><code>Int</code> (1, 2, 3‚Ä¶)</td><td><code>String</code> (UUID: <code>"a3f2c8..."</code>)</td></tr>
<tr><td><strong>ID Parsing</strong></td><td><code>toIntOrNull()</code></td><td>Direct string (no parsing)</td></tr>
<tr><td><strong>Data Model</strong></td><td><code>Task(id: Int, title: String)</code></td><td><code>Task(id: String, title: String, completed: Boolean, createdAt: LocalDateTime)</code></td></tr>
<tr><td><strong>Storage</strong></td><td><code>TaskRepository</code> object (singleton)</td><td><code>TaskStore</code> class (instantiable, testable)</td></tr>
<tr><td><strong>Location</strong></td><td><code>data/TaskRepository.kt</code></td><td><code>model/Task.kt</code> + <code>storage/TaskStore.kt</code></td></tr>
<tr><td><strong>Add Method</strong></td><td><code>repo.add(title: String): Task</code></td><td><code>store.add(task: Task)</code></td></tr>
<tr><td><strong>Get Method</strong></td><td><code>repo.find(id: Int): Task?</code></td><td><code>store.getById(id: String): Task?</code></td></tr>
<tr><td><strong>Validation</strong></td><td>None (basic title check)</td><td><code>Task.validate(title)</code> with detailed errors</td></tr>
</tbody></table>
</div>
<h3 id="migration-steps-complete-before-activity-1"><a class="header" href="#migration-steps-complete-before-activity-1">Migration Steps (Complete Before Activity 1)</a></h3>
<p><strong>1. Create the Task model</strong> (<code>src/main/kotlin/model/Task.kt</code>):</p>
<pre><code class="language-kotlin">package model

import java.time.LocalDateTime
import java.util.UUID

data class Task(
    val id: String = UUID.randomUUID().toString(),
    val title: String,
    val completed: Boolean = false,
    val createdAt: LocalDateTime = LocalDateTime.now()
)
</code></pre>
<p><strong>2. Create the TaskStore</strong> (<code>src/main/kotlin/storage/TaskStore.kt</code>):</p>
<pre><code class="language-kotlin">package storage

import model.Task

class TaskStore {
    private val tasks = mutableListOf&lt;Task&gt;()

    fun getAll(): List&lt;Task&gt; = tasks.toList()
    fun getById(id: String): Task? = tasks.find { it.id == id }
    fun add(task: Task) { tasks.add(task) }
    fun update(task: Task): Boolean {
        val index = tasks.indexOfFirst { it.id == task.id }
        return if (index != -1) { tasks[index] = task; true } else false
    }
    fun delete(id: String): Boolean = tasks.removeIf { it.id == id }
}
</code></pre>
<p><strong>3. Update your routes</strong> (<code>src/main/kotlin/routes/TaskRoutes.kt</code>):</p>
<p><strong>Before (Week 7):</strong></p>
<pre><code class="language-kotlin">fun Routing.configureTaskRoutes() {
    post("/tasks") {
        val title = call.receiveParameters()["title"] ?: ""
        val task = TaskRepository.add(title)  // Int ID
        // ...
    }

    delete("/tasks/{id}") {
        val id = call.parameters["id"]?.toIntOrNull() ?: return@delete
        TaskRepository.delete(id)
    }
}
</code></pre>
<p><strong>After (Week 8):</strong></p>
<pre><code class="language-kotlin">fun Routing.configureTaskRoutes(store: TaskStore = TaskStore()) {
    post("/tasks") {
        val title = call.receiveParameters()["title"] ?: ""
        val task = Task(title = title)  // UUID auto-generated
        store.add(task)
        // ...
    }

    delete("/tasks/{id}") {
        val id = call.parameters["id"] ?: return@delete  // No toIntOrNull
        store.delete(id)
    }
}
</code></pre>
<p><strong>4. Key changes in templates</strong>:</p>
<ul>
<li>Task IDs are now strings: <code>task-{{ task.id }}</code> (works the same in Pebble)</li>
<li>No visual changes needed‚ÄîUUIDs display in URLs, but users don‚Äôt see them</li>
</ul>
<p><strong>5. Test your migration</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Server starts without errors</li>
<li><input disabled="" type="checkbox"/>
Can add tasks (UUID IDs auto-generated)</li>
<li><input disabled="" type="checkbox"/>
Can edit tasks (String ID routing works)</li>
<li><input disabled="" type="checkbox"/>
Can delete tasks (no <code>toIntOrNull</code> errors)</li>
<li><input disabled="" type="checkbox"/>
Templates render correctly with UUID IDs</li>
</ul>
<h3 id="what-to-keep-from-week-7"><a class="header" href="#what-to-keep-from-week-7">What to Keep from Week 7</a></h3>
<p><strong>‚úÖ Keep your Week 7 templates</strong> (they work with String IDs):</p>
<ul>
<li>Form actions: <code>/tasks/{{ task.id }}/edit</code> works with both Int and String</li>
<li>HTMX attributes: <code>hx-delete="/tasks/{{ task.id }}"</code> works the same</li>
</ul>
<p><strong>‚úÖ Keep your accessibility features</strong>:</p>
<ul>
<li>ARIA labels, live regions, focus management all transfer directly</li>
</ul>
<p><strong>‚ö†Ô∏è Update route parameter handling</strong>:</p>
<ul>
<li>Remove all <code>toIntOrNull()</code> for task IDs (keep for page numbers!)</li>
<li>Change <code>TaskRepository.*</code> ‚Üí <code>store.*</code></li>
</ul>
<hr />
<h2 id="learning-focus-4"><a class="header" href="#learning-focus-4">Learning Focus</a></h2>
<h3 id="lab-objectives-4"><a class="header" href="#lab-objectives-4">Lab Objectives</a></h3>
<p>By the end of this session, you will have:</p>
<ul>
<li>Factored the tasks page into reusable Pebble partials (<code>_layout</code>, <code>_list</code>, <code>_item</code>, <code>_pager</code>)</li>
<li>Added production-ready UI with header, navigation, and footer partials</li>
<li>Implemented filtering + pagination with a dual-path architecture (full-page and HTMX fragment routes)</li>
<li>Maintained accessible result announcements (<code>aria-describedby</code>) and predictable focus</li>
<li>Used <code>hx-push-url</code> so history and bookmarking work across pages</li>
<li>Documented trade-offs in server-side vs client-side filtering</li>
</ul>
<h3 id="learning-outcomes-addressed-4"><a class="header" href="#learning-outcomes-addressed-4">Learning Outcomes Addressed</a></h3>
<p>This lab contributes to the following module Learning Outcomes (<a href="wk08/../references/learning-outcomes.html">full definitions</a>):</p>
<ul>
<li><strong>LO5</strong>: Create interface prototypes ‚Äî evidenced by HTMX partials implementation</li>
<li><strong>LO7</strong>: Analyse design constraints ‚Äî evidenced by pagination trade-offs document</li>
<li><strong>LO13</strong>: Integrate HCI with SE ‚Äî evidenced by server-rendered fragments</li>
</ul>
<hr />
<hr />
<h2 id="background-inclusive-prototyping-at-scale"><a class="header" href="#background-inclusive-prototyping-at-scale">Background: Inclusive prototyping at scale</a></h2>
<p>Why refactor now? As lists grow, duplication becomes dangerous: accessibility fixes, aria hooks, and HTMX attributes drift if they live in multiple places. Partials keep the source of truth in one file so every flow (full page and fragment) inherits the same semantics.</p>
<p>Pagination and filtering are not just performance tricks; they control cognitive load, especially for screen-reader participants who would otherwise wade through hundreds of list items. Implement them with inclusive defaults: predictable focus, result announcements, and URLs that respect the back button.</p>
<p>Keep these references handy while you work:</p>
<ul>
<li><a href="wk08/references/pebble-cheatsheet.html">Pebble Cheatsheet</a></li>
<li><code>../references/template-map-week8.md</code> (visual map of the partials you are about to create)</li>
<li><code>../references/htmx-pattern-cheatsheet.md</code> (Active Search, OOB status, indicators)</li>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/Accessibility/Understanding_WCAG/Navigation_and_orienting#pagination">MDN: Accessible Pagination Patterns</a></li>
</ul>
<blockquote>
<p><strong>Visual</strong>: Template hierarchy for the tasks UI</p>
</blockquote>
<pre class="mermaid">graph TD
  Base[_layout/base.peb&lt;br/&gt;skip link, live region, Pico.css]
  Base --&gt; Index[tasks/index.peb]
  Index --&gt; List[tasks/_list.peb]
  List --&gt; Item[tasks/_item.peb]
  Index --&gt; Pager[tasks/_pager.peb]
  Item --&gt;|Forms| Routes[(Ktor routes)]
  Pager --&gt;|Links| Routes
  Routes --&gt; HTMX[HTMX fragment responses]
  Routes --&gt; PRG[Full-page PRG responses]
</pre>
<p><small>Full legend in <a href="wk08/../references/process-visuals.html#template-hierarchy">Process Visuals</a>.</small></p>
<h3 id="worked-example-active-search-with-parity"><a class="header" href="#worked-example-active-search-with-parity">Worked example: Active Search with parity</a></h3>
<p>The filter form uses HTMX for fast updates, but must still function when JS is disabled. Compare the enhanced and fallback behaviours:</p>
<pre><code class="language-html">&lt;form action="/tasks" method="get"
      hx-get="/tasks/fragment"
      hx-target="#task-area"
      hx-trigger="keyup changed delay:300ms, submit from:closest(form)"
      hx-push-url="true"&gt;
  &lt;label for="q"&gt;Filter tasks&lt;/label&gt;
  &lt;input id="q" name="q" value="{{ query|default('') }}" type="search"
         aria-describedby="q-hint"&gt;
  &lt;small id="q-hint"&gt;Type to filter; works without JavaScript.&lt;/small&gt;
  &lt;button type="submit"&gt;Apply&lt;/button&gt;
&lt;/form&gt;
</code></pre>
<ul>
<li><strong>HTMX path</strong>: typing triggers <code>/tasks/fragment</code>, which returns <code>_list</code> + <code>_pager</code> + a status update (<code>Found X tasks</code>). <code>hx-push-url"true"</code> keeps the URL in sync so back/forward works.</li>
<li><strong>No-JS path</strong>: pressing Enter submits the form to <code>/tasks</code>; the full page renders using the same partials. Because labels and hints live in the partial, accessibility remains intact in both cases.</li>
</ul>
<p>When verifying parity, disable JS and watch the address bar: URLs should still reflect the current query and page so participants can bookmark or share the state.</p>
<hr />
<h2 id="0-baseline-check-5-min"><a class="header" href="#0-baseline-check-5-min">0. Baseline check (5 min)</a></h2>
<p>Run <code>./gradlew run</code> and load <code>http://localhost:8080/tasks</code>:</p>
<ul>
<li>Confirm add/edit/delete from Week 7 still work with JS on.</li>
<li>Disable JavaScript and re-run the same flows to ensure parity.</li>
<li>If anything regressed, fix it before adding complexity.</li>
</ul>
<hr />
<h2 id="1-factor-templates-into-partials-40-min"><a class="header" href="#1-factor-templates-into-partials-40-min">1. Factor templates into partials (40 min)</a></h2>
<blockquote>
<p><strong>üí° Template Naming Convention: Underscore Prefix</strong></p>
<p>Starting in Week 8, we adopt a <strong>underscore prefix</strong> (<code>_</code>) for <strong>partial templates</strong>:</p>
<div class="table-wrapper"><table><thead><tr><th>Name</th><th>Type</th><th>Purpose</th><th>Example</th></tr></thead><tbody>
<tr><td><code>index.peb</code></td><td><strong>Full page</strong></td><td>Complete HTML document (extends base)</td><td><code>tasks/index.peb</code></td></tr>
<tr><td><code>_item.peb</code></td><td><strong>Partial</strong></td><td>Fragment included in other templates</td><td><code>tasks/_item.peb</code></td></tr>
<tr><td><code>_list.peb</code></td><td><strong>Partial</strong></td><td>Reusable component (used multiple times)</td><td><code>tasks/_list.peb</code></td></tr>
<tr><td><code>_layout/base.peb</code></td><td><strong>Layout</strong></td><td>Shared page structure</td><td><code>_layout/base.peb</code></td></tr>
</tbody></table>
</div>
<p><strong>Why the underscore?</strong></p>
<ul>
<li><strong>Visual distinction</strong>: Instantly recognizable as a partial (not a standalone page)</li>
<li><strong>Common convention</strong>: Used by Rails, Jekyll, Sass, and other template systems</li>
<li><strong>Prevent direct access</strong>: In some frameworks, <code>_</code> files are not served directly</li>
</ul>
<p><strong>Rule of thumb</strong>:</p>
<ul>
<li><strong>No underscore</strong> = Full page that can be rendered directly (e.g., <code>/tasks</code> ‚Üí <code>tasks/index.peb</code>)</li>
<li><strong>Underscore</strong> = Fragment included via <code>{% include %}</code> or HTMX <code>hx-get</code></li>
</ul>
<p><strong>This week‚Äôs structure</strong>:</p>
<pre><code>templates/
‚îú‚îÄ‚îÄ _layout/
‚îÇ   ‚îî‚îÄ‚îÄ base.peb        ‚Üê Shared layout (underscore because it's a partial)
‚îî‚îÄ‚îÄ tasks/
    ‚îú‚îÄ‚îÄ index.peb       ‚Üê Full page (no underscore)
    ‚îú‚îÄ‚îÄ _item.peb       ‚Üê Partial: single task &lt;li&gt;
    ‚îú‚îÄ‚îÄ _list.peb       ‚Üê Partial: task list &lt;ul&gt;
    ‚îî‚îÄ‚îÄ _pager.peb      ‚Üê Partial: pagination nav
</code></pre>
</blockquote>
<p>We want a structure like the one in <code>../references/template-map-week8.md</code>.</p>
<h3 id="11-base-layout"><a class="header" href="#11-base-layout">1.1 Base layout</a></h3>
<p>Create <code>templates/_layout/base.peb</code> with the shared head, status region, skip link, Pico CSS, HTMX script, and utility classes. This keeps accessibility hooks (live region, focus outline, visually hidden class) in a single place.</p>
<h3 id="12-task-item-partial"><a class="header" href="#12-task-item-partial">1.2 Task item partial</a></h3>
<p>Create <code>templates/tasks/_item.peb</code> that renders a single <code>&lt;li&gt;</code> with:</p>
<ul>
<li>Stable id <code>task-{{ t.id }}</code>.</li>
<li>The title and the Edit/Delete forms from Week 7 (keep ARIA labels and dual attributes).</li>
<li>No inline business logic‚Äîjust markup and data from the model.</li>
</ul>
<p><strong>Example</strong> (<code>templates/tasks/_item.peb</code>):</p>
<pre><code class="language-pebble">&lt;li id="task-{{ task.id }}" class="task-view"&gt;
  &lt;span class="task-title"&gt;{{ task.title }}&lt;/span&gt;

  &lt;form action="/tasks/{{ task.id }}/edit" method="get" style="display: inline;"
        hx-get="/tasks/{{ task.id }}/edit"
        hx-target="#task-{{ task.id }}"
        hx-swap="outerHTML"&gt;
    &lt;button type="submit" aria-label="Edit task: {{ task.title }}"&gt;Edit&lt;/button&gt;
  &lt;/form&gt;

  &lt;form action="/tasks/{{ task.id }}/delete" method="post" style="display: inline;"
        hx-delete="/tasks/{{ task.id }}"
        hx-target="#task-{{ task.id }}"
        hx-swap="outerHTML"
        hx-confirm="Delete the task '{{ task.title }}'?"&gt;
    &lt;button type="submit" aria-label="Delete task: {{ task.title }}"&gt;Delete&lt;/button&gt;
  &lt;/form&gt;
&lt;/li&gt;
</code></pre>
<p><strong>Key patterns</strong>:</p>
<ul>
<li>Dual attributes: <code>action</code> (no-JS) + <code>hx-get</code>/<code>hx-delete</code> (HTMX)</li>
<li>Accessible labels: <code>aria-label</code> provides context for screen readers</li>
<li>Delete confirmation: <code>hx-confirm</code> prompts before deletion (HTMX only)</li>
</ul>
<h3 id="13-task-list-partial"><a class="header" href="#13-task-list-partial">1.3 Task list partial</a></h3>
<p>Create <code>templates/tasks/_list.peb</code> containing:</p>
<pre><code class="language-pebble">&lt;ul id="task-list" aria-describedby="result-count"&gt;
  {% for task in page.items %}
    {% include "tasks/_item.peb" with {"task": task} %}
  {% endfor %}
&lt;/ul&gt;
&lt;p id="result-count" class="visually-hidden"&gt;
  Showing {{ page.items|length }} of {{ page.totalItems }} tasks{% if query %} matching "{{ query }}"{% endif %}
&lt;/p&gt;
</code></pre>
<p>This ensures screen readers hear the result count whenever the list changes.</p>
<h3 id="14-update-index-page"><a class="header" href="#14-update-index-page">1.4 Update index page</a></h3>
<p>Modify <code>templates/tasks/index.peb</code> so it extends <code>_layout/base.peb</code>, renders the add form, and includes <code>_list.peb</code> and <code>_pager.peb</code> inside a <code>&lt;div id="task-area"&gt;</code> container (we will populate <code>_pager.peb</code> shortly).</p>
<p>‚úã <strong>Checkpoint</strong>: restart the server and confirm the tasks page renders exactly as before (no functionality has changed yet). If anything broke, inspect your partials and template paths.</p>
<h3 id="15-add-production-ready-ui-with-headernavfooter-partials-15-min"><a class="header" href="#15-add-production-ready-ui-with-headernavfooter-partials-15-min">1.5 Add production-ready UI with header/nav/footer partials (15 min)</a></h3>
<p>Now that you understand the partial pattern, let‚Äôs apply it to create a more polished, production-ready UI. We‚Äôll factor the base layout into reusable header, navigation, and footer components.</p>
<p><strong>Why add this now?</strong></p>
<ul>
<li><strong>Maintainability</strong>: Accessibility features (skip links, ARIA live regions) stay in one place</li>
<li><strong>Reusability</strong>: Header and footer will be consistent across all pages</li>
<li><strong>Professionalism</strong>: Navigation and session info help people understand context</li>
<li><strong>Best practice</strong>: Industry-standard template organization (header/nav/footer separation)</li>
</ul>
<p><strong>What you‚Äôre building:</strong></p>
<pre><code>templates/_layout/
‚îú‚îÄ‚îÄ base.peb         ‚Üê Updated to include partials
‚îú‚îÄ‚îÄ _header.peb      ‚Üê Skip link, ARIA live region, includes nav
‚îú‚îÄ‚îÄ _nav.peb         ‚Üê Site branding, main navigation links
‚îî‚îÄ‚îÄ _footer.peb      ‚Üê University branding, helpful links, session info
</code></pre>
<h4 id="151-create-header-partial"><a class="header" href="#151-create-header-partial">1.5.1 Create header partial</a></h4>
<p>Create <code>templates/_layout/_header.peb</code>:</p>
<pre><code class="language-pebble">{# Header partial with navigation and branding #}
{# WCAG 2.4.1: Skip link for keyboard navigation #}
&lt;a class="skip-link" href="#main"&gt;Skip to main content&lt;/a&gt;

{# WCAG 4.1.3: ARIA live region for dynamic status announcements #}
{# Polite: non-interrupting announcements after current speech finishes #}
&lt;div id="status" role="status" aria-live="polite" aria-atomic="true" class="visually-hidden"&gt;&lt;/div&gt;

&lt;header&gt;
  {% include "_layout/_nav.peb" %}
&lt;/header&gt;
</code></pre>
<p><strong>Key accessibility features:</strong></p>
<ul>
<li><strong>Skip link</strong>: People navigating with keyboard can jump directly to main content (WCAG 2.4.1)</li>
<li><strong>Live region</strong>: Screen readers announce status updates without interrupting navigation (WCAG 4.1.3)</li>
<li><strong>Semantic <code>&lt;header&gt;</code></strong>: Screen readers identify site header as a landmark</li>
</ul>
<h4 id="152-create-navigation-partial"><a class="header" href="#152-create-navigation-partial">1.5.2 Create navigation partial</a></h4>
<p>Create <code>templates/_layout/_nav.peb</code>:</p>
<pre><code class="language-pebble">{# Navigation partial with site branding and main menu #}
{# WCAG 1.3.1: Semantic nav element for screen readers #}
&lt;nav aria-label="Main navigation"&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;strong&gt;COMP2850 Task Manager&lt;/strong&gt;&lt;/li&gt;
  &lt;/ul&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href="/tasks"&gt;Tasks&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href="/health"&gt;Health&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
</code></pre>
<p><strong>Pico CSS pattern</strong>: Pico‚Äôs <code>&lt;nav&gt;</code> styling automatically creates a horizontal navigation bar with the first <code>&lt;ul&gt;</code> on the left (branding) and second <code>&lt;ul&gt;</code> on the right (links).</p>
<p><strong>Why <code>aria-label</code>?</strong>: If you have multiple <code>&lt;nav&gt;</code> elements on a page, labels like <code>aria-label="Main navigation"</code> help people using screen readers distinguish between them.</p>
<h4 id="153-create-footer-partial"><a class="header" href="#153-create-footer-partial">1.5.3 Create footer partial</a></h4>
<p>Create <code>templates/_layout/_footer.peb</code>:</p>
<pre><code class="language-pebble">{# Footer partial with helpful links and session info #}
{# WCAG 1.3.1: Semantic footer element #}
&lt;footer&gt;
  &lt;div class="container"&gt;
    &lt;p&gt;
      &lt;small&gt;
        COMP2850 HCI &amp;bull; Server-first architecture &amp;bull;
        &lt;a href="https://htmx.org/docs/" target="_blank" rel="noopener"&gt;HTMX Docs&lt;/a&gt; &amp;bull;
        &lt;a href="https://www.w3.org/WAI/WCAG22/quickref/" target="_blank" rel="noopener"&gt;WCAG 2.2&lt;/a&gt;
      &lt;/small&gt;
    &lt;/p&gt;
    &lt;p&gt;
      &lt;small&gt;
        Session: {{ sessionId | default('N/A') }} &amp;bull;
        Mode: &lt;span id="mode-indicator"&gt;No-JS&lt;/span&gt;
      &lt;/small&gt;
    &lt;/p&gt;
    &lt;script&gt;
      // Update mode indicator when JS is available
      document.getElementById('mode-indicator').textContent = 'HTMX';
    &lt;/script&gt;
  &lt;/div&gt;
&lt;/footer&gt;
</code></pre>
<p><strong>What the footer provides:</strong></p>
<ul>
<li><strong>Context links</strong>: Quick access to HTMX and WCAG documentation</li>
<li><strong>Session visibility</strong>: Helps with debugging (which session is active?)</li>
<li><strong>Mode indicator</strong>: Uses client-side detection to show whether JavaScript is enabled (No-JS baseline, HTMX enhanced)</li>
</ul>
<p><strong>Security note</strong>: <code>target="_blank"</code> requires <code>rel="noopener"</code> to prevent the new page from accessing <code>window.opener</code>.</p>
<h4 id="154-update-base-layout-to-use-partials"><a class="header" href="#154-update-base-layout-to-use-partials">1.5.4 Update base layout to use partials</a></h4>
<p>Now update <code>templates/_layout/base.peb</code> to include these partials. Replace your current base.peb with:</p>
<pre><code class="language-pebble">&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
  &lt;meta charset="utf-8" /&gt;
  &lt;meta name="viewport" content="width=device-width, initial-scale=1" /&gt;
  &lt;title&gt;{% block title %}COMP2850 Task Manager{% endblock %}&lt;/title&gt;

  {# Pico CSS for baseline accessible styles (WCAG 2.2 AA compliant) #}
  &lt;link rel="stylesheet" href="https://unpkg.com/@picocss/pico@2/css/pico.min.css"&gt;

  {# HTMX for progressive enhancement #}
  &lt;script src="https://unpkg.com/htmx.org@1.9.12"&gt;&lt;/script&gt;

  &lt;style&gt;
    /* Visually hidden but accessible to screen readers (WCAG 1.3.1) */
    .visually-hidden {
      position: absolute !important;
      height: 1px;
      width: 1px;
      overflow: hidden;
      clip: rect(1px, 1px, 1px, 1px);
      white-space: nowrap;
    }

    /* Skip link for keyboard navigation (WCAG 2.4.1) */
    .skip-link {
      position: absolute;
      left: -10000px;
      width: 1px;
      height: 1px;
      overflow: hidden;
    }
    .skip-link:focus {
      position: static;
      width: auto;
      height: auto;
      background: #1976d2;
      color: white;
      padding: 0.5rem 1rem;
      text-decoration: none;
      font-weight: bold;
      z-index: 9999;
    }

    /* Pagination styles */
    .pagination {
      display: flex;
      gap: 0.5rem;
      align-items: center;
    }
  &lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
  {# Include header with navigation and accessibility features #}
  {% include "_layout/_header.peb" %}

  {# Main landmark for screen readers (WCAG 1.3.1) #}
  {# tabindex="-1" allows programmatic focus for skip link #}
  &lt;main id="main" class="container" tabindex="-1"&gt;
    {% block content %}
    {# Page-specific content goes here #}
    {% endblock %}
  &lt;/main&gt;

  {# Include footer with helpful links and session info #}
  {% include "_layout/_footer.peb" %}
&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<p><strong>What changed:</strong></p>
<ul>
<li>Moved skip link and live region to <code>_header.peb</code></li>
<li>Added navigation via <code>_nav.peb</code></li>
<li>Added footer with helpful links and session info</li>
<li>Enhanced CSS for skip link visibility on focus</li>
<li>Added <code>{% block title %}</code> so pages can customize the <code>&lt;title&gt;</code> tag</li>
</ul>
<h4 id="155-update-route-handlers-to-pass-session-data"><a class="header" href="#155-update-route-handlers-to-pass-session-data">1.5.5 Update route handlers to pass session data</a></h4>
<p>For the footer to display session info, update your route handlers to include <code>sessionId</code> and <code>isHtmx</code> in the template model:</p>
<pre><code class="language-kotlin">get("/tasks") {
    val query = call.request.queryParameters["q"].orEmpty()
    val page = call.request.queryParameters["page"]?.toIntOrNull() ?: 1
    val data = repo.search(query = query, page = page, size = 10)

    // Add session info for footer
    val sessionId = call.sessions.get&lt;UserSession&gt;()?.id ?: "guest"
    val isHtmx = call.request.headers["HX-Request"]?.equals("true", ignoreCase = true) == true

    val model = mapOf(
        "title" to "Tasks",
        "page" to data,
        "query" to query,
        "sessionId" to sessionId,
        "isHtmx" to isHtmx
    )
    call.respondHtml(PebbleRender.render("tasks/index.peb", model))
}
</code></pre>
<p><strong>Note</strong>: If you don‚Äôt have session support yet, you can pass a placeholder value like <code>"dev-session"</code> for now.</p>
<p>‚úã <strong>Checkpoint</strong>: restart the server and verify:</p>
<ul>
<li><strong>Navigation bar</strong> appears at the top with ‚ÄúCOMP2850 Task Manager‚Äù branding and Tasks/Health links</li>
<li><strong>Skip link</strong> becomes visible when you press Tab (test keyboard navigation)</li>
<li><strong>Footer</strong> shows at the bottom with helpful links and session info</li>
<li><strong>All existing functionality</strong> still works (add/edit/delete tasks)</li>
<li><strong>Accessibility</strong>: Skip link works, navigation is keyboard-accessible, footer links open in new tabs</li>
</ul>
<p><strong>Benefits of this refactoring:</strong></p>
<ul>
<li>üé® <strong>Professional appearance</strong>: Navigation and branding make it look like a real web app</li>
<li>‚ôø <strong>Accessibility maintained</strong>: Skip links and ARIA regions still work</li>
<li>üîß <strong>Easier maintenance</strong>: Update navigation in one place, all pages inherit it</li>
<li>üìö <strong>Learning transfer</strong>: This pattern applies to any server-rendered web app</li>
</ul>
<hr />
<h2 id="2-add-pagination-and-filtering-35-min"><a class="header" href="#2-add-pagination-and-filtering-35-min">2. Add pagination and filtering (35 min)</a></h2>
<h3 id="21-repository-paging-helper"><a class="header" href="#21-repository-paging-helper">2.1 Repository paging helper</a></h3>
<p>Add a <code>Page&lt;T&gt;</code> data class and a <code>search(query, page, size)</code> helper in your repository or service layer so routes can request paged data. Keep the page number clamped (<code>coerceIn</code>) to valid bounds.</p>
<h3 id="22-pager-partial"><a class="header" href="#22-pager-partial">2.2 Pager partial</a></h3>
<p>Create <code>templates/tasks/_pager.peb</code>:</p>
<pre><code class="language-pebble">&lt;nav aria-label="Pagination"&gt;
  &lt;ul class="pagination"&gt;
    {% if page.currentPage &gt; 1 %}
      &lt;li&gt;
        &lt;a href="/tasks?q={{ query|default('') }}&amp;page={{ page.currentPage - 1 }}"
           hx-get="/tasks/fragment?q={{ query|default('') }}&amp;page={{ page.currentPage - 1 }}"
           hx-target="#task-area"
           hx-push-url="true"&gt;
          Previous
        &lt;/a&gt;
      &lt;/li&gt;
    {% endif %}
    &lt;li aria-current="page"&gt;Page {{ page.currentPage }} of {{ page.totalPages }}&lt;/li&gt;
    {% if page.currentPage &lt; page.totalPages %}
      &lt;li&gt;
        &lt;a href="/tasks?q={{ query|default('') }}&amp;page={{ page.currentPage + 1 }}"
           hx-get="/tasks/fragment?q={{ query|default('') }}&amp;page={{ page.currentPage + 1 }}"
           hx-target="#task-area"
           hx-push-url="true"&gt;
          Next
        &lt;/a&gt;
      &lt;/li&gt;
    {% endif %}
  &lt;/ul&gt;
&lt;/nav&gt;
</code></pre>
<p>Dual attributes guarantee the pager works both with and without HTMX.</p>
<h3 id="23-filter-form"><a class="header" href="#23-filter-form">2.3 Filter form</a></h3>
<p>Above the task area add a filter form:</p>
<pre><code class="language-pebble">&lt;form action="/tasks" method="get"
      hx-get="/tasks/fragment"
      hx-target="#task-area"
      hx-trigger="keyup changed delay:300ms, submit from:closest(form)"
      hx-push-url="true"&gt;
  &lt;label for="q"&gt;Filter tasks&lt;/label&gt;
  &lt;input id="q" name="q" value="{{ query|default('') }}" type="search"
         aria-describedby="q-hint"&gt;
  &lt;small id="q-hint"&gt;Type to filter; works without JavaScript.&lt;/small&gt;
  &lt;button type="submit"&gt;Apply&lt;/button&gt;
&lt;/form&gt;
</code></pre>
<p>The visible submit button provides the no-JS fallback; HTMX enhances with Active Search. Use the indicator pattern from the cheat sheet if you want to show loading state.</p>
<h3 id="24-routes"><a class="header" href="#24-routes">2.4 Routes</a></h3>
<p>Add two GET handlers in your Ktor routing block:</p>
<pre><code class="language-kotlin">get("/tasks") {
    val query = call.request.queryParameters["q"].orEmpty()
    val page = call.request.queryParameters["page"]?.toIntOrNull() ?: 1
    val data = repo.search(query = query, page = page, size = 10)
    val model = mapOf("title" to "Tasks", "page" to data, "query" to query)
    call.respondHtml(PebbleRender.render("tasks/index.peb", model))
}

get("/tasks/fragment") {
    val query = call.request.queryParameters["q"].orEmpty()
    val page = call.request.queryParameters["page"]?.toIntOrNull() ?: 1
    val data = repo.search(query = query, page = page, size = 10)
    val list = PebbleRender.render("tasks/_list.peb", mapOf("page" to data, "query" to query))
    val pager = PebbleRender.render("tasks/_pager.peb", mapOf("page" to data, "query" to query))
    val status = """&lt;div id="status" hx-swap-oob="true"&gt;Found ${data.total} tasks.&lt;/div&gt;"""
    call.respondText(list + pager + status, ContentType.Text.Html)
}
</code></pre>
<p><code>/tasks</code> handles full-page renders. <code>/tasks/fragment</code> returns fragments + an out-of-band status update for HTMX.</p>
<p>‚úã <strong>Checkpoint</strong>:</p>
<ul>
<li>Filter form updates the list as you type (HTMX) and on submit (no-JS).</li>
<li>Pager links update the list and URL with HTMX; back/forward work.</li>
<li>Live region announces ‚ÄúFound X tasks.‚Äù</li>
<li>With JavaScript disabled, the filter submits and redraws the whole page; pager links still navigate correctly.</li>
</ul>
<hr />
<h2 id="3-test-with-assistive-technology-10-min"><a class="header" href="#3-test-with-assistive-technology-10-min">3. Test with assistive technology (10 min)</a></h2>
<p>Use the checklist:</p>
<ul>
<li>Keyboard-only: Tab through filter form, pagination links, and tasks. Focus order should make sense and remain visible.</li>
<li>Screen reader: Trigger a filter change and ensure the result count is announced. Navigate the pager links; confirm <code>aria-current</code> is read out.</li>
<li>No-JS parity: Disable JS and confirm filtering/paging still work via full-page loads.</li>
<li>History: After filtering, use the back button‚Äîdoes the list revert? If not, check <code>hx-push-url</code> and your full-page route.</li>
</ul>
<p>Record outcomes in <code>wk08/docs/prototyping-constraints.md</code> under an ‚ÄúAccessibility verification‚Äù section.</p>
<hr />
<h2 id="4-document-trade-offs-15-min"><a class="header" href="#4-document-trade-offs-15-min">4. Document trade-offs (15 min)</a></h2>
<p>Open <code>wk08/docs/prototyping-constraints.starter.md</code> (or create <code>prototyping-constraints.md</code>) and note:</p>
<ul>
<li>Rendering splits (full page vs fragments).</li>
<li>Accessibility hooks (result count, live region, focus handling).</li>
<li>State management decisions (query parameter naming, page size choices).</li>
<li>Risks you introduced (duplicate HTML fragments, maintaining <code>_list</code> and <code>_pager</code>, potential 404 on out-of-range pages).</li>
</ul>
<p>This documentation is evidence for Week 10 prioritisation and helps staff review your implementation quickly.</p>
<hr />
<h2 id="commit-guidance"><a class="header" href="#commit-guidance">Commit guidance</a></h2>
<pre><code class="language-bash">git add templates/_layout/base.peb templates/tasks/_*.peb templates/tasks/index.peb src/main/kotlin wk08/docs/prototyping-constraints.md

git commit -m "wk8s1: partials + pagination/filter with hx-push-url" --no-verify
</code></pre>
<p>Suggested commit body:</p>
<pre><code>- factored tasks templates into base layout, list, item, pager partials
- added search form with dual-path (HTMX + full-page) handling
- implemented pagination routes returning fragments + status announcements
- verified keyboard, screen reader, JS-off parity
- documented rendering splits and trade-offs in wk08/docs/prototyping-constraints.md
</code></pre>
<hr />
<h2 id="advanced-template-view-adapter-pattern-optional"><a class="header" href="#advanced-template-view-adapter-pattern-optional">Advanced: Template View Adapter Pattern (Optional)</a></h2>
<p><strong>For students comfortable with abstraction layers</strong>:</p>
<p>The current approach passes the <code>Page</code> object directly to templates (<code>"page" to data</code>), which keeps templates coupled to the Kotlin data class structure. If you change <code>Page.currentPage</code> to <code>Page.number</code>, all templates break.</p>
<p><strong>Alternative: View adapter method</strong></p>
<p>Add a <code>toPebbleContext()</code> method to <code>Page</code> that flattens properties into template-friendly names:</p>
<pre><code class="language-kotlin">fun toPebbleContext(itemsKey: String = "items"): Map&lt;String, Any&gt; = mapOf(
    itemsKey to items,
    "currentPage" to currentPage,
    "totalPages" to totalPages,
    "totalItems" to totalItems,
    "pageSize" to pageSize,
    "hasPrevious" to hasPrevious,
    "hasNext" to hasNext,
    "previousPage" to previousPage,
    "nextPage" to nextPage
)
</code></pre>
<p>Then routes can use:</p>
<pre><code class="language-kotlin">val model = page.toPebbleContext("tasks") + mapOf("query" to query)
</code></pre>
<p>And templates access flattened variables:</p>
<pre><code class="language-pebble">{{ tasks|length }} of {{ totalItems }}
&lt;li&gt;Page {{ currentPage }} of {{ totalPages }}&lt;/li&gt;
</code></pre>
<p><strong>Trade-offs</strong>:</p>
<ul>
<li>‚úÖ Decouples templates from Kotlin internals (can rename properties safely)</li>
<li>‚úÖ Cleaner template syntax (shorter variable names)</li>
<li>‚ùå Extra abstraction layer to understand</li>
<li>‚ùå ‚ÄúMagic‚Äù variable names (harder to trace where they come from)</li>
</ul>
<p><strong>When to use</strong>: Production codebases where template stability matters. For learning, the direct approach (<code>page.items</code>, <code>page.page</code>) is clearer.</p>
<hr />
<h2 id="whats-next"><a class="header" href="#whats-next">What‚Äôs next?</a></h2>
<p>Week 8 Lab 2 focuses on wiring additional routes, error handling, and no-JS verification scripts. Keep your server running and your documentation open‚Äîwe will extend the same patterns immediately.</p>
<p>Optional stretch this week: add a ‚Äúmark complete‚Äù flow using the same partials and log any accessibility considerations.</p>
<hr />
<h2 id="further-resources"><a class="header" href="#further-resources">Further resources</a></h2>
<ul>
<li><a href="https://htmx.org/examples/active-search/">HTMX Examples ‚Äî Active Search</a></li>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/Accessibility/Understanding_WCAG/Navigation_and_orienting#pagination">MDN ‚Äî Accessible Pagination Patterns</a></li>
</ul>
<p>You now have a scalable, accessible list structure ready for deeper evaluation and instrumentation.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-8--lab-1--student-guide-code-reading--documentation"><a class="header" href="#week-8--lab-1--student-guide-code-reading--documentation">Week 8 ‚Ä¢ Lab 1 ‚Äî Student Guide: Code Reading &amp; Documentation</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-8-orange" alt="Week 8" />
<img src="https://img.shields.io/badge/Lab-1-green" alt="Lab 1" />
<img src="https://img.shields.io/badge/Type-Student_Guide-purple" alt="Guide" /></p>
<blockquote>
<p><strong>Purpose</strong>: If you found the Week 8 Lab 1 implementation challenging, this guide provides working code so you can focus on <strong>understanding patterns</strong> and <strong>documenting trade-offs</strong> rather than fighting syntax. The goal is to understand HCI concepts (pagination constraints, accessibility, dual-mode architecture), not to become a Kotlin expert.</p>
</blockquote>
<hr />
<h2 id="how-to-use-this-guide-1"><a class="header" href="#how-to-use-this-guide-1">How to Use This Guide</a></h2>
<p><strong>If you‚Äôve already written working pagination/filtering code:</strong> Skip Part 1, go straight to Part 2 (verification and documentation).</p>
<p><strong>If you‚Äôre stuck on implementation:</strong> Use Part 1 code, then complete Parts 2 &amp; 3 (verification + documentation).</p>
<hr />
<h2 id="part-1-working-implementation-optional"><a class="header" href="#part-1-working-implementation-optional">Part 1: Working Implementation (Optional)</a></h2>
<blockquote>
<p><strong>Important</strong>: This code is provided to help you focus on <strong>learning HCI concepts</strong>, not as a shortcut. You must understand the design decisions and document them in Part 3.</p>
</blockquote>
<blockquote>
<p><strong>Week 8 Architecture</strong>: Week 8 uses <code>TaskStore</code> (class) with String UUID IDs instead of Week 7‚Äôs <code>TaskRepository</code> (object) with Int IDs. Create the TaskStore first, then add pagination.</p>
</blockquote>
<details>
<summary>Click to reveal: <code>src/main/kotlin/storage/TaskStore.kt</code> (new file)</summary>
<pre><code class="language-kotlin">package storage

import model.Task
import java.io.File

/**
 * Simple in-memory task storage with CSV persistence.
 * Week 8 uses String UUID IDs.
 */
class TaskStore(private val csvFile: File = File("data/tasks.csv")) {
    private val tasks = mutableListOf&lt;Task&gt;()

    init {
        if (csvFile.exists()) {
            // Load tasks from CSV (implement if needed)
        }
    }

    fun getAll(): List&lt;Task&gt; = tasks.toList()

    fun getById(id: String): Task? = tasks.find { it.id == id }

    fun add(task: Task) {
        tasks.add(task)
    }

    fun update(task: Task): Boolean {
        val index = tasks.indexOfFirst { it.id == task.id }
        return if (index != -1) {
            tasks[index] = task
            true
        } else false
    }

    fun delete(id: String): Boolean = tasks.removeIf { it.id == id }
}
</code></pre>
</details>
<details>
<summary>Click to reveal: <code>src/main/kotlin/data/Page.kt</code> (new file)</summary>
<pre><code class="language-kotlin">package data

/**
 * Generic pagination container.
 * Wraps a list of items with metadata for page navigation.
 */
data class Page&lt;T&gt;(
    val items: List&lt;T&gt;,
    val page: Int,
    val pages: Int,
    val total: Int
) {
    val hasPrevious: Boolean get() = page &gt; 1
    val hasNext: Boolean get() = page &lt; pages
    val previousPage: Int get() = page - 1
    val nextPage: Int get() = page + 1
}
</code></pre>
</details>
<details>
<parameter name="summary">Click to reveal: Add to <code>TaskStore</code> class</summary>
<pre><code class="language-kotlin">/**
 * Search tasks by title and return paginated results.
 */
fun search(query: String, page: Int, pageSize: Int = 10): Page&lt;Task&gt; {
    val filtered = if (query.isBlank()) {
        getAll()
    } else {
        getAll().filter { task -&gt;
            task.title.contains(query, ignoreCase = true)
        }
    }

    val totalItems = filtered.size
    val totalPages = if (totalItems == 0) 1 else (totalItems + pageSize - 1) / pageSize
    val validPage = page.coerceIn(1, totalPages)
    val startIndex = (validPage - 1) * pageSize
    val pageItems = filtered.drop(startIndex).take(pageSize)

    return Page(
        items = pageItems,
        page = validPage,
        pages = totalPages,
        total = totalItems
    )
}
</code></pre>
<p><strong>Note</strong>: Add this method to your <code>TaskStore</code> class (not <code>TaskRepository</code>). Week 8 uses TaskStore with String UUID IDs.</p>
</details>
<details>
<summary>Click to reveal: Add to <code>TaskRoutes.kt</code></summary>
<pre><code class="language-kotlin">// Fragment endpoint for HTMX updates
get("/tasks/fragment") {
    val q = call.request.queryParameters["q"]?.trim().orEmpty()
    val page = call.request.queryParameters["page"]?.toIntOrNull() ?: 1
    val pageData = store.search(q, page, 10)

    val list = call.renderTemplate("tasks/_list.peb", mapOf("page" to pageData, "q" to q))
    val pager = call.renderTemplate("tasks/_pager.peb", mapOf("page" to pageData, "q" to q))
    val status = """&lt;div id="status" hx-swap-oob="true"&gt;Updated: showing ${pageData.items.size} of ${pageData.total} tasks&lt;/div&gt;"""

    call.respondText(list + pager + status, ContentType.Text.Html)
}

// Update existing GET /tasks to use pagination
get("/tasks") {
    val q = call.request.queryParameters["q"]?.trim().orEmpty()
    val page = call.request.queryParameters["page"]?.toIntOrNull() ?: 1
    val pageData = store.search(q, page, 10)

    val html = call.renderTemplate("tasks/index.peb", mapOf(
        "page" to pageData,
        "q" to q,
        "title" to "Tasks"
    ))
    call.respondText(html, ContentType.Text.Html)
}
</code></pre>
</details>
<details>
<summary>Click to reveal: <code>src/main/resources/templates/tasks/_list.peb</code> (new file)</summary>
<pre><code class="language-pebble">{# Task list partial with accessible result count #}
&lt;ul id="task-list" aria-describedby="result-count"&gt;
  {% for task in page.items %}
    {% include "tasks/_item.peb" with {"task": task} %}
  {% endfor %}
&lt;/ul&gt;

{# WCAG 4.1.3: Result count for people using assistive technology #}
&lt;p id="result-count" class="visually-hidden"&gt;
  Showing {{ page.items|length }} of {{ page.total }} tasks{% if q %} matching "{{ q }}"{% endif %}
&lt;/p&gt;
</code></pre>
</details>
<details>
<summary>Click to reveal: <code>src/main/resources/templates/tasks/_pager.peb</code> (new file)</summary>
<pre><code class="language-pebble">{# Pagination navigation with dual-mode support (HTMX + no-JS) #}
&lt;nav aria-label="Pagination"&gt;
  &lt;ul class="pagination"&gt;
    {% if page.hasPrevious %}
      &lt;li&gt;
        &lt;a href="/tasks?q={{ q|default('') }}&amp;page={{ page.previousPage }}"
           hx-get="/tasks/fragment?q={{ q|default('') }}&amp;page={{ page.previousPage }}"
           hx-target="#task-area"
           hx-push-url="true"&gt;
          Previous
        &lt;/a&gt;
      &lt;/li&gt;
    {% endif %}

    &lt;li aria-current="page"&gt;
      Page {{ page.page }} of {{ page.pages }}
    &lt;/li&gt;

    {% if page.hasNext %}
      &lt;li&gt;
        &lt;a href="/tasks?q={{ q|default('') }}&amp;page={{ page.nextPage }}"
           hx-get="/tasks/fragment?q={{ q|default('') }}&amp;page={{ page.nextPage }}"
           hx-target="#task-area"
           hx-push-url="true"&gt;
          Next
        &lt;/a&gt;
      &lt;/li&gt;
    {% endif %}
  &lt;/ul&gt;
&lt;/nav&gt;
</code></pre>
</details>
<details>
<summary>Click to reveal: Modifications to <code>tasks/index.peb</code></summary>
<pre><code class="language-pebble">{% extends "_layout/base.peb" %}
{% block content %}

&lt;h1&gt;Tasks&lt;/h1&gt;

{# Add Task Form - targets #task-area (not #task-list) for Week 8 #}
&lt;form action="/tasks" method="post"
      hx-post="/tasks"
      hx-target="#task-area"
      hx-swap="innerHTML"
      hx-on::after-request="this.reset()"&gt;
  &lt;label for="title"&gt;Title&lt;/label&gt;
  &lt;input type="text" id="title" name="title" required aria-describedby="title-hint"&gt;
  &lt;small id="title-hint"&gt;Keep it short and specific.&lt;/small&gt;
  &lt;button type="submit"&gt;Add Task&lt;/button&gt;
&lt;/form&gt;

{# Filter Form - dual-mode (HTMX + no-JS) #}
&lt;form action="/tasks" method="get"
      hx-get="/tasks/fragment"
      hx-target="#task-area"
      hx-push-url="true"
      hx-trigger="keyup changed delay:300ms from:#q, submit"&gt;
  &lt;label for="q"&gt;Filter tasks&lt;/label&gt;
  &lt;input type="search"
         id="q"
         name="q"
         value="{{ q|default('') }}"
         aria-describedby="q-hint"&gt;
  &lt;small id="q-hint"&gt;Type to filter (debounced 300ms); works without JavaScript.&lt;/small&gt;
  &lt;button type="submit"&gt;Apply Filter&lt;/button&gt;
&lt;/form&gt;

{# Task area wrapper for HTMX targeting #}
&lt;div id="task-area"&gt;
  {% include "tasks/_list.peb" %}
  {% include "tasks/_pager.peb" %}
&lt;/div&gt;

{% endblock %}
</code></pre>
<p><strong>Key changes from Week 7:</strong></p>
<ul>
<li>Add Task form now targets <code>#task-area</code> (not <code>#task-list</code>) with <code>innerHTML</code> swap (not <code>beforeend</code>)</li>
<li>This is because the server response includes the full list + pagination, not just a single <code>&lt;li&gt;</code></li>
</ul>
</details>
<hr />
<h2 id="part-2-verification-checklist"><a class="header" href="#part-2-verification-checklist">Part 2: Verification Checklist</a></h2>
<p>Test your implementation works correctly:</p>
<h3 id="dual-mode-testing-2"><a class="header" href="#dual-mode-testing-2">Dual-Mode Testing</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
<strong>With JavaScript enabled</strong>: Type in filter box ‚Üí observe smooth updates without page reload</li>
<li><input disabled="" type="checkbox"/>
<strong>With JavaScript disabled</strong>: Click ‚ÄúApply Filter‚Äù ‚Üí observe full page reload with correct results</li>
<li><input disabled="" type="checkbox"/>
<strong>Pagination links</strong>: Both Previous/Next work in JS and no-JS modes</li>
</ul>
<h3 id="accessibility-testing-1"><a class="header" href="#accessibility-testing-1">Accessibility Testing</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
<strong>Keyboard navigation</strong>: Tab through filter form ‚Üí pagination ‚Üí tasks (logical order, visible focus)</li>
<li><input disabled="" type="checkbox"/>
<strong>Screen reader</strong> (if available): Filter tasks ‚Üí result count is announced</li>
<li><input disabled="" type="checkbox"/>
<strong>No-JS parity</strong>: All features work identically with JavaScript disabled</li>
</ul>
<h3 id="url-and-history"><a class="header" href="#url-and-history">URL and History</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
<strong>Browser URL bar</strong>: Reflects current filter and page (<code>?q=search&amp;page=2</code>)</li>
<li><input disabled="" type="checkbox"/>
<strong>Back button</strong>: Returns to previous filter/page state</li>
<li><input disabled="" type="checkbox"/>
<strong>Bookmarking</strong>: Filtered/paginated URL returns to same state when reopened</li>
</ul>
<h3 id="edge-cases"><a class="header" href="#edge-cases">Edge Cases</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
<strong>Empty filter results</strong>: Shows appropriate message</li>
<li><input disabled="" type="checkbox"/>
<strong>Invalid page number</strong> (e.g., <code>?page=999</code>): Handled gracefully</li>
<li><input disabled="" type="checkbox"/>
<strong>Adding task while filtered</strong>: Task appears if it matches filter</li>
</ul>
<p>Record any issues in your backlog (<code>wk08/backlog/issues.csv</code>).</p>
<hr />
<h2 id="part-3-documentation-deliverable"><a class="header" href="#part-3-documentation-deliverable">Part 3: Documentation Deliverable</a></h2>
<p>Create <code>wk08/docs/prototyping-constraints.md</code> using this template:</p>
<pre><code class="language-markdown"># Prototyping Constraints &amp; Trade-offs

## Rendering splits
- Full page: [describe what `/tasks` returns and when it's used]
- Fragment: [describe what `/tasks/fragment` returns and when it's used]

## URL &amp; History
- [Explain how `hx-push-url="true"` maintains browser history]
- [What breaks if you remove it?]

## Accessibility hooks
- [Describe the live region `#status` and its purpose]
- [Explain `aria-describedby` connection between list and result count]
- [Why is result count visually hidden?]

## State management
- [How do query parameters (`q`, `page`) maintain state?]
- [Why must pagination links include the filter query?]

## Performance notes
- Page size: [your choice - justify it]
- Fragment response size vs full page: [estimate bandwidth savings]
- Debounce delay: [300ms - why this value?]

## Future risks
- [What could go wrong with this approach?]
- [Scalability concerns (e.g., 10,000 tasks)?]
- [Template maintenance burden?]

## Accessibility verification

### Keyboard testing
- [Results from Tab navigation test]

### Screen reader testing
- [If available: what was announced when filtering?]

### No-JS parity
- [Confirmation that all features work without JavaScript]
</code></pre>
<p><strong>Word limit</strong>: ~400-500 words total (concise bullet points preferred)</p>
<hr />
<h2 id="assessment-1"><a class="header" href="#assessment-1">Assessment</a></h2>
<p>Your work is assessed on:</p>
<ul>
<li><strong>Understanding</strong>: Clear explanation of dual-mode pattern</li>
<li><strong>Trade-off analysis</strong>: Thoughtful consideration of performance, accessibility, maintenance</li>
<li><strong>Evidence</strong>: Testing results documented</li>
</ul>
<p><strong>Not assessed</strong>: Whether you wrote the code from scratch or used the provided implementation.</p>
<hr />
<h2 id="commit--continue-4"><a class="header" href="#commit--continue-4">Commit &amp; Continue</a></h2>
<pre><code class="language-bash">git add templates/ src/ wk08/docs/prototyping-constraints.md
git commit -m "wk8s1: pagination + filtering with dual-mode support"
</code></pre>
<p>Proceed to <strong>Week 8 Lab 2</strong> for validation and no-JS parity verification.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-8--lab-2--wire-routes-verify-no-js-parity-capture-trade-offs"><a class="header" href="#week-8--lab-2--wire-routes-verify-no-js-parity-capture-trade-offs">Week 8 ‚Ä¢ Lab 2 ‚Äî Wire Routes, Verify No-JS Parity, Capture Trade-offs</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-8-orange" alt="Week 8" />
<img src="https://img.shields.io/badge/Lab-2-green" alt="Lab 2" />
<img src="https://img.shields.io/badge/Status-Draft-yellow" alt="Status" /></p>
<hr />
<h2 id="before-lab-required-reading-15-mins"><a class="header" href="#before-lab-required-reading-15-mins">Before Lab: Required Reading (15 mins)</a></h2>
<p>üìñ <strong>Essential</strong></p>
<ul>
<li>Ensure Week 8 starter repo updates (pagination work) are committed/pushed</li>
<li><a href="https://htmx.org/reference/#events">HTMX: Events Reference</a> (htmx:responseError, htmx:beforeSwap)</li>
<li><a href="https://htmx.org/attributes/hx-confirm/">HTMX: hx-confirm</a></li>
<li><a href="https://webaim.org/techniques/forms/">WebAIM: Creating Accessible Forms</a></li>
</ul>
<p>üìñ <strong>Contextual</strong>:</p>
<ul>
<li>Review <a href="wk08/../references/htmx-pattern-cheatsheet.html">HTMX Pattern Cheatsheet</a> (OOB pattern)</li>
<li>Review <a href="wk08/../references/assistive-testing-checklist.html">Assistive Testing Checklist</a></li>
<li>Review Week 7 Lab 1 inline edit implementation</li>
</ul>
<hr />
<h2 id="prerequisite-week-8-architecture-string-uuids--taskstore"><a class="header" href="#prerequisite-week-8-architecture-string-uuids--taskstore">Prerequisite: Week 8 Architecture (String UUIDs + TaskStore)</a></h2>
<p>Week 8 Lab 2 builds on the <strong>Week 8 architecture</strong> introduced in Lab 1. If you completed Lab 1, you should already have:</p>
<ul>
<li>‚úÖ <code>model/Task.kt</code> with String UUID IDs</li>
<li>‚úÖ <code>storage/TaskStore.kt</code> with <code>getById()</code>, <code>add()</code>, <code>update()</code>, <code>delete()</code> methods</li>
<li>‚úÖ Routes updated to use <code>store.*</code> instead of <code>TaskRepository.*</code></li>
</ul>
<p><strong>If you haven‚Äôt migrated yet</strong>, complete the architecture transition from Lab 1 first, or see the <a href="wk08/wk8-lab2-student-guide.html">Lab 2 Student Guide</a> for complete TaskStore implementation.</p>
<h3 id="quick-architecture-reference"><a class="header" href="#quick-architecture-reference">Quick Architecture Reference</a></h3>
<p><strong>Task Model</strong> (<code>model/Task.kt</code>):</p>
<pre><code class="language-kotlin">data class Task(
    val id: String = UUID.randomUUID().toString(),
    val title: String,
    val completed: Boolean = false,
    val createdAt: LocalDateTime = LocalDateTime.now()
)
</code></pre>
<p><strong>Key Validation</strong> (Lab 2 adds this to Task companion object):</p>
<pre><code class="language-kotlin">companion object {
    const val MIN_TITLE_LENGTH = 3
    const val MAX_TITLE_LENGTH = 100

    fun validate(title: String): ValidationResult = when {
        title.isBlank() -&gt; ValidationResult.Error("Title is required.")
        title.length &lt; MIN_TITLE_LENGTH -&gt; ValidationResult.Error("Title must be at least $MIN_TITLE_LENGTH characters.")
        title.length &gt; MAX_TITLE_LENGTH -&gt; ValidationResult.Error("Title must be less than $MAX_TITLE_LENGTH characters.")
        else -&gt; ValidationResult.Success
    }
}

sealed class ValidationResult {
    data object Success : ValidationResult()
    data class Error(val message: String) : ValidationResult()
}
</code></pre>
<p><strong>Route Pattern Changes from Week 7</strong>:</p>
<ul>
<li>‚ùå <code>call.parameters["id"]?.toIntOrNull()</code> ‚Üí ‚úÖ <code>call.parameters["id"]</code></li>
<li>‚ùå <code>TaskRepository.find(id)</code> ‚Üí ‚úÖ <code>store.getById(id)</code></li>
<li>‚ùå <code>TaskRepository.add(title)</code> ‚Üí ‚úÖ <code>val task = Task(title = title); store.add(task)</code></li>
<li>‚ùå <code>task.title = newTitle</code> (mutable) ‚Üí ‚úÖ <code>task.copy(title = newTitle)</code> (immutable)</li>
</ul>
<hr />
<h2 id="introduction-from-prototype-to-production-ready"><a class="header" href="#introduction-from-prototype-to-production-ready">Introduction: From Prototype to Production-Ready</a></h2>
<p>In Week 8 Lab 1 you added pagination and filtering. The basic functionality works: people can browse, filter, and page through tasks.</p>
<p><strong>Today‚Äôs reality check</strong>: What happens when:</p>
<ul>
<li>Someone submits an empty form?</li>
<li>JavaScript is disabled or fails to load?</li>
<li>A person uses only keyboard navigation?</li>
<li>Network drops mid-request?</li>
</ul>
<p><strong>Production systems must handle failure gracefully</strong>. This lab hardens your prototype:</p>
<ol>
<li><strong>Validation</strong>: Server-side validation with accessible error messaging</li>
<li><strong>Parity</strong>: Identical functionality with/without JavaScript</li>
<li><strong>Testing</strong>: Repeatable verification scripts</li>
<li><strong>Documentation</strong>: Trade-offs, risks, mitigations</li>
</ol>
<p><strong>HCI Connection</strong>: Robust error handling is an <strong>inclusion imperative</strong>‚Äîvalidation errors disproportionately affect people with cognitive disabilities, people using screen readers, and those with unreliable connectivity. WCAG 3.3 (Input Assistance) requires clear, accessible error identification.</p>
<hr />
<h2 id="learning-focus-5"><a class="header" href="#learning-focus-5">Learning Focus</a></h2>
<h3 id="lab-objectives-5"><a class="header" href="#lab-objectives-5">Lab Objectives</a></h3>
<p>By the end of this session, you will have:</p>
<ul>
<li>Validated form inputs with accessible error messaging</li>
<li>Ensured create/edit/delete work identically with and without JavaScript</li>
<li>Tested no-JS parity with repeatable scripts</li>
<li>Documented design trade-offs (progressive enhancement vs SPA) and mitigation strategies</li>
<li>Verified accessibility of error states with keyboard and screen reader</li>
</ul>
<h3 id="learning-outcomes-addressed-5"><a class="header" href="#learning-outcomes-addressed-5">Learning Outcomes Addressed</a></h3>
<p>This lab contributes to the following module Learning Outcomes (<a href="wk08/../references/learning-outcomes.html">full definitions</a>):</p>
<ul>
<li><strong>LO7</strong>: Analyse design constraints ‚Äî evidenced by no-JS parity testing + trade-offs doc</li>
<li><strong>LO9</strong>: Apply inclusive design ‚Äî evidenced by no-JS accessibility verification</li>
<li><strong>LO13</strong>: Integrate HCI with SE ‚Äî evidenced by routing patterns</li>
</ul>
<hr />
<h2 id="key-concepts-4"><a class="header" href="#key-concepts-4">Key Concepts</a></h2>
<h3 id="server-side-validation"><a class="header" href="#server-side-validation">Server-Side Validation</a></h3>
<blockquote>
<p><strong>Server-Side Validation</strong> [GLOSSARY]</p>
<p>Validation logic executed on the server (not browser). <strong>Always required</strong>, even with client-side validation.</p>
<p><strong>Why</strong>:</p>
<ul>
<li>Client-side can be bypassed (disabled JS, malicious requests)</li>
<li>Security boundary: never trust client input</li>
<li>Accessibility: server can return appropriate error responses for HTMX and no-JS paths</li>
</ul>
<p><strong>Pattern</strong>:</p>
<pre><code class="language-kotlin">val title = call.receiveParameters()["title"].orEmpty().trim()
if (title.isBlank()) {
    // Return error response (HTML for HTMX, redirect for no-JS)
}
</code></pre>
<p><strong>HCI Connection</strong>: Server validation enables <strong>progressive enhancement</strong>‚Äîsame validation logic serves both enhanced (HTMX) and baseline (HTML-only) experiences.</p>
<p>üîó <a href="https://cheatsheetseries.owasp.org/cheatsheets/Input_Validation_Cheat_Sheet.html">OWASP: Input Validation</a></p>
</blockquote>
<h3 id="post-redirect-get-prg-pattern"><a class="header" href="#post-redirect-get-prg-pattern">Post-Redirect-Get (PRG) Pattern</a></h3>
<blockquote>
<p><strong>Post-Redirect-Get (PRG)</strong> [GLOSSARY]</p>
<p>Respond to successful POST with redirect (303) instead of HTML. Prevents duplicate submissions on browser refresh.</p>
<p><strong>Flow</strong>:</p>
<ol>
<li>Person submits form ‚Üí <code>POST /tasks</code></li>
<li>Server validates, saves task</li>
<li>Server responds <code>303 See Other</code> ‚Üí <code>Location: /tasks</code></li>
<li>Browser follows redirect ‚Üí <code>GET /tasks</code></li>
<li>Person sees updated task list</li>
</ol>
<p><strong>Why</strong>:</p>
<ul>
<li>Refresh reloads <code>GET /tasks</code> (safe), not <code>POST /tasks</code> (duplicate)</li>
<li>Back button works predictably</li>
<li>URL reflects current state</li>
</ul>
<p><strong>Kotlin (Ktor)</strong>:</p>
<pre><code class="language-kotlin">post("/tasks") {
    // Validate and save...
    if (!call.isHtmx()) {
        call.respondRedirect("/tasks", permanent = false)
    }
}
</code></pre>
<p><strong>HCI Connection</strong>: PRG reduces cognitive load‚Äîback/forward/refresh do what people expect. Critical for accessibility (people often use back button to recover from errors).</p>
<p>üîó <a href="https://en.wikipedia.org/wiki/Post/Redirect/Get">Wikipedia: Post/Redirect/Get</a></p>
</blockquote>
<h3 id="dual-path-architecture"><a class="header" href="#dual-path-architecture">Dual-Path Architecture</a></h3>
<blockquote>
<p><strong>Dual-Path Architecture</strong> [GLOSSARY]</p>
<p>Single server route handles both HTMX (enhanced) and no-JS (baseline) requests with different responses.</p>
<p><strong>Detection</strong>:</p>
<pre><code class="language-kotlin">fun ApplicationCall.isHtmx(): Boolean =
    request.headers["HX-Request"]?.equals("true", ignoreCase = true) == true
</code></pre>
<p><strong>Response Strategy</strong>:</p>
<ul>
<li><strong>HTMX path</strong>: Return HTML fragment + OOB status</li>
<li><strong>No-JS path</strong>: Return full page or redirect (PRG)</li>
</ul>
<p><strong>Example</strong>:</p>
<pre><code class="language-kotlin">post("/tasks") {
    val title = call.receiveParameters()["title"].orEmpty().trim()
    if (title.isBlank()) {
        if (call.isHtmx()) {
            val status = """&lt;div id="status" hx-swap-oob="true"&gt;Title is required.&lt;/div&gt;"""
            return@post call.respondText(status, ContentType.Text.Html, HttpStatusCode.BadRequest)
        } else {
            return@post call.respondRedirect("/tasks?error=title")
        }
    }
    // Success path...
}
</code></pre>
<p><strong>HCI Connection</strong>: Dual-path ensures <strong>functional parity</strong> across technical contexts‚Äîequivalent experience regardless of JavaScript availability.</p>
<p>üîó <a href="https://hypermedia.systems/progressive-enhancement/">hypermedia.systems: Progressive Enhancement</a></p>
</blockquote>
<h3 id="accessible-error-identification"><a class="header" href="#accessible-error-identification">Accessible Error Identification</a></h3>
<blockquote>
<p><strong>Accessible Error Identification</strong> [GLOSSARY]</p>
<p>WCAG 3.3.1 (Level A): Errors must be identified in text and associated with the problematic input.</p>
<p><strong>Requirements</strong>:</p>
<ol>
<li>Error message in text (not just colour/icon)</li>
<li>Programmatic association (<code>aria-describedby</code> or <code>aria-errormessage</code>)</li>
<li>Focus management (people navigating with keyboard land on/near error)</li>
<li>Screen reader announcement (live region or summary)</li>
</ol>
<p><strong>Pattern (inline)</strong>:</p>
<pre><code class="language-html">&lt;label for="title"&gt;Task title&lt;/label&gt;
&lt;input id="title" name="title" aria-describedby="title-error" aria-invalid="true"&gt;
&lt;p id="title-error" role="alert"&gt;Title is required. Please enter at least one character.&lt;/p&gt;
</code></pre>
<p><strong>Pattern (summary)</strong>:</p>
<pre><code class="language-html">&lt;div role="alert" aria-live="assertive" tabindex="-1" id="error-summary"&gt;
  &lt;h2&gt;There is a problem&lt;/h2&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href="#title"&gt;Title is required&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/div&gt;
</code></pre>
<p><strong>HCI Connection</strong>: Clear error identification reduces cognitive load and is critical for people using screen readers who can‚Äôt see visual error states.</p>
<p>üîó <a href="https://www.w3.org/WAI/WCAG22/Understanding/error-identification.html">WCAG 3.3.1: Error Identification</a>
üîó <a href="https://design-system.service.gov.uk/components/error-message/">GOV.UK: Error Message Pattern</a></p>
</blockquote>
<h3 id="no-js-parity-testing"><a class="header" href="#no-js-parity-testing">No-JS Parity Testing</a></h3>
<blockquote>
<p><strong>No-JS Parity Testing</strong> [GLOSSARY]</p>
<p>Verifying that all functionality works identically with JavaScript disabled.</p>
<p><strong>Why</strong>:</p>
<ul>
<li>JavaScript may fail to load (network, CDN, blocker)</li>
<li>Some organisations disable JS for security</li>
<li>Testing baseline ensures server-first architecture is sound</li>
<li>Legal requirement in some jurisdictions (accessibility standards)</li>
</ul>
<p><strong>Methods</strong>:</p>
<ol>
<li><strong>Browser DevTools</strong>: Settings ‚Üí Disable JavaScript</li>
<li><strong>Command-line</strong>: <code>curl</code>, <code>wget</code>, <code>httpie</code></li>
<li><strong>Automated</strong>: Playwright with JS disabled, or server-side rendering tests</li>
</ol>
<p><strong>Checklist items</strong>:</p>
<ul>
<li>Forms submit and validate</li>
<li>Navigation works (links, pagination)</li>
<li>Error messages appear and are accessible</li>
<li>Success feedback is visible</li>
<li>Browser history behaves predictably</li>
</ul>
<p><strong>HCI Connection</strong>: No-JS parity is <strong>progressive enhancement</strong> verification‚Äîensures you‚Äôre truly building server-first, not HTMX-first.</p>
<p>üîó <a href="https://www.gov.uk/service-manual/technology/using-progressive-enhancement">GOV.UK: Building a resilient frontend</a></p>
</blockquote>
<hr />
<h2 id="activity-a-harden-create-flow-35-min"><a class="header" href="#activity-a-harden-create-flow-35-min">Activity A: Harden Create Flow (35 min)</a></h2>
<p>In Week 8 Lab 1 you built <code>POST /tasks</code> for basic functionality. Now add validation and dual-path error handling.</p>
<h3 id="step-1-add-server-side-validation-10-min"><a class="header" href="#step-1-add-server-side-validation-10-min">Step 1: Add server-side validation (10 min)</a></h3>
<p><strong>Current code</strong> (Week 8 Lab 1):</p>
<pre><code class="language-kotlin">post("/tasks") {
    val title = call.receiveParameters()["title"].orEmpty().trim()
    val task = Task(title = title)
    store.add(task)
    if (call.isHtmx()) {
        val item = PebbleRender.render("tasks/_item.peb", mapOf("t" to task))
        val status = """&lt;div id="status" hx-swap-oob="true"&gt;Added "${task.title}".&lt;/div&gt;"""
        return@post call.respondText(item + status, ContentType.Text.Html)
    }
    call.respondRedirect("/tasks")
}
</code></pre>
<p><strong>Problem</strong>: No validation. Empty/whitespace titles are accepted.</p>
<p><strong>Add validation</strong>:</p>
<pre><code class="language-kotlin">post("/tasks") {
    val title = call.receiveParameters()["title"].orEmpty().trim()

    // Validation
    if (title.isBlank()) {
        if (call.isHtmx()) {
            val status = """&lt;div id="status" hx-swap-oob="true"&gt;Title is required.&lt;/div&gt;"""
            return@post call.respondText(status, ContentType.Text.Html, HttpStatusCode.BadRequest)
        } else {
            // No-JS: redirect with error query param
            return@post call.respondRedirect("/tasks?error=title")
        }
    }

    if (title.length &gt; 200) {
        if (call.isHtmx()) {
            val status = """&lt;div id="status" hx-swap-oob="true"&gt;Title too long (max 200 chars).&lt;/div&gt;"""
            return@post call.respondText(status, ContentType.Text.Html, HttpStatusCode.BadRequest)
        } else {
            return@post call.respondRedirect("/tasks?error=title&amp;msg=too_long")
        }
    }

    // Success path
    val task = Task(title = title)
    store.add(task)
    if (call.isHtmx()) {
        val item = PebbleRender.render("tasks/_item.peb", mapOf("t" to task))
        val status = """&lt;div id="status" hx-swap-oob="true"&gt;Added "${task.title}".&lt;/div&gt;"""
        return@post call.respondText(item + status, ContentType.Text.Html)
    }
    call.respondRedirect("/tasks")
}
</code></pre>
<p><strong>Key points</strong>:</p>
<ul>
<li>Always validate on server (never trust client)</li>
<li>Return <code>400 Bad Request</code> for HTMX errors (semantic HTTP)</li>
<li>Use query parameters for no-JS errors (preserve form state)</li>
</ul>
<h3 id="step-2-update-template-to-show-no-js-errors-15-min"><a class="header" href="#step-2-update-template-to-show-no-js-errors-15-min">Step 2: Update template to show no-JS errors (15 min)</a></h3>
<p><strong>Update <code>templates/tasks/index.peb</code></strong>:</p>
<p>Add error summary at top (before form):</p>
<pre><code class="language-twig">{% if error %}
&lt;div role="alert" aria-live="assertive" class="error-summary" id="error-summary" tabindex="-1"&gt;
  &lt;h2&gt;There is a problem&lt;/h2&gt;
  &lt;ul&gt;
    {% if error == "title" %}
    &lt;li&gt;&lt;a href="#title"&gt;{% if msg == "too_long" %}Title is too long (max 200 characters){% else %}Title is required{% endif %}&lt;/a&gt;&lt;/li&gt;
    {% endif %}
  &lt;/ul&gt;
&lt;/div&gt;
{% endif %}
</code></pre>
<p><strong>Update form input</strong>:</p>
<pre><code class="language-twig">&lt;label for="title"&gt;Task title&lt;/label&gt;
&lt;input id="title" name="title" type="text"
       {% if error == "title" %}aria-invalid="true" aria-describedby="title-error"{% endif %}
       required&gt;
{% if error == "title" %}
&lt;p id="title-error" class="error-message"&gt;
  {% if msg == "too_long" %}Title is too long (max 200 characters){% else %}Title is required{% endif %}
&lt;/p&gt;
{% endif %}
</code></pre>
<p><strong>Update GET /tasks route</strong> to pass error params:</p>
<pre><code class="language-kotlin">get("/tasks") {
    val error = call.request.queryParameters["error"]
    val msg = call.request.queryParameters["msg"]
    val q = call.request.queryParameters["q"].orEmpty()
    val page = call.request.queryParameters["page"]?.toIntOrNull() ?: 1
    val data = store.search(q, page)

    val model = mapOf(
        "title" to "Tasks",
        "page" to data,
        "q" to q,
        "error" to error,
        "msg" to msg
    )

    val html = PebbleRender.render("tasks/index.peb", model)
    call.respondText(html, ContentType.Text.Html)
}
</code></pre>
<p><strong>Add CSS for error states</strong> (<code>static/style.css</code> or Pico CSS variables):</p>
<pre><code class="language-css">.error-summary {
  background: #fef7f7;
  border: 2px solid #d32f2f;
  padding: 1rem;
  margin-bottom: 1rem;
  border-radius: 4px;
}

.error-summary h2 {
  color: #d32f2f;
  font-size: 1.2rem;
  margin-top: 0;
}

.error-message {
  color: #d32f2f;
  font-size: 0.9rem;
  margin-top: 0.25rem;
}

input[aria-invalid="true"] {
  border-color: #d32f2f;
}
</code></pre>
<h3 id="step-3-test-both-paths-10-min"><a class="header" href="#step-3-test-both-paths-10-min">Step 3: Test both paths (10 min)</a></h3>
<p><strong>HTMX path</strong>:</p>
<ol>
<li>With JS enabled, submit empty form</li>
<li>Expect: Status message ‚ÄúTitle is required.‚Äù appears in <code>#status</code> live region</li>
<li>Form remains on page, input keeps focus</li>
<li>Try typing and submitting‚Äîshould succeed</li>
</ol>
<p><strong>No-JS path</strong>:</p>
<ol>
<li>Disable JS (DevTools ‚Üí Settings ‚Üí Disable JavaScript)</li>
<li>Submit empty form</li>
<li>Expect: Full page reload with error summary at top</li>
<li>Click error link ‚Üí focus moves to <code>#title</code> input</li>
<li>Fill form, submit ‚Üí redirect to <code>/tasks</code> with new task visible</li>
</ol>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Both paths show validation errors</li>
<li><input disabled="" type="checkbox"/>
HTMX errors use live region (announced by screen reader)</li>
<li><input disabled="" type="checkbox"/>
No-JS errors use summary with focusable link</li>
<li><input disabled="" type="checkbox"/>
Error messages are specific and actionable</li>
<li><input disabled="" type="checkbox"/>
Success path still works for both</li>
</ul>
<hr />
<h2 id="activity-b-harden-delete-flow-25-min"><a class="header" href="#activity-b-harden-delete-flow-25-min">Activity B: Harden Delete Flow (25 min)</a></h2>
<p>Delete is destructive‚Äîmust confirm and handle both JS/no-JS.</p>
<h3 id="step-1-add-confirmation-dialog-10-min"><a class="header" href="#step-1-add-confirmation-dialog-10-min">Step 1: Add confirmation dialog (10 min)</a></h3>
<p><strong>Update <code>templates/tasks/_item.peb</code></strong>:</p>
<p>Current button:</p>
<pre><code class="language-twig">&lt;button type="button" hx-delete="/tasks/{{ t.id }}" hx-target="#task-{{ t.id }}" hx-swap="outerHTML"&gt;
  Delete
&lt;/button&gt;
</code></pre>
<p><strong>Add confirmation + accessible label</strong>:</p>
<pre><code class="language-twig">&lt;button type="button"
        hx-delete="/tasks/{{ t.id }}"
        hx-target="#task-{{ t.id }}"
        hx-swap="outerHTML"
        hx-confirm="Delete the task '{{ t.title }}'?"
        aria-label="Delete task: {{ t.title }}"&gt;
  Delete
&lt;/button&gt;
</code></pre>
<p><strong>Why</strong>:</p>
<ul>
<li><code>hx-confirm</code> prompts before request (HTMX feature)</li>
<li><code>aria-label</code> provides context for screen readers (otherwise just ‚ÄúDelete Delete Delete‚Ä¶‚Äù in a list)</li>
</ul>
<h3 id="step-2-add-no-js-delete-support-15-min"><a class="header" href="#step-2-add-no-js-delete-support-15-min">Step 2: Add no-JS delete support (15 min)</a></h3>
<p><strong>Problem</strong>: <code>hx-delete</code> requires JavaScript. No-JS needs a form.</p>
<p><strong>Dual-path solution</strong>:</p>
<p>Replace button with <strong>form</strong> that works both ways:</p>
<pre><code class="language-twig">&lt;form action="/tasks/{{ t.id }}/delete" method="post" style="display: inline;"&gt;
  &lt;button type="submit"
          hx-delete="/tasks/{{ t.id }}"
          hx-target="#task-{{ t.id }}"
          hx-swap="outerHTML"
          hx-confirm="Delete the task '{{ t.title }}'?"
          aria-label="Delete task: {{ t.title }}"&gt;
    Delete
  &lt;/button&gt;
&lt;/form&gt;
</code></pre>
<p><strong>Explanation</strong>:</p>
<ul>
<li><strong>No-JS</strong>: Form submits <code>POST /tasks/{id}/delete</code></li>
<li><strong>HTMX</strong>: <code>hx-delete</code> intercepts, sends <code>DELETE /tasks/{id}</code> instead</li>
<li>Both paths work!</li>
</ul>
<p><strong>Update routes</strong> (<code>src/main/kotlin/routes/Tasks.kt</code>):</p>
<pre><code class="language-kotlin">// HTMX path (HTTP DELETE)
delete("/tasks/{id}") {
    val id = call.parameters["id"] ?: return@delete call.respond(HttpStatusCode.BadRequest)
    val task = store.getById(id)
    store.delete(id)

    val status = """&lt;div id="status" hx-swap-oob="true"&gt;Deleted "${task?.title ?: "task"}".&lt;/div&gt;"""
    // Return empty string (outerHTML swap removes the &lt;li&gt;)
    call.respondText(status, ContentType.Text.Html)
}

// No-JS path (POST fallback)
post("/tasks/{id}/delete") {
    val id = call.parameters["id"] ?: return@post call.respond(HttpStatusCode.BadRequest)
    store.delete(id)
    call.respondRedirect("/tasks")
}
</code></pre>
<p><strong>Trade-off to document</strong>: No-JS delete has no confirmation (browser POST doesn‚Äôt prompt). Options:</p>
<ol>
<li>Accept the trade-off (document in constraints doc)</li>
<li>Add intermediate confirmation page (<code>GET /tasks/{id}/delete/confirm</code>)</li>
<li>Use client-side confirmation (but that requires JS‚Ä¶)</li>
</ol>
<p>For this lab, <strong>accept and document</strong> the trade-off.</p>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
HTMX delete shows confirmation dialog</li>
<li><input disabled="" type="checkbox"/>
After confirm, task disappears with status message</li>
<li><input disabled="" type="checkbox"/>
No-JS delete submits form and redirects</li>
<li><input disabled="" type="checkbox"/>
Screen reader announces ‚ÄúDeleted [title]‚Äù (HTMX) or reads updated page (no-JS)</li>
</ul>
<hr />
<h2 id="activity-c-script-no-js-verification-20-min"><a class="header" href="#activity-c-script-no-js-verification-20-min">Activity C: Script No-JS Verification (20 min)</a></h2>
<p>Create a repeatable test script so anyone (teammate, tutor, future you) can verify parity.</p>
<h3 id="step-1-create-verification-document-15-min"><a class="header" href="#step-1-create-verification-document-15-min">Step 1: Create verification document (15 min)</a></h3>
<p><strong>Create <code>wk08/lab-w8/scripts/nojs-check.md</code></strong>:</p>
<pre><code class="language-markdown"># No-JS Parity Verification Script ‚Äî Week 8

**Purpose**: Verify all task flows work identically with JavaScript disabled.

**Setup**:
1. Open Chrome DevTools ‚Üí Settings ‚Üí Preferences ‚Üí Disable JavaScript
2. Alternatively: Use Firefox ‚Üí Settings ‚Üí Privacy &amp; Security ‚Üí Permissions ‚Üí Uncheck JavaScript
3. Hard refresh (Ctrl+Shift+R / Cmd+Shift+R) to clear cached JS

---

## Test 1: Add Task (Success Case)

**Steps**:
1. Navigate to `/tasks`
2. Enter title "No-JS test task"
3. Click "Add Task"

**Expected**:
- Full page reload (check Network tab: only HTML request)
- New task appears in list
- URL remains `/tasks` (PRG redirect)
- No error messages

**Evidence**: Screenshot of task list with new task visible.

**Result**: [ ] Pass  [ ] Fail

---

## Test 2: Add Task (Validation Error)

**Steps**:
1. Leave title field empty
2. Click "Add Task"

**Expected**:
- Full page reload
- URL shows `/tasks?error=title`
- Error summary appears at top: "There is a problem"
- Link to "#title" input
- Input has red border, error message below
- Focus can navigate to error link and then to input

**Evidence**: Screenshot of error summary and highlighted input.

**Result**: [ ] Pass  [ ] Fail

---

## Test 3: Filter Tasks

**Steps**:
1. Add tasks "Alpha", "Bravo", "Charlie"
2. Enter "ra" in filter box
3. Click "Apply" or submit form

**Expected**:
- Full page reload
- URL shows `/tasks?q=ra&amp;page=1`
- Only "Bravo" and "Charlie" visible (partial match)
- Result count updates: "Showing 2 tasks"

**Evidence**: Screenshot of filtered results with URL visible.

**Result**: [ ] Pass  [ ] Fail

---

## Test 4: Pagination

**Steps**:
1. Add 15 tasks (assuming page size = 10)
2. Navigate to page 2 using "Next" link

**Expected**:
- Full page reload
- URL shows `/tasks?page=2`
- Tasks 11-15 visible
- "Previous" link appears
- "Next" link disabled or hidden

**Evidence**: Screenshot of page 2 with navigation controls.

**Result**: [ ] Pass  [ ] Fail

---

## Test 5: Edit Task (inline)

**Steps**:
1. Click "Edit" on a task
2. Change title to "Updated via no-JS"
3. Submit

**Expected**:
- Full page reload (or inline form renders in server response)
- URL remains `/tasks` or shows task context
- Updated title visible
- No JavaScript errors (none should exist)

**Evidence**: Screenshot of updated task.

**Result**: [ ] Pass  [ ] Fail

---

## Test 6: Delete Task

**Steps**:
1. Click "Delete" button on a task

**Expected**:
- Form submits to `POST /tasks/{id}/delete`
- Full page reload
- Task removed from list
- URL redirects to `/tasks`
- **No confirmation** (documented trade-off)

**Evidence**: Screenshot of task list with item removed.

**Result**: [ ] Pass  [ ] Fail

---

## Test 7: Keyboard Navigation

**Steps**:
1. Tab through entire page (skip link ‚Üí form ‚Üí tasks ‚Üí pagination)
2. Ensure visible focus indicator at each stop
3. Activate "Add Task" with Enter
4. Navigate to error link with Tab, activate with Enter

**Expected**:
- Focus order matches visual order
- All interactive elements reachable
- Enter activates links/buttons
- Focus visible on all elements

**Evidence**: Notes on tab order, screenshot of visible focus.

**Result**: [ ] Pass  [ ] Fail

---

## Test 8: Browser History

**Steps**:
1. Start at `/tasks`
2. Add task (redirects to `/tasks`)
3. Filter to "test" (reloads to `/tasks?q=test`)
4. Go to page 2 (reloads to `/tasks?q=test&amp;page=2`)
5. Click browser Back button twice

**Expected**:
- Back #1 ‚Üí `/tasks?q=test&amp;page=1` (filtered, page 1)
- Back #2 ‚Üí `/tasks?q=test` (filtered, page 1 implicit)
- Back #3 ‚Üí `/tasks` (no filter)
- History stack matches expected behaviour

**Evidence**: Notes on history behaviour.

**Result**: [ ] Pass  [ ] Fail

---

## Summary

**Passed**: _____ / 8
**Failed**: _____ / 8

**Issues found**: (log in `backlog/backlog.csv` with IDs wk8-XX)

**Notes**:
- Attach screenshots to `evidence/wk8/nojs-parity/`
- Update `docs/prototyping-constraints.md` with any new trade-offs discovered
- Re-run this script after any route or template changes

---

**Verified by**: __________
**Date**: __________
</code></pre>
<h3 id="step-2-run-the-script-5-min"><a class="header" href="#step-2-run-the-script-5-min">Step 2: Run the script (5 min)</a></h3>
<p>Execute Tests 1-6 yourself. Capture screenshots in <code>evidence/wk8/nojs-parity/</code>.</p>
<p>Log any failures in <code>backlog/backlog.csv</code>:</p>
<pre><code class="language-csv">id,week,priority,category,description,wcag,status
wk8-01,8,high,functionality,"Delete has no confirmation in no-JS mode",,open
wk8-02,8,medium,ux,"Filter form submits on Enter but no visual feedback",,open
</code></pre>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Script documents all major flows</li>
<li><input disabled="" type="checkbox"/>
Script is repeatable by someone else</li>
<li><input disabled="" type="checkbox"/>
Evidence captured in structured folder</li>
<li><input disabled="" type="checkbox"/>
Failures logged in backlog</li>
</ul>
<hr />
<h2 id="activity-d-document-trade-offs-and-constraints-15-min"><a class="header" href="#activity-d-document-trade-offs-and-constraints-15-min">Activity D: Document Trade-offs and Constraints (15 min)</a></h2>
<p>Update <code>wk08/docs/prototyping-constraints.md</code> with a section on <strong>dual-path architecture trade-offs</strong>.</p>
<p><strong>Create or extend the file</strong>:</p>
<pre><code class="language-markdown"># Prototyping Constraints and Trade-offs ‚Äî Week 8

## Dual-Path Architecture

### Design Decision
Every route handles both HTMX (enhanced) and no-JS (baseline) requests.

### Benefits
- **Inclusion**: Works for everyone regardless of JS availability
- **Resilience**: Graceful degradation if JS fails to load
- **Testing**: Baseline path proves server-first architecture is sound
- **Progressive enhancement**: Start with accessible baseline, enhance with HTMX

### Costs
- **Code complexity**: Each route has conditional logic (`if (call.isHtmx())`)
- **Response duplication**: Must generate both fragments and full pages
- **Testing burden**: Every feature requires two test paths
- **Performance**: No-JS path triggers full page reloads (slower perceived performance)

### Risks
- **Divergence**: HTMX and no-JS paths could drift if not tested regularly
- **Error handling**: Easy to forget no-JS error path during rapid development
- **Template maintenance**: Changes to page structure must update both full templates and fragments

### Mitigations
- ‚úÖ **Verification script**: `scripts/nojs-check.md` provides repeatable tests
- ‚úÖ **Shared partials**: `_item.peb`, `_list.peb` used by both paths (single source of truth)
- ‚úÖ **Backlog tracking**: Log parity issues immediately (see `backlog/backlog.csv`)
- ‚úÖ **Weekly retesting**: Run no-JS script before each commit
- ‚ö†Ô∏è **Automated tests** (future): Playwright tests with JS disabled

---

## Validation Strategy

### Design Decision
All validation on server. No client-side validation (no `&lt;input required&gt;` enforcement).

### Benefits
- **Security**: Client-side validation can be bypassed (view source, disable JS, curl)
- **Consistency**: Same validation rules for HTMX and no-JS paths
- **Accessibility**: Server returns appropriate error format for each context

### Costs
- **Latency**: Must wait for server round-trip to see validation errors
- **UX**: No instant feedback on typos (could add client-side hints later)

### Risks
- **Frustration**: People might repeatedly submit invalid forms before reading error
- **Network dependency**: People offline can't get any feedback

### Mitigations
- ‚úÖ **Clear error messages**: Specific, actionable text ("Title is required" not "Invalid input")
- ‚úÖ **Accessible error identification**: WCAG 3.3.1 compliance (aria-invalid, aria-describedby, role=alert)
- ‚úÖ **Focus management**: Error link navigates directly to problematic field
- üîÆ **Future enhancement**: Add client-side hints (maxlength indicator, real-time char count) as progressive enhancement

---

## Delete Confirmation

### Design Decision
HTMX path uses `hx-confirm` (browser confirmation dialog). No-JS path has no confirmation.

### Benefits
- **HTMX**: Prevents accidental deletions for people with JavaScript enabled
- **Implementation simplicity**: No intermediate confirmation page needed

### Costs
- **Inconsistency**: Different UX depending on JS availability
- **Accessibility**: Browser confirm dialogs are not customisable (can't improve copy)

### Risks
- **Accidental deletion**: People without JavaScript might delete tasks by mistake
- **Compliance**: Depending on context, irreversible actions might require confirmation (WCAG 2.2.1 Timing Adjustable, 3.3.4 Error Prevention)

### Mitigations
- ‚úÖ **Documentation**: Trade-off explicitly noted in constraints doc
- ‚úÖ **Backlog item**: Consider adding `/tasks/{id}/delete/confirm` page for no-JS (low priority)
- ‚ö†Ô∏è **Research with participants** (Week 9): Test whether delete accidents occur in pilots
- üîÆ **Future option**: Add "Undo" feature (restore from soft-delete within 30s)

---

## State Management

### Design Decision
Use query parameters for filter and page state (`?q=search&amp;page=2`).

### Benefits
- **Shareable**: URL captures full state (can bookmark or share filtered view)
- **History**: Back/forward buttons work predictably
- **No-JS compatible**: Query params work without JavaScript
- **Stateless server**: No session state needed for pagination

### Costs
- **URL pollution**: Long query strings for complex filters
- **Encoding**: Must properly encode/decode special characters
- **Analytics**: Harder to track "unique pages" if many query variations exist

### Risks
- **Drift**: If fragment requests use different query params than full page, state can desync
- **Limits**: Some servers/proxies have URL length limits (~2000 chars)

### Mitigations
- ‚úÖ **Consistent param names**: Use `q` and `page` everywhere
- ‚úÖ **Validation**: Sanitise and bound page numbers (reject negative, exceeds max)
- ‚úÖ **Encoding**: Use `call.request.queryParameters` (Ktor handles encoding)
- üîÆ **Future**: If filters grow complex, consider POST with session state

---

## Performance Considerations

### Active Search Debounce
- **Decision**: 300ms debounce on `hx-trigger="keyup changed delay:300ms"`
- **Benefit**: Reduces server load (doesn't fire on every keystroke)
- **Cost**: 300ms perceived latency before filter applies
- **Mitigation**: Show loading indicator (`hx-indicator`) during request

### Page Size
- **Decision**: 10 tasks per page
- **Benefit**: Fast page loads, manageable scroll
- **Cost**: More pagination clicks for large datasets
- **Mitigation**: Could add page size selector (10/25/50) in future

### Fragment Size
- **Decision**: Return `_list + _pager + status` (~2-5KB) instead of full page (~15KB)
- **Benefit**: 70% bandwidth reduction on filter/pagination
- **Cost**: Requires dual-path logic
- **Measurement**: Use browser DevTools Network tab to verify savings

---

## Evidence and Testing

**Verification scripts**: `wk08/lab-w8/scripts/nojs-check.md`
**Evidence folder**: `evidence/wk8/nojs-parity/`
**Backlog references**: IDs `wk8-01` to `wk8-XX`

**Review schedule**: Re-run parity tests after:
- Any route changes
- Template structure updates
- Before Week 9 instrumentation (ensure baseline is solid)
- Before Gradescope Task 1 submission

**Ownership**: Entire team responsible for verifying parity. Pair on changes: one person tests HTMX, another tests no-JS.
</code></pre>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Document includes design decisions, benefits, costs, risks, mitigations</li>
<li><input disabled="" type="checkbox"/>
Each trade-off links to evidence or backlog items</li>
<li><input disabled="" type="checkbox"/>
Future improvements noted with üîÆ prefix</li>
<li><input disabled="" type="checkbox"/>
Clear ownership and review schedule</li>
</ul>
<hr />
<h2 id="activity-e-retest-with-assistive-technology-20-min"><a class="header" href="#activity-e-retest-with-assistive-technology-20-min">Activity E: Retest with Assistive Technology (20 min)</a></h2>
<p>Now that error handling and delete confirmation are in place, verify accessibility.</p>
<h3 id="step-1-keyboard-testing-5-min"><a class="header" href="#step-1-keyboard-testing-5-min">Step 1: Keyboard testing (5 min)</a></h3>
<p><strong>Test error recovery</strong>:</p>
<ol>
<li>Submit empty form</li>
<li>Tab to error summary link</li>
<li>Press Enter ‚Üí focus moves to <code>#title</code> input</li>
<li>Type title, press Enter to submit</li>
<li>Verify success message appears</li>
</ol>
<p><strong>Test delete</strong>:</p>
<ol>
<li>Tab to Delete button</li>
<li>Press Enter ‚Üí confirmation dialog appears</li>
<li>Press Enter again to confirm</li>
<li>Verify screen reader announces deletion status</li>
</ol>
<p>‚úã Check:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Error link is keyboard-accessible</li>
<li><input disabled="" type="checkbox"/>
Error link moves focus to input when activated</li>
<li><input disabled="" type="checkbox"/>
Delete button keyboard-accessible</li>
<li><input disabled="" type="checkbox"/>
Confirmation dialog keyboard-accessible</li>
</ul>
<h3 id="step-2-screen-reader-testing-10-min"><a class="header" href="#step-2-screen-reader-testing-10-min">Step 2: Screen reader testing (10 min)</a></h3>
<p><strong>Use NVDA (Windows) or Orca (Linux)</strong>:</p>
<p><strong>Test error announcement (HTMX)</strong>:</p>
<ol>
<li>Forms mode (<code>F</code> key in NVDA) ‚Üí navigate to Add Task form</li>
<li>Leave title empty, submit</li>
<li>Listen for status region update: ‚ÄúTitle is required.‚Äù</li>
<li>Verify SR announces the error (live region should trigger)</li>
</ol>
<p><strong>Test error summary (no-JS)</strong>:</p>
<ol>
<li>Disable JS, submit empty form</li>
<li>SR should read: ‚ÄúAlert. There is a problem. List with 1 item. Link. Title is required.‚Äù</li>
<li>Activate link ‚Üí SR announces: ‚ÄúEdit. Title.‚Äù</li>
</ol>
<p><strong>Test delete status</strong>:</p>
<ol>
<li>Navigate to Delete button</li>
<li>SR announces: ‚ÄúDelete task: [title]. Button.‚Äù</li>
<li>Activate, confirm</li>
<li>SR announces: ‚ÄúDeleted [title].‚Äù (from live region)</li>
</ol>
<p>‚úã Check:</p>
<ul>
<li><input disabled="" type="checkbox"/>
HTMX errors announced via live region</li>
<li><input disabled="" type="checkbox"/>
No-JS errors announced via alert role</li>
<li><input disabled="" type="checkbox"/>
Delete button has accessible name</li>
<li><input disabled="" type="checkbox"/>
Delete confirmation accessible</li>
<li><input disabled="" type="checkbox"/>
Status messages announced</li>
</ul>
<h3 id="step-3-no-js-screen-reader-test-5-min"><a class="header" href="#step-3-no-js-screen-reader-test-5-min">Step 3: No-JS screen reader test (5 min)</a></h3>
<p>Disable JS and repeat error flow with screen reader:</p>
<ol>
<li>Submit empty form (no-JS)</li>
<li>SR reads error summary</li>
<li>Activate error link</li>
<li>Verify focus lands on input</li>
<li>Fill form, submit</li>
<li>Verify SR reads updated page</li>
</ol>
<p>‚úã Check:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Error summary is first thing announced after page load</li>
<li><input disabled="" type="checkbox"/>
Error links are navigable</li>
<li><input disabled="" type="checkbox"/>
Focus management works</li>
<li><input disabled="" type="checkbox"/>
Success state is clear</li>
</ul>
<p><strong>Document findings</strong>: Add any issues to <code>backlog/backlog.csv</code>. Capture screen reader output in <code>evidence/wk8/sr-testing.txt</code>.</p>
<hr />
<h2 id="commit--reflect-10-min"><a class="header" href="#commit--reflect-10-min">Commit &amp; Reflect (10 min)</a></h2>
<h3 id="commit-message"><a class="header" href="#commit-message">Commit message</a></h3>
<pre><code class="language-bash">git add src/main/kotlin/routes/Tasks.kt templates/tasks/index.peb templates/tasks/_item.peb wk08/lab-w8/scripts/nojs-check.md wk08/docs/prototyping-constraints.md evidence/wk8/ backlog/backlog.csv

git commit -m "$(cat &lt;&lt;'EOF'
wk8s2: dual-path validation, no-JS parity, trade-offs doc

- Added server-side validation for create (blank, max length)
- Dual-path error handling: HTMX (OOB status) vs no-JS (redirect + summary)
- Accessible error identification: aria-invalid, aria-describedby, role=alert
- Hardened delete flow: hx-confirm for HTMX, form fallback for no-JS
- Created repeatable no-JS verification script (scripts/nojs-check.md)
- Documented dual-path trade-offs, risks, mitigations (docs/prototyping-constraints.md)
- Tested with keyboard and screen reader (NVDA/Orca)
- Evidence captured in evidence/wk8/nojs-parity/

Trade-off accepted: No-JS delete has no confirmation (documented in constraints)
EOF
)"
</code></pre>
<h3 id="reflection-questions-3"><a class="header" href="#reflection-questions-3">Reflection questions</a></h3>
<p><strong>Answer in <code>wk08/reflection.md</code></strong>:</p>
<ol>
<li>
<p><strong>Dual-path complexity</strong>: Was it harder to maintain HTMX and no-JS paths than you expected? What helped keep them in sync?</p>
</li>
<li>
<p><strong>Error handling</strong>: How did accessible error identification change your approach? Did you discover any WCAG requirements you hadn‚Äôt considered?</p>
</li>
<li>
<p><strong>Trade-offs</strong>: Which trade-off (e.g., no-JS delete confirmation) felt most significant? Would you design it differently with more time?</p>
</li>
<li>
<p><strong>Testing</strong>: How useful was the scripted no-JS verification? Will you use similar scripts in future projects?</p>
</li>
<li>
<p><strong>Inclusion impact</strong>: Who specifically benefits from the dual-path architecture? Think about connectivity, device age, organisational policies.</p>
</li>
<li>
<p><strong>Next steps</strong>: What would you improve before Week 9 instrumentation? Any technical debt to address?</p>
</li>
</ol>
<hr />
<h2 id="looking-ahead-week-9-evaluation"><a class="header" href="#looking-ahead-week-9-evaluation">Looking Ahead: Week 9 Evaluation</a></h2>
<p>Next week you‚Äôll instrument your prototype to capture metrics during peer pilots:</p>
<ul>
<li><strong>Task completion time</strong>: How long to add/edit/delete tasks</li>
<li><strong>Error rates</strong>: How often do validation errors occur</li>
<li><strong>No-JS performance</strong>: Compare HTMX vs no-JS completion times</li>
<li><strong>Confidence ratings</strong>: Post-task subjective feedback</li>
</ul>
<p><strong>Why this week matters</strong>: You can‚Äôt evaluate a prototype that doesn‚Äôt handle errors gracefully. Week 8 Lab 2 ensures your baseline is solid before adding instrumentation.</p>
<p><strong>Preparation</strong>:</p>
<ul>
<li>Verify all flows work (HTMX + no-JS)</li>
<li>Ensure backlog is up to date</li>
<li>Review <a href="wk08/../references/evaluation-metrics-quickref.html">Evaluation Metrics Quick Reference</a> to understand what data you‚Äôll collect</li>
</ul>
<hr />
<h2 id="further-reading--resources"><a class="header" href="#further-reading--resources">Further Reading &amp; Resources</a></h2>
<h3 id="essential"><a class="header" href="#essential">Essential</a></h3>
<ul>
<li><a href="https://www.w3.org/WAI/WCAG22/Understanding/input-assistance">WCAG 3.3: Input Assistance</a> ‚Äî Error identification and prevention</li>
<li><a href="https://design-system.service.gov.uk/components/error-message/">GOV.UK: Error Message Pattern</a> ‚Äî Accessible error design</li>
<li><a href="https://webaim.org/techniques/forms/">WebAIM: Creating Accessible Forms</a> ‚Äî Comprehensive guide including validation and screen reader considerations</li>
</ul>
<h3 id="htmx-patterns"><a class="header" href="#htmx-patterns">HTMX Patterns</a></h3>
<ul>
<li><a href="wk08/../references/htmx-pattern-cheatsheet.html">HTMX Pattern Cheatsheet</a> ‚Äî OOB status, confirmation, error handling</li>
<li><a href="https://htmx.org/examples/inline-validation/">HTMX: Validation Example</a> ‚Äî Alternative inline pattern</li>
<li><a href="https://htmx.org/attributes/hx-confirm/">HTMX: hx-confirm</a> ‚Äî Confirmation dialogs</li>
</ul>
<h3 id="testing"><a class="header" href="#testing">Testing</a></h3>
<ul>
<li><a href="wk08/../references/assistive-testing-checklist.html">Assistive Testing Checklist</a> ‚Äî Weekly testing checklist</li>
<li><a href="https://www.gov.uk/service-manual/technology/testing-with-assistive-technologies">GOV.UK: Testing with Assistive Technologies</a></li>
<li><a href="https://webaim.org/articles/screenreader_testing/">WebAIM: Screen Reader Testing</a></li>
</ul>
<h3 id="progressive-enhancement"><a class="header" href="#progressive-enhancement">Progressive Enhancement</a></h3>
<ul>
<li><a href="https://alistapart.com/article/understandingprogressiveenhancement/">A List Apart: Understanding Progressive Enhancement</a></li>
<li><a href="https://hypermedia.systems/progressive-enhancement/">hypermedia.systems: Progressive Enhancement</a></li>
<li><a href="https://www.gov.uk/service-manual/technology/using-progressive-enhancement">GOV.UK: Building a Resilient Frontend</a></li>
</ul>
<h3 id="academic"><a class="header" href="#academic">Academic</a></h3>
<ul>
<li><strong>Nielsen, J. (1994).</strong> <em>Heuristic evaluation.</em> In <em>Usability inspection methods</em> (pp. 25-62). ‚Äî Error prevention heuristic</li>
<li><strong>W3C (2023).</strong> <em>Web Content Accessibility Guidelines (WCAG) 2.2.</em> ‚Äî 3.3.1, 3.3.3, 4.1.3</li>
</ul>
<hr />
<h2 id="glossary-summary-3"><a class="header" href="#glossary-summary-3">Glossary Summary</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Term</th><th>One-line definition</th></tr></thead><tbody>
<tr><td><strong>Server-side validation</strong></td><td>Validation logic executed on the server; required for security and no-JS parity</td></tr>
<tr><td><strong>Post-Redirect-Get (PRG)</strong></td><td>Pattern where POST responds with redirect to prevent duplicate submissions</td></tr>
<tr><td><strong>Dual-path architecture</strong></td><td>Single route handles both HTMX (fragment) and no-JS (full page) requests</td></tr>
<tr><td><strong>Accessible error identification</strong></td><td>WCAG 3.3.1: Errors identified in text and programmatically associated with inputs</td></tr>
<tr><td><strong>No-JS parity testing</strong></td><td>Verifying all functionality works identically with JavaScript disabled</td></tr>
<tr><td><strong>Progressive enhancement</strong></td><td>Build accessible baseline first, then enhance with JavaScript as enhancement layer</td></tr>
<tr><td><strong>Live region</strong></td><td>ARIA region (<code>role="status"</code> or <code>aria-live</code>) that announces dynamic content changes</td></tr>
<tr><td><strong>hx-confirm</strong></td><td>HTMX attribute that shows browser confirmation dialog before sending request</td></tr>
<tr><td><strong>aria-invalid</strong></td><td>ARIA attribute indicating field contains validation error (<code>true</code>/<code>false</code>)</td></tr>
<tr><td><strong>aria-describedby</strong></td><td>ARIA attribute linking field to descriptive text (hint or error message)</td></tr>
</tbody></table>
</div>
<hr />
<p><strong>Lab complete!</strong> You now have a robust, accessible, dual-path prototype ready for evaluation instrumentation in Week 9.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-8--lab-2--student-guide-validation--no-js-parity"><a class="header" href="#week-8--lab-2--student-guide-validation--no-js-parity">Week 8 ‚Ä¢ Lab 2 ‚Äî Student Guide: Validation &amp; No-JS Parity</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-8-orange" alt="Week 8" />
<img src="https://img.shields.io/badge/Lab-2-green" alt="Lab 2" />
<img src="https://img.shields.io/badge/Type-Student_Guide-purple" alt="Guide" /></p>
<blockquote>
<p><strong>Purpose</strong>: Week 8 Lab 2 hardens your prototype with server-side validation, accessible error messaging, and dual-path architecture (HTMX + no-JS). This guide provides working code and testing scripts so you can focus on understanding trade-offs and documenting design decisions.</p>
</blockquote>
<hr />
<h2 id="how-to-use-this-guide-2"><a class="header" href="#how-to-use-this-guide-2">How to Use This Guide</a></h2>
<p><strong>If you‚Äôve implemented validation and dual-path logic:</strong> Skip Part 1, go to Part 2 (testing script) and Part 3 (documentation).</p>
<p><strong>If you need implementation help:</strong> Use Part 1 code, then complete Parts 2 &amp; 3.</p>
<hr />
<h2 id="part-1-working-implementation-optional-1"><a class="header" href="#part-1-working-implementation-optional-1">Part 1: Working Implementation (Optional)</a></h2>
<details>
<summary>Click to reveal: Task validation model (<code>src/main/kotlin/model/Task.kt</code>)</summary>
<pre><code class="language-kotlin">data class Task(
    val id: String = UUID.randomUUID().toString(),
    val title: String,
    val completed: Boolean = false,
    val createdAt: LocalDateTime = LocalDateTime.now()
) {
    companion object {
        const val MIN_TITLE_LENGTH = 3
        const val MAX_TITLE_LENGTH = 100

        fun validate(title: String): ValidationResult =
            when {
                title.isBlank() -&gt;
                    ValidationResult.Error("Title is required. Please enter a task description.")
                title.length &lt; MIN_TITLE_LENGTH -&gt;
                    ValidationResult.Error(
                        "Title must be at least $MIN_TITLE_LENGTH characters. Currently: ${title.length} characters."
                    )
                title.length &gt; MAX_TITLE_LENGTH -&gt;
                    ValidationResult.Error(
                        "Title must be less than $MAX_TITLE_LENGTH characters. Currently: ${title.length} characters."
                    )
                else -&gt; ValidationResult.Success
            }
    }
}

sealed class ValidationResult {
    data object Success : ValidationResult()
    data class Error(val message: String) : ValidationResult()
}
</code></pre>
</details>
<details>
<summary>Click to reveal: TaskStore for Week 8 (<code>src/main/kotlin/storage/TaskStore.kt</code>)</summary>
<pre><code class="language-kotlin">package storage

import model.Task
import java.io.File

/**
 * Task storage with String UUID IDs.
 * Week 8 architecture - replaces Week 7's TaskRepository with Int IDs.
 */
class TaskStore(private val csvFile: File = File("data/tasks.csv")) {
    private val tasks = mutableListOf&lt;Task&gt;()

    fun getAll(): List&lt;Task&gt; = tasks.toList()
    fun getById(id: String): Task? = tasks.find { it.id == id }
    fun add(task: Task) { tasks.add(task) }
    fun update(task: Task): Boolean {
        val index = tasks.indexOfFirst { it.id == task.id }
        return if (index != -1) { tasks[index] = task; true } else false
    }
    fun delete(id: String): Boolean = tasks.removeIf { it.id == id }

    fun search(query: String, page: Int, pageSize: Int = 10): Page&lt;Task&gt; {
        val filtered = if (query.isBlank()) getAll()
                      else getAll().filter { it.title.contains(query, ignoreCase = true) }
        val totalItems = filtered.size
        val totalPages = if (totalItems == 0) 1 else (totalItems + pageSize - 1) / pageSize
        val validPage = page.coerceIn(1, totalPages)
        val startIndex = (validPage - 1) * pageSize
        return Page(
            items = filtered.drop(startIndex).take(pageSize),
            page = validPage,
            pages = totalPages,
            total = totalItems
        )
    }
}
</code></pre>
<p><strong>Note</strong>: Also need <code>data class Page&lt;T&gt;(val items: List&lt;T&gt;, val page: Int, val pages: Int, val total: Int)</code> in <code>data/Page.kt</code></p>
</details>
<details>
<summary>Click to reveal: Create task with validation (<code>TaskRoutes.kt</code>)</summary>
<pre><code class="language-kotlin">post("/tasks") {
    val params = receiveParameters()
    val title = params["title"]?.trim() ?: ""
    val query = params["q"]?.trim() ?: ""

    when (val validation = Task.validate(title)) {
        is ValidationResult.Error -&gt; {
            // Validation failed
            if (isHtmxRequest()) {
                // HTMX path: return error status via live region
                val paginated = paginateTasks(store, query, 1)
                val statusHtml = """&lt;div id="status" hx-swap-oob="true" role="alert" aria-live="assertive" class="error"&gt;${validation.message}&lt;/div&gt;"""
                val list = renderTemplate("tasks/_list.peb", mapOf("page" to paginated, "q" to query))
                val pager = renderTemplate("tasks/_pager.peb", mapOf("page" to paginated, "q" to query))
                respondText(list + pager + statusHtml, ContentType.Text.Html)
            } else {
                // No-JS path: redirect with error query parameter
                respondRedirect("/tasks?error=title")
            }
        }
        ValidationResult.Success -&gt; {
            // Validation passed - create task
            val task = Task(title = title)
            store.add(task)

            if (isHtmxRequest()) {
                val paginated = paginateTasks(store, query, 1)
                val statusHtml = """&lt;div id="status" hx-swap-oob="true" role="status"&gt;Task "${task.title}" added successfully.&lt;/div&gt;"""
                val list = renderTemplate("tasks/_list.peb", mapOf("page" to paginated, "q" to query))
                val pager = renderTemplate("tasks/_pager.peb", mapOf("page" to paginated, "q" to query))
                respondText(list + pager + statusHtml, ContentType.Text.Html)
            } else {
                respondRedirect("/tasks")
            }
        }
    }
}
</code></pre>
</details>
<details>
<summary>Click to reveal: No-JS error display (<code>templates/tasks/index.peb</code>)</summary>
<pre><code class="language-pebble">{% extends "_layout/base.peb" %}
{% block content %}

&lt;h1&gt;Tasks&lt;/h1&gt;

{# Error summary for no-JS mode #}
{% if error %}
&lt;div role="alert" aria-live="assertive" class="error-summary" id="error-summary" tabindex="-1"&gt;
  &lt;h2&gt;There is a problem&lt;/h2&gt;
  &lt;ul&gt;
    {% if error == "title" %}
    &lt;li&gt;&lt;a href="#title"&gt;Title is required&lt;/a&gt;&lt;/li&gt;
    {% endif %}
  &lt;/ul&gt;
&lt;/div&gt;
{% endif %}

{# Add Task Form #}
&lt;form action="/tasks" method="post"
      hx-post="/tasks"
      hx-target="#task-area"
      hx-swap="innerHTML"
      hx-on::after-request="this.reset()"&gt;
  &lt;label for="title"&gt;Title&lt;/label&gt;
  &lt;input id="title" name="title" type="text"
         {% if error == "title" %}aria-invalid="true" aria-describedby="title-error"{% endif %}
         required&gt;
  {% if error == "title" %}
  &lt;p id="title-error" class="error-message"&gt;Title is required&lt;/p&gt;
  {% endif %}
  &lt;button type="submit"&gt;Add Task&lt;/button&gt;
&lt;/form&gt;

{# ...rest of template... #}
{% endblock %}
</code></pre>
<p><strong>Don‚Äôt forget</strong>: Update <code>GET /tasks</code> to pass <code>error</code> parameter to template:</p>
<pre><code class="language-kotlin">get("/tasks") {
    val error = request.queryParameters["error"]
    val q = request.queryParameters["q"]?.trim() ?: ""
    // ...pass error to template context
}
</code></pre>
</details>
<details>
<summary>Click to reveal: Task item with Edit and Delete (<code>templates/tasks/_item.peb</code>)</summary>
<pre><code class="language-pebble">&lt;li id="task-{{ task.id }}" class="task-view"&gt;
  &lt;span class="task-title"&gt;{{ task.title }}&lt;/span&gt;

  &lt;form action="/tasks/{{ task.id }}/edit" method="get" style="display: inline;"
        hx-get="/tasks/{{ task.id }}/edit"
        hx-target="#task-{{ task.id }}"
        hx-swap="outerHTML"&gt;
    &lt;button type="submit" aria-label="Edit task: {{ task.title }}"&gt;Edit&lt;/button&gt;
  &lt;/form&gt;

  {# Delete form with dual attributes #}
  &lt;form action="/tasks/{{ task.id }}/delete" method="post" style="display: inline;"
        hx-delete="/tasks/{{ task.id }}"
        hx-target="#task-{{ task.id }}"
        hx-swap="outerHTML"
        hx-confirm="Delete the task '{{ task.title }}'?"&gt;
    &lt;button type="submit" aria-label="Delete task: {{ task.title }}"&gt;Delete&lt;/button&gt;
  &lt;/form&gt;
&lt;/li&gt;
</code></pre>
<p><strong>Route handlers (dual-path)</strong>:</p>
<pre><code class="language-kotlin">// HTMX path (HTTP DELETE)
delete("/tasks/{id}") {
    val id = call.parameters["id"] ?: return@delete call.respond(HttpStatusCode.BadRequest)
    val task = store.getById(id)
    store.delete(id)
    val status = """&lt;div id="status" hx-swap-oob="true" role="status"&gt;Deleted "${task?.title ?: "task"}".&lt;/div&gt;"""
    call.respondText(status, ContentType.Text.Html)
}

// No-JS fallback (POST)
post("/tasks/{id}/delete") {
    val id = call.parameters["id"] ?: return@post call.respond(HttpStatusCode.BadRequest)
    val task = store.getById(id)
    store.delete(id)

    if (isHtmxRequest()) {
        val statusHtml = """&lt;div id="status" hx-swap-oob="true" role="status"&gt;Task "${task?.title ?: "Unknown"}" deleted.&lt;/div&gt;"""
        call.respondText(statusHtml, ContentType.Text.Html)
    } else {
        call.respondRedirect("/tasks")
    }
}
</code></pre>
</details>
<details>
<summary>Click to reveal: Edit with validation and dual-path (<code>TaskRoutes.kt</code>)</summary>
<p><strong>Update your Week 7 edit routes for Week 8 architecture:</strong></p>
<pre><code class="language-kotlin">// GET /tasks/{id}/edit - Show edit form
get("/tasks/{id}/edit") {
    val id = parameters["id"] ?: return@get respond(HttpStatusCode.BadRequest)
    val task = store.getById(id)

    if (task == null) {
        respond(HttpStatusCode.NotFound)
        return@get
    }

    if (isHtmxRequest()) {
        // HTMX: return inline edit fragment
        val html = renderTemplate("tasks/_edit.peb", mapOf("task" to task.toPebbleContext()))
        respondText(html, ContentType.Text.Html)
    } else {
        // No-JS: redirect to list (edit not supported without JS)
        respondRedirect("/tasks")
    }
}

// POST /tasks/{id}/edit - Save edits with validation
post("/tasks/{id}/edit") {
    val id = parameters["id"] ?: return@post respond(HttpStatusCode.BadRequest)
    val task = store.getById(id)

    if (task == null) {
        respond(HttpStatusCode.NotFound)
        return@post
    }

    val newTitle = receiveParameters()["title"]?.trim() ?: ""
    val validation = Task.validate(newTitle)

    if (validation is ValidationResult.Error) {
        if (isHtmxRequest()) {
            // HTMX: return edit form with error
            val html = renderTemplate("tasks/_edit.peb", mapOf(
                "task" to task.toPebbleContext(),
                "error" to validation.message
            ))
            respondText(html, ContentType.Text.Html)
        } else {
            // No-JS: redirect back
            respondRedirect("/tasks")
        }
        return@post
    }

    // Update task
    val updated = task.copy(title = newTitle)
    store.update(updated)

    if (isHtmxRequest()) {
        // HTMX: return view fragment
        val html = renderTemplate("tasks/_item.peb", mapOf("task" to updated.toPebbleContext()))
        val status = """&lt;div id="status" hx-swap-oob="true" role="status"&gt;Task updated successfully.&lt;/div&gt;"""
        respondText(html + status, ContentType.Text.Html)
    } else {
        // No-JS: redirect to list
        respondRedirect("/tasks")
    }
}
</code></pre>
<p><strong>Key changes from Week 7:</strong></p>
<ul>
<li>String IDs (no <code>toIntOrNull()</code>)</li>
<li><code>store.getById()</code> instead of <code>TaskRepository.get()</code></li>
<li><code>Task.validate()</code> for validation (same as add task)</li>
<li><code>task.copy()</code> for immutable updates</li>
</ul>
<p><strong>Edit template</strong> (<code>templates/tasks/_edit.peb</code>):</p>
<pre><code class="language-pebble">&lt;li id="task-{{ task.id }}" class="task-edit"&gt;
  &lt;form action="/tasks/{{ task.id }}/edit" method="post"
        hx-post="/tasks/{{ task.id }}/edit"
        hx-target="#task-{{ task.id }}"
        hx-swap="outerHTML"&gt;

    &lt;label for="title-{{ task.id }}"&gt;Title&lt;/label&gt;
    &lt;input type="text"
           id="title-{{ task.id }}"
           name="title"
           value="{{ task.title }}"
           required
           autofocus
           {% if error %}aria-invalid="true" aria-describedby="error-{{ task.id }}"{% endif %}&gt;

    {% if error %}
    &lt;p id="error-{{ task.id }}" class="error-message" role="alert"&gt;{{ error }}&lt;/p&gt;
    {% endif %}

    &lt;button type="submit"&gt;Save&lt;/button&gt;
    &lt;a href="/tasks"
       hx-get="/tasks/{{ task.id }}/view"
       hx-target="#task-{{ task.id }}"
       hx-swap="outerHTML"
       role="button"&gt;Cancel&lt;/a&gt;
  &lt;/form&gt;
&lt;/li&gt;
</code></pre>
</details>
<hr />
<h2 id="part-2-no-js-parity-verification-script"><a class="header" href="#part-2-no-js-parity-verification-script">Part 2: No-JS Parity Verification Script</a></h2>
<p>Create <code>wk08/scripts/nojs-check.md</code> with this testing script:</p>
<pre><code class="language-markdown"># No-JS Parity Verification Script ‚Äî Week 8

**Purpose**: Verify all task flows work identically with JavaScript disabled.

**Setup**:
1. Open browser DevTools ‚Üí Settings ‚Üí Disable JavaScript
2. Hard refresh (Ctrl+Shift+R / Cmd+Shift+R)

---

## Test 1: Add Task (Success Case)

**Steps**:
1. Navigate to `/tasks`
2. Enter title "No-JS test task"
3. Click "Add Task"

**Expected**:
- Full page reload
- New task appears in list
- URL remains `/tasks`
- No error messages

**Result**: [ ] Pass  [ ] Fail

---

## Test 2: Add Task (Validation Error)

**Steps**:
1. Leave title field empty
2. Click "Add Task"

**Expected**:
- Full page reload
- URL shows `/tasks?error=title`
- Error summary appears at top
- Input has `aria-invalid="true"`

**Result**: [ ] Pass  [ ] Fail

---

## Test 3: Filter Tasks

**Steps**:
1. Add tasks "Alpha", "Bravo", "Charlie"
2. Enter "ra" in filter box
3. Click "Apply" button

**Expected**:
- Full page reload
- URL shows `/tasks?q=ra&amp;page=1`
- Only "Bravo" and "Charlie" visible

**Result**: [ ] Pass  [ ] Fail

---

## Test 4: Pagination

**Steps**:
1. Add 15 tasks
2. Click "Next" link

**Expected**:
- Full page reload
- URL shows `/tasks?page=2`
- Tasks 11-15 visible
- "Previous" link appears

**Result**: [ ] Pass  [ ] Fail

---

## Test 5: Delete Task

**Steps**:
1. Click "Delete" button on a task

**Expected**:
- Form submits to `POST /tasks/{id}/delete`
- Full page reload
- Task removed from list
- **No confirmation dialog** (documented trade-off)

**Result**: [ ] Pass  [ ] Fail

---

## Test 6: Keyboard Navigation

**Steps**:
1. Tab through entire page
2. Press Enter on "Add Task"
3. Tab to error link, press Enter

**Expected**:
- Focus order matches visual order
- All interactive elements reachable
- Error link moves focus to input

**Result**: [ ] Pass  [ ] Fail

---

## Test 7: Browser History

**Steps**:
1. Start at `/tasks`
2. Filter to "test"
3. Go to page 2
4. Click browser Back button twice

**Expected**:
- Back #1 ‚Üí filtered, page 1
- Back #2 ‚Üí unfiltered

**Result**: [ ] Pass  [ ] Fail

---

## Summary

**Passed**: _____ / 7
**Failed**: _____ / 7

**Issues found**: (log in `wk08/backlog/issues.csv`)

**Evidence**: Capture screenshots in `wk08/evidence/nojs-parity/`

---

**Verified by**: __________
**Date**: __________
</code></pre>
<p>Run this script and capture evidence.</p>
<hr />
<h2 id="part-3-documentation--reflection"><a class="header" href="#part-3-documentation--reflection">Part 3: Documentation &amp; Reflection</a></h2>
<h3 id="update-wk08docsprototyping-constraintsmd"><a class="header" href="#update-wk08docsprototyping-constraintsmd">Update <code>wk08/docs/prototyping-constraints.md</code></a></h3>
<p>Add these sections to your existing file from Lab 1:</p>
<pre><code class="language-markdown">## Dual-Path Architecture (Lab 2)

### Design Decision
Every route handles both HTMX (enhanced) and no-JS (baseline) requests.

### Benefits
- Works for everyone regardless of JS availability
- Resilience if JS fails to load
- Testing baseline proves server-first architecture

### Costs
- Code complexity (conditional logic in every route)
- Testing burden (two paths per feature)
- Template maintenance

### Mitigations
- Shared partials (`_item.peb`, `_list.peb`)
- Verification script (`scripts/nojs-check.md`)
- Backlog tracking for parity issues

---

## Validation Strategy

### Design Decision
All validation on server. No client-side enforcement.

### Benefits
- Security (client-side can be bypassed)
- Consistency across HTMX/no-JS paths
- Accessible error responses

### Costs
- Latency (round-trip for validation)
- No instant feedback

### Mitigations
- Clear error messages (WCAG 3.3.1)
- `aria-invalid`, `aria-describedby` for screen readers
- Focus management (error link ‚Üí input)

---

## Delete Confirmation Trade-off

### Design Decision
HTMX uses `hx-confirm`. No-JS has no confirmation.

### Risk
People might accidentally delete tasks in no-JS mode.

### Mitigation
- Documented in constraints doc
- Backlog item: consider adding `/tasks/{id}/delete/confirm` page
- Future: "Undo" feature (restore from soft-delete)

---

## Evidence

**Verification script**: `wk08/scripts/nojs-check.md`
**Test results**: [7/7 passed - date]
**Evidence folder**: `wk08/evidence/nojs-parity/`
**Backlog items**: wk8-01 (delete confirmation), wk8-02 (...)
</code></pre>
<h3 id="create-wk08reflectionmd"><a class="header" href="#create-wk08reflectionmd">Create <code>wk08/reflection.md</code></a></h3>
<p>Answer these 6 questions (keep responses concise):</p>
<pre><code class="language-markdown"># Week 8 Lab 2 Reflection

## 1. Dual-path complexity
Was it harder to maintain HTMX and no-JS paths than you expected? What helped keep them in sync?

[Your answer]

---

## 2. Error handling
How did accessible error identification change your approach? Did you discover any WCAG requirements you hadn't considered?

[Your answer]

---

## 3. Trade-offs
Which trade-off (e.g., no-JS delete confirmation) felt most significant? Would you design it differently with more time?

[Your answer]

---

## 4. Testing
How useful was the scripted no-JS verification? Will you use similar scripts in future projects?

[Your answer]

---

## 5. Inclusion impact
Who specifically benefits from the dual-path architecture? Think about connectivity, device age, organisational policies.

[Your answer]

---

## 6. Next steps
What would you improve before Week 9 instrumentation? Any technical debt to address?

[Your answer]
</code></pre>
<hr />
<h2 id="assessment-2"><a class="header" href="#assessment-2">Assessment</a></h2>
<p>Your work is assessed on:</p>
<ul>
<li><strong>Verification evidence</strong>: Completed nojs-check.md with results</li>
<li><strong>Trade-off documentation</strong>: Clear explanation of design decisions, risks, mitigations</li>
<li><strong>Reflection quality</strong>: Thoughtful answers showing understanding of inclusion and constraints</li>
</ul>
<p><strong>Not assessed</strong>: Whether you wrote validation code from scratch.</p>
<hr />
<h2 id="commit--continue-5"><a class="header" href="#commit--continue-5">Commit &amp; Continue</a></h2>
<pre><code class="language-bash">git add src/ templates/ wk08/scripts/ wk08/docs/ wk08/reflection.md wk08/evidence/
git commit -m "wk8s2: dual-path validation, no-JS parity, trade-offs doc"
</code></pre>
<p>Proceed to <strong>Week 9</strong> for evaluation instrumentation.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-9--lab-1--evaluation-plan-metrics-schema-and-instrumentation"><a class="header" href="#week-9--lab-1--evaluation-plan-metrics-schema-and-instrumentation">Week 9 ‚Ä¢ Lab 1 ‚Äî Evaluation Plan, Metrics Schema, and Instrumentation</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-9-orange" alt="Week 9" />
<img src="https://img.shields.io/badge/Lab-1-green" alt="Lab 1" />
<img src="https://img.shields.io/badge/Status-Draft-yellow" alt="Status" /></p>
<hr />
<h2 id="before-lab-required-reading-20-mins"><a class="header" href="#before-lab-required-reading-20-mins">Before Lab: Required Reading (20 mins)</a></h2>
<p>üìñ <strong>Essential</strong></p>
<ul>
<li>Pull Week 9 starter repo branch (baseline instrumentation stubs):</li>
<li><a href="https://www.nngroup.com/articles/usability-testing-101/">Nielsen Norman Group: How to Conduct a Usability Test</a></li>
<li><a href="https://www.w3.org/WAI/test-evaluate/metrics/">W3C: Measuring Accessibility</a></li>
<li>Review <a href="wk09/../references/evaluation-metrics-quickref.html">Evaluation Metrics Quick Reference</a></li>
<li>Review <a href="wk09/../references/consent-pii-faq.html">Consent and PII FAQ</a></li>
</ul>
<p>üìñ <strong>Contextual</strong>:</p>
<ul>
<li><a href="https://hypermedia.systems/">hypermedia.systems: Instrumentation</a> (optional chapter if available)</li>
<li><a href="https://www.gov.uk/service-manual/user-research/plan-a-research-session">GOV.UK: Planning user research</a></li>
</ul>
<hr />
<h2 id="introduction-from-prototype-to-evidence"><a class="header" href="#introduction-from-prototype-to-evidence">Introduction: From Prototype to Evidence</a></h2>
<p>Weeks 6‚Äì8 built a functional, accessible task list prototype. <strong>Now the critical question</strong>: Does it actually work for real people?</p>
<p><strong>HCI is empirical</strong>. We can‚Äôt claim ‚Äúthis is usable‚Äù without evidence. This week you:</p>
<ol>
<li>Design an evaluation plan (what to measure, how)</li>
<li>Instrument your prototype to capture objective data</li>
<li>Prepare for peer pilots (Week 9 Lab 2)</li>
</ol>
<p><strong>Why this matters</strong>:</p>
<ul>
<li><strong>Assessment</strong> requires quantitative data (completion times, error rates) + qualitative insights</li>
<li><strong>Week 10 redesign</strong> depends on identifying real bottlenecks (not guesses)</li>
<li><strong>Assessment portfolio (due end Week 10)</strong> needs evidence chains: problem ‚Üí measurement ‚Üí fix ‚Üí verification</li>
<li><strong>Industry practice</strong>: Product decisions backed by data, not opinions</li>
</ul>
<p><strong>Ethical imperative</strong>: Evaluation must respect privacy. We follow <strong>low-risk peer study protocols</strong>‚Äîno recordings, no PII, informed consent, opt-out honoured.</p>
<hr />
<h2 id="learning-focus-6"><a class="header" href="#learning-focus-6">Learning Focus</a></h2>
<h3 id="lab-objectives-6"><a class="header" href="#lab-objectives-6">Lab Objectives</a></h3>
<blockquote>
<p><strong>Staff reference</strong>: Full instrumentation implementation lives in the <a href="wk09/../../resources/code-resources.html#week-9">solution repository</a>.
By the end of this session, you will have:</p>
</blockquote>
<ul>
<li>Designed task-based evaluation protocol with 3+ tasks and clear success criteria</li>
<li>Defined metrics (time-on-task, errors, SUS, confidence)</li>
<li>Written an ethical, repeatable protocol for peer pilots</li>
<li>Instrumented codebase to capture metrics (server-side logging)</li>
<li>Verified instrumentation captures data correctly for JS-on and JS-off paths</li>
</ul>
<h3 id="learning-outcomes-addressed-6"><a class="header" href="#learning-outcomes-addressed-6">Learning Outcomes Addressed</a></h3>
<p>This lab contributes to the following module Learning Outcomes (<a href="wk09/../references/learning-outcomes.html">full definitions</a>):</p>
<ul>
<li><strong>LO1</strong>: Differentiate people-centred methods ‚Äî evidenced by method selection rationale</li>
<li><strong>LO8</strong>: Design and execute evaluation ‚Äî evidenced by protocol + metrics + instrumentation</li>
<li><strong>LO13</strong>: Integrate HCI with SE ‚Äî evidenced by server-side instrumentation code</li>
</ul>
<hr />
<h2 id="key-concepts-5"><a class="header" href="#key-concepts-5">Key Concepts</a></h2>
<h3 id="usability-evaluation"><a class="header" href="#usability-evaluation">Usability Evaluation</a></h3>
<blockquote>
<p><strong>Usability Evaluation</strong> [GLOSSARY]</p>
<p>Systematic assessment of how well people can use a system to achieve goals. <strong>Formative</strong> (improve design during development) vs <strong>Summative</strong> (measure final quality).</p>
<p><strong>This module uses formative evaluation</strong>: gather data during development (Week 9), redesign (Week 10), verify improvements (Week 10/11).</p>
<p><strong>Components</strong>:</p>
<ul>
<li><strong>Tasks</strong>: Realistic scenarios with measurable outcomes</li>
<li><strong>Metrics</strong>: Objective (time, errors) + subjective (satisfaction, confidence)</li>
<li><strong>Participants</strong>: Peers, representative of target population</li>
<li><strong>Protocol</strong>: Step-by-step procedure ensuring consistency</li>
</ul>
<p><strong>HCI Connection</strong>: ISO 9241-11 defines usability as ‚Äúextent to which a product can be used by specified users to achieve specified goals with effectiveness, efficiency, and satisfaction.‚Äù</p>
<p><strong>Academic rigour</strong>: Evaluation design determines validity of findings. Poor tasks ‚Üí biased data ‚Üí wrong redesign decisions.</p>
<p>üîó <a href="https://www.iso.org/standard/63500.html">ISO 9241-11:2018 Usability</a>
üîó <a href="https://www.nngroup.com/articles/usability-101-introduction-to-usability/">Nielsen: Usability 101</a></p>
</blockquote>
<h3 id="task-based-evaluation"><a class="header" href="#task-based-evaluation">Task-Based Evaluation</a></h3>
<blockquote>
<p><strong>Task-Based Evaluation</strong> [GLOSSARY]</p>
<p>Participants complete realistic tasks while researchers observe and measure. Contrasts with feature walkthroughs or preference surveys.</p>
<p><strong>Task characteristics</strong>:</p>
<ul>
<li><strong>Realistic</strong>: Matches actual use context (‚ÄúFind invoices‚Äù not ‚ÄúUse filter‚Äù)</li>
<li><strong>Measurable</strong>: Clear success condition (found correct result, completed within time)</li>
<li><strong>Scoped</strong>: Completable in 2-5 minutes per task</li>
<li><strong>Representative</strong>: Covers critical flows identified in backlog</li>
</ul>
<p><strong>Example</strong>:</p>
<pre><code>Task T1: Search for Tasks
Scenario: "You need to find all tasks containing the word 'invoice'.
           Use the filter to show only matching tasks and count how many remain."
Success: Reports correct count within 2 minutes, no validation errors
</code></pre>
<p><strong>Why not feature-based?</strong> ‚ÄúTest the filter‚Äù is vague‚Äîparticipants don‚Äôt know when they‚Äôve succeeded. Task-based evaluation mirrors real-world goals.</p>
<p><strong>HCI Connection</strong>: Tasks ground evaluation in <strong>ecological validity</strong>‚Äîfindings generalize to real use.</p>
<p>üîó <a href="https://www.nngroup.com/articles/task-scenarios-usability-testing/">Nielsen: Task Scenarios for Usability Testing</a></p>
</blockquote>
<h3 id="objective-vs-subjective-metrics"><a class="header" href="#objective-vs-subjective-metrics">Objective vs Subjective Metrics</a></h3>
<blockquote>
<p><strong>Objective Metrics</strong> [GLOSSARY]</p>
<p>Measurable, observable data: completion time, error count, HTTP status codes. <strong>No interpretation required</strong>.</p>
<p><strong>Examples</strong>:</p>
<ul>
<li><strong>Time-on-task</strong>: Milliseconds from task start to completion (server-timed)</li>
<li><strong>Completion rate</strong>: Did participant achieve goal? (0 = fail, 1 = success)</li>
<li><strong>Error rate</strong>: <code>validation_error / (success + validation_error)</code></li>
<li><strong>Click/keystroke count</strong>: Efficiency measure (lower is better for same outcome)</li>
</ul>
<p><strong>Benefits</strong>: Repeatable, comparable across participants, statistically analysable
<strong>Limitations</strong>: Don‚Äôt capture frustration, confusion, satisfaction</p>
<hr />
<p><strong>Subjective Metrics</strong> [GLOSSARY]</p>
<p>Self-reported feelings, perceptions, attitudes. Require interpretation.</p>
<p><strong>Examples</strong>:</p>
<ul>
<li><strong>Confidence rating</strong>: ‚ÄúHow confident are you that you completed the task correctly?‚Äù (1‚Äì5 scale)</li>
<li><strong>Difficulty rating</strong>: ‚ÄúHow difficult was this task?‚Äù (1‚Äì7 scale)</li>
<li><strong>Satisfaction</strong>: Post-session questionnaire (SUS, UMUX-Lite)</li>
<li><strong>Qualitative notes</strong>: Open-ended feedback (‚ÄúI wasn‚Äôt sure if it saved‚Äù)</li>
</ul>
<p><strong>Benefits</strong>: Capture affective response, uncover unexpected issues
<strong>Limitations</strong>: Vary by person, memory biases, social desirability</p>
<p><strong>HCI Connection</strong>: Both required. ISO 9241-11 defines usability as <strong>effectiveness</strong> (objective: completion), <strong>efficiency</strong> (objective: time), and <strong>satisfaction</strong> (subjective).</p>
<p>üîó <a href="https://measuringux.com/">Measuring UX</a> ‚Äî Quantitative UX metrics handbook</p>
</blockquote>
<h3 id="server-side-instrumentation"><a class="header" href="#server-side-instrumentation">Server-Side Instrumentation</a></h3>
<blockquote>
<p><strong>Server-Side Instrumentation</strong> [GLOSSARY]</p>
<p>Logging application events at the server (not client). Data captured regardless of JavaScript availability.</p>
<p><strong>Why server-side?</strong></p>
<ul>
<li><strong>Reliability</strong>: Can‚Äôt be blocked by ad blockers, disabled JS, browser crashes</li>
<li><strong>Privacy</strong>: No third-party analytics (e.g., Google Analytics) that track across sites</li>
<li><strong>Parity</strong>: Same data structure for HTMX and no-JS paths</li>
<li><strong>Control</strong>: You own the data (no GDPR concerns with external processors)</li>
</ul>
<p><strong>Pattern</strong>:</p>
<pre><code class="language-kotlin">post("/tasks/{id}/edit") {
    val start = System.currentTimeMillis()
    // ... validation, update logic ...
    val duration = System.currentTimeMillis() - start
    Logger.write(session, reqId, "T2_edit", "success", "", duration, 200, jsMode)
}
</code></pre>
<p><strong>Log structure</strong> (CSV):</p>
<pre><code class="language-csv">ts_iso,session_id,request_id,task_code,step,outcome,ms,http_status,js_mode
2025-10-13T14:23:01Z,abc123,r001,T1_filter,success,,1847,200,on
2025-10-13T14:23:15Z,abc123,r002,T2_edit,validation_error,blank_title,234,400,on
</code></pre>
<p><strong>HCI Connection</strong>: Instrumentation enables <strong>empirical HCI</strong>‚Äîquantify behaviour at scale (beyond 5 pilot peers).</p>
<p>üîó <a href="https://www.exp-platform.com/">Kohavi et al.: Online Controlled Experiments</a> ‚Äî Industry practice</p>
</blockquote>
<h3 id="privacy-by-design-revisited"><a class="header" href="#privacy-by-design-revisited">Privacy by Design (Revisited)</a></h3>
<blockquote>
<p><strong>Privacy by Design</strong> [GLOSSARY]</p>
<p>Build data minimization and privacy into system architecture (not bolt on later).</p>
<p><strong>Week 9 requirements</strong>:</p>
<ul>
<li><strong>Anonymous session IDs</strong>: Random tokens (e.g., <code>sid=X7kL9p</code>), not names/emails</li>
<li><strong>No PII in logs</strong>: No IP addresses, device fingerprints, real names</li>
<li><strong>Opt-out mechanism</strong>: Participants can request data deletion (delete rows matching session_id)</li>
<li><strong>Local storage</strong>: Logs stay in private repo, not synced to public forks</li>
<li><strong>Consent clarity</strong>: Protocol explains what‚Äôs logged and why</li>
</ul>
<p><strong>Example ‚Äî BAD</strong>:</p>
<pre><code class="language-csv">timestamp,email,task,duration
2025-10-13,alice@leeds.ac.uk,T1,1800
</code></pre>
<p>‚ùå Email is PII, violates GDPR</p>
<p><strong>Example ‚Äî GOOD</strong>:</p>
<pre><code class="language-csv">ts_iso,session_id,request_id,task_code,step,outcome,ms,http_status,js_mode
2025-10-13T14:23:01Z,X7kL9p,r001,T1_filter,success,,1800,200,on
</code></pre>
<p>‚úÖ Anonymous, minimal, fit-for-purpose</p>
<p><strong>UK context</strong>: Data Protection Act 2018 + UK GDPR require <strong>lawful basis</strong> for processing. Low-risk peer studies at universities typically use ‚Äúlegitimate interest‚Äù or ‚Äúconsent‚Äù basis. <strong>Must document</strong> in protocol.</p>
<p>üîó Review <a href="wk09/../references/consent-pii-faq.html">Consent and PII FAQ</a> for full guidance
üîó <a href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/accountability-and-governance/guide-to-accountability-and-governance/accountability-and-governance/data-protection-by-design-and-default/">ICO: Privacy by Design</a></p>
</blockquote>
<h3 id="median-vs-mean"><a class="header" href="#median-vs-mean">Median vs Mean</a></h3>
<blockquote>
<p><strong>Median</strong> [GLOSSARY]</p>
<p>Middle value in sorted dataset. <strong>Resistant to outliers</strong>.</p>
<p><strong>Example</strong>: Task completion times [10s, 12s, 15s, 18s, 120s]</p>
<ul>
<li>Mean = (10+12+15+18+120)/5 = <strong>35s</strong> ‚Üê skewed by 120s outlier</li>
<li>Median = <strong>15s</strong> ‚Üê middle value, represents typical experience</li>
</ul>
<p><strong>Why use median in HCI?</strong> Completion times often have outliers (someone distracted, interrupted, confused). Median tells you what most people experienced.</p>
<p><strong>Median Absolute Deviation (MAD)</strong>: Robust measure of spread.</p>
<pre><code>MAD = median(|x_i - median(x)|)
</code></pre>
<p>Less sensitive to outliers than standard deviation.</p>
<p><strong>HCI Connection</strong>: Report median + MAD for timing data. Use mean for Likert scales (confidence ratings) where outliers are meaningful.</p>
<p>üîó <a href="https://measuringux.com/median/">Measuring UX: Why Median?</a></p>
</blockquote>
<hr />
<h2 id="activity-a-define-evaluation-tasks-30-min"><a class="header" href="#activity-a-define-evaluation-tasks-30-min">Activity A: Define Evaluation Tasks (30 min)</a></h2>
<p><strong>Goal</strong>: Create 3-4 realistic tasks that cover critical flows and accessibility concerns.</p>
<h3 id="step-1-review-backlog-and-audit-findings-10-min"><a class="header" href="#step-1-review-backlog-and-audit-findings-10-min">Step 1: Review backlog and audit findings (10 min)</a></h3>
<p>Open <code>backlog/backlog.csv</code> and identify:</p>
<ul>
<li>High-priority features (create, edit, delete, filter)</li>
<li>Accessibility fixes from Week 7 (inline edit, status announcements)</li>
<li>No-JS parity concerns from Week 8</li>
</ul>
<p><strong>Example backlog snippet</strong>:</p>
<pre><code class="language-csv">id,week,priority,category,description,wcag,status
wk7-03,7,high,a11y,"Status messages not announced in no-JS mode",4.1.3,fixed
wk8-01,8,high,parity,"Delete confirmation missing in no-JS",3.3.4,open
wk8-05,8,medium,ux,"Filter doesn't show 'no results' message",3.3.1,open
</code></pre>
<p><strong>Identify task candidates</strong>:</p>
<ul>
<li><strong>T1</strong>: Filter tasks (tests search, result announcement, no-results state)</li>
<li><strong>T2</strong>: Edit task inline (tests validation, focus management, status announcement)</li>
<li><strong>T3</strong>: Add task (tests create flow, PRG, error handling)</li>
<li><strong>T4</strong>: Delete task (tests confirmation, dual-path, status)</li>
</ul>
<h3 id="step-2-write-task-scenarios-15-min"><a class="header" href="#step-2-write-task-scenarios-15-min">Step 2: Write task scenarios (15 min)</a></h3>
<p><strong>Create <code>wk09/lab-wk9/research/tasks.md</code></strong>:</p>
<pre><code class="language-markdown"># Evaluation Tasks ‚Äî Week 9

## Task T1: Filter Tasks

**Scenario**:
"You've been asked to find all tasks containing the word 'report'. Use the filter box to show only matching tasks, then count how many tasks remain."

**Setup**:
- Pre-populate task list with 10 tasks, 3 containing "report" in title
- Example: "Submit expense report", "Draft annual report", "Review quarterly report", plus 7 others

**Success criteria**:
- Participant uses filter box (types "report")
- Participant reports correct count (3 tasks)
- Completed within 2 minutes
- No validation errors

**Metrics**:
- Time from page load to stating count (ms)
- Completion (0 = fail, 1 = success)
- Validation errors (count)
- Confidence rating (1‚Äì5): "How confident are you that you found all matching tasks?"

**Accessibility checks**:
- Result count announced by screen reader?
- Keyboard-only completion possible?
- Works with JS disabled?

---

## Task T2: Edit Task Title

**Scenario**:
"The task 'Submit invoices' has a typo. Change it to 'Submit invoices by Friday' and save the change."

**Setup**:
- Task ID 5: "Submit invoices" (visible in list)
- Participant must click Edit, change text, save

**Success criteria**:
- Participant activates edit mode
- Participant updates title correctly
- Change persists after save
- Completed within 90 seconds
- No validation errors

**Metrics**:
- Time from click Edit to save confirmation (ms)
- Completion (0/1)
- Validation errors (e.g., blank title submitted by mistake)
- Confidence rating (1‚Äì5)

**Accessibility checks**:
- Status message "Updated [title]" announced?
- Focus remains on/near edited task?
- Works with keyboard only?
- Works with JS disabled?

---

## Task T3: Add New Task

**Scenario**:
"You need to remember to 'Call supplier about delivery'. Add this as a new task."

**Setup**:
- Empty or partially filled task list
- Form visible at top of page

**Success criteria**:
- Participant types exact title (or close match)
- Submits form
- New task appears in list
- Completed within 60 seconds

**Metrics**:
- Time from focus in input to confirmation (ms)
- Completion (0/1)
- Validation errors (if they submit blank by accident)
- Confidence rating (1‚Äì5)

**Accessibility checks**:
- Status message "Added [title]" announced?
- Form remains usable after error (if triggered)?
- Works with JS disabled (PRG)?

---

## Task T4: Delete Task

**Scenario**:
"The task 'Test entry' is no longer needed. Delete it from the list."

**Setup**:
- Task ID 8: "Test entry" (visible in list)

**Success criteria**:
- Participant clicks Delete button
- Confirms deletion (HTMX path) or submits form (no-JS)
- Task removed from list
- Completed within 45 seconds

**Metrics**:
- Time from click Delete to confirmation (ms)
- Completion (0/1)
- Confirmation dialog acknowledged (HTMX only)
- Confidence rating (1‚Äì5)

**Accessibility checks**:
- Delete button has accessible name ("Delete task: Test entry")?
- Status message "Deleted [title]" announced (HTMX)?
- Works with keyboard only?
- Works with JS disabled (no confirmation, but functions)?

---

## Task Order

**Recommended sequence**:
1. **Warm-up** (not timed): "Browse the task list and familiarize yourself with the interface."
2. T3 (Add) ‚Äî Low cognitive load, builds confidence
3. T1 (Filter) ‚Äî Medium complexity, tests search
4. T2 (Edit) ‚Äî Tests inline interaction, validation
5. T4 (Delete) ‚Äî Destructive action, tests confirmation
6. **Debrief** (qualitative): Open-ended questions

**Counterbalance** if testing multiple participants: alternate T1/T2 order to avoid learning effects.

---

## Notes for Facilitator

- **Do not help** unless participant is completely stuck (&gt;3 min). Note as "facilitated" in observations.
- **Think-aloud optional**: Ask participants to narrate their thoughts if comfortable. Don't force.
- **Screen reader users**: Allow extra time for navigation. Log SR-specific observations separately.
- **Keyboard-only**: Offer keyboard-only variant to 1-2 participants for comparison.
- **No-JS**: Test at least 1 participant with JS disabled to verify parity.

---

## Success Definitions

**Completion codes**:
- `1` = Task fully completed, correct outcome
- `0.5` = Partial completion (e.g., found filter but wrong count)
- `0` = Failed or abandoned

**Time bounds**:
- T1: 120s
- T2: 90s
- T3: 60s
- T4: 45s

If participant exceeds time, prompt: "Would you like to continue, or shall we move to the next task?"
</code></pre>
<h3 id="step-3-validate-tasks-with-team-5-min"><a class="header" href="#step-3-validate-tasks-with-team-5-min">Step 3: Validate tasks with team (5 min)</a></h3>
<p>Walk through each task with your pair/team:</p>
<ul>
<li>Are scenarios realistic?</li>
<li>Are success criteria measurable?</li>
<li>Do they cover your backlog priorities?</li>
<li>Can they be completed in allocated time?</li>
</ul>
<p>Adjust wording if anything is ambiguous.</p>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
3-4 tasks defined with clear scenarios</li>
<li><input disabled="" type="checkbox"/>
Success criteria objective and measurable</li>
<li><input disabled="" type="checkbox"/>
Metrics list includes objective + subjective</li>
<li><input disabled="" type="checkbox"/>
Accessibility checks specified per task</li>
<li><input disabled="" type="checkbox"/>
Task order and timing planned</li>
</ul>
<hr />
<h2 id="activity-b-define-metrics-and-measures-20-min"><a class="header" href="#activity-b-define-metrics-and-measures-20-min">Activity B: Define Metrics and Measures (20 min)</a></h2>
<p><strong>Goal</strong>: Specify exactly how you‚Äôll calculate each metric. Prevents ambiguity during analysis (Week 10).</p>
<p><strong>Create <code>wk09/lab-wk9/research/measures.md</code></strong>:</p>
<pre><code class="language-markdown"># Metrics Definitions ‚Äî Week 9

Reference: [Evaluation Metrics Quick Reference](../references/evaluation-metrics-quickref.md)

---

## Objective Metrics

### 1. Completion Rate

**Definition**: Proportion of participants who successfully complete the task.

**Calculation**:
</code></pre>
<p>Completion rate = (# successes) / (# attempts)</p>
<pre><code>
**Data source**: Manual observation + server logs (look for `step=success`)

**Reporting**: Percentage per task (e.g., "T1: 4/5 = 80%")

**Split by**:
- JS-on vs JS-off
- Keyboard-only vs mouse
- Screen reader vs visual

---

### 2. Time-on-Task

**Definition**: Duration from task start to completion or abandonment.

**Calculation**:
- **Server-timed**: `ms` column in metrics.csv (start to success event)
- **Backup**: Facilitator stopwatch (start when participant reads scenario, stop when they say "done")

**Reporting**:
- **Median** (primary): Middle value, resistant to outliers
- **MAD**: Median absolute deviation for spread
- **Range**: Min-max for context

**Example**:
</code></pre>
<p>T1 (Filter):
Median: 24s
MAD: 6s
Range: 12s‚Äì58s (n=5)</p>
<pre><code>
**Split by**: JS-on vs JS-off (expect no-JS to be slower due to full page reloads)

---

### 3. Error Rate

**Definition**: Proportion of attempts that trigger validation errors.

**Calculation**:
</code></pre>
<p>Error rate = (# validation_error events) / (# total attempts)</p>
<pre><code>
**Data source**: `data/metrics.csv` where `step=validation_error`

**Reporting**: Percentage per task + qualitative notes on error type

**Example**:
</code></pre>
<p>T3 (Add Task):
Error rate: 2/5 = 40%
Errors: 1√ó blank title, 1√ó exceeded max length</p>
<pre><code>
**HCI insight**: High error rates ‚Üí poor affordances, unclear constraints, or accessibility issues

---

### 4. Validation Error Count

**Definition**: Number of validation errors per participant per task.

**Calculation**: Count rows in `metrics.csv` with `step=validation_error` for given session + task

**Reporting**: Mean errors per task

**Example**:
</code></pre>
<p>T2 (Edit):
Mean errors per participant: 0.4 (2 errors across 5 participants)</p>
<pre><code>
---

## Subjective Metrics

### 5. Confidence Rating

**Definition**: Self-reported confidence that task was completed correctly.

**Scale**: 1 (not at all confident) ‚Üí 5 (very confident)

**Collection method**: Ask immediately after each task:
&gt; "On a scale of 1 to 5, how confident are you that you completed that task correctly?"

**Reporting**:
- Mean + standard deviation
- Distribution (how many rated 1, 2, 3, 4, 5)

**Example**:
</code></pre>
<p>T1 (Filter):
Mean confidence: 4.2 ¬± 0.8
Distribution: 0√ó1, 0√ó2, 1√ó3, 2√ó4, 2√ó5</p>
<pre><code>
**HCI insight**: Low confidence despite successful completion ‚Üí interface doesn't provide sufficient feedback

---

### 6. Difficulty Rating (optional)

**Definition**: Perceived difficulty of task.

**Scale**: 1 (very easy) ‚Üí 7 (very difficult)

**Collection method**: Post-task question:
&gt; "How difficult was that task?"

**Reporting**: Mean ¬± SD per task

---

### 7. Post-Session Satisfaction (optional)

**Method**: 2-question UMUX-Lite (if time permits):
1. "This system's capabilities meet my requirements" (1‚Äì7: strongly disagree ‚Üí strongly agree)
2. "This system is easy to use" (1‚Äì7: strongly disagree ‚Üí strongly agree)

**Calculation**: Average of the two responses (higher = better perceived usability)

**Reporting**: Mean score across all participants

**Note**: UMUX-Lite takes &lt;30 seconds, validated proxy for SUS (System Usability Scale)

---

## Qualitative Observations

### 8. Facilitator Notes

**Capture**:
- Hesitations ("Participant paused 10s before clicking filter")
- Verbalizations ("I'm not sure if it saved")
- Accessibility issues ("Screen reader didn't announce result count")
- Workarounds ("Used Ctrl+F instead of built-in filter")

**Format**: Timestamped notes in `pilot-notes.md`

**Analysis**: Thematic coding in Week 10 (group similar issues, link to backlog items)

---

## Accessibility-Specific Metrics

### 9. Keyboard-Only Completion

**Definition**: Can task be completed using only keyboard (no mouse)?

**Measurement**: Binary per task (yes/no)

**Reporting**: "T1: Keyboard-accessible ‚úÖ" or "T3: Tab order broken, failed ‚úó"

---

### 10. Screen Reader Announcement Quality

**Definition**: Are status messages and result counts announced appropriately?

**Measurement**: Qualitative note per task (announced / not announced / partial)

**Reporting**: List issues with WCAG references (4.1.3 Status Messages)

---

## Data Integrity Checks

Before analysis (Week 10):
- **Completeness**: All tasks have `session_id`, `task_code`, `step`
- **Plausibility**: Times within expected ranges (12s‚Äì120s for T1)
- **Consistency**: JS-mode matches observed condition
- **Outliers**: Flag times &gt;3√ó median for review

Document any anomalies in `wk09/lab-wk9/research/data-notes.md`

---

## Summary Table

| Metric | Type | Source | Calculation | Reporting |
|--------|------|--------|-------------|-----------|
| Completion rate | Objective | Manual + logs | successes / attempts | % per task |
| Time-on-task | Objective | Server logs | Median + MAD | Seconds |
| Error rate | Objective | Server logs | errors / attempts | % per task |
| Confidence | Subjective | Post-task question | Mean ¬± SD | 1‚Äì5 scale |
| Facilitator notes | Qualitative | Manual observation | Thematic coding | Categories |
| KB-only completion | Accessibility | Manual test | Binary | ‚úÖ/‚úó |
| SR announcements | Accessibility | SR observation | Qualitative | Issues list |
</code></pre>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Every metric has clear definition</li>
<li><input disabled="" type="checkbox"/>
Calculation methods specified</li>
<li><input disabled="" type="checkbox"/>
Data sources identified (logs vs manual)</li>
<li><input disabled="" type="checkbox"/>
Reporting format decided (median vs mean, etc.)</li>
<li><input disabled="" type="checkbox"/>
Accessibility metrics included</li>
</ul>
<hr />
<h2 id="activity-c-write-ethical-protocol-25-min"><a class="header" href="#activity-c-write-ethical-protocol-25-min">Activity C: Write Ethical Protocol (25 min)</a></h2>
<p><strong>Goal</strong>: Document the procedure so it‚Äôs repeatable and ethical.</p>
<p><strong>Create <code>wk09/lab-wk9/research/protocol.md</code></strong>:</p>
<pre><code class="language-markdown"># Peer Pilot Protocol ‚Äî Week 9

## Study Overview

**Purpose**: Evaluate usability and accessibility of task list prototype with peer participants.

**Type**: Low-risk formative evaluation, peer-to-peer within module.

**Scope**:
- 5‚Äì6 participants (lab pairs)
- 4 tasks per session (~15‚Äì20 minutes)
- No audio/video recording
- No personally identifiable information collected

**Ethical approval**: Covered by module's blanket low-risk consent for peer learning activities (verified with module leader).

**Data retention**: Anonymised logs stored in private repo for academic year, deleted after module assessment complete.

---

## Participant Requirements

**Inclusion**:
- Enrolled in COMP2850
- Comfortable using web browsers
- Able to provide informed consent

**Exclusion**:
- None (module is inclusive by design)

**Accessibility accommodations**:
- Screen reader users: allowed extra time, SR-specific observations recorded separately
- Keyboard-only users: explicitly invited to test no-mouse variant
- No-JS users: at least one session conducted with JS disabled

---

## Consent Process

**Before starting** (read aloud):

&gt; "Thanks for agreeing to pilot our prototype. This is a quick usability test‚Äîabout 15 minutes. I'll ask you to complete 4 tasks while I observe and take notes. I'm testing the interface, not you, so there are no wrong answers.
&gt;
&gt; **What we're collecting**:
&gt; - Task completion times (from server logs)
&gt; - Whether you complete each task successfully
&gt; - Errors or validation issues
&gt; - Your confidence ratings after each task
&gt; - My notes on any hesitations or accessibility issues
&gt;
&gt; **What we're NOT collecting**:
&gt; - Your name, email, or student ID
&gt; - Screen recordings or audio
&gt; - Your device details beyond 'keyboard-only' or 'screen reader'
&gt;
&gt; I'll assign you a random session code (like `sid=X7kL9p`) which will appear in the logs. You can request that I delete all data linked to your session code at any time, even after today.
&gt;
&gt; **You can stop at any time**, no questions asked, and it won't affect your grade.
&gt;
&gt; Do you have any questions before we start?"

**Verbal consent**: "Are you happy to proceed?"

Record in `wk09/lab-wk9/research/consent-log.md`:
</code></pre>
<p>Date: 2025-10-15
Participant code: P1
Session ID: X7kL9p
Consent: Verbal consent given
Notes: Requested keyboard-only variant</p>
<pre><code>
**Opt-out path**: If participant requests deletion:
1. Open `data/metrics.csv`
2. Delete all rows where `session_id=X7kL9p`
3. Note in `consent-log.md`: "Data deleted on request [date]"

---

## Session Setup

**Environment**:
- Quiet space in lab (not open-plan area)
- Participant laptop/desktop with browser open to prototype
- Facilitator laptop for notes (don't share screen)

**Pre-pilot**:
1. Generate random session ID: `openssl rand -hex 3` ‚Üí e.g., `7a9f2c`
2. Set cookie in participant browser:
   ```javascript
   document.cookie = "sid=7a9f2c; path=/";
</code></pre>
<ol start="3">
<li>Navigate to <code>/tasks</code> (should be pre-populated with seed data)</li>
<li>Position facilitator to side (not behind‚Äîfeels invasive)</li>
</ol>
<p><strong>Materials</strong>:</p>
<ul>
<li>Printed task scenarios (or read aloud)</li>
<li><code>pilot-notes.md</code> template open</li>
<li>Stopwatch (backup timing)</li>
</ul>
<hr />
<h2 id="session-flow"><a class="header" href="#session-flow">Session Flow</a></h2>
<h3 id="0-introduction-2-min"><a class="header" href="#0-introduction-2-min">0. Introduction (2 min)</a></h3>
<ul>
<li>Consent process (see above)</li>
<li>Explain think-aloud (optional): ‚ÄúFeel free to say what you‚Äôre thinking as you go, but no pressure.‚Äù</li>
<li>Set expectations: ‚ÄúI won‚Äôt help unless you‚Äôre stuck for &gt;3 minutes.‚Äù</li>
</ul>
<h3 id="1-warm-up-2-min-not-timed"><a class="header" href="#1-warm-up-2-min-not-timed">1. Warm-up (2 min, not timed)</a></h3>
<p>‚ÄúTake a minute to browse the task list. Click around, get familiar. Let me know when you‚Äôre ready to start the timed tasks.‚Äù</p>
<h3 id="2-task-t3-add-task-60s-limit"><a class="header" href="#2-task-t3-add-task-60s-limit">2. Task T3: Add Task (60s limit)</a></h3>
<p><strong>Read scenario</strong>:
‚ÄúYou need to remember to ‚ÄòCall supplier about delivery‚Äô. Add this as a new task.‚Äù</p>
<p><strong>Start timing</strong> when participant focuses in input field (or reads scenario, if using stopwatch).</p>
<p><strong>Observe</strong>:</p>
<ul>
<li>Do they find the form immediately?</li>
<li>Do they submit blank by mistake?</li>
<li>Do they notice the success confirmation?</li>
</ul>
<p><strong>Post-task question</strong>:
‚ÄúOn a scale of 1 to 5, how confident are you that you completed that correctly?‚Äù</p>
<p><strong>Record</strong>: Completion (0/1), confidence, notes</p>
<hr />
<h3 id="3-task-t1-filter-tasks-120s-limit"><a class="header" href="#3-task-t1-filter-tasks-120s-limit">3. Task T1: Filter Tasks (120s limit)</a></h3>
<p><strong>Read scenario</strong>:
‚ÄúYou‚Äôve been asked to find all tasks containing the word ‚Äòreport‚Äô. Use the filter to show only matching tasks, then count how many remain.‚Äù</p>
<p><strong>Observe</strong>:</p>
<ul>
<li>Do they find the filter box?</li>
<li>Do they read the result count?</li>
<li>Do they manually count items?</li>
</ul>
<p><strong>Post-task</strong>: Confidence rating</p>
<hr />
<h3 id="4-task-t2-edit-task-90s-limit"><a class="header" href="#4-task-t2-edit-task-90s-limit">4. Task T2: Edit Task (90s limit)</a></h3>
<p><strong>Read scenario</strong>:
‚ÄúThe task ‚ÄòSubmit invoices‚Äô has a typo. Change it to ‚ÄòSubmit invoices by Friday‚Äô and save the change.‚Äù</p>
<p><strong>Observe</strong>:</p>
<ul>
<li>Do they find Edit button?</li>
<li>Do they trigger validation errors?</li>
<li>Do they check that change persisted?</li>
</ul>
<p><strong>Post-task</strong>: Confidence rating</p>
<hr />
<h3 id="5-task-t4-delete-task-45s-limit"><a class="header" href="#5-task-t4-delete-task-45s-limit">5. Task T4: Delete Task (45s limit)</a></h3>
<p><strong>Read scenario</strong>:
‚ÄúThe task ‚ÄòTest entry‚Äô is no longer needed. Delete it.‚Äù</p>
<p><strong>Observe</strong>:</p>
<ul>
<li>Confirmation dialog (HTMX) or direct submit (no-JS)?</li>
<li>Do they verify deletion succeeded?</li>
</ul>
<p><strong>Post-task</strong>: Confidence rating</p>
<hr />
<h3 id="6-debrief-3-min"><a class="header" href="#6-debrief-3-min">6. Debrief (3 min)</a></h3>
<p><strong>Ask</strong>:</p>
<ol>
<li>‚ÄúWhich task felt most difficult?‚Äù</li>
<li>‚ÄúDid anything surprise you or not work as you expected?‚Äù</li>
<li>‚ÄúWere there any points where you weren‚Äôt sure if something had worked?‚Äù</li>
<li>‚Äú(For SR/keyboard users) Did you encounter any accessibility barriers?‚Äù</li>
</ol>
<p><strong>Record</strong> verbatim quotes in notes.</p>
<p><strong>Thank participant</strong>:
‚ÄúThat‚Äôs really helpful, thank you. Your feedback will directly improve the prototype.‚Äù</p>
<hr />
<h2 id="facilitator-guidelines"><a class="header" href="#facilitator-guidelines">Facilitator Guidelines</a></h2>
<p><strong>Do</strong>:</p>
<ul>
<li>Remain neutral (don‚Äôt lead: ‚ÄúDid you see the status message?‚Äù)</li>
<li>Take detailed notes (timestamps, direct quotes)</li>
<li>Allow silence (don‚Äôt fill pauses)</li>
<li>Note when you intervene (‚ÄúPrompted after 3min stuck‚Äù)</li>
</ul>
<p><strong>Don‚Äôt</strong>:</p>
<ul>
<li>Explain the interface before tasks</li>
<li>Show participant how to do something (defeats the test)</li>
<li>Justify design choices (‚ÄúIt‚Äôs supposed to work like this‚Ä¶‚Äù)</li>
<li>Make participant feel judged</li>
</ul>
<p><strong>If participant is completely stuck</strong>:</p>
<ul>
<li>Wait 3 minutes</li>
<li>Ask: ‚ÄúWhat are you looking for?‚Äù (diagnostic question)</li>
<li>If still stuck: ‚ÄúLet‚Äôs move to the next task‚Äù</li>
<li><strong>Mark task as failed, note reason</strong></li>
</ul>
<hr />
<h2 id="data-recording"><a class="header" href="#data-recording">Data Recording</a></h2>
<p><strong>Automated</strong> (server logs ‚Üí <code>data/metrics.csv</code>):</p>
<ul>
<li>Timestamp, session_id, task_code, step (start/success/validation_error), ms, js_mode</li>
</ul>
<p><strong>Manual</strong> (<code>wk09/lab-wk9/research/pilot-notes.md</code>):</p>
<pre><code>Session: P1 (sid=7a9f2c)
Date: 2025-10-15
Variant: Keyboard-only, JS-on

| Time | Task | Observation | Tag |
|------|------|-------------|-----|
| 14:23 | T3 | Participant hesitated before submitting‚Äîunsure if 'Enter' or button | ux-feedback |
| 14:25 | T3 | Success message not noticed initially | a11y-status |
| 14:26 | T1 | Typed 'report' slowly, watching for instant results | ux-expectation |
| 14:27 | T1 | Screen reader announced "Showing 3 tasks" ‚úì | a11y-pass |
| 14:29 | T2 | Clicked Edit, validation error triggered (blank submission) | error-handling |
| 14:30 | T2 | Recovered from error, completed successfully | resilience |

Debrief notes:
- "I liked that the filter worked without clicking a button"
- "I wasn't sure the edit saved‚Äîmaybe make the message more obvious?"
- SR announced status messages correctly throughout
</code></pre>
<p><strong>Subjective ratings</strong> (post-task, in notes):</p>
<pre><code>Confidence ratings (1‚Äì5):
  T3: 5
  T1: 4
  T2: 3 ("not sure it saved")
  T4: 5
</code></pre>
<hr />
<h2 id="post-session"><a class="header" href="#post-session">Post-Session</a></h2>
<p><strong>Immediate</strong>:</p>
<ol>
<li>Save notes to <code>wk09/lab-wk9/research/pilots/P1-notes.md</code></li>
<li>Check <code>data/metrics.csv</code> for completeness (all tasks logged?)</li>
<li>Note any missing data or anomalies</li>
</ol>
<p><strong>After all pilots</strong>:</p>
<ol>
<li>Copy <code>data/metrics.csv</code> to <code>wk09/assessment/results.csv</code></li>
<li>Aggregate notes into themes (Week 10 lab)</li>
<li>Calculate medians, error rates (Week 10 lab)</li>
</ol>
<hr />
<h2 id="accessibility-variants"><a class="header" href="#accessibility-variants">Accessibility Variants</a></h2>
<h3 id="keyboard-only-session"><a class="header" href="#keyboard-only-session">Keyboard-Only Session</a></h3>
<ul>
<li>Participant uses Tab, Enter, Space only (no mouse)</li>
<li>Observe tab order, focus visibility, keyboard traps</li>
<li>Note any unreachable elements</li>
</ul>
<h3 id="screen-reader-session"><a class="header" href="#screen-reader-session">Screen Reader Session</a></h3>
<ul>
<li>Participant uses NVDA (Windows) or Orca (Linux)</li>
<li>Allow 2√ó time for navigation</li>
<li>Note announcements, label quality, live region behaviour</li>
<li>Capture SR output in notes (verbatim if possible)</li>
</ul>
<h3 id="no-js-session"><a class="header" href="#no-js-session">No-JS Session</a></h3>
<ul>
<li>Disable JavaScript in browser settings before starting</li>
<li>Expect slower times (full page reloads)</li>
<li>Verify all tasks still function (parity check)</li>
<li>Note any missing features or broken flows</li>
</ul>
<hr />
<h2 id="risk-mitigation"><a class="header" href="#risk-mitigation">Risk Mitigation</a></h2>
<p><strong>Participant distress</strong>: If participant becomes frustrated:</p>
<ul>
<li>Reassure: ‚ÄúThis is really helpful feedback‚Äîit‚Äôs the interface, not you.‚Äù</li>
<li>Offer to skip task or stop session</li>
</ul>
<p><strong>Technical failure</strong>: If server crashes mid-session:</p>
<ul>
<li>Restart server, reload page</li>
<li>Resume from next task (don‚Äôt re-run completed tasks)</li>
<li>Note incident in data-notes.md</li>
</ul>
<p><strong>Data loss</strong>: If logs don‚Äôt record correctly:</p>
<ul>
<li>Use facilitator stopwatch times as backup</li>
<li>Note in data-notes.md: ‚ÄúSession P3: server logs incomplete, used manual timing‚Äù</li>
</ul>
<hr />
<h2 id="summary-checklist"><a class="header" href="#summary-checklist">Summary Checklist</a></h2>
<p>Before each session:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Generate session ID, set cookie</li>
<li><input disabled="" type="checkbox"/>
Seed task database with test data</li>
<li><input disabled="" type="checkbox"/>
Print or queue task scenarios</li>
<li><input disabled="" type="checkbox"/>
Open pilot-notes template</li>
<li><input disabled="" type="checkbox"/>
Confirm server running</li>
</ul>
<p>During session:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Read consent script, obtain verbal consent</li>
<li><input disabled="" type="checkbox"/>
Record session metadata (P code, sid, date)</li>
<li><input disabled="" type="checkbox"/>
Time each task (automated + backup)</li>
<li><input disabled="" type="checkbox"/>
Collect confidence ratings</li>
<li><input disabled="" type="checkbox"/>
Take qualitative notes with timestamps</li>
<li><input disabled="" type="checkbox"/>
Debrief open questions</li>
</ul>
<p>After session:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Save notes to pilots/ directory</li>
<li><input disabled="" type="checkbox"/>
Verify logs in metrics.csv</li>
<li><input disabled="" type="checkbox"/>
Thank participant, reiterate opt-out path</li>
</ul>
<pre><code>
‚úã **Stop and check**:
- [ ] Consent process clear and ethical
- [ ] Session flow structured and timed
- [ ] Facilitator guidelines prevent bias
- [ ] Data recording specified (auto + manual)
- [ ] Accessibility variants documented
- [ ] Risk mitigation addressed

---

## Activity D: Implement Instrumentation (35 min)

**Goal**: Add server-side logging to capture task events.

### Step 1: Define schema (5 min)

**Create `wk09/lab-wk9/instr/schema.md`**:

```markdown
# Metrics CSV Schema

**File**: `data/metrics.csv`

**Columns**:
```csv
ts_iso,session_id,request_id,task_code,step,outcome,ms,http_status,js_mode
</code></pre>
<div class="table-wrapper"><table><thead><tr><th>Column</th><th>Type</th><th>Description</th><th>Example</th></tr></thead><tbody>
<tr><td><code>ts_iso</code></td><td>ISO 8601 timestamp</td><td>Event timestamp (UTC)</td><td><code>2025-10-13T14:23:01.832Z</code></td></tr>
<tr><td><code>session_id</code></td><td>String (6-12 chars)</td><td>Anonymous session identifier</td><td><code>X7kL9p</code></td></tr>
<tr><td><code>request_id</code></td><td>String</td><td>Unique request identifier</td><td><code>r001</code></td></tr>
<tr><td><code>task_code</code></td><td>String</td><td>Task identifier from evaluation plan</td><td><code>T1_filter</code>, <code>T2_edit</code>, <code>T3_add</code>, <code>T4_delete</code></td></tr>
<tr><td><code>step</code></td><td>Enum</td><td>Event type</td><td><code>start</code>, <code>success</code>, <code>validation_error</code>, <code>fail</code>, <code>server_error</code></td></tr>
<tr><td><code>outcome</code></td><td>String</td><td>Specific outcome (for errors)</td><td><code>blank_title</code>, <code>max_length</code>, empty for success</td></tr>
<tr><td><code>ms</code></td><td>Integer</td><td>Duration in milliseconds (start to event)</td><td><code>1847</code></td></tr>
<tr><td><code>http_status</code></td><td>Integer</td><td>HTTP status code</td><td><code>200</code>, <code>400</code>, <code>500</code></td></tr>
<tr><td><code>js_mode</code></td><td>Enum</td><td>JavaScript availability</td><td><code>on</code> (HTMX), <code>off</code> (no-JS)</td></tr>
</tbody></table>
</div>
<p><strong>Example rows</strong>:</p>
<pre><code class="language-csv">ts_iso,session_id,request_id,task_code,step,outcome,ms,http_status,js_mode
2025-10-13T14:23:01.832Z,X7kL9p,r001,T1_filter,success,,1847,200,on
2025-10-13T14:25:12.123Z,X7kL9p,r002,T3_add,validation_error,blank_title,234,400,on
2025-10-13T14:26:03.456Z,X7kL9p,r003,T3_add,success,,567,200,on
2025-10-13T14:28:15.789Z,X7kL9p,r004,T2_edit,success,,1234,200,on
</code></pre>
<blockquote>
<p><strong>üìä Walkthrough: Understanding a User Session</strong></p>
<p>Let‚Äôs trace <strong>one participant</strong> (session <code>X7kL9p</code>) through their tasks:</p>
<div class="table-wrapper"><table><thead><tr><th>#</th><th>Time</th><th>Task</th><th>What Happened</th><th><code>step</code></th><th><code>outcome</code></th><th><code>ms</code></th><th><code>js_mode</code></th></tr></thead><tbody>
<tr><td><strong>1</strong></td><td>14:23:01</td><td><strong>T1</strong> (Filter)</td><td>‚úÖ Successfully filtered tasks</td><td><code>success</code></td><td><em>(empty)</em></td><td>1847ms</td><td><code>on</code> (HTMX)</td></tr>
<tr><td><strong>2</strong></td><td>14:25:12</td><td><strong>T3</strong> (Add)</td><td>‚ùå Tried to add blank title</td><td><code>validation_error</code></td><td><code>blank_title</code></td><td>234ms</td><td><code>on</code> (HTMX)</td></tr>
<tr><td><strong>3</strong></td><td>14:26:03</td><td><strong>T3</strong> (Add)</td><td>‚úÖ Retry succeeded</td><td><code>success</code></td><td><em>(empty)</em></td><td>567ms</td><td><code>on</code> (HTMX)</td></tr>
<tr><td><strong>4</strong></td><td>14:28:15</td><td><strong>T2</strong> (Edit)</td><td>‚úÖ Edited task inline</td><td><code>success</code></td><td><em>(empty)</em></td><td>1234ms</td><td><code>on</code> (HTMX)</td></tr>
</tbody></table>
</div>
<p><strong>Observations</strong>:</p>
<ul>
<li><strong>Same <code>session_id</code></strong> (<code>X7kL9p</code>) = all rows belong to one participant‚Äôs session</li>
<li><strong>Row 2 ‚Üí Row 3</strong>: User made a validation error (<code>blank_title</code>), then retried successfully</li>
<li><strong><code>ms</code> column</strong>: Row 2 is fast (234ms) because validation happens server-side instantly, Row 1 is slower (1847ms) because filtering queries the database</li>
<li><strong><code>js_mode=on</code></strong>: This participant had JavaScript enabled (HTMX working)</li>
<li><strong><code>outcome</code> empty for success</strong>: Only populated when <code>step=validation_error</code> or <code>fail</code></li>
</ul>
<p><strong>Why this matters for analysis</strong>:</p>
<ul>
<li><strong>Error rate</strong>: 1 error / 4 attempts = 25% error rate for this participant</li>
<li><strong>Recovery</strong>: User recovered from error (Row 3 success after Row 2 error) = good resilience</li>
<li><strong>Time-to-task</strong>: Row 1 took 1.8 seconds (reasonable for filter operation)</li>
<li><strong>Comparison</strong>: We can compare this participant‚Äôs times against median times for T1, T2, T3, T4</li>
</ul>
</blockquote>
<p><strong>Notes</strong>:</p>
<ul>
<li><code>ms</code> measures server-side duration only (not client rendering)</li>
<li><code>start</code> events optional (can derive from first log per task per session)</li>
<li><code>outcome</code> field allows filtering by specific error types in analysis</li>
</ul>
<pre><code>
### Step 2: Create Logger helper (10 min)

**Create `src/main/kotlin/utils/Logger.kt`**:

```kotlin
package utils

import io.ktor.http.HttpStatusCode
import java.io.File
import java.time.Instant
import java.time.format.DateTimeFormatter

/**
 * Simple CSV logger for HCI evaluation metrics.
 * Thread-safe, appends to data/metrics.csv.
 *
 * Privacy: Ensure session_id is anonymous (no PII).
 */
data class LogEntry(
    val sessionId: String,
    val requestId: String,
    val taskCode: String,
    val step: String,
    val outcome: String,
    val durationMs: Long,
    val statusCode: Int,
    val jsMode: String,
)

object Logger {
    private val out =
        File("data/metrics.csv").apply {
            parentFile?.mkdirs()
            if (!exists()) writeText("ts_iso,session_id,request_id,task_code,step,outcome,ms,http_status,js_mode\n")
        }

    @Synchronized
    fun write(entry: LogEntry) {
        val ts = DateTimeFormatter.ISO_INSTANT.format(Instant.now())
        out.appendText(
            "$ts,${entry.sessionId},${entry.requestId},${entry.taskCode},${entry.step}," +
                "${entry.outcome},${entry.durationMs},${entry.statusCode},${entry.jsMode}\n",
        )
    }

    fun validationError(
        sessionId: String,
        requestId: String,
        taskCode: String,
        outcome: String,
        jsMode: String,
    ) {
        write(
            LogEntry(
                sessionId = sessionId,
                requestId = requestId,
                taskCode = taskCode,
                step = "validation_error",
                outcome = outcome,
                durationMs = 0,
                statusCode = HttpStatusCode.BadRequest.value,
                jsMode = jsMode,
            )
        )
    }

    fun success(
        sessionId: String,
        requestId: String,
        taskCode: String,
        durationMs: Long,
        jsMode: String,
    ) {
        write(
            LogEntry(
                sessionId = sessionId,
                requestId = requestId,
                taskCode = taskCode,
                step = "success",
                outcome = "",
                durationMs = durationMs,
                statusCode = HttpStatusCode.OK.value,
                jsMode = jsMode,
            )
        )
    }
}
</code></pre>
<h3 id="step-3-create-timing-helper-10-min"><a class="header" href="#step-3-create-timing-helper-10-min">Step 3: Create timing helper (10 min)</a></h3>
<p><strong>Create <code>src/main/kotlin/utils/Timing.kt</code></strong>:</p>
<pre><code class="language-kotlin">package utils

import io.ktor.server.application.*
import io.ktor.util.*

/**
 * Timing helper for HCI evaluation.
 * Wraps a block of code, measures duration, logs result.
 */

// AttributeKey for storing request start time
val RequestStartTimeKey = AttributeKey&lt;Long&gt;("RequestStartTime")

// AttributeKey for request ID
val RequestIdKey = AttributeKey&lt;String&gt;("RequestId")

/**
 * Extension function to time a block of code and log the result.
 *
 * Usage:
 *   call.timed(taskCode = "T1_filter", jsMode = "on") {
 *       // ... validation, processing, etc.
 *       // If validation fails, throw exception or return early
 *   }
 *
 * Automatically logs success or captures exceptions.
 */
suspend fun ApplicationCall.timed(
    taskCode: String,
    jsMode: String,
    block: suspend ApplicationCall.() -&gt; Unit
) {
    val start = System.currentTimeMillis()
    call.attributes.put(RequestStartTimeKey, start)

    val session = request.cookies["sid"] ?: "anon"
    val reqId = attributes.getOrNull(RequestIdKey) ?: newReqId()

    try {
        block()
        val duration = System.currentTimeMillis() - start
        Logger.success(session, reqId, taskCode, duration, jsMode)
    } catch (e: Exception) {
        val duration = System.currentTimeMillis() - start
        Logger.write(session, reqId, taskCode, "server_error", e.message ?: "unknown", duration, 500, jsMode)
        throw e
    }
}

/**
 * Helper to detect JavaScript mode from HTMX header.
 */
fun ApplicationCall.isHtmx(): Boolean =
    request.headers["HX-Request"]?.equals("true", ignoreCase = true) == true

fun ApplicationCall.jsMode(): String =
    if (isHtmx()) "on" else "off"

/**
 * Generate a unique request ID.
 */
private var requestCounter = 0
fun newReqId(): String = "r${String.format("%04d", ++requestCounter)}"
</code></pre>
<h3 id="step-4-instrument-routes-10-min"><a class="header" href="#step-4-instrument-routes-10-min">Step 4: Instrument routes (10 min)</a></h3>
<p><strong>Update <code>src/main/kotlin/routes/Tasks.kt</code></strong> (example for POST /tasks):</p>
<pre><code class="language-kotlin">post("/tasks") {
    val reqId = newReqId()
    call.attributes.put(RequestIdKey, reqId)

    val session = call.request.cookies["sid"] ?: "anon"
    val jsMode = call.jsMode()

    call.timed(taskCode = "T3_add", jsMode = jsMode) {
        val title = call.receiveParameters()["title"].orEmpty().trim()

        // Validation
        if (title.isBlank()) {
            Logger.validationError(session, reqId, "T3_add", "blank_title", 0, jsMode)
            if (call.isHtmx()) {
                val status = """&lt;div id="status" hx-swap-oob="true"&gt;Title is required.&lt;/div&gt;"""
                return@timed call.respondText(status, ContentType.Text.Html, HttpStatusCode.BadRequest)
            } else {
                return@timed call.respondRedirect("/tasks?error=title")
            }
        }

        if (title.length &gt; 200) {
            Logger.validationError(session, reqId, "T3_add", "max_length", 0, jsMode)
            if (call.isHtmx()) {
                val status = """&lt;div id="status" hx-swap-oob="true"&gt;Title too long (max 200 chars).&lt;/div&gt;"""
                return@timed call.respondText(status, ContentType.Text.Html, HttpStatusCode.BadRequest)
            } else {
                return@timed call.respondRedirect("/tasks?error=title&amp;msg=too_long")
            }
        }

        // Success path
        val task = repo.add(title)
        if (call.isHtmx()) {
            val item = PebbleRender.render("tasks/_item.peb", mapOf("t" to task))
            val status = """&lt;div id="status" hx-swap-oob="true"&gt;Added "${task.title}".&lt;/div&gt;"""
            call.respondText(item + status, ContentType.Text.Html)
        } else {
            call.respondRedirect("/tasks")
        }
    }
}
</code></pre>
<p><strong>Similarly instrument</strong>:</p>
<ul>
<li><code>GET /tasks</code> with <code>T1_filter</code> (if query param <code>q</code> present)</li>
<li><code>POST /tasks/{id}/edit</code> with <code>T2_edit</code></li>
<li><code>DELETE /tasks/{id}</code> with <code>T4_delete</code></li>
</ul>
<p><strong>Note on task codes</strong>:</p>
<ul>
<li><strong>Evaluation tasks</strong> (T1-T4): These match the tasks defined in your evaluation protocol
<ul>
<li><code>T1_filter</code> ‚Äî Search and filter the task list</li>
<li><code>T2_edit</code> ‚Äî Edit or toggle task status</li>
<li><code>T3_add</code> ‚Äî Add a new task</li>
<li><code>T4_delete</code> ‚Äî Delete a task</li>
</ul>
</li>
<li><strong>Baseline logging</strong> (optional): You may also log general interactions not part of the evaluation
<ul>
<li><code>T0_list</code> ‚Äî General task list view (not timed in evaluation)</li>
<li>Helps distinguish evaluation sessions from general usage analytics</li>
</ul>
</li>
</ul>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Logger.kt compiles and creates metrics.csv</li>
<li><input disabled="" type="checkbox"/>
Timing.kt provides timed{} helper</li>
<li><input disabled="" type="checkbox"/>
At least one route instrumented (POST /tasks)</li>
<li><input disabled="" type="checkbox"/>
Validation errors logged explicitly</li>
</ul>
<hr />
<h2 id="activity-e-dry-run-and-verify-10-min"><a class="header" href="#activity-e-dry-run-and-verify-10-min">Activity E: Dry Run and Verify (10 min)</a></h2>
<p><strong>Goal</strong>: Confirm instrumentation works before real pilots.</p>
<h3 id="step-1-set-session-cookie-2-min"><a class="header" href="#step-1-set-session-cookie-2-min">Step 1: Set session cookie (2 min)</a></h3>
<p>Open browser DevTools Console:</p>
<pre><code class="language-javascript">document.cookie = "sid=DRY_RUN_01; path=/";
</code></pre>
<p>Reload page.</p>
<h3 id="step-2-execute-test-tasks-5-min"><a class="header" href="#step-2-execute-test-tasks-5-min">Step 2: Execute test tasks (5 min)</a></h3>
<p><strong>With JS enabled</strong>:</p>
<ol>
<li>Add task ‚ÄúTest task 1‚Äù ‚Üí expect success row in metrics.csv</li>
<li>Submit empty form ‚Üí expect validation_error row</li>
<li>Add task ‚ÄúTest task 2‚Äù ‚Üí expect success row</li>
<li>Edit a task ‚Üí expect T2_edit success row</li>
<li>Delete a task ‚Üí expect T4_delete success row</li>
</ol>
<p><strong>Disable JS</strong>:
6. Repeat add task (empty + valid) ‚Üí expect js_mode=off rows</p>
<h3 id="step-3-inspect-logs-3-min"><a class="header" href="#step-3-inspect-logs-3-min">Step 3: Inspect logs (3 min)</a></h3>
<p>Open <code>data/metrics.csv</code>:</p>
<p><strong>Expected columns</strong>:</p>
<pre><code class="language-csv">ts_iso,session_id,request_id,task_code,step,outcome,ms,http_status,js_mode
</code></pre>
<p><strong>Example rows</strong>:</p>
<pre><code class="language-csv">2025-10-13T15:01:23.456Z,DRY_RUN_01,r001,T3_add,success,,567,200,on
2025-10-13T15:01:45.789Z,DRY_RUN_01,r002,T3_add,validation_error,blank_title,0,400,on
2025-10-13T15:02:10.123Z,DRY_RUN_01,r003,T3_add,success,,432,200,on
2025-10-13T15:03:00.000Z,DRY_RUN_01,r004,T2_edit,success,,1234,200,on
2025-10-13T15:03:30.500Z,DRY_RUN_01,r005,T4_delete,success,,210,200,on
2025-10-13T15:04:15.800Z,DRY_RUN_01,r006,T3_add,success,,3456,200,off
</code></pre>
<p><strong>Verify</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
All columns present</li>
<li><input disabled="" type="checkbox"/>
Timestamps in ISO 8601 format</li>
<li><input disabled="" type="checkbox"/>
session_id consistent (DRY_RUN_01)</li>
<li><input disabled="" type="checkbox"/>
task_code matches your task definitions</li>
<li><input disabled="" type="checkbox"/>
js_mode correct (on for HTMX, off for no-JS)</li>
<li><input disabled="" type="checkbox"/>
Durations plausible (not negative, not absurdly high)</li>
<li><input disabled="" type="checkbox"/>
HTTP status codes correct (200 success, 400 validation error)</li>
</ul>
<p><strong>If anything is wrong</strong>: Fix Logger.kt or route instrumentation, re-run dry run.</p>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Dry run completed with JS-on and JS-off paths</li>
<li><input disabled="" type="checkbox"/>
metrics.csv contains valid rows</li>
<li><input disabled="" type="checkbox"/>
Validation errors logged correctly</li>
<li><input disabled="" type="checkbox"/>
Durations captured</li>
</ul>
<hr />
<h2 id="commit--reflect-10-min-1"><a class="header" href="#commit--reflect-10-min-1">Commit &amp; Reflect (10 min)</a></h2>
<h3 id="commit-message-1"><a class="header" href="#commit-message-1">Commit message</a></h3>
<pre><code class="language-bash">git add wk09/lab-wk9/research wk09/lab-wk9/instr src/main/kotlin/utils data/metrics.csv

git commit -m "$(cat &lt;&lt;'EOF'
wk9s1: evaluation plan + server-side instrumentation

- Defined 4 tasks (filter, edit, add, delete) with success criteria
- Documented objective + subjective metrics (completion, time, errors, confidence)
- Created ethical protocol with consent process, session flow, accessibility variants
- Implemented Logger.kt (CSV appender, thread-safe)
- Implemented Timing.kt (timed{} helper, jsMode detection)
- Instrumented POST /tasks with T3_add logging + validation errors
- Dry-run verified: metrics.csv captures correct data for JS-on/off paths
- Scaffolded assessment draft evidence pack (eval-plan.md, protocol.md)

Ready for peer pilots in Week 9 Lab 2.


EOF
)"
</code></pre>
<h3 id="reflection-questions-4"><a class="header" href="#reflection-questions-4">Reflection questions</a></h3>
<p><strong>Answer in <code>wk09/reflection.md</code></strong>:</p>
<ol>
<li>
<p><strong>Metrics selection</strong>: Which metrics will be most useful for identifying usability issues? Why did you prioritise objective vs subjective data?</p>
</li>
<li>
<p><strong>Ethical considerations</strong>: What was most challenging about designing a privacy-respecting evaluation? How did you ensure no PII would be collected?</p>
</li>
<li>
<p><strong>Instrumentation trade-offs</strong>: Server-side logging has limitations (doesn‚Äôt capture client-side rendering time, scroll behaviour, etc.). What gaps might this create in your analysis?</p>
</li>
<li>
<p><strong>Task design</strong>: How realistic are your task scenarios? Would they generalize to non-peer participants (e.g., non-CS students)?</p>
</li>
<li>
<p><strong>Accessibility</strong>: How confident are you that your instrumentation will capture accessibility issues (SR announcements, keyboard traps)? What additional data would you need?</p>
</li>
<li>
<p><strong>Pilot readiness</strong>: What could go wrong during Week 9 Lab 2 pilots? How have you mitigated those risks?</p>
</li>
</ol>
<hr />
<h2 id="looking-ahead-week-9-lab-2-pilots"><a class="header" href="#looking-ahead-week-9-lab-2-pilots">Looking Ahead: Week 9 Lab 2 Pilots</a></h2>
<p>Next session (Lab 2):</p>
<ul>
<li>Run 5‚Äì6 peer pilots using your protocol</li>
<li>Collect metrics.csv data + qualitative notes</li>
<li>Debrief participants</li>
<li>Prepare draft evidence pack for assessment submission</li>
</ul>
<p><strong>Before Lab 2</strong>:</p>
<ul>
<li>Review protocol with your pair (practice reading consent script)</li>
<li>Test dry-run one more time (ensure nothing broke)</li>
<li>Prepare seed data (task list with known tasks for T1/T2/T4)</li>
<li>Print task scenarios or have them ready to read</li>
</ul>
<p><strong>Week 10</strong> will analyse this data‚Äîsolid planning now saves hours of confusion later.</p>
<hr />
<h2 id="further-reading--resources-1"><a class="header" href="#further-reading--resources-1">Further Reading &amp; Resources</a></h2>
<h3 id="essential-1"><a class="header" href="#essential-1">Essential</a></h3>
<ul>
<li><a href="wk09/../references/evaluation-metrics-quickref.html">Evaluation Metrics Quick Reference</a> ‚Äî Median, MAD, error rate calculations</li>
<li><a href="wk09/../references/consent-pii-faq.html">Consent and PII FAQ</a> ‚Äî PII definitions, opt-out procedures</li>
<li><a href="https://www.nngroup.com/articles/how-many-test-users/">Nielsen: How Many Test Users?</a> ‚Äî 5 users find 85% of issues</li>
</ul>
<h3 id="hci-evaluation-methods"><a class="header" href="#hci-evaluation-methods">HCI Evaluation Methods</a></h3>
<ul>
<li><strong>Lazar et al. (2017).</strong> <em>Research Methods in Human-Computer Interaction</em> (2nd ed.). Chapters 5-6 (usability testing, metrics)</li>
<li><a href="https://dl.acm.org/doi/book/10.5555/291224">SIGCHI: Usability Evaluation</a> ‚Äî Academic grounding</li>
<li><a href="https://measuringux.com/">Measuring UX</a> ‚Äî Practical guide to quantitative UX</li>
</ul>
<h3 id="ethics--privacy-1"><a class="header" href="#ethics--privacy-1">Ethics &amp; Privacy</a></h3>
<ul>
<li><a href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/accountability-and-governance/guide-to-accountability-and-governance/accountability-and-governance/data-protection-by-design-and-default/">ICO: Data Protection by Design</a></li>
<li><a href="https://www.bps.org.uk/guideline/code-ethics-and-conduct">BPS Code of Ethics</a> ‚Äî UK professional standards for research</li>
<li><a href="https://researchsupport.leeds.ac.uk/research-ethics/">University of Leeds Research Ethics</a> ‚Äî Institutional policy</li>
</ul>
<h3 id="instrumentation"><a class="header" href="#instrumentation">Instrumentation</a></h3>
<ul>
<li><a href="https://www.exp-platform.com/">Kohavi et al.: Online Controlled Experiments</a> ‚Äî A/B testing at scale (industry context)</li>
<li><a href="https://developers.google.com/analytics/devguides/collection/protocol/ga4">Google Analytics 4: Measurement Protocol</a> ‚Äî Example of event-based logging (we avoid third-party but shows patterns)</li>
</ul>
<h3 id="accessibility-evaluation"><a class="header" href="#accessibility-evaluation">Accessibility Evaluation</a></h3>
<ul>
<li><a href="https://webaim.org/articles/evaluatingcognitive/">WebAIM: Evaluating Accessibility</a> ‚Äî Cognitive disabilities focus</li>
<li><a href="https://www.w3.org/WAI/test-evaluate/involving-users/">W3C: Involving Users in Evaluating Web Accessibility</a></li>
</ul>
<hr />
<h2 id="glossary-summary-4"><a class="header" href="#glossary-summary-4">Glossary Summary</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Term</th><th>One-line definition</th></tr></thead><tbody>
<tr><td><strong>Usability evaluation</strong></td><td>Systematic assessment of how well people can use a system to achieve goals</td></tr>
<tr><td><strong>Task-based evaluation</strong></td><td>Participants complete realistic scenarios while researchers observe and measure</td></tr>
<tr><td><strong>Objective metrics</strong></td><td>Measurable, observable data (time, errors, completion) without interpretation</td></tr>
<tr><td><strong>Subjective metrics</strong></td><td>Self-reported feelings, perceptions, attitudes (confidence, satisfaction)</td></tr>
<tr><td><strong>Server-side instrumentation</strong></td><td>Logging events at the server; reliable, privacy-respecting, works regardless of JS</td></tr>
<tr><td><strong>Privacy by Design</strong></td><td>Build data minimization and privacy into system architecture from the start</td></tr>
<tr><td><strong>Median</strong></td><td>Middle value in sorted dataset; resistant to outliers</td></tr>
<tr><td><strong>MAD</strong></td><td>Median Absolute Deviation; robust measure of spread</td></tr>
<tr><td><strong>Informed consent</strong></td><td>Participants understand what data is collected, how it‚Äôs used, and can opt out</td></tr>
<tr><td><strong>Low-risk study</strong></td><td>Peer-to-peer evaluation with minimal data collection, no vulnerable groups</td></tr>
</tbody></table>
</div>
<hr />
<p><strong>Lab complete!</strong> You have a comprehensive evaluation plan, ethical protocol, and working instrumentation. Week 9 Lab 2 will collect real data from peer pilots.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-9--lab-1--student-guide-evaluation-planning--instrumentation"><a class="header" href="#week-9--lab-1--student-guide-evaluation-planning--instrumentation">Week 9 ‚Ä¢ Lab 1 ‚Äî Student Guide: Evaluation Planning &amp; Instrumentation</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-9-orange" alt="Week 9" />
<img src="https://img.shields.io/badge/Lab-1-green" alt="Lab 1" />
<img src="https://img.shields.io/badge/Type-Student_Guide-purple" alt="Guide" /></p>
<blockquote>
<p><strong>Purpose</strong>: Week 9 Lab 1 is about planning your evaluation - creating test tasks, defining metrics, writing an ethical protocol, and adding instrumentation to capture data during Week 9 Lab 2 pilots.</p>
</blockquote>
<hr />
<h2 id="deliverables-2"><a class="header" href="#deliverables-2">Deliverables</a></h2>
<p>By the end of this lab:</p>
<ul>
<li>‚úÖ <code>wk09/research/tasks.md</code> - 3-4 realistic test scenarios</li>
<li>‚úÖ <code>wk09/research/measures.md</code> - Metrics definition</li>
<li>‚úÖ <code>wk09/research/protocol.md</code> - Evaluation protocol (consent + procedure)</li>
<li>‚úÖ <code>wk09/research/data-notes.md</code> - Data recording guidance</li>
<li>‚úÖ Basic instrumentation code (optional logging in routes)</li>
</ul>
<hr />
<h2 id="quick-start-create-files-1"><a class="header" href="#quick-start-create-files-1">Quick Start: Create Files</a></h2>
<pre><code class="language-bash">mkdir -p wk09/research wk09/evidence
touch wk09/research/tasks.md
touch wk09/research/measures.md
touch wk09/research/protocol.md
touch wk09/research/data-notes.md
</code></pre>
<hr />
<h2 id="part-1-define-test-tasks-20-minutes"><a class="header" href="#part-1-define-test-tasks-20-minutes">Part 1: Define Test Tasks (20 minutes)</a></h2>
<p>Based on your backlog priorities, create 3-4 realistic tasks.</p>
<p><strong>Copy into</strong> <code>wk09/research/tasks.md</code>:</p>
<details>
<summary>Click to expand: Test Tasks Template</summary>
<pre><code class="language-markdown"># Evaluation Tasks ‚Äî Week 9

## Task 1: Filter and Complete
**Scenario**: You've just finished your COMP2850 HCI lab write-up.

**Instructions**:
1. Find the task titled "Write HCI lab notes"
2. Mark it as complete
3. Verify it's marked correctly

**Success criteria**:
- Participant finds correct task within 30 seconds
- Toggle works (checkbox/button responds)
- Visual confirmation shown (strikethrough, badge, status message)

**Inclusion focus**: Keyboard access, screen reader announcement

---

## Task 2: Add New Task
**Scenario**: You've just been assigned a new coursework deadline.

**Instructions**:
1. Add a new task: "Submit COMP2870 Assignment 2"
2. Confirm it appears in the list

**Success criteria**:
- Form submission works (HTMX + no-JS)
- New task appears immediately (or after reload for no-JS)
- Confirmation message shown

**Inclusion focus**: Error handling (if blank title), status announcements

---

## Task 3: Edit Task Inline
**Scenario**: You made a typo in a task title.

**Instructions**:
1. Find task "Buy milk"
2. Edit it to "Buy oat milk"
3. Save the change

**Success criteria**:
- Edit mode activates (input appears)
- Save updates the title
- Focus returns to edited task

**Inclusion focus**: Focus management, keyboard-only editing, Cancel button

---

## Task 4: Delete Completed Task
**Scenario**: You've completed "Email supervisor" and want to remove it.

**Instructions**:
1. Find task "Email supervisor"
2. Delete it
3. Confirm it's gone

**Success criteria**:
- Confirmation shown (HTMX) OR form submits (no-JS)
- Task removed from list
- Status message announced

**Inclusion focus**: Confirmation (HTMX has `hx-confirm`, no-JS has none - documented trade-off)

---

## Metrics per Task

For each task, record:
- **Time-on-task** (seconds from start to completion)
- **Success** (1 = completed, 0 = abandoned)
- **Error count** (validation errors, wrong clicks)
- **Mode** (HTMX or no-JS)
</code></pre>
</details>
<p><strong>Checklist</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
3-4 tasks written with scenarios</li>
<li><input disabled="" type="checkbox"/>
Success criteria defined</li>
<li><input disabled="" type="checkbox"/>
Inclusion focus identified per task</li>
</ul>
<hr />
<h2 id="part-2-define-metrics-25-minutes"><a class="header" href="#part-2-define-metrics-25-minutes">Part 2: Define Metrics (25 minutes)</a></h2>
<p><strong>Copy into</strong> <code>wk09/research/measures.md</code>:</p>
<details>
<summary>Click to expand: Measures Template</summary>
<pre><code class="language-markdown"># Evaluation Metrics ‚Äî Week 9

## Quantitative Measures

### 1. Time-on-Task (Efficiency)
**Definition**: Seconds from task start to successful completion
**How to collect**: Manual stopwatch OR instrumentation (timestamp diff)
**Analysis**: Mean, median, outliers per task

**Why it matters**: Long times indicate usability problems or confusion

---

### 2. Task Success Rate (Effectiveness)
**Definition**: Percentage of participants who complete task without help
**How to collect**: Binary (1 = success, 0 = fail/abandon)
**Analysis**: Success % per task, identify problematic tasks

**Why it matters**: &lt;80% success = serious usability issue

---

### 3. Error Rate (Accuracy)
**Definition**: Number of validation errors, wrong clicks, back-tracking per task
**How to collect**: Manual tally during observation OR server logs (400 errors)
**Analysis**: Mean errors per task, categorise by type

**Why it matters**: Frequent errors = unclear interface or poor error prevention

---

### 4. Mode Comparison (HTMX vs No-JS)
**Definition**: Time and success differences between JS-enabled and no-JS paths
**How to collect**: Run each participant in one mode, compare groups
**Analysis**: t-test or Mann-Whitney U test (if N &gt; 10 per group)

**Why it matters**: Validates dual-path parity claim

---

## Qualitative Measures

### 5. Post-Task Confidence (Subjective)
**Definition**: 5-point Likert scale: "I am confident I completed the task correctly"
**How to collect**: Verbal question after each task
**Analysis**: Mean score per task, identify low-confidence tasks

**Why it matters**: Low confidence despite success = poor feedback design

---

### 6. Think-Aloud Observations
**Definition**: Verbal comments during task ("Where's the Save button?", "I'm confused")
**How to collect**: Note-taking during pilot
**Analysis**: Thematic coding (confusion points, positive remarks)

**Why it matters**: Reveals WHY metrics are good/bad

---

### 7. Accessibility Barriers (Observational)
**Definition**: Moments where keyboard/SR participant struggles
**How to collect**: Note when Tab order confuses, focus lost, SR silent
**Analysis**: List barriers, map to WCAG criteria

**Why it matters**: Direct evidence of inclusion failures

---

## Data Collection Plan

**Per participant**:
- Task 1-4: Time, success, errors, confidence, mode
- Think-aloud notes: Freeform observations
- Accessibility notes: Specific barriers encountered

**Sample size**: 3-5 participants (peer pilots)

**Storage**: `data/metrics.csv` (local, .gitignored)
</code></pre>
</details>
<p><strong>Checklist</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
4+ quantitative metrics defined</li>
<li><input disabled="" type="checkbox"/>
2+ qualitative measures defined</li>
<li><input disabled="" type="checkbox"/>
Data collection plan specified</li>
</ul>
<hr />
<h2 id="part-3-evaluation-protocol-30-minutes"><a class="header" href="#part-3-evaluation-protocol-30-minutes">Part 3: Evaluation Protocol (30 minutes)</a></h2>
<p><strong>Copy into</strong> <code>wk09/research/protocol.md</code>:</p>
<details>
<summary>Click to expand: Protocol Template</summary>
<pre><code class="language-markdown"># Evaluation Protocol ‚Äî Week 9 Pilots

**Module**: COMP2850 HCI
**Activity**: Task-based usability pilots
**Date**: [YYYY-MM-DD]
**Researcher**: [Your Name]

---

## Purpose

Evaluate task manager usability and accessibility through structured pilots. Data will inform Week 10 redesign and assessment submission.

## Consent (GDPR/Data Protection Act 2018)

**Lawful basis**: Legitimate interest (educational research) + informed consent

**Before starting**, confirm:
- [ ] Purpose explained (evaluate task manager, not testing you)
- [ ] Tasks described (4 scenarios, ~15 minutes)
- [ ] Data collected listed (times, clicks, observations - no PII)
- [ ] Right to withdraw explained (stop anytime, data deleted)
- [ ] Participant verbally consents

**Record**: Participant pseudonym (P1, P2...), date, consent confirmed (initials)

---

## Procedure

### Setup (5 minutes)
1. **Assign mode**: Participant 1 ‚Üí HTMX, Participant 2 ‚Üí No-JS (alternate)
2. **Disable JS if needed**: Chrome DevTools ‚Üí Settings ‚Üí Disable JavaScript
3. **Set session ID**: Manual cookie OR URL param (`?sid=P1`)
4. **Open task manager**: http://localhost:8080/tasks

### Orientation (2 minutes)
"You'll complete 4 tasks with a task manager. I'll time you and take notes. **Think aloud** - say what you're thinking ('Where's the Edit button?', 'This is confusing'). There are no wrong answers - we're testing the interface, not you. You can stop anytime."

### Task Execution (12 minutes)
For each task (T1-T4):
1. **Read scenario** aloud from `tasks.md`
2. **Start timer** when participant begins
3. **Observe** (note clicks, hesitations, comments)
4. **Stop timer** when task complete OR participant gives up
5. **Ask confidence**: "On a scale 1-5, how confident are you that you completed correctly?"
6. **Record**: Time, success (1/0), errors, confidence, notes

### Debrief (3 minutes)
"Thanks! Any final thoughts? What was most confusing? What worked well?"

**Total time**: ~20 minutes per participant

---

## Data Recording

### Manual Notes Template
</code></pre>
<p>Participant: [P1, P2, P3‚Ä¶]
Mode: [HTMX / No-JS]
Date: [YYYY-MM-DD]
Duration: [~20 min]</p>
<p>Task 1: [Start time HH:MM:SS] ‚Üí [End time HH:MM:SS] = [X seconds]
Success: [1/0]
Errors: [count]
Confidence: [1-5]
Notes: [Observations, quotes]</p>
<p>[Repeat for T2-T4]</p>
<p>Post-pilot notes:</p>
<ul>
<li>Accessibility barriers:</li>
<li>Positive moments:</li>
<li>Redesign ideas:</li>
</ul>
<pre><code>
### Automated Instrumentation (Optional)
If you added logging to routes:
- `data/metrics.csv`: timestamp, task_id, action, duration, status
- `data/errors.csv`: timestamp, task_id, error_type, message

---

## Risks &amp; Mitigations

| Risk | Mitigation |
|------|-----------|
| Participant feels tested | Emphasise "testing interface, not you" |
| Task too hard, participant frustrated | Allow skip after 2 min struggle |
| Data breach (PII in notes) | Use pseudonyms only, `.gitignore` data files |
| Observer bias | Neutral prompts ("What are you thinking?"), don't lead |

---

## Ethics Checklist

- [ ] Consent obtained verbally before start
- [ ] Pseudonyms used (P1, P2...), no real names
- [ ] Data stored locally (not cloud), Git repo private
- [ ] Right to withdraw explained
- [ ] No coercion (peers can decline without penalty)
- [ ] Data deletion plan stated (end of semester OR anonymised)

---

**Reference**: BPS Code of Human Research Ethics (2021), UK GDPR (2018)
</code></pre>
</details>
<p><strong>Checklist</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Protocol written with setup, procedure, debrief</li>
<li><input disabled="" type="checkbox"/>
Consent process documented</li>
<li><input disabled="" type="checkbox"/>
Data recording template provided</li>
<li><input disabled="" type="checkbox"/>
Ethics checklist complete</li>
</ul>
<hr />
<h2 id="part-4-data-recording-guidance-15-minutes"><a class="header" href="#part-4-data-recording-guidance-15-minutes">Part 4: Data Recording Guidance (15 minutes)</a></h2>
<p><strong>Copy into</strong> <code>wk09/research/data-notes.md</code>:</p>
<details>
<summary>Click to expand: Data Notes Template</summary>
<pre><code class="language-markdown"># Data Recording Notes ‚Äî Week 9

## Manual Recording (Required)

For each participant, record in notebook:
- **Task times**: Use stopwatch, record to nearest second
- **Success**: Binary 1/0 (did they complete correctly?)
- **Errors**: Tally clicks on wrong elements, validation errors shown
- **Confidence**: Ask "1-5, how confident?" after each task
- **Think-aloud**: Note direct quotes in "quotation marks"

## Automated Instrumentation (Optional)

If you add logging to routes:

### Example: Log Task Creation Time
```kotlin
post("/tasks") {
    val startTime = System.currentTimeMillis()
    // ... validation, create task ...
    val endTime = System.currentTimeMillis()
    val duration = endTime - startTime

    // Log to CSV
    logMetric("task_create", duration, success = true)
}
</code></pre>
<h3 id="log-format-datametricscsv"><a class="header" href="#log-format-datametricscsv">Log Format (<code>data/metrics.csv</code>)</a></h3>
<pre><code class="language-csv">timestamp,session_id,task_id,action,duration_ms,success,mode
2025-01-15T10:30:15,P1,T2,task_create,1230,true,htmx
2025-01-15T10:31:45,P1,T3,task_edit,2100,true,htmx
</code></pre>
<h2 id="observational-codes"><a class="header" href="#observational-codes">Observational Codes</a></h2>
<p>Use these shorthand codes in notes:</p>
<ul>
<li><strong>KBD</strong>: Keyboard navigation issue</li>
<li><strong>SR</strong>: Screen reader problem</li>
<li><strong>FOC</strong>: Focus management issue</li>
<li><strong>ERR</strong>: Validation error shown</li>
<li><strong>CONF</strong>: Participant expressed confusion</li>
<li><strong>POS</strong>: Positive comment</li>
</ul>
<p>Example: ‚ÄúP2 [KBD] couldn‚Äôt find Cancel button with Tab‚Äù</p>
<h2 id="anomalies-to-note"><a class="header" href="#anomalies-to-note">Anomalies to Note</a></h2>
<ul>
<li>Browser crashed / page froze</li>
<li>Participant asked clarifying question (we answered)</li>
<li>Network delay (slow response)</li>
<li>Observer error (forgot to start timer)</li>
</ul>
<p><strong>Record all anomalies</strong> so analysis accounts for them.</p>
<hr />
<p><strong>Storage</strong>: Keep notes in physical notebook during pilots, transcribe to digital after.
<strong>Backup</strong>: Photos of notebook pages saved to <code>wk09/evidence/notes-backup/</code></p>
<pre><code>
&lt;/details&gt;

**Checklist**:
- [ ] Manual recording template provided
- [ ] Optional instrumentation example given
- [ ] Observational codes defined
- [ ] Anomaly guidance clear

---

## Part 5: Optional Instrumentation (30 minutes)

If you want automated metrics, add logging to routes. Example:

&lt;details&gt;
&lt;summary&gt;Click to expand: Simple Logging Code&lt;/summary&gt;

**Create** `src/main/kotlin/utils/MetricsLogger.kt`:

```kotlin
package utils

import java.io.File
import java.time.LocalDateTime
import java.time.format.DateTimeFormatter

object MetricsLogger {
    private val logFile = File("data/metrics.csv")
    private val formatter = DateTimeFormatter.ISO_LOCAL_DATE_TIME

    init {
        if (!logFile.exists()) {
            logFile.parentFile?.mkdirs()
            logFile.writeText("timestamp,session_id,task_id,action,duration_ms,success,mode\n")
        }
    }

    fun log(
        sessionId: String,
        taskId: String,
        action: String,
        durationMs: Long,
        success: Boolean,
        mode: String
    ) {
        val timestamp = LocalDateTime.now().format(formatter)
        val line = "$timestamp,$sessionId,$taskId,$action,$durationMs,$success,$mode\n"
        logFile.appendText(line)
    }
}
</code></pre>
<p><strong>Use in routes</strong>:</p>
<pre><code class="language-kotlin">post("/tasks") {
    val start = System.currentTimeMillis()
    val sessionId = call.sessions.get&lt;String&gt;("sessionId") ?: "unknown"
    val mode = if (call.isHtmx()) "htmx" else "nojs"

    // ... create task logic ...

    val duration = System.currentTimeMillis() - start
    MetricsLogger.log(sessionId, "T2", "task_create", duration, success = true, mode)

    // ... respond ...
}
</code></pre>
</details>
<p><strong>Note</strong>: Instrumentation is optional. Manual recording is sufficient for Week 9.</p>
<hr />
<h2 id="commit--continue-6"><a class="header" href="#commit--continue-6">Commit &amp; Continue</a></h2>
<pre><code class="language-bash">git add wk09/
git commit -m "feat(wk9-lab1): evaluation planning and instrumentation

- Created 4 test tasks with scenarios and success criteria
- Defined 7 metrics (time, success, errors, confidence, think-aloud)
- Documented evaluation protocol with consent and procedure
- Provided data recording templates and observational codes
- Added optional instrumentation code example

Ready for Week 9 Lab 2 pilots."
</code></pre>
<p><strong>Next</strong>: Week 9 Lab 2 - Run pilots, collect data, analyse, draft assessment evidence.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-9--lab-2--peer-pilots-debrief-and-assessment-draft-pack"><a class="header" href="#week-9--lab-2--peer-pilots-debrief-and-assessment-draft-pack">Week 9 ‚Ä¢ Lab 2 ‚Äî Peer Pilots, Debrief, and Assessment Draft Pack</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-9-orange" alt="Week 9" />
<img src="https://img.shields.io/badge/Lab-2-green" alt="Lab 2" />
<img src="https://img.shields.io/badge/Status-Draft-yellow" alt="Status" /></p>
<hr />
<h2 id="before-lab-required-reading-10-mins"><a class="header" href="#before-lab-required-reading-10-mins">Before Lab: Required Reading (10 mins)</a></h2>
<p>üìñ <strong>Essential</strong>:</p>
<ul>
<li>Push/log Week 9 starter repo instrumentation before pilots</li>
<li>Review your Week 9 Lab 1 protocol (<code>wk09/lab-wk9/research/protocol.md</code>)</li>
<li>Review <code>references/consent-pii-faq.md</code></li>
<li><a href="https://www.nngroup.com/articles/how-many-test-users/">Nielsen: How Many Test Users in Usability Studies?</a></li>
</ul>
<p>üìñ <strong>Quick reference</strong>:</p>
<ul>
<li><a href="wk09/../references/evaluation-metrics-quickref.html">Evaluation Metrics Quick Reference</a></li>
<li><a href="wk09/../references/assistive-testing-checklist.html">Assistive Testing Checklist</a></li>
<li><a href="wk09/../references/screenshot-guide.html">Screenshot Evidence Guide</a></li>
</ul>
<hr />
<h2 id="introduction-from-plan-to-data"><a class="header" href="#introduction-from-plan-to-data">Introduction: From Plan to Data</a></h2>
<p>Week 9 Lab 1 built the evaluation infrastructure. <strong>Today you execute</strong>.</p>
<p>Running peer pilots is <strong>the most critical empirical HCI activity</strong> in this module:</p>
<ul>
<li><strong>Data collection</strong>: Objective metrics (time, errors, completion) + subjective (confidence, satisfaction)</li>
<li><strong>Qualitative insights</strong>: Observe real struggles, accessibility barriers, unexpected behaviours</li>
<li><strong>Evidence generation</strong>: Logs, notes, screenshots for assessment portfolio (due end Week 10)</li>
</ul>
<p><strong>Why this matters</strong>:</p>
<ul>
<li>Week 10 redesign <strong>depends on</strong> identifying real problems (not assumed ones)</li>
<li>Assessment grade depends on evidence quality (traceability from raw data ‚Üí findings ‚Üí mitigations)</li>
<li>Professional practice: Decisions backed by data, not opinions</li>
</ul>
<p><strong>Ethical imperative</strong>: Participants are peers, not research subjects. Treat them respectfully, honour consent, protect privacy.</p>
<hr />
<h2 id="learning-focus-7"><a class="header" href="#learning-focus-7">Learning Focus</a></h2>
<h3 id="lab-objectives-7"><a class="header" href="#lab-objectives-7">Lab Objectives</a></h3>
<blockquote>
<p><strong>Staff reference</strong>: Sample data + completed pilot pack available in the <a href="wk09/../../resources/code-resources.html#week-9">solution repository</a>.
By the end of this session, you will have:</p>
</blockquote>
<ul>
<li>Conducted 4 peer pilots following ethical protocol</li>
<li>Collected quantitative data (time-on-task, errors, SUS) and qualitative observations</li>
<li>Taken observer notes (quotes, errors, time-on-task)</li>
<li>Debriefed with participants and synthesised findings</li>
<li>Documented findings with evidence chains (raw data ‚Üí issue ‚Üí backlog item)</li>
<li>Assembled draft assessment evidence pack</li>
</ul>
<h3 id="learning-outcomes-addressed-7"><a class="header" href="#learning-outcomes-addressed-7">Learning Outcomes Addressed</a></h3>
<p>This lab contributes to the following module Learning Outcomes (<a href="wk09/../references/learning-outcomes.html">full definitions</a>):</p>
<ul>
<li><strong>LO6</strong>: Apply iterative design ‚Äî evidenced by pilot data ‚Üí findings synthesis</li>
<li><strong>LO8</strong>: Design and execute evaluation ‚Äî evidenced by 4 pilot sessions + data</li>
<li><strong>LO11</strong>: Collaborate in teams ‚Äî evidenced by peer pilot facilitation + observer role</li>
<li><strong>LO12</strong>: Demonstrate professionalism ‚Äî evidenced by consent adherence + respectful facilitation</li>
</ul>
<hr />
<h2 id="key-concepts-6"><a class="header" href="#key-concepts-6">Key Concepts</a></h2>
<h3 id="pilot-study"><a class="header" href="#pilot-study">Pilot Study</a></h3>
<blockquote>
<p><strong>Pilot Study</strong> [GLOSSARY]</p>
<p>Small-scale preliminary study to test evaluation protocol and gather initial data. <strong>Formative</strong> (improve design) vs <strong>Summative</strong> (final quality assessment).</p>
<p><strong>This module uses formative pilots</strong>: Identify issues to fix in Week 10, not measure final quality.</p>
<p><strong>Characteristics</strong>:</p>
<ul>
<li>Small sample (5‚Äì10 participants typical for qualitative insights)</li>
<li>Controlled tasks (defined in Week 9 Lab 1)</li>
<li>Mixed methods (quantitative metrics + qualitative observation)</li>
<li>Iterative (findings inform redesign)</li>
</ul>
<p><strong>Nielsen‚Äôs 5-user rule</strong>: 5 participants find ~85% of usability issues. Diminishing returns after that for formative testing.</p>
<p><strong>HCI Connection</strong>: Empirical HCI requires <strong>ecological validity</strong>‚Äîtest with real people doing realistic tasks, not just hypothetical analysis.</p>
<p>üîó <a href="https://www.nngroup.com/articles/why-you-only-need-to-test-with-5-users/">Nielsen: Why You Only Need to Test with 5 Users</a></p>
</blockquote>
<h3 id="qualitative-vs-quantitative-data"><a class="header" href="#qualitative-vs-quantitative-data">Qualitative vs Quantitative Data</a></h3>
<blockquote>
<p><strong>Quantitative Data</strong> [GLOSSARY]</p>
<p>Numerical measurements: times, counts, percentages. <strong>Objective</strong>, statistically analysable.</p>
<p><strong>Examples from this module</strong>:</p>
<ul>
<li>Task completion time: Median 24s (MAD 6s)</li>
<li>Error rate: 2/5 = 40%</li>
<li>Completion rate: 4/5 = 80%</li>
</ul>
<p><strong>Strengths</strong>: Comparable, repeatable, supports statistical tests
<strong>Limitations</strong>: Doesn‚Äôt explain ‚Äúwhy‚Äù‚Äîneed qualitative data to interpret</p>
<hr />
<p><strong>Qualitative Data</strong> [GLOSSARY]</p>
<p>Non-numerical observations: quotes, behaviours, patterns. <strong>Subjective</strong>, interpretive.</p>
<p><strong>Examples from this module</strong>:</p>
<ul>
<li>‚ÄúParticipant paused 10s, said ‚ÄòI‚Äôm not sure if it saved‚Äô‚Äù</li>
<li>‚ÄúScreen reader did not announce filter result count‚Äù</li>
<li>‚ÄúParticipant used Ctrl+F instead of built-in filter‚Äù</li>
</ul>
<p><strong>Strengths</strong>: Reveals ‚Äúwhy‚Äù issues occur, uncovers unexpected problems
<strong>Limitations</strong>: Varies by participant, researcher bias, harder to generalize</p>
<p><strong>HCI Connection</strong>: Best practice = <strong>mixed methods</strong> (both quant + qual). Numbers show <em>what</em> happened, observations show <em>why</em>.</p>
<p>üîó <a href="https://dl.acm.org/doi/book/10.5555/2737875">Lazar et al.: Research Methods in HCI</a> ‚Äî Chapter 9</p>
</blockquote>
<h3 id="think-aloud-protocol"><a class="header" href="#think-aloud-protocol">Think-Aloud Protocol</a></h3>
<blockquote>
<p><strong>Think-Aloud Protocol</strong> [GLOSSARY]</p>
<p>Participants verbalize their thoughts while completing tasks. Reveals cognitive process, confusion points, expectations.</p>
<p><strong>Types</strong>:</p>
<ul>
<li><strong>Concurrent</strong>: Talk while doing task (can be distracting, slower)</li>
<li><strong>Retrospective</strong>: Explain after completing (less disruptive but memory decay)</li>
</ul>
<p><strong>For this module</strong>: <strong>Optional concurrent</strong> (invite, don‚Äôt force). Some participants find it natural, others find it intrusive.</p>
<p><strong>Example quote captured</strong>:</p>
<blockquote>
<p>‚ÄúI‚Äôm looking for a filter‚Ä¶ is this the search box? I‚Äôll try typing here.‚Äù</p>
</blockquote>
<p><strong>HCI Connection</strong>: Think-aloud reveals <strong>mental models</strong>‚Äîhow people understand the interface vs how it actually works.</p>
<p><strong>Accessibility note</strong>: Think-aloud can be difficult for screen reader users (talking competes with SR audio). Allow silence.</p>
<p>üîó <a href="https://www.nngroup.com/articles/thinking-aloud-the-1-usability-tool/">Nielsen: Thinking Aloud: The #1 Usability Tool</a></p>
</blockquote>
<h3 id="evidence-chain"><a class="header" href="#evidence-chain">Evidence Chain</a></h3>
<blockquote>
<p><strong>Evidence Chain</strong> [GLOSSARY]</p>
<p>Traceability from raw data ‚Üí finding ‚Üí backlog item ‚Üí fix ‚Üí verification. Critical for academic rigour and professional practice.</p>
<p><strong>Example chain</strong>:</p>
<ol>
<li><strong>Raw data</strong>: <code>metrics.csv</code> shows <code>T2_edit, validation_error, blank_title</code> for session <code>WK9A03</code></li>
<li><strong>Observation</strong>: Pilot notes say ‚ÄúParticipant didn‚Äôt notice error message, submitted blank again‚Äù</li>
<li><strong>Finding</strong>: ‚ÄúError messages not accessible to screen readers (WCAG 4.1.3 violation)‚Äù</li>
<li><strong>Backlog item</strong>: <code>wk9-05: Add role=alert to validation errors</code></li>
<li><strong>Fix</strong> (Week 10): Update template with <code>&lt;p role="alert"&gt;</code></li>
<li><strong>Verification</strong>: Retest with screen reader, confirm announcement</li>
</ol>
<p><strong>Why this matters</strong>:</p>
<ul>
<li><strong>Assessment</strong>: Markers check evidence chains (no evidence = no marks)</li>
<li><strong>Professional practice</strong>: Design decisions require justification</li>
<li><strong>Accreditation</strong>: External panels expect rigorous HCI process</li>
</ul>
<p><strong>HCI Connection</strong>: Evidence chains demonstrate <strong>systematic design process</strong>, not ad-hoc changes.</p>
<p>üîó <a href="https://www.gov.uk/service-manual/measuring-success/using-data-to-improve-your-service">GOV.UK Service Manual: Using data in service design</a></p>
</blockquote>
<h3 id="thematic-coding"><a class="header" href="#thematic-coding">Thematic Coding</a></h3>
<blockquote>
<p><strong>Thematic Coding</strong> [GLOSSARY]</p>
<p>Systematic process of identifying patterns (themes) in qualitative data. Used to analyse pilot notes.</p>
<p><strong>Process</strong>:</p>
<ol>
<li><strong>Read notes</strong>: Familiarize yourself with all observations</li>
<li><strong>Code</strong>: Label each observation with tags (e.g., ‚Äúsr-announcement‚Äù, ‚Äúvalidation-error‚Äù, ‚Äúfocus-management‚Äù)</li>
<li><strong>Group</strong>: Cluster similar codes into themes (e.g., all ‚Äúsr-announcement‚Äù issues ‚Üí theme: ‚ÄúStatus feedback‚Äù)</li>
<li><strong>Interpret</strong>: What do these themes tell us about usability/accessibility?</li>
</ol>
<p><strong>Example</strong> (simplified):</p>
<pre><code>Observation: "Participant didn't notice success message" ‚Üí Code: feedback-timing
Observation: "SR didn't announce deletion" ‚Üí Code: sr-announcement
Observation: "Participant asked 'did it save?'" ‚Üí Code: feedback-clarity

Theme: "Success feedback insufficient" (3 codes)
Priority: High (affects confidence, inclusion)
</code></pre>
<p><strong>This module</strong>: Light-touch thematic coding in Week 10. Full formal coding (inter-rater reliability, etc.) is postgraduate-level.</p>
<p>üîó <a href="https://www.tandfonline.com/doi/abs/10.1191/1478088706qp063oa">Braun &amp; Clarke: Thematic Analysis</a> ‚Äî Academic reference</p>
</blockquote>
<hr />
<h2 id="activity-a-pilot-preparation-10-min"><a class="header" href="#activity-a-pilot-preparation-10-min">Activity A: Pilot Preparation (10 min)</a></h2>
<p><strong>Goal</strong>: Ensure everything is ready before first participant arrives.</p>
<h3 id="step-1-technical-setup-5-min"><a class="header" href="#step-1-technical-setup-5-min">Step 1: Technical setup (5 min)</a></h3>
<ol>
<li><strong>Start server</strong>: <code>./gradlew run</code> (or IDE run configuration)</li>
<li><strong>Test routes</strong>: Visit <code>/tasks</code>, confirm prototype works (add/edit/filter/delete)</li>
<li><strong>Clear old data</strong> (optional): If <code>data/metrics.csv</code> contains dry-run rows, either delete them or note the starting row number so you know which rows are real pilot data</li>
</ol>
<p><strong>Verify instrumentation</strong>:</p>
<ul>
<li>Submit a test task ‚Üí check <code>metrics.csv</code> for new row</li>
<li>Submit empty form ‚Üí check for <code>validation_error</code> row</li>
<li>Disable JS, repeat ‚Üí check <code>js_mode=off</code> appears</li>
</ul>
<p>If anything‚Äôs broken, <strong>fix it now</strong> (don‚Äôt waste participants‚Äô time).</p>
<h3 id="step-2-materials-ready-3-min"><a class="header" href="#step-2-materials-ready-3-min">Step 2: Materials ready (3 min)</a></h3>
<p><strong>Physical/digital checklists</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Protocol document (<code>wk09/lab-wk9/research/protocol.md</code>) printed or on second screen</li>
<li><input disabled="" type="checkbox"/>
Task scenarios ready to read aloud</li>
<li><input disabled="" type="checkbox"/>
Consent script ready (memorize or have visible)</li>
<li><input disabled="" type="checkbox"/>
<code>pilot-notes.md</code> template open in editor</li>
<li><input disabled="" type="checkbox"/>
Stopwatch/timer (backup for server timing)</li>
<li><input disabled="" type="checkbox"/>
Post-task questions printed (confidence rating 1‚Äì5)</li>
</ul>
<p><strong>Participant setup</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Clean browser session (clear cookies, cache)</li>
<li><input disabled="" type="checkbox"/>
Navigate to prototype homepage</li>
<li><input disabled="" type="checkbox"/>
DevTools closed (don‚Äôt intimidate participant with console)</li>
</ul>
<h3 id="step-3-role-allocation-2-min"><a class="header" href="#step-3-role-allocation-2-min">Step 3: Role allocation (2 min)</a></h3>
<p><strong>Work in pairs or triads</strong>:</p>
<ul>
<li><strong>Facilitator</strong>: Reads scenarios, asks questions, manages timing</li>
<li><strong>Note-taker</strong>: Records observations, direct quotes, timestamps</li>
<li><strong>Participant</strong>: Completes tasks</li>
</ul>
<p><strong>Rotate roles</strong> after each pilot (everyone gets experience facilitating and participating).</p>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Server running, prototype functional</li>
<li><input disabled="" type="checkbox"/>
metrics.csv logging correctly</li>
<li><input disabled="" type="checkbox"/>
Protocol and materials ready</li>
<li><input disabled="" type="checkbox"/>
Roles assigned</li>
</ul>
<hr />
<h2 id="activity-b-run-pilot-sessions-6080-min"><a class="header" href="#activity-b-run-pilot-sessions-6080-min">Activity B: Run Pilot Sessions (60‚Äì80 min)</a></h2>
<p><strong>Goal</strong>: Conduct 5‚Äì6 peer pilots following your ethical protocol.</p>
<p><strong>Timing</strong>:</p>
<ul>
<li>~15 minutes per pilot (4 tasks + debrief)</li>
<li>~5 minutes between pilots (swap roles, generate new session ID)</li>
<li>Total: 5 pilots √ó 20 min = ~100 min</li>
</ul>
<p><strong>If time is tight</strong>: Minimum 3 pilots (one with keyboard-only, one with JS-off, one standard).</p>
<h3 id="pilot-1-standard-htmx-mouse-js-on"><a class="header" href="#pilot-1-standard-htmx-mouse-js-on">Pilot 1: Standard (HTMX, mouse, JS-on)</a></h3>
<h4 id="setup-3-min"><a class="header" href="#setup-3-min">Setup (3 min)</a></h4>
<ol>
<li>
<p><strong>Generate session ID</strong>:</p>
<pre><code class="language-bash">openssl rand -hex 3  # Example output: 7a9f2c
</code></pre>
<p>Or use: <code>https://www.random.org/strings/</code> (6 chars, alphanumeric)</p>
</li>
<li>
<p><strong>Set cookie</strong> in participant browser (DevTools Console):</p>
<pre><code class="language-javascript">document.cookie = "sid=P1_7a9f; path=/";
</code></pre>
</li>
<li>
<p><strong>Record in consent log</strong> (<code>wk09/lab-wk9/research/consent-log.md</code>):</p>
<pre><code class="language-markdown">## Pilot 1
Date: 2025-10-15
Participant code: P1
Session ID: P1_7a9f
Variant: Standard (HTMX, mouse, JS-on)
Consent: Verbal consent given at 14:15
Notes: None
</code></pre>
</li>
</ol>
<h4 id="consent-process-2-min"><a class="header" href="#consent-process-2-min">Consent process (2 min)</a></h4>
<p><strong>Read script</strong> (from protocol.md):</p>
<blockquote>
<p>‚ÄúThanks for agreeing to pilot our prototype. This is a quick usability test‚Äîabout 15 minutes. I‚Äôll ask you to complete 4 tasks while I observe and take notes. I‚Äôm testing the interface, not you, so there are no wrong answers.</p>
<p><strong>What we‚Äôre collecting</strong>: task times, whether you complete successfully, any errors, your confidence ratings, and my notes on any issues.</p>
<p><strong>What we‚Äôre NOT collecting</strong>: your name, email, student ID, or any recordings.</p>
<p>Your session code is <code>P1_7a9f</code>. You can request data deletion anytime.</p>
<p><strong>You can stop at any time.</strong> Do you have questions?‚Äú</p>
</blockquote>
<p><strong>Wait for verbal consent</strong>: ‚ÄúAre you happy to proceed?‚Äù</p>
<p>If participant declines or seems uncertain, thank them and find another volunteer.</p>
<h4 id="warm-up-2-min-not-timed"><a class="header" href="#warm-up-2-min-not-timed">Warm-up (2 min, not timed)</a></h4>
<p>‚ÄúTake a minute to browse the task list. Click around, get familiar. Think aloud if you‚Äôre comfortable‚Äîsay what you‚Äôre thinking‚Äîbut no pressure. Let me know when you‚Äôre ready for the first task.‚Äù</p>
<p><strong>Note-taker observes</strong>: Initial reactions, confusion points, do they notice key UI elements?</p>
<h4 id="task-t3-add-task-60s-limit"><a class="header" href="#task-t3-add-task-60s-limit">Task T3: Add Task (60s limit)</a></h4>
<p><strong>Facilitator reads</strong>:</p>
<blockquote>
<p>‚ÄúYou need to remember to ‚ÄòCall supplier about delivery‚Äô. Add this as a new task.‚Äù</p>
</blockquote>
<p><strong>Start timing</strong>: When participant focuses in input or begins typing.</p>
<p><strong>Note-taker records</strong>:</p>
<ul>
<li>Timestamp (e.g., <code>14:18</code>)</li>
<li>Did they find form immediately?</li>
<li>Did they hesitate or look confused?</li>
<li>Did they submit blank by mistake?</li>
<li>Did they notice success confirmation?</li>
</ul>
<p><strong>Post-task question</strong>:</p>
<blockquote>
<p>‚ÄúOn a scale of 1 to 5, how confident are you that you completed that correctly?‚Äù</p>
</blockquote>
<p>Record answer: <code>Confidence: 5</code></p>
<p><strong>Check logs</strong>: Open <code>data/metrics.csv</code>, verify new row with <code>task_code=T3_add, step=success, session_id=P1_7a9f</code>.</p>
<hr />
<h4 id="task-t1-filter-tasks-120s-limit"><a class="header" href="#task-t1-filter-tasks-120s-limit">Task T1: Filter Tasks (120s limit)</a></h4>
<p><strong>Facilitator reads</strong>:</p>
<blockquote>
<p>‚ÄúYou‚Äôve been asked to find all tasks containing the word ‚Äòreport‚Äô. Use the filter to show only matching tasks, then count how many remain.‚Äù</p>
</blockquote>
<p><strong>Note-taker records</strong>:</p>
<ul>
<li>How long to find filter box?</li>
<li>Did they type ‚Äúreport‚Äù or ‚ÄúReport‚Äù (case sensitivity)?</li>
<li>Did they notice result count indicator?</li>
<li>Did they manually count items vs read count?</li>
</ul>
<p><strong>Post-task question</strong>: Confidence (1‚Äì5)</p>
<hr />
<h4 id="task-t2-edit-task-90s-limit"><a class="header" href="#task-t2-edit-task-90s-limit">Task T2: Edit Task (90s limit)</a></h4>
<p><strong>Facilitator reads</strong>:</p>
<blockquote>
<p>‚ÄúThe task ‚ÄòSubmit invoices‚Äô has a typo. Change it to ‚ÄòSubmit invoices by Friday‚Äô and save the change.‚Äù</p>
</blockquote>
<p><strong>Note-taker records</strong>:</p>
<ul>
<li>How quickly did they find Edit button?</li>
<li>Any validation errors triggered?</li>
<li>Did they verify edit saved?</li>
<li>Any confusion about inline vs full-page edit?</li>
</ul>
<p><strong>Post-task question</strong>: Confidence (1‚Äì5)</p>
<hr />
<h4 id="task-t4-delete-task-45s-limit"><a class="header" href="#task-t4-delete-task-45s-limit">Task T4: Delete Task (45s limit)</a></h4>
<p><strong>Facilitator reads</strong>:</p>
<blockquote>
<p>‚ÄúThe task ‚ÄòTest entry‚Äô is no longer needed. Delete it.‚Äù</p>
</blockquote>
<p><strong>Note-taker records</strong>:</p>
<ul>
<li>Confirmation dialog appeared? (HTMX)</li>
<li>Did they expect confirmation?</li>
<li>Did they verify deletion succeeded?</li>
</ul>
<p><strong>Post-task question</strong>: Confidence (1‚Äì5)</p>
<hr />
<h4 id="debrief-3-min"><a class="header" href="#debrief-3-min">Debrief (3 min)</a></h4>
<p><strong>Facilitator asks</strong>:</p>
<ol>
<li>‚ÄúWhich task felt most difficult?‚Äù</li>
<li>‚ÄúDid anything surprise you or not work as expected?‚Äù</li>
<li>‚ÄúWere there any points where you weren‚Äôt sure if something had worked?‚Äù</li>
</ol>
<p><strong>Record verbatim quotes</strong> in notes:</p>
<pre><code>Debrief P1:
- "T2 edit was hardest‚ÄîI wasn't sure if it saved"
- "T1 filter was easy once I found the box"
- "Success messages were subtle, I had to look for them"
</code></pre>
<p><strong>Thank participant</strong>:</p>
<blockquote>
<p>‚ÄúThat‚Äôs really helpful, thank you. Your feedback will directly improve the prototype.‚Äù</p>
</blockquote>
<hr />
<h3 id="pilot-2-keyboard-only-variant"><a class="header" href="#pilot-2-keyboard-only-variant">Pilot 2: Keyboard-Only Variant</a></h3>
<p>Repeat entire process with new participant, <strong>new session ID</strong> (e.g., <code>P2_4d8e</code>).</p>
<p><strong>Key difference</strong>: Participant uses <strong>Tab, Enter, Space only</strong> (no mouse).</p>
<p><strong>Record variant</strong> in consent log: <code>Variant: Keyboard-only, JS-on</code></p>
<p><strong>Additional observations to capture</strong>:</p>
<ul>
<li>Tab order logical?</li>
<li>All interactive elements reachable?</li>
<li>Focus visible on all stops?</li>
<li>Any keyboard traps?</li>
<li>Skip link working?</li>
</ul>
<p><strong>Expected</strong>: May be slower (tabbing takes time). Note accessibility issues (missing focus indicators, unreachable buttons).</p>
<hr />
<h3 id="pilot-3-no-js-variant"><a class="header" href="#pilot-3-no-js-variant">Pilot 3: No-JS Variant</a></h3>
<p><strong>Key difference</strong>: Disable JavaScript before starting.</p>
<p><strong>Setup</strong>:</p>
<ol>
<li>Chrome DevTools ‚Üí Settings ‚Üí Preferences ‚Üí Disable JavaScript (checkbox)</li>
<li>Hard refresh (Ctrl+Shift+R / Cmd+Shift+R)</li>
</ol>
<p><strong>Record variant</strong>: <code>Variant: No-JS (JS-off)</code></p>
<p><strong>Additional observations</strong>:</p>
<ul>
<li>Full page reloads on every form submit?</li>
<li>Error messages visible after redirect?</li>
<li>PRG pattern working (refresh doesn‚Äôt duplicate submission)?</li>
<li>Confirmation missing for delete? (expected trade-off)</li>
</ul>
<p><strong>Expected</strong>: Slower task times (full page reloads). Verify <code>metrics.csv</code> shows <code>js_mode=off</code>.</p>
<hr />
<h3 id="pilots-46-standard-or-screen-reader"><a class="header" href="#pilots-46-standard-or-screen-reader">Pilots 4‚Äì6: Standard or Screen Reader</a></h3>
<p><strong>Standard</strong>: Repeat Pilot 1 process with new participants for more data points.</p>
<p><strong>Screen Reader</strong> (if time permits):</p>
<ul>
<li>Participant uses NVDA (Windows) or Orca (Linux)</li>
<li>Allow 2√ó time (SR navigation slower)</li>
<li>Facilitator <strong>silent</strong> unless participant asks questions (talking competes with SR audio)</li>
</ul>
<p><strong>SR-specific observations</strong>:</p>
<ul>
<li>Are labels announced correctly?</li>
<li>Are status messages announced (<code>role="status"</code>)?</li>
<li>Are error messages linked to inputs (<code>aria-describedby</code>)?</li>
<li>Can participant complete tasks independently?</li>
</ul>
<p><strong>Record variant</strong>: <code>Variant: Screen reader (NVDA), keyboard-only, JS-on</code></p>
<hr />
<h3 id="between-pilots-5-min-each"><a class="header" href="#between-pilots-5-min-each">Between Pilots (5 min each)</a></h3>
<ol>
<li><strong>Save notes</strong>: Copy notes to <code>wk09/lab-wk9/research/pilots/P1-notes.md</code> (or keep in single file with headings)</li>
<li><strong>Check logs</strong>: Verify <code>metrics.csv</code> has rows for all completed tasks</li>
<li><strong>Swap roles</strong>: Next person facilitates, previous facilitator becomes note-taker or participant</li>
<li><strong>Generate new session ID</strong>: Never reuse (contaminates data)</li>
<li><strong>Clear browser state</strong>: Delete cookies, close tabs, fresh start</li>
</ol>
<hr />
<h3 id="facilitator-guidelines-reference"><a class="header" href="#facilitator-guidelines-reference">Facilitator Guidelines (Reference)</a></h3>
<p><strong>Do</strong>:</p>
<ul>
<li>Stay neutral (tone, facial expressions)</li>
<li>Allow silence (don‚Äôt fill pauses‚Äîpeople think quietly)</li>
<li>Record exact quotes when possible</li>
<li>Note timestamps for key events</li>
</ul>
<p><strong>Don‚Äôt</strong>:</p>
<ul>
<li>Explain interface (‚ÄúThe filter is at the top‚Äù)</li>
<li>Justify design (‚ÄúIt‚Äôs supposed to work like this‚Äù)</li>
<li>Lead participant (‚ÄúDid you see the success message?‚Äù)</li>
<li>Show impatience (sighs, tapping, checking watch)</li>
</ul>
<p><strong>If participant stuck (&gt;3 min)</strong>:</p>
<ol>
<li>Ask diagnostic question: ‚ÄúWhat are you looking for?‚Äù</li>
<li>If still stuck: ‚ÄúLet‚Äôs move to the next task‚Äù</li>
<li>Mark task as <code>completion=0</code>, note reason in pilot-notes</li>
</ol>
<p><strong>If participant becomes frustrated</strong>:</p>
<ul>
<li>Reassure: ‚ÄúThis is really helpful feedback‚Äîit‚Äôs the interface, not you.‚Äù</li>
<li>Offer break or stop session</li>
<li>Never pressure to continue</li>
</ul>
<hr />
<p>‚úã <strong>Stop and check</strong> (after completing pilots):</p>
<ul>
<li><input disabled="" type="checkbox"/>
3‚Äì6 pilots completed with different variants</li>
<li><input disabled="" type="checkbox"/>
Consent logged for each participant</li>
<li><input disabled="" type="checkbox"/>
metrics.csv contains rows for all tasks (check session_ids)</li>
<li><input disabled="" type="checkbox"/>
Pilot notes saved with timestamps, quotes, observations</li>
<li><input disabled="" type="checkbox"/>
Subjective ratings captured (confidence 1‚Äì5)</li>
</ul>
<hr />
<h2 id="activity-c-data-verification-and-initial-analysis-15-min"><a class="header" href="#activity-c-data-verification-and-initial-analysis-15-min">Activity C: Data Verification and Initial Analysis (15 min)</a></h2>
<p><strong>Goal</strong>: Ensure collected data is complete and usable before leaving lab.</p>
<h3 id="step-1-check-metricscsv-completeness-5-min"><a class="header" href="#step-1-check-metricscsv-completeness-5-min">Step 1: Check metrics.csv completeness (5 min)</a></h3>
<p>Open <code>data/metrics.csv</code> and verify:</p>
<p><strong>Expected structure</strong>:</p>
<pre><code class="language-csv">ts_iso,session_id,request_id,task_code,step,outcome,ms,http_status,js_mode
2025-10-15T14:18:23.456Z,P1_7a9f,r001,T3_add,success,,567,200,on
2025-10-15T14:19:45.789Z,P1_7a9f,r002,T1_filter,success,,1847,200,on
2025-10-15T14:21:12.123Z,P1_7a9f,r003,T2_edit,validation_error,blank_title,0,400,on
2025-10-15T14:21:34.456Z,P1_7a9f,r004,T2_edit,success,,1234,200,on
2025-10-15T14:22:10.789Z,P1_7a9f,r005,T4_delete,success,,210,200,on
</code></pre>
<p><strong>Checklist</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
All session_ids present (P1, P2, P3, ‚Ä¶)</li>
<li><input disabled="" type="checkbox"/>
All task_codes present (T1, T2, T3, T4) per session</li>
<li><input disabled="" type="checkbox"/>
<code>step</code> values valid (success, validation_error, fail)</li>
<li><input disabled="" type="checkbox"/>
Timestamps in chronological order</li>
<li><input disabled="" type="checkbox"/>
<code>js_mode</code> matches variant (off for Pilot 3)</li>
<li><input disabled="" type="checkbox"/>
Durations plausible (not negative, not absurdly high like 999999ms)</li>
</ul>
<p><strong>If data missing</strong>:</p>
<ul>
<li>Note in <code>wk09/lab-wk9/research/data-notes.md</code>:
<pre><code>Pilot 2 (P2_4d8e): Task T4 not logged due to server restart. Used facilitator stopwatch time: 38s.
</code></pre>
</li>
</ul>
<h3 id="step-2-calculate-quick-summary-stats-5-min"><a class="header" href="#step-2-calculate-quick-summary-stats-5-min">Step 2: Calculate quick summary stats (5 min)</a></h3>
<p><strong>Use spreadsheet or manual calculation</strong>:</p>
<p><strong>Completion rates</strong> (per task):</p>
<pre><code>T1 (Filter):    5 success / 5 attempts = 100%
T2 (Edit):      4 success / 5 attempts = 80% (1 participant gave up)
T3 (Add):       5 success / 5 attempts = 100%
T4 (Delete):    5 success / 5 attempts = 100%
</code></pre>
<p><strong>Median times</strong> (from <code>ms</code> column, filter <code>step=success</code>):</p>
<pre><code>T1: [1847, 2103, 1654, 2345, 1899] ‚Üí Median = 1899ms (~19s)
T2: [1234, 1567, 1123, 1890] ‚Üí Median = 1400ms (~14s)
T3: [567, 432, 689, 543, 601] ‚Üí Median = 567ms (~6s)
T4: [210, 198, 234, 221, 205] ‚Üí Median = 210ms (~2s)
</code></pre>
<p><strong>Error rates</strong>:</p>
<pre><code>T2: 2 validation_error events / 6 total attempts = 33%
T3: 1 validation_error / 5 attempts = 20%
</code></pre>
<p><strong>Record in <code>wk09/lab-wk9/research/summary-stats.md</code></strong>:</p>
<pre><code class="language-markdown"># Pilot Summary Stats (n=5)

## Completion Rates
| Task | Completion | Notes |
|------|-----------|-------|
| T1 (Filter) | 5/5 (100%) | All participants successful |
| T2 (Edit) | 4/5 (80%) | P3 gave up after 2 validation errors |
| T3 (Add) | 5/5 (100%) | 1 validation error (P2 submitted blank) |
| T4 (Delete) | 5/5 (100%) | No issues |

## Median Times (success only)
| Task | Median (ms) | Median (s) | Range |
|------|------------|------------|-------|
| T1 | 1899 | 19s | 16s‚Äì23s |
| T2 | 1400 | 14s | 11s‚Äì19s |
| T3 | 567 | 6s | 4s‚Äì7s |
| T4 | 210 | 2s | 2s‚Äì2.3s |

## Error Rates
| Task | Validation Errors | Rate | Notes |
|------|------------------|------|-------|
| T2 | 2 errors (P2, P3) | 33% | Blank title submitted |
| T3 | 1 error (P2) | 20% | Blank title submitted |

## JS-On vs JS-Off (T3 comparison)
- JS-on (n=4): Median 567ms
- JS-off (n=1, P3): 3456ms (full page reload)
- **Difference**: ~6√ó slower without JS (expected)
</code></pre>
<h3 id="step-3-flag-anomalies-5-min"><a class="header" href="#step-3-flag-anomalies-5-min">Step 3: Flag anomalies (5 min)</a></h3>
<p><strong>Look for</strong>:</p>
<ul>
<li>Outliers: Times &gt;3√ó median (distraction? confusion? technical issue?)</li>
<li>Missing data: Tasks with no log entries</li>
<li>Impossible values: Negative times, empty session_ids</li>
<li>Inconsistencies: <code>js_mode=on</code> for Pilot 3 (should be <code>off</code>)</li>
</ul>
<p><strong>Document in data-notes.md</strong>:</p>
<pre><code class="language-markdown"># Data Quality Notes

## Anomalies
- Pilot 1, T1: Duration 1847ms is within normal range ‚úì
- Pilot 3, T3: Duration 3456ms (no-JS) is expected (full page reload) ‚úì
- Pilot 4, T2: Missing log entry‚Äîserver crashed, used stopwatch: 17s

## Exclusions
- None (all data usable)

## Notes
- P3 (no-JS) consistently slower‚Äîconfirms dual-path performance difference
- P2 triggered 2 validation errors (blank submissions)‚Äîpossible focus management issue
</code></pre>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
metrics.csv verified complete</li>
<li><input disabled="" type="checkbox"/>
Summary stats calculated (completion, median times, error rates)</li>
<li><input disabled="" type="checkbox"/>
Anomalies documented</li>
<li><input disabled="" type="checkbox"/>
Data quality acceptable for Week 10 analysis</li>
</ul>
<hr />
<h2 id="activity-d-translate-findings-to-backlog-20-min"><a class="header" href="#activity-d-translate-findings-to-backlog-20-min">Activity D: Translate Findings to Backlog (20 min)</a></h2>
<p><strong>Goal</strong>: Create evidence chains from pilot observations to actionable backlog items.</p>
<h3 id="step-1-review-pilot-notes-5-min"><a class="header" href="#step-1-review-pilot-notes-5-min">Step 1: Review pilot notes (5 min)</a></h3>
<p><strong>Read through all pilot notes</strong> (<code>pilots/P1-notes.md</code>, etc.) and highlight:</p>
<ul>
<li><strong>Accessibility issues</strong>: SR didn‚Äôt announce, keyboard trap, missing label</li>
<li><strong>Usability issues</strong>: Confusion, hesitation, unexpected behaviour</li>
<li><strong>Error patterns</strong>: Multiple participants hit same validation error</li>
<li><strong>Positive observations</strong>: What worked well (keep in redesign)</li>
</ul>
<p><strong>Example notes</strong>:</p>
<pre><code class="language-markdown">## Pilot 1 (P1_7a9f)
- 14:18 T3: Participant hesitated before clicking "Add Task" button‚Äîunsure if Enter would work
- 14:19 T1: Typed "report", waited, then said "is it filtering automatically?"‚Äîexpected to click button
- 14:21 T2: Validation error (blank submission), participant said "I didn't see an error message"
- 14:22 T4: Delete confirmation dialog appeared, participant confirmed without hesitation ‚úì

## Pilot 2 (P2_4d8e, keyboard-only)
- 14:35 T3: Tab order correct, focus visible ‚úì
- 14:37 T1: Result count not announced by screen reader (tested with NVDA for demo) ‚úó
- 14:39 T2: Blank submission error‚ÄîSR didn't announce error message ‚úó
- 14:40 T4: Delete button accessible, confirmation worked ‚úì

## Pilot 3 (P3_1f2a, no-JS)
- 15:00 T3: Full page reload after submit‚Äîslower but functional ‚úì
- 15:02 T1: Filter worked with form submit‚Äîno issues ‚úì
- 15:04 T2: Gave up after 2 validation errors‚Äîerror summary not focusable ‚úó
- 15:05 T4: No confirmation dialog (expected trade-off), task completed ‚úì
</code></pre>
<h3 id="step-2-identify-themes-5-min"><a class="header" href="#step-2-identify-themes-5-min">Step 2: Identify themes (5 min)</a></h3>
<p><strong>Group similar issues</strong>:</p>
<div class="table-wrapper"><table><thead><tr><th>Theme</th><th>Code</th><th>Observations</th></tr></thead><tbody>
<tr><td><strong>Status feedback</strong></td><td>sr-announcement</td><td>P1: ‚Äúdidn‚Äôt see error‚Äù, P2: SR didn‚Äôt announce, P3: error not focusable</td></tr>
<tr><td><strong>Filter expectations</strong></td><td>ux-expectation</td><td>P1: expected button, not auto-filter</td></tr>
<tr><td><strong>Validation errors</strong></td><td>error-handling</td><td>P2, P3: blank submissions frequent</td></tr>
<tr><td><strong>Keyboard accessibility</strong></td><td>a11y-keyboard</td><td>P2: tab order good ‚úì</td></tr>
<tr><td><strong>No-JS parity</strong></td><td>parity-nojs</td><td>P3: slower but functional ‚úì</td></tr>
</tbody></table>
</div>
<h3 id="step-3-create-backlog-items-10-min"><a class="header" href="#step-3-create-backlog-items-10-min">Step 3: Create backlog items (10 min)</a></h3>
<p><strong>Open <code>backlog/backlog.csv</code></strong> and add entries for significant issues.</p>
<p><strong>Template</strong>:</p>
<pre><code class="language-csv">id,week,priority,category,description,wcag,status,evidence,mitigation,candidate_fix
</code></pre>
<p><strong>Example entries</strong>:</p>
<pre><code class="language-csv">wk9-01,9,high,a11y,"Validation errors not announced by screen readers",4.1.3,open,"data/metrics.csv#P2_4d8e T2 validation_error; pilots/P2-notes.md L12; pilots/P3-notes.md L8","Add role=alert to error messages, aria-describedby for input association",true

wk9-02,9,medium,ux,"Filter auto-search confuses some participants (expected button)",,"open","pilots/P1-notes.md L6","Consider adding visible 'Apply' button or help text",false

wk9-03,9,high,a11y,"Error summary not keyboard-focusable in no-JS mode",3.2.1,open,"pilots/P3-notes.md L10; data/metrics.csv#P3_1f2a T2 fail","Add tabindex=-1 to error summary, focus on page load",true

wk9-04,9,low,ux,"Delete confirmation missing in no-JS (documented trade-off)",3.3.4,open,"pilots/P3-notes.md L12; wk08/docs/prototyping-constraints.md L78","Consider adding /tasks/{id}/delete/confirm page",false

wk9-05,9,high,a11y,"Result count after filter not announced to SR",4.1.3,open,"pilots/P2-notes.md L8","Move result count into live region (role=status)",true
</code></pre>
<p><strong>Key fields</strong>:</p>
<ul>
<li><strong>id</strong>: Unique identifier (wk9-01, wk9-02, ‚Ä¶)</li>
<li><strong>priority</strong>: high (blocks task completion or WCAG A/AA violation), medium (impacts efficiency), low (nice-to-have)</li>
<li><strong>wcag</strong>: Reference if applicable (3.3.1, 4.1.3, etc.)</li>
<li><strong>evidence</strong>: Direct links to data sources (file paths, line numbers, session IDs)</li>
<li><strong>mitigation</strong>: Proposed fix (specific, actionable)</li>
<li><strong>candidate_fix</strong>: <code>true</code> if you plan to implement in Week 10 (limit to 2-3)</li>
</ul>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Pilot notes reviewed and themes identified</li>
<li><input disabled="" type="checkbox"/>
backlog.csv updated with evidence-linked items</li>
<li><input disabled="" type="checkbox"/>
Priority set based on inclusion impact + frequency</li>
<li><input disabled="" type="checkbox"/>
2-3 items marked as candidate fixes for Week 10</li>
</ul>
<hr />
<h2 id="activity-e-assemble-assessment-draft-pack-20-min"><a class="header" href="#activity-e-assemble-assessment-draft-pack-20-min">Activity E: Assemble Assessment Draft Pack (20 min)</a></h2>
<p><strong>Goal</strong>: Create a complete evidence pack for assessment submission (to be refined and submitted by end Week 10).</p>
<p><strong>Directory structure</strong>: <code>wk09/assessment/</code></p>
<h3 id="step-1-copy-evaluation-plan-materials-5-min"><a class="header" href="#step-1-copy-evaluation-plan-materials-5-min">Step 1: Copy evaluation plan materials (5 min)</a></h3>
<p><strong>Files to include</strong>:</p>
<ol>
<li>
<p><strong><code>01-evaluation-plan.md</code></strong>: Copy from <code>wk09/lab-wk9/research/tasks.md</code> + <code>measures.md</code></p>
<ul>
<li>Task definitions</li>
<li>Metrics definitions</li>
<li>Success criteria</li>
</ul>
</li>
<li>
<p><strong><code>02-protocol.md</code></strong>: Copy from <code>wk09/lab-wk9/research/protocol.md</code></p>
<ul>
<li>Consent process</li>
<li>Session flow</li>
<li>Facilitator guidelines</li>
<li>Ethical considerations</li>
</ul>
</li>
<li>
<p><strong><code>03-consent-log.md</code></strong>: Copy from <code>wk09/lab-wk9/research/consent-log.md</code></p>
<ul>
<li>Participant codes</li>
<li>Session IDs</li>
<li>Variants tested</li>
<li>Consent confirmation</li>
</ul>
</li>
</ol>
<h3 id="step-2-include-quantitative-data-5-min"><a class="header" href="#step-2-include-quantitative-data-5-min">Step 2: Include quantitative data (5 min)</a></h3>
<p><strong>Create <code>04-results.csv</code></strong>:</p>
<p>Option A: Copy relevant rows from <code>data/metrics.csv</code>:</p>
<pre><code class="language-bash">grep -E "P1_|P2_|P3_|P4_|P5_" data/metrics.csv &gt; wk09/assessment/04-results.csv
</code></pre>
<p>Option B: Symbolic link (keeps data in one place):</p>
<pre><code class="language-bash">ln -s ../../../data/metrics.csv wk09/assessment/04-results.csv
</code></pre>
<p><strong>Include README.md</strong> explaining columns:</p>
<pre><code class="language-markdown"># Results Data

**File**: `04-results.csv`

**Columns**:
- `ts_iso`: Event timestamp (ISO 8601 UTC)
- `session_id`: Anonymous participant identifier (P1_7a9f, etc.)
- `request_id`: Request trace ID
- `task_code`: Task identifier (T1_filter, T2_edit, T3_add, T4_delete)
- `step`: Event type (success, validation_error, fail)
- `outcome`: Specific error type (blank_title, max_length, etc.)
- `ms`: Duration in milliseconds
- `http_status`: HTTP response code (200, 400, 500)
- `js_mode`: JavaScript availability (on, off)

**Sessions**:
- P1_7a9f: Standard (HTMX, mouse, JS-on)
- P2_4d8e: Keyboard-only (JS-on)
- P3_1f2a: No-JS (JS-off)
- P4_8c3b: Standard (HTMX, mouse, JS-on)
- P5_2a7d: Standard (HTMX, mouse, JS-on)

**Analysis**: See `05-findings.md` for summary statistics and interpretation.
</code></pre>
<h3 id="step-3-document-findings-5-min"><a class="header" href="#step-3-document-findings-5-min">Step 3: Document findings (5 min)</a></h3>
<p><strong>Create <code>05-findings.md</code></strong> summarizing key issues with evidence chains and WCAG references (see Week 9 Lab 1 for detailed example format).</p>
<h3 id="step-4-collect-evidence-artefacts-5-min"><a class="header" href="#step-4-collect-evidence-artefacts-5-min">Step 4: Collect evidence artefacts (5 min)</a></h3>
<p><strong>Create <code>06-evidence/</code> directory</strong>:</p>
<pre><code>wk09/assessment/06-evidence/
‚îú‚îÄ‚îÄ screenshots/
‚îÇ   ‚îú‚îÄ‚îÄ t2-validation-error-nojs.png
‚îÇ   ‚îú‚îÄ‚îÄ t1-filter-results.png
‚îÇ   ‚îî‚îÄ‚îÄ annotations.md (descriptions + alt text)
‚îú‚îÄ‚îÄ pilot-notes/
‚îÇ   ‚îú‚îÄ‚îÄ P1-notes.md
‚îÇ   ‚îú‚îÄ‚îÄ P2-notes.md
‚îÇ   ‚îî‚îÄ‚îÄ P3-notes.md
‚îî‚îÄ‚îÄ consent-log.md
</code></pre>
<p><strong>Remove any PII</strong> from screenshots and notes.</p>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Evaluation plan + protocol copied to assessment/</li>
<li><input disabled="" type="checkbox"/>
Quantitative data (metrics.csv) included or linked</li>
<li><input disabled="" type="checkbox"/>
Findings document complete with statistics + evidence chains</li>
<li><input disabled="" type="checkbox"/>
Evidence artefacts collected (screenshots, notes)</li>
<li><input disabled="" type="checkbox"/>
All files sanitized (no PII)</li>
</ul>
<hr />
<h2 id="commit--reflect-10-min-2"><a class="header" href="#commit--reflect-10-min-2">Commit &amp; Reflect (10 min)</a></h2>
<h3 id="commit-message-2"><a class="header" href="#commit-message-2">Commit message</a></h3>
<pre><code class="language-bash">git add data/metrics.csv backlog/backlog.csv wk09/research wk09/assessment

git commit -m "$(cat &lt;&lt;'EOF'
wk9s2: completed peer pilots (n=5), assembled assessment draft pack

- Conducted 5 peer pilots: 3 standard (HTMX), 1 keyboard-only, 1 no-JS
- Collected quantitative data: completion rates (80-100%), median times (2s‚Äì19s), error rates (20-33% for T2/T3)
- Captured qualitative observations: validation error accessibility issues, status feedback insufficient, filter UX expectations
- Verified no-JS parity: functional but 6√ó slower (expected)
- Created evidence chains: raw data ‚Üí findings ‚Üí backlog items (wk9-01 to wk9-05)
- Assembled assessment draft pack: plan, protocol, results.csv, findings.md, evidence artefacts
- Identified Priority 1 fixes for Week 10: validation error accessibility (role=alert, aria-describedby, focusable summary)

Key findings:
- Validation errors not accessible to SR users (WCAG 4.1.3 violation)
- Error summary not keyboard-focusable in no-JS mode (WCAG 3.2.1)
- Status messages too subtle (affects confidence)
- High error rate on T2 edit (33%‚Äîblank submissions due to focus management)

Ready for Week 10 analysis and redesign.


EOF
)"
</code></pre>
<h3 id="reflection-questions-5"><a class="header" href="#reflection-questions-5">Reflection questions</a></h3>
<p><strong>Answer in <code>wk09/reflection.md</code></strong>:</p>
<ol>
<li>
<p><strong>Pilot experience</strong>: What surprised you most during pilots? Did participants struggle where you expected, or were there unexpected issues?</p>
</li>
<li>
<p><strong>Ethical practice</strong>: How comfortable were participants? Did consent process feel sufficient? Any near-misses on PII collection?</p>
</li>
<li>
<p><strong>Data quality</strong>: How confident are you in the quantitative data (metrics.csv)? Any concerns about accuracy, completeness, or bias?</p>
</li>
<li>
<p><strong>Qualitative insights</strong>: What did observation reveal that logs couldn‚Äôt capture? How valuable was think-aloud (if used)?</p>
</li>
<li>
<p><strong>Accessibility impact</strong>: Which findings have highest inclusion impact? How would you prioritise fixes if you could only do one?</p>
</li>
<li>
<p><strong>Week 10 readiness</strong>: What are your Priority 1 fixes? How will you verify they worked?</p>
</li>
</ol>
<hr />
<h2 id="looking-ahead-week-10-analysis--redesign"><a class="header" href="#looking-ahead-week-10-analysis--redesign">Looking Ahead: Week 10 Analysis &amp; Redesign</a></h2>
<p>Next week:</p>
<ul>
<li><strong>Lab 1</strong>: Analyse metrics in depth (median, MAD, error rates), prioritise backlog with inclusion √ó impact scores, plan redesign</li>
<li><strong>Lab 2</strong>: Implement Priority 1-2 fixes, re-verify accessibility, update backlog, finalise assessment submission</li>
</ul>
<p><strong>Before Week 10</strong>:</p>
<ul>
<li>Review <a href="wk09/../references/evaluation-metrics-quickref.html">Evaluation Metrics Quick Reference</a> for analysis formulas</li>
<li>Refresh WCAG 2.2 guidelines for fixes (3.3.1, 4.1.3)</li>
<li>Think about trade-offs: which fixes are quick wins vs major refactors?</li>
</ul>
<hr />
<h2 id="further-reading--resources-2"><a class="header" href="#further-reading--resources-2">Further Reading &amp; Resources</a></h2>
<h3 id="essential-2"><a class="header" href="#essential-2">Essential</a></h3>
<ul>
<li>Review Week 9 Lab 1 (evaluation planning) for context</li>
<li><a href="wk09/../references/evaluation-metrics-quickref.html">Evaluation Metrics Quick Reference</a> ‚Äî Median, MAD, error rate formulas</li>
<li><a href="https://www.gov.uk/service-manual/user-research/analyse-a-research-session">GOV.UK: Analysing user research</a></li>
</ul>
<h3 id="hci-evaluation"><a class="header" href="#hci-evaluation">HCI Evaluation</a></h3>
<ul>
<li><a href="https://www.nngroup.com/articles/usability-testing-101/">Nielsen: How to Conduct a Usability Test</a></li>
<li><a href="https://dl.acm.org/doi/book/10.5555/2737875">Lazar et al.: Research Methods in HCI</a> ‚Äî Chapters 9-10 (qualitative methods)</li>
<li><a href="https://measuringux.com/">Measuring UX</a> ‚Äî Quantitative analysis techniques</li>
</ul>
<h3 id="qualitative-analysis"><a class="header" href="#qualitative-analysis">Qualitative Analysis</a></h3>
<ul>
<li><a href="https://www.tandfonline.com/doi/abs/10.1191/1478088706qp063oa">Braun &amp; Clarke: Thematic Analysis</a></li>
<li><a href="https://www.gov.uk/service-manual/user-research/analyse-a-research-session">GOV.UK: Analysing qualitative data</a></li>
</ul>
<h3 id="ethics"><a class="header" href="#ethics">Ethics</a></h3>
<ul>
<li>Review <code>references/consent-pii-faq.md</code></li>
<li><a href="https://www.bps.org.uk/guideline/code-ethics-and-conduct">BPS Code of Ethics</a></li>
</ul>
<hr />
<h2 id="glossary-summary-5"><a class="header" href="#glossary-summary-5">Glossary Summary</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Term</th><th>One-line definition</th></tr></thead><tbody>
<tr><td><strong>Pilot study</strong></td><td>Small-scale preliminary study to test protocol and gather initial data</td></tr>
<tr><td><strong>Quantitative data</strong></td><td>Numerical measurements (times, counts, percentages); objective, statistical</td></tr>
<tr><td><strong>Qualitative data</strong></td><td>Non-numerical observations (quotes, behaviours, patterns); subjective, interpretive</td></tr>
<tr><td><strong>Think-aloud protocol</strong></td><td>Participants verbalize thoughts while completing tasks; reveals mental models</td></tr>
<tr><td><strong>Evidence chain</strong></td><td>Traceability from raw data ‚Üí finding ‚Üí backlog item ‚Üí fix ‚Üí verification</td></tr>
<tr><td><strong>Thematic coding</strong></td><td>Systematic process of identifying patterns (themes) in qualitative data</td></tr>
<tr><td><strong>Median</strong></td><td>Middle value in sorted dataset; resistant to outliers</td></tr>
<tr><td><strong>MAD</strong></td><td>Median Absolute Deviation; robust measure of spread</td></tr>
<tr><td><strong>Completion rate</strong></td><td>Proportion of participants who successfully complete a task</td></tr>
<tr><td><strong>Error rate</strong></td><td>Proportion of attempts that trigger validation errors</td></tr>
</tbody></table>
</div>
<hr />
<p><strong>Lab complete!</strong> You have real pilot data, evidence chains, and a draft assessment pack. Week 10 will analyse this data rigorously, implement prioritised fixes, and finalise your assessment submission (due end Week 10).</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-9--lab-2--student-guide-run-pilots--draft-assessment"><a class="header" href="#week-9--lab-2--student-guide-run-pilots--draft-assessment">Week 9 ‚Ä¢ Lab 2 ‚Äî Student Guide: Run Pilots &amp; Draft Assessment</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-9-orange" alt="Week 9" />
<img src="https://img.shields.io/badge/Lab-2-green" alt="Lab 2" />
<img src="https://img.shields.io/badge/Type-Student_Guide-purple" alt="Guide" /></p>
<blockquote>
<p><strong>Purpose</strong>: Week 9 Lab 2 is where you execute your evaluation plan - run pilots with 3-5 participants, collect data, analyse findings, and draft your assessment evidence pack.</p>
</blockquote>
<hr />
<h2 id="deliverables-3"><a class="header" href="#deliverables-3">Deliverables</a></h2>
<p>By the end of this lab:</p>
<ul>
<li>‚úÖ Pilot data from 3-5 participants (<code>wk09/data/pilot-notes.md</code>)</li>
<li>‚úÖ Analysed findings (<code>wk09/analysis/findings.md</code>)</li>
<li>‚úÖ Evidence chain documentation (<code>wk09/analysis/evidence-chains.md</code>)</li>
<li>‚úÖ Draft assessment pack outline (<code>wk09/assessment/</code>)</li>
<li>‚úÖ Updated backlog with pilot findings</li>
</ul>
<hr />
<h2 id="part-1-run-pilots-60-minutes"><a class="header" href="#part-1-run-pilots-60-minutes">Part 1: Run Pilots (60 minutes)</a></h2>
<h3 id="setup-checklist"><a class="header" href="#setup-checklist">Setup Checklist</a></h3>
<p>Before first participant:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Server running: <code>./gradlew run</code></li>
<li><input disabled="" type="checkbox"/>
Protocol document open (<code>wk09/research/protocol.md</code>)</li>
<li><input disabled="" type="checkbox"/>
Stopwatch/timer ready</li>
<li><input disabled="" type="checkbox"/>
Notebook + pen for observations</li>
<li><input disabled="" type="checkbox"/>
Tasks scenarios printed or on screen (<code>wk09/research/tasks.md</code>)</li>
</ul>
<h3 id="per-participant-procedure-20-minutes-each"><a class="header" href="#per-participant-procedure-20-minutes-each">Per-Participant Procedure (20 minutes each)</a></h3>
<ol>
<li><strong>Consent</strong> (2 min): Read consent script, confirm verbal agreement, assign pseudonym (P1, P2‚Ä¶)</li>
<li><strong>Setup mode</strong> (1 min):
<ul>
<li>Participant 1, 3, 5 ‚Üí HTMX (JS enabled)</li>
<li>Participant 2, 4 ‚Üí No-JS (disable in DevTools)</li>
</ul>
</li>
<li><strong>Orientation</strong> (2 min): ‚ÄúTesting interface, not you. Think aloud. Can stop anytime.‚Äù</li>
<li><strong>Execute tasks</strong> (12 min): For each task T1-T4:
<ul>
<li>Read scenario aloud</li>
<li>Start timer</li>
<li>Observe (note clicks, confusion, comments)</li>
<li>Stop timer when complete OR give up</li>
<li>Ask: ‚Äú1-5, how confident you completed correctly?‚Äù</li>
</ul>
</li>
<li><strong>Debrief</strong> (3 min): ‚ÄúMost confusing part? What worked well?‚Äù</li>
</ol>
<h3 id="data-recording-template"><a class="header" href="#data-recording-template">Data Recording Template</a></h3>
<p><strong>Create</strong> <code>wk09/data/pilot-notes.md</code>:</p>
<details>
<summary>Click to expand: Pilot Notes Template</summary>
<pre><code class="language-markdown"># Pilot Data ‚Äî Week 9

## Participant P1
**Mode**: HTMX
**Date**: [YYYY-MM-DD HH:MM]
**Consent**: ‚úÖ Verbal confirmed
**Duration**: 18 minutes

---

### Task 1: Filter and Complete
**Start**: 10:30:00 ‚Üí **End**: 10:30:45 = **45 seconds**
**Success**: 1 (completed)
**Errors**: 0
**Confidence**: 4/5
**Observations**:
- Hesitated finding filter box ("Where's the search?")
- Clicked checkbox, immediate visual feedback good
- Said "Oh nice, it just works!" (positive)

---

### Task 2: Add New Task
**Start**: 10:31:00 ‚Üí **End**: 10:31:25 = **25 seconds**
**Success**: 1
**Errors**: 1 (tried to submit blank, saw error)
**Confidence**: 5/5
**Observations**:
- Typed title, pressed Enter (didn't click button - good!)
- Blank submit ‚Üí error message showed (red, "Title required")
- Corrected, submitted successfully
- Status message: "Task added" - SR announced (tested with NVDA)

---

[Repeat for T3, T4]

---

### Debrief Notes
**Most confusing**: "Cancel button in edit mode - wasn't sure if it would save or not"
**Most helpful**: "Instant feedback when I add tasks, no waiting"
**Accessibility**: Used keyboard only (requested). All features reachable. Focus visible.

---

## Participant P2
**Mode**: No-JS
[Repeat structure]

---

[Repeat for P3-P5]
</code></pre>
</details>
<p><strong>Checklist</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
3-5 pilots completed</li>
<li><input disabled="" type="checkbox"/>
All times, success, errors, confidence recorded</li>
<li><input disabled="" type="checkbox"/>
Think-aloud quotes captured</li>
<li><input disabled="" type="checkbox"/>
Mode (HTMX/no-JS) noted per participant</li>
</ul>
<hr />
<h2 id="part-2-analyse-findings-40-minutes"><a class="header" href="#part-2-analyse-findings-40-minutes">Part 2: Analyse Findings (40 minutes)</a></h2>
<h3 id="aggregate-data"><a class="header" href="#aggregate-data">Aggregate Data</a></h3>
<p><strong>Create</strong> <code>wk09/analysis/findings.md</code>:</p>
<details>
<summary>Click to expand: Findings Analysis Template</summary>
<pre><code class="language-markdown"># Pilot Findings Analysis ‚Äî Week 9

**Participants**: 5 (3 HTMX, 2 No-JS)
**Date range**: [YYYY-MM-DD to YYYY-MM-DD]

---

## Quantitative Summary

### Task 1: Filter and Complete
| Metric | HTMX (n=3) | No-JS (n=2) | Overall |
|--------|------------|-------------|---------|
| Mean time (s) | 42 | 58 | 48 |
| Success rate | 100% | 100% | 100% |
| Mean errors | 0.3 | 0 | 0.2 |
| Mean confidence | 4.3/5 | 4.0/5 | 4.2/5 |

**Interpretation**: Task 1 successful for all. HTMX slightly faster (no page reload). Low error rate. High confidence.

---

### Task 2: Add New Task
| Metric | HTMX | No-JS | Overall |
|--------|------|-------|---------|
| Mean time (s) | 28 | 35 | 30.6 |
| Success rate | 100% | 100% | 100% |
| Mean errors | 0.7 | 1.0 | 0.8 |
| Mean confidence | 4.7/5 | 3.5/5 | 4.2/5 |

**Interpretation**: High success but errors common (validation). HTMX confidence higher (instant feedback). No-JS participants less sure (PRG redirect, no confirmation message).

---

[Repeat for T3, T4]

---

## Qualitative Themes

### Theme 1: Confirmation Feedback Critical
**Evidence**: 4/5 participants mentioned needing "confirmation it worked"
**Quotes**:
- P1 (HTMX): "I like seeing 'Task added' immediately"
- P3 (No-JS): "I had to scroll down to check it was there - not obvious"

**Design implication**: No-JS path needs explicit success message (PRG currently shows none).

---

### Theme 2: Edit Cancel Button Confusing
**Evidence**: 3/5 participants hesitated on Cancel button
**Quotes**:
- P2: "Will Cancel save my changes or lose them?"
- P4: "I clicked it to test - wasn't sure"

**Design implication**: Button label needs clarification ("Cancel (discard changes)")

---

### Theme 3: Keyboard Access Excellent
**Evidence**: 2 participants tested keyboard-only (requested). Both succeeded all tasks.
**Quotes**:
- P5 (keyboard-only): "Tab order makes sense, focus always visible"

**Design implication**: Keep current keyboard implementation.

---

## Accessibility Observations

### Screen Reader (NVDA)
- ‚úÖ Labels announced correctly ("Task title, edit text")
- ‚úÖ Status messages announced ("Task added successfully")
- ‚ùå Error messages not announced in no-JS path (redirect loses `role="alert"`)

### Keyboard Navigation
- ‚úÖ All features reachable
- ‚úÖ Focus visible
- ‚ö†Ô∏è Tab order logical but Edit‚ÜíSave‚ÜíCancel could be clearer

---

## Prioritised Issues

Based on frequency + severity:

1. **High**: No confirmation message in no-JS path (affects 2/2 no-JS participants, low confidence)
2. **Medium**: Cancel button ambiguous (3/5 confused, but completed anyway)
3. **Low**: Edit button focus order (minor hesitation, all succeeded)
</code></pre>
</details>
<p><strong>Checklist</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Quantitative summary per task (times, success, errors, confidence)</li>
<li><input disabled="" type="checkbox"/>
Qualitative themes identified (3-5 themes)</li>
<li><input disabled="" type="checkbox"/>
Accessibility observations noted</li>
<li><input disabled="" type="checkbox"/>
Prioritised issues list</li>
</ul>
<hr />
<h2 id="part-3-evidence-chains-20-minutes"><a class="header" href="#part-3-evidence-chains-20-minutes">Part 3: Evidence Chains (20 minutes)</a></h2>
<p>Link raw data ‚Üí finding ‚Üí backlog item ‚Üí WCAG (if applicable).</p>
<p><strong>Create</strong> <code>wk09/analysis/evidence-chains.md</code>:</p>
<details>
<summary>Click to expand: Evidence Chains Template</summary>
<pre><code class="language-markdown"># Evidence Chains ‚Äî Week 9

## Chain 1: No Confirmation in No-JS Path

**Raw data**: P3 (No-JS) confidence = 2/5, said "Had to scroll to check". P4 (No-JS) confidence = 3/5, refreshed page to verify.

**Finding**: No-JS participants lack confidence because PRG redirect shows no explicit success message.

**Backlog item**: ID 15, "No confirmation after form submission (no-JS)", Severity: High, Inclusion risk: Cognitive, Low digital literacy

**WCAG**: 3.3.3 Error Suggestion (AA) - Not error, but related (success feedback equally important)

**Evidence file**: `wk09/data/pilot-notes.md` lines 45-48 (P3), lines 89-92 (P4)

**Screenshot**: `wk09/evidence/nojs-no-confirmation.png`

---

## Chain 2: Cancel Button Ambiguous Label

**Raw data**: P2, P4, P5 all hesitated on Cancel (pilot notes timestamps show 3-5 second pause). P2 quote: "Will it save or lose changes?"

**Finding**: "Cancel" label doesn't clarify whether changes are discarded.

**Backlog item**: ID 16, "Edit Cancel button label unclear", Severity: Medium, Inclusion risk: Cognitive

**WCAG**: 2.4.6 Headings and Labels (AA) - Labels should be descriptive

**Evidence file**: `wk09/data/pilot-notes.md` lines 22-23 (P2), lines 67-68 (P4)

**Screenshot**: `wk09/evidence/edit-cancel-ambiguous.png`

---

[Repeat for 3-5 key findings]
</code></pre>
</details>
<p><strong>Checklist</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
3-5 evidence chains documented</li>
<li><input disabled="" type="checkbox"/>
Each chain links data ‚Üí finding ‚Üí backlog ‚Üí WCAG</li>
<li><input disabled="" type="checkbox"/>
Screenshots/quotes referenced</li>
</ul>
<hr />
<h2 id="part-4-draft-assessment-pack-30-minutes"><a class="header" href="#part-4-draft-assessment-pack-30-minutes">Part 4: Draft Assessment Pack (30 minutes)</a></h2>
<p>Start assembling your assessment submission (due end Week 10).</p>
<p><strong>Create</strong> <code>wk09/assessment/outline.md</code>:</p>
<details>
<summary>Click to expand: Task 1 Draft Outline</summary>
<pre><code class="language-markdown"># Assessment Draft Outline

## Section 1: Evaluation Plan (15%)

### 1.1 Test Tasks (5%)
- [ ] Copy from `wk09/research/tasks.md`
- [ ] Ensure 3-4 tasks with scenarios, success criteria
- [ ] Highlight inclusion focus per task

### 1.2 Metrics (5%)
- [ ] Copy from `wk09/research/measures.md`
- [ ] Define quantitative (time, success, errors) + qualitative (think-aloud)
- [ ] Justify why these metrics

### 1.3 Protocol (5%)
- [ ] Copy from `wk09/research/protocol.md`
- [ ] Include consent process, procedure, ethics checklist
- [ ] Note UK GDPR compliance

---

## Section 2: Findings (40%)

### 2.1 Quantitative Results (15%)
- [ ] Summary tables per task (times, success, errors, confidence)
- [ ] Compare HTMX vs No-JS
- [ ] Identify outliers / problematic tasks

### 2.2 Qualitative Analysis (15%)
- [ ] 3-5 themes from think-aloud
- [ ] Direct quotes as evidence
- [ ] Link themes to design implications

### 2.3 Accessibility Observations (10%)
- [ ] Keyboard navigation results
- [ ] Screen reader testing notes
- [ ] WCAG criteria met/failed

---

## Section 3: Evidence Chains (25%)

### 3.1 High-Priority Findings (15%)
- [ ] Evidence chain for each (data ‚Üí finding ‚Üí backlog ‚Üí WCAG)
- [ ] Screenshots showing issues
- [ ] Participant quotes

### 3.2 Backlog Integration (10%)
- [ ] Show how findings update backlog
- [ ] Severity + inclusion risk scores
- [ ] Candidate fixes for Week 10

---

## Section 4: Reflection (20%)

### 4.1 Process Critique (10%)
- [ ] What went well in pilots?
- [ ] What would you change?
- [ ] Limitations (small sample, peer pilots)

### 4.2 Next Steps (10%)
- [ ] Prioritised redesign plan (Week 10)
- [ ] Which issues to fix first and why
- [ ] Trade-offs to document

---

## Files to Include

- [ ] `wk09/research/tasks.md`
- [ ] `wk09/research/measures.md`
- [ ] `wk09/research/protocol.md`
- [ ] `wk09/data/pilot-notes.md`
- [ ] `wk09/analysis/findings.md`
- [ ] `wk09/analysis/evidence-chains.md`
- [ ] Screenshots from `wk09/evidence/`
- [ ] Updated `backlog/backlog.csv`

**Total word count target**: ~2500-3000 words
**Due**: [Check Gradescope deadline]
</code></pre>
</details>
<p><strong>Checklist</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Assessment outline created</li>
<li><input disabled="" type="checkbox"/>
All required sections listed</li>
<li><input disabled="" type="checkbox"/>
Evidence files identified</li>
</ul>
<hr />
<h2 id="commit--continue-7"><a class="header" href="#commit--continue-7">Commit &amp; Continue</a></h2>
<pre><code class="language-bash">git add wk09/
git commit -m "feat(wk9-lab2): pilot execution, analysis, Task 1 draft

- Completed 5 pilots (3 HTMX, 2 No-JS)
- Collected quantitative data (times, success, errors, confidence)
- Analysed qualitative themes from think-aloud observations
- Documented 5 evidence chains linking data to backlog
- Created draft assessment outline with all required sections

Ready for Week 10 redesign implementation."
</code></pre>
<p><strong>Next</strong>: Week 10 Lab 1 - Analyse metrics and prioritise redesign.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-10--lab-1--analyse-metrics-prioritise-fixes-plan-inclusive-redesign"><a class="header" href="#week-10--lab-1--analyse-metrics-prioritise-fixes-plan-inclusive-redesign">Week 10 ‚Ä¢ Lab 1 ‚Äî Analyse Metrics, Prioritise Fixes, Plan Inclusive Redesign</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-10-orange" alt="Week 10" />
<img src="https://img.shields.io/badge/Lab-1-green" alt="Lab 1" />
<img src="https://img.shields.io/badge/Status-Draft-yellow" alt="Status" /></p>
<hr />
<h2 id="before-lab-required-reading-15-mins-1"><a class="header" href="#before-lab-required-reading-15-mins-1">Before Lab: Required Reading (15 mins)</a></h2>
<p>üìñ <strong>Essential</strong>:</p>
<ul>
<li>Review <a href="wk10/../references/evaluation-metrics-quickref.html">Evaluation Metrics Quick Reference</a> (formulas for median, MAD, error rates)</li>
<li>Review Week 9 Lab 2 findings (<code>wk09/assessment/05-findings.md</code>)</li>
<li><a href="https://www.nngroup.com/articles/how-to-rate-the-severity-of-usability-problems/">Nielsen: Prioritising Web Usability Issues</a></li>
</ul>
<p>üìñ <strong>Contextual</strong>:</p>
<ul>
<li><a href="https://www.gov.uk/service-manual/measuring-success/using-data-to-improve-your-service">GOV.UK: Using data to improve your service</a></li>
<li><a href="https://www.w3.org/WAI/test-evaluate/report/">W3C: Prioritising Accessibility Issues</a></li>
</ul>
<hr />
<h2 id="introduction-from-data-to-decisions"><a class="header" href="#introduction-from-data-to-decisions">Introduction: From Data to Decisions</a></h2>
<p>Week 9 collected raw pilot data: logs, times, errors, quotes. <strong>Today you turn that data into actionable insights</strong>.</p>
<p><strong>Data analysis is NOT just number-crunching</strong>. It‚Äôs:</p>
<ul>
<li><strong>Interpretation</strong>: What do the numbers <em>mean</em> for real people?</li>
<li><strong>Prioritisation</strong>: Which issues matter most for inclusion + usability?</li>
<li><strong>Planning</strong>: What specific changes will fix the highest-impact problems?</li>
</ul>
<p><strong>Why this matters</strong>:</p>
<ul>
<li><strong>assessment</strong>: Requires before/after metrics + evidence of data-driven redesign</li>
<li><strong>Week 10 Lab 2</strong>: You‚Äôll implement Priority 1 fixes‚Äîplanning today prevents thrashing tomorrow</li>
<li><strong>Professional practice</strong>: Product decisions require justification (stakeholders ask ‚Äúwhy this fix?‚Äù)</li>
</ul>
<p><strong>Inclusion lens</strong>: Numbers alone don‚Äôt show <strong>who</strong> is excluded. Must combine quantitative (completion rates, times) with qualitative (SR didn‚Äôt announce, keyboard trap) to understand barriers.</p>
<hr />
<h2 id="learning-focus-8"><a class="header" href="#learning-focus-8">Learning Focus</a></h2>
<h3 id="lab-objectives-8"><a class="header" href="#lab-objectives-8">Lab Objectives</a></h3>
<p>By the end of this session, you will have:</p>
<ul>
<li>Calculated summary statistics (median, MAD, completion rate, error rate) per task</li>
<li>Analysed pilot data (quantitative + qualitative)</li>
<li>Interpreted metrics to identify inclusion impacts (SR users, keyboard-only, no-JS)</li>
<li>Prioritised issues using (Impact + Inclusion) ‚Äì Effort matrix</li>
<li>Created redesign brief with evidence chains</li>
</ul>
<h3 id="learning-outcomes-addressed-8"><a class="header" href="#learning-outcomes-addressed-8">Learning Outcomes Addressed</a></h3>
<p>This lab contributes to the following module Learning Outcomes (<a href="wk10/../references/learning-outcomes.html">full definitions</a>):</p>
<ul>
<li><strong>LO6</strong>: Apply iterative design ‚Äî evidenced by data-driven prioritisation</li>
<li><strong>LO8</strong>: Design and execute evaluation ‚Äî evidenced by metric analysis</li>
<li><strong>LO9</strong>: Apply inclusive design ‚Äî evidenced by inclusion weighting in prioritisation</li>
</ul>
<hr />
<h2 id="key-concepts-7"><a class="header" href="#key-concepts-7">Key Concepts</a></h2>
<h3 id="descriptive-statistics"><a class="header" href="#descriptive-statistics">Descriptive Statistics</a></h3>
<blockquote>
<p><strong>Descriptive Statistics</strong> [GLOSSARY]</p>
<p>Summarize and describe main features of a dataset. <strong>Not inferential</strong> (we don‚Äôt generalize beyond our 5 pilots).</p>
<p><strong>Key measures for HCI</strong>:</p>
<ul>
<li><strong>Median</strong>: Middle value when sorted (50th percentile)</li>
<li><strong>MAD</strong>: Median Absolute Deviation (robust measure of spread)</li>
<li><strong>Range</strong>: Min‚Äìmax (shows extremes)</li>
<li><strong>Count</strong>: Number of observations (sample size)</li>
</ul>
<p><strong>Why median, not mean?</strong> Completion times are often skewed (outliers from distractions, confusion). Median represents ‚Äútypical‚Äù experience.</p>
<p><strong>Example</strong>:
Task times: [12s, 15s, 18s, 20s, 120s]</p>
<ul>
<li>Mean = 37s ‚Üê skewed by 120s outlier</li>
<li>Median = 18s ‚Üê typical experience</li>
</ul>
<p><strong>HCI Connection</strong>: Descriptive stats make evaluation findings <strong>communicable</strong>‚Äîstakeholders understand ‚Äútypical task takes 18s‚Äù better than raw logs.</p>
<p>üîó <a href="https://measuringux.com/median/">Measuring UX: Median</a></p>
</blockquote>
<h3 id="median-absolute-deviation-mad"><a class="header" href="#median-absolute-deviation-mad">Median Absolute Deviation (MAD)</a></h3>
<blockquote>
<p><strong>MAD (Median Absolute Deviation)</strong> [GLOSSARY]</p>
<p>Robust measure of variability. Less sensitive to outliers than standard deviation.</p>
<p><strong>Formula</strong>:</p>
<pre><code>MAD = median(|x_i - median(x)|)
</code></pre>
<p><strong>Steps</strong>:</p>
<ol>
<li>Find median of dataset</li>
<li>Calculate absolute deviations: <code>|each value - median|</code></li>
<li>Find median of those deviations</li>
</ol>
<p><strong>Example</strong>:
Times: [12s, 15s, 18s, 20s, 25s]</p>
<ol>
<li>Median = 18s</li>
<li>Deviations: |12-18|=6, |15-18|=3, |18-18|=0, |20-18|=2, |25-18|=7</li>
<li>MAD = median([6, 3, 0, 2, 7]) = 3s</li>
</ol>
<p><strong>Interpretation</strong>: Low MAD (e.g., 2s) = consistent experiences. High MAD (e.g., 15s) = varied experiences‚Äîoften signals accessibility barriers (some participants breeze through, others struggle).</p>
<p><strong>HCI Connection</strong>: MAD flags <strong>inclusion issues</strong>‚Äîif SR users take 40s and sighted users take 15s, MAD will be high.</p>
<p>üîó <a href="https://en.wikipedia.org/wiki/Median_absolute_deviation">Wikipedia: Median Absolute Deviation</a></p>
</blockquote>
<h3 id="completion-rate"><a class="header" href="#completion-rate">Completion Rate</a></h3>
<blockquote>
<p><strong>Completion Rate</strong> [GLOSSARY]</p>
<p>Proportion of task attempts that succeeded.</p>
<p><strong>Formula</strong>:</p>
<pre><code>Completion rate = n_success / n_total_attempts
</code></pre>
<p><strong>Range</strong>: 0 (no one succeeded) to 1.0 (everyone succeeded)</p>
<p><strong>Example</strong>:</p>
<ul>
<li>4 participants completed T2 successfully</li>
<li>1 participant gave up (marked <code>fail</code> in logs)</li>
<li>Total: 5 attempts</li>
<li>Completion rate = 4/5 = 0.80 = 80%</li>
</ul>
<p><strong>Interpretation</strong>:</p>
<ul>
<li><strong>1.0</strong>: Task is achievable by all participants (baseline expectation)</li>
<li><strong>0.8‚Äì0.99</strong>: Minor issues‚Äîsome participants struggled but most succeeded</li>
<li><strong>&lt;0.8</strong>: Serious usability/accessibility problem‚Äî1 in 5+ people can‚Äôt complete</li>
</ul>
<p><strong>Split by js_mode</strong>: If <code>js_mode=on</code> has 1.0 but <code>js_mode=off</code> has 0.5, you have <strong>parity failure</strong> (no-JS path broken).</p>
<p><strong>HCI Connection</strong>: Completion rate is <strong>effectiveness</strong> measure (ISO 9241-11). If people can‚Äôt complete tasks, system is not usable.</p>
<p>üîó <a href="https://www.iso.org/standard/63500.html">ISO 9241-11: Usability Definitions</a></p>
</blockquote>
<h3 id="error-rate"><a class="header" href="#error-rate">Error Rate</a></h3>
<blockquote>
<p><strong>Error Rate</strong> [GLOSSARY]</p>
<p>Proportion of task attempts that triggered validation errors.</p>
<p><strong>Formula</strong>:</p>
<pre><code>Error rate = n_validation_errors / (n_success + n_validation_errors)
</code></pre>
<p><strong>Example</strong>:</p>
<ul>
<li>T3 (Add Task): 5 success, 1 validation_error (blank title submitted)</li>
<li>Error rate = 1 / (5 + 1) = 0.17 = 17%</li>
</ul>
<p><strong>Interpretation</strong>:</p>
<ul>
<li><strong>0‚Äì10%</strong>: Acceptable‚Äîrare mistakes</li>
<li><strong>10‚Äì30%</strong>: Moderate‚Äîform could be clearer</li>
<li><strong>&gt;30%</strong>: High‚Äîlikely affordance issues, missing labels, or confusing instructions</li>
</ul>
<p><strong>Root causes</strong>:</p>
<ul>
<li>Missing affordances (‚ÄúI didn‚Äôt know it was required‚Äù)</li>
<li>Unclear constraints (‚ÄúHow long can the title be?‚Äù)</li>
<li>Focus management (‚ÄúI accidentally submitted blank‚Äù)</li>
<li>Cognitive load (‚ÄúToo many fields, got confused‚Äù)</li>
</ul>
<p><strong>HCI Connection</strong>: Error rate measures <strong>efficiency</strong> (ISO 9241-11). High error rates ‚Üí wasted time, frustration, accessibility barriers.</p>
<p>üîó <a href="https://www.w3.org/WAI/WCAG22/Understanding/input-assistance">WCAG 3.3: Input Assistance</a></p>
</blockquote>
<h3 id="prioritisation-framework"><a class="header" href="#prioritisation-framework">Prioritisation Framework</a></h3>
<blockquote>
<p><strong>Prioritisation Framework</strong> [GLOSSARY]</p>
<p>Systematic method to rank backlog items by urgency/importance.</p>
<p><strong>This module‚Äôs framework</strong>:</p>
<pre><code>Priority score = (Impact + Inclusion) - Effort
</code></pre>
<p><strong>Dimensions (1‚Äì5 scale)</strong>:</p>
<ul>
<li><strong>Impact</strong>: How many people affected? How severe?
<ul>
<li>5 = Blocks task completion for most participants</li>
<li>3 = Slows down or frustrates some participants</li>
<li>1 = Minor annoyance, rare</li>
</ul>
</li>
<li><strong>Inclusion</strong>: Does it disproportionately affect disabled people?
<ul>
<li>5 = SR/keyboard/cognitive disability users can‚Äôt complete</li>
<li>3 = Affects some disabled participants (e.g., low vision)</li>
<li>1 = Affects everyone equally</li>
</ul>
</li>
<li><strong>Effort</strong>: How hard to fix?
<ul>
<li>5 = Major refactor, &gt;8 hours</li>
<li>3 = Moderate, 2‚Äì4 hours</li>
<li>1 = Quick fix, &lt;1 hour</li>
</ul>
</li>
</ul>
<p><strong>Score interpretation</strong>:</p>
<ul>
<li><strong>8‚Äì10</strong>: Critical‚Äîfix immediately (Week 10 Lab 2)</li>
<li><strong>5‚Äì7</strong>: High priority‚Äîfix if time permits</li>
<li><strong>&lt;5</strong>: Defer or document as known issue</li>
</ul>
<p><strong>Example</strong>:
Issue: ‚ÄúValidation errors not announced by SR‚Äù</p>
<ul>
<li>Impact: 5 (blocks T2 completion for SR users)</li>
<li>Inclusion: 5 (disproportionately affects SR users)</li>
<li>Effort: 2 (add <code>role=alert</code>, update template)</li>
<li><strong>Score</strong>: (5+5)-2 = <strong>8</strong> ‚Üí <strong>Priority 1</strong></li>
</ul>
<p><strong>HCI Connection</strong>: Prioritisation makes <strong>inclusion explicit</strong>‚Äînot just ‚Äúfix the bugs‚Äù but ‚Äúfix barriers first.‚Äù</p>
<p>üîó <a href="https://www.w3.org/WAI/test-evaluate/report/#prioritise">W3C: Prioritising Accessibility Issues</a></p>
</blockquote>
<h3 id="evidence-chain-revisited"><a class="header" href="#evidence-chain-revisited">Evidence Chain (Revisited)</a></h3>
<blockquote>
<p><strong>Evidence Chain</strong> [GLOSSARY]</p>
<p>Traceability from raw data ‚Üí analysis ‚Üí finding ‚Üí fix ‚Üí verification.</p>
<p><strong>Week 10 adds analysis layer</strong>:</p>
<ol>
<li><strong>Raw data</strong>: <code>metrics.csv</code> shows <code>T2_edit, js_mode=off, completion_rate=0.5</code></li>
<li><strong>Analysis</strong>: <code>analysis/analysis.csv</code> confirms: median 2300ms, MAD 450ms, error rate 0.5</li>
<li><strong>Interpretation</strong>: No-JS path lacks accessible error feedback (pilot notes confirm)</li>
<li><strong>Finding</strong>: ‚ÄúNo-JS edit has 50% completion due to non-focusable error summary‚Äù</li>
<li><strong>Prioritisation</strong>: Impact=5, Inclusion=5, Effort=2 ‚Üí Score=8 (Priority 1)</li>
<li><strong>Fix plan</strong>: Add <code>tabindex="-1"</code> to error summary, auto-focus on page load</li>
<li><strong>Verification</strong> (Week 10 Lab 2): Retest with no-JS, measure completion rate ‚â•0.9</li>
</ol>
<p><strong>assessment requires</strong>:</p>
<ul>
<li>Before metrics (Week 9)</li>
<li>Analysis + prioritisation (Week 10 Lab 1)</li>
<li>After metrics (Week 10 Lab 2)</li>
<li>Evidence chain documented throughout</li>
</ul>
<p>üîó Review Week 9 Lab 2 for initial evidence chain guidance</p>
</blockquote>
<hr />
<h2 id="activity-a-prepare-analysis-workspace-5-min"><a class="header" href="#activity-a-prepare-analysis-workspace-5-min">Activity A: Prepare Analysis Workspace (5 min)</a></h2>
<p><strong>Goal</strong>: Set up directory structure and verify data integrity before analysis.</p>
<h3 id="step-1-create-analysis-directory-2-min"><a class="header" href="#step-1-create-analysis-directory-2-min">Step 1: Create analysis directory (2 min)</a></h3>
<pre><code class="language-bash">mkdir -p analysis
mkdir -p wk10/lab-wk10/docs
mkdir -p wk10/assessment
</code></pre>
<h3 id="step-2-verify-raw-data-3-min"><a class="header" href="#step-2-verify-raw-data-3-min">Step 2: Verify raw data (3 min)</a></h3>
<p><strong>Open <code>data/metrics.csv</code></strong> and check:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Contains rows for all 5 pilots (session IDs: P1, P2, P3, P4, P5)</li>
<li><input disabled="" type="checkbox"/>
All task codes present (T1, T2, T3, T4)</li>
<li><input disabled="" type="checkbox"/>
<code>step</code> values valid (<code>success</code>, <code>validation_error</code>, <code>fail</code>)</li>
<li><input disabled="" type="checkbox"/>
Durations plausible (not negative, not &gt;10000ms unless noted)</li>
<li><input disabled="" type="checkbox"/>
<code>js_mode</code> correctly set (<code>on</code> for Pilots 1,2,4,5; <code>off</code> for Pilot 3)</li>
</ul>
<p><strong>If issues found</strong>: Review Week 9 <code>data-notes.md</code> for documented anomalies. Exclude corrupt rows or correct manually.</p>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
<code>analysis/</code> directory exists</li>
<li><input disabled="" type="checkbox"/>
<code>data/metrics.csv</code> verified complete</li>
<li><input disabled="" type="checkbox"/>
Ready to run analysis script</li>
</ul>
<hr />
<h2 id="activity-b-calculate-summary-statistics-25-min"><a class="header" href="#activity-b-calculate-summary-statistics-25-min">Activity B: Calculate Summary Statistics (25 min)</a></h2>
<p><strong>Goal</strong>: Generate <code>analysis/analysis.csv</code> with median, MAD, completion, error rates per task.</p>
<h3 id="step-1-run-analysis-script-15-min"><a class="header" href="#step-1-run-analysis-script-15-min">Step 1: Run analysis script (15 min)</a></h3>
<p><strong>Option A: Use provided Kotlin script</strong> (if available at <code>wk10/lab-wk10/scripts/Analyse.kt</code>):</p>
<pre><code class="language-bash">kotlinc wk10/lab-wk10/scripts/Analyse.kt -include-runtime -d analyse.jar
java -jar analyse.jar
</code></pre>
<p><strong>Option B: Manual calculation with spreadsheet</strong>:</p>
<ol>
<li>Import <code>data/metrics.csv</code> into Google Sheets / Excel</li>
<li>Create pivot table grouping by <code>task_code</code> + <code>js_mode</code></li>
<li>Calculate for each group:</li>
</ol>
<p><strong>Median time</strong> (filter <code>step=success</code> only):</p>
<pre><code>=MEDIAN(IF((task=$A2)*(step="success"), ms, ""))
</code></pre>
<p><strong>MAD</strong> (median absolute deviation):</p>
<pre><code>1. Calculate median for group
2. Create column: ABS(ms - median)
3. MEDIAN of that column
</code></pre>
<p><strong>Completion rate</strong>:</p>
<pre><code>=COUNTIF(step, "success") / (COUNTIF(step, "success") + COUNTIF(step, "fail"))
</code></pre>
<p><strong>Error rate</strong>:</p>
<pre><code>=COUNTIF(step, "validation_error") / (COUNTIF(step, "success") + COUNTIF(step, "validation_error"))
</code></pre>
<p><strong>Option C: Python script</strong>:</p>
<pre><code class="language-python">import pandas as pd
import numpy as np

# Load data
df = pd.read_csv('data/metrics.csv')

# Filter success rows for timing
success = df[df['step'] == 'success']

# Group by task and js_mode
grouped = success.groupby(['task_code', 'js_mode'])

# Calculate statistics
stats = grouped['ms'].agg([
    ('n_success', 'count'),
    ('median_ms', 'median'),
    ('mad_ms', lambda x: np.median(np.abs(x - np.median(x))))
]).reset_index()

# Calculate completion rate (per task+js_mode)
total_attempts = df.groupby(['task_code', 'js_mode']).size().reset_index(name='n_total')
success_count = df[df['step']=='success'].groupby(['task_code', 'js_mode']).size().reset_index(name='n_success')
completion = total_attempts.merge(success_count, on=['task_code', 'js_mode'], how='left')
completion['completion_rate'] = completion['n_success'] / completion['n_total']

# Calculate error rate
errors = df[df['step']=='validation_error'].groupby(['task_code', 'js_mode']).size().reset_index(name='n_errors')
error_rate = success_count.merge(errors, on=['task_code', 'js_mode'], how='left').fillna(0)
error_rate['error_rate'] = error_rate['n_errors'] / (error_rate['n_success'] + error_rate['n_errors'])

# Merge all
final = stats.merge(completion[['task_code', 'js_mode', 'completion_rate']], on=['task_code', 'js_mode'])
final = final.merge(error_rate[['task_code', 'js_mode', 'error_rate']], on=['task_code', 'js_mode'])

# Save
final.to_csv('analysis/analysis.csv', index=False)
print(final)
</code></pre>
<h3 id="step-2-verify-output-5-min"><a class="header" href="#step-2-verify-output-5-min">Step 2: Verify output (5 min)</a></h3>
<p><strong>Open <code>analysis/analysis.csv</code></strong>:</p>
<p><strong>Expected columns</strong>:</p>
<pre><code class="language-csv">task_code,js_mode,n_success,median_ms,mad_ms,completion_rate,error_rate
T1_filter,on,5,1899,203,1.00,0.00
T1_filter,off,1,3245,0,1.00,0.00
T2_edit,on,4,1400,184,0.80,0.33
T2_edit,off,0,,,0.00,
T3_add,on,5,567,78,1.00,0.20
T3_add,off,1,3456,0,1.00,0.00
T4_delete,on,5,210,12,1.00,0.00
T4_delete,off,1,198,0,1.00,0.00
</code></pre>
<p><strong>Sanity checks</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Median times plausible (T3 &lt; T2 &lt; T1, since T3 is simplest)</li>
<li><input disabled="" type="checkbox"/>
No-JS times slower than JS-on (expected‚Äîfull page reloads)</li>
<li><input disabled="" type="checkbox"/>
Completion rates ‚â§1.0</li>
<li><input disabled="" type="checkbox"/>
Error rates between 0 and 1</li>
<li><input disabled="" type="checkbox"/>
No NaN/blank for tasks with data</li>
</ul>
<p><strong>If anomalies</strong>: Cross-reference with <code>data/metrics.csv</code>. Document in <code>analysis/data-notes.md</code>.</p>
<h3 id="step-3-add-all-js_mode-aggregate-5-min"><a class="header" href="#step-3-add-all-js_mode-aggregate-5-min">Step 3: Add ‚Äúall‚Äù js_mode aggregate (5 min)</a></h3>
<p>Calculate combined stats (all participants regardless of JS):</p>
<pre><code class="language-python"># Add 'all' js_mode (combines on+off)
all_stats = success.groupby(['task_code'])['ms'].agg([
    ('n_success', 'count'),
    ('median_ms', 'median'),
    ('mad_ms', lambda x: np.median(np.abs(x - np.median(x))))
]).reset_index()
all_stats['js_mode'] = 'all'
# ... repeat for completion/error rates, append to analysis.csv
</code></pre>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
<code>analysis/analysis.csv</code> exists with correct columns</li>
<li><input disabled="" type="checkbox"/>
All tasks present (T1, T2, T3, T4)</li>
<li><input disabled="" type="checkbox"/>
Stats calculated for <code>js_mode=on</code>, <code>off</code>, <code>all</code></li>
<li><input disabled="" type="checkbox"/>
Values plausible (no negative times, completion ‚â§1.0)</li>
</ul>
<hr />
<h2 id="activity-c-interpret-metrics-with-inclusion-lens-25-min"><a class="header" href="#activity-c-interpret-metrics-with-inclusion-lens-25-min">Activity C: Interpret Metrics with Inclusion Lens (25 min)</a></h2>
<p><strong>Goal</strong>: Write narrative interpretation of statistics linking to inclusion barriers.</p>
<h3 id="step-1-create-summary-document-5-min"><a class="header" href="#step-1-create-summary-document-5-min">Step 1: Create summary document (5 min)</a></h3>
<p><strong>Create <code>analysis/summary.md</code></strong>:</p>
<pre><code class="language-markdown"># Pilot Data Analysis Summary ‚Äî Week 10

**Study**: Peer pilots (n=5) conducted Week 9
**Purpose**: Identify usability and accessibility barriers through quantitative + qualitative analysis

---

## Summary Statistics

[Insert tables from analysis.csv]

## Task-by-Task Interpretation

[Analysis for each task with inclusion lens]

## Priority Findings

[Top 3-5 issues for redesign]
</code></pre>
<h3 id="step-2-build-metrics-tables-10-min"><a class="header" href="#step-2-build-metrics-tables-10-min">Step 2: Build metrics tables (10 min)</a></h3>
<p><strong>Copy data from <code>analysis/analysis.csv</code> into Markdown tables</strong>:</p>
<pre><code class="language-markdown">## Task Completion Times (Median ¬± MAD)

| Task | JS-On | JS-Off | All | Notes |
|------|-------|--------|-----|-------|
| T1 (Filter) | 1899ms ¬± 203ms (n=5) | 3245ms ¬± 0ms (n=1) | 2015ms ¬± 380ms (n=6) | No-JS 71% slower |
| T2 (Edit) | 1400ms ¬± 184ms (n=4) | ‚Äî (n=0) | 1400ms ¬± 184ms (n=4) | No-JS: 0% completion |
| T3 (Add) | 567ms ¬± 78ms (n=5) | 3456ms ¬± 0ms (n=1) | 850ms ¬± 890ms (n=6) | No-JS 6√ó slower |
| T4 (Delete) | 210ms ¬± 12ms (n=5) | 198ms ¬± 0ms (n=1) | 208ms ¬± 12ms (n=6) | Consistent |

## Completion &amp; Error Rates

| Task | JS-On Completion | JS-Off Completion | JS-On Errors | JS-Off Errors |
|------|------------------|-------------------|--------------|---------------|
| T1 | 5/5 (100%) | 1/1 (100%) | 0% | 0% |
| T2 | 4/5 (80%) | 0/1 (0%) | 33% | ‚Äî |
| T3 | 5/5 (100%) | 1/1 (100%) | 20% | 0% |
| T4 | 5/5 (100%) | 1/1 (100%) | 0% | 0% |
</code></pre>
<h3 id="step-3-write-task-by-task-interpretations-10-min"><a class="header" href="#step-3-write-task-by-task-interpretations-10-min">Step 3: Write task-by-task interpretations (10 min)</a></h3>
<p><strong>For each task, write 2-3 paragraphs</strong>:</p>
<p><strong>Template</strong>:</p>
<pre><code class="language-markdown">### Task T2: Edit Task

**Quantitative findings**:
- JS-on: 80% completion (4/5), median 1400ms, 33% error rate
- JS-off: 0% completion (0/1)‚Äîparticipant gave up after 2 validation errors
- MAD 184ms (moderate variability‚Äîsome participants breezed through, others struggled)

**Qualitative evidence** (from `pilots/P2-notes.md`, `pilots/P3-notes.md`):
- P2 (keyboard-only): "Blank submission error‚ÄîSR didn't announce error message"
- P3 (no-JS): "Gave up after 2 validation errors‚Äîerror summary not focusable, couldn't find it with Tab"

**Inclusion impact**: **Critical**
- Screen reader users: Error messages not announced (`role="status"` missing)
- Keyboard-only users: Error summary exists but not in tab order (`tabindex="-1"` missing)
- No-JS users: Cannot complete task‚Äîerror summary not focusable, no auto-focus on page load

**WCAG violations**:
- 3.3.1 Error Identification (Level A): Errors not programmatically determinable
- 4.1.3 Status Messages (Level AA): Validation errors not announced
- 3.2.1 On Focus (Level A): Focus not managed after error

**Root cause**: Dual-path error handling incomplete. HTMX path has `hx-swap-oob` status but no `role=alert`. No-JS path renders error summary but doesn't set `tabindex="-1"` or auto-focus.

**Proposed fix** (Priority 1):
- Add `role="alert"` to HTMX error responses
- Add `tabindex="-1"` to no-JS error summary `&lt;div id="error-summary"&gt;`
- Auto-focus error summary on page load (server-side or small progressive enhancement script)
- Add `aria-describedby` linking input to error message

**Expected impact**: Completion rate ‚â•90% for all variants, error rate &lt;10% (with improved affordances).
</code></pre>
<p><strong>Repeat for all 4 tasks</strong>, prioritising those with issues.</p>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Metrics tables complete and formatted</li>
<li><input disabled="" type="checkbox"/>
Task-by-task interpretations written</li>
<li><input disabled="" type="checkbox"/>
Inclusion impacts identified (SR, keyboard, no-JS, cognitive)</li>
<li><input disabled="" type="checkbox"/>
WCAG violations referenced</li>
<li><input disabled="" type="checkbox"/>
Root causes hypothesized</li>
</ul>
<hr />
<h2 id="activity-d-prioritise-backlog-with-scoring-20-min"><a class="header" href="#activity-d-prioritise-backlog-with-scoring-20-min">Activity D: Prioritise Backlog with Scoring (20 min)</a></h2>
<p><strong>Goal</strong>: Rank backlog items by Priority score = (Impact + Inclusion) - Effort.</p>
<h3 id="step-1-create-prioritisation-spreadsheet-5-min"><a class="header" href="#step-1-create-prioritisation-spreadsheet-5-min">Step 1: Create prioritisation spreadsheet (5 min)</a></h3>
<p><strong>Create <code>analysis/prioritisation.csv</code></strong>:</p>
<pre><code class="language-csv">id,title,task_code,problem,impact,inclusion,effort,score,evidence,proposed_fix,candidate_fix
</code></pre>
<h3 id="step-2-score-top-issues-10-min"><a class="header" href="#step-2-score-top-issues-10-min">Step 2: Score top issues (10 min)</a></h3>
<p><strong>For each issue identified in Activity C</strong>:</p>
<ol>
<li><strong>Impact</strong> (1‚Äì5): How many participants affected? How severely?</li>
<li><strong>Inclusion</strong> (1‚Äì5): Disproportionate effect on disabled participants?</li>
<li><strong>Effort</strong> (1‚Äì5): Time to implement fix?</li>
<li><strong>Score</strong>: (Impact + Inclusion) - Effort</li>
</ol>
<blockquote>
<p><strong>üéØ Worked Examples: Scoring Prioritisation</strong></p>
<div class="table-wrapper"><table><thead><tr><th>Issue</th><th>Impact</th><th>Inclusion</th><th>Effort</th><th>Score</th><th>Rationale</th></tr></thead><tbody>
<tr><td><strong>Validation errors not announced (SR)</strong></td><td><strong>5</strong></td><td><strong>5</strong></td><td>2</td><td><strong>8</strong></td><td>Impact=5 (all SR users blocked on edit task), Inclusion=5 (SR-specific barrier), Effort=2 (add <code>role=alert</code>), Score=(5+5)-2=8</td></tr>
<tr><td><strong>No-JS error summary not focusable</strong></td><td><strong>5</strong></td><td><strong>5</strong></td><td>2</td><td><strong>8</strong></td><td>Impact=5 (all no-JS users affected), Inclusion=5 (keyboard/no-mouse users can‚Äôt navigate), Effort=2 (add <code>tabindex=-1</code>), Score=(5+5)-2=8</td></tr>
<tr><td><strong>Filter result count not announced</strong></td><td><strong>3</strong></td><td><strong>4</strong></td><td>1</td><td><strong>6</strong></td><td>Impact=3 (minor: doesn‚Äôt block task, but confusing), Inclusion=4 (SR users miss feedback), Effort=1 (move text to live region), Score=(3+4)-1=6</td></tr>
<tr><td><strong>Auto-search confuses some</strong></td><td><strong>3</strong></td><td><strong>2</strong></td><td>2</td><td><strong>3</strong></td><td>Impact=3 (affects 2/5 pilots, minor confusion), Inclusion=2 (not equity-specific), Effort=2 (add button + help text), Score=(3+2)-2=3</td></tr>
<tr><td><strong>No-JS delete lacks confirmation</strong></td><td><strong>2</strong></td><td><strong>2</strong></td><td>4</td><td><strong>0</strong></td><td>Impact=2 (rare: only no-JS + delete use case), Inclusion=2 (low risk, recoverable), Effort=4 (new route + page + tests), Score=(2+2)-4=0 ‚Üí <strong>Deprioritise</strong></td></tr>
</tbody></table>
</div>
<p><strong>Key distinctions</strong>:</p>
<ul>
<li><strong>Impact vs Inclusion</strong>: Impact = ‚Äúhow many people?‚Äù / Inclusion = ‚Äúwho is disproportionately affected?‚Äù
<ul>
<li>Example 1: High impact (5) + high inclusion (5) = SR validation errors block <strong>everyone</strong> using SR</li>
<li>Example 4: Medium impact (3) + low inclusion (2) = auto-search confusion is <strong>general usability</strong> issue, not equity-specific</li>
</ul>
</li>
<li><strong>When Effort &gt; Benefit</strong>: Example 5 scores 0 (even though impact+inclusion=4) because effort=4 makes ROI negative</li>
<li><strong>Tie-breaking</strong>: Examples 1 &amp; 2 both score 8 ‚Üí prioritise together if they relate to same task (T2_edit)</li>
</ul>
<p><strong>Decision-making</strong>:</p>
<ul>
<li><strong>Priority 1</strong> (fix in Lab 2): Score ‚â•8 + WCAG violation + feasible in 2 hours</li>
<li><strong>Priority 2</strong> (semester 2 backlog): Score 5-7</li>
<li><strong>Deprioritise</strong>: Score &lt;5 or effort outweighs benefit</li>
</ul>
</blockquote>
<p><strong>Example entries</strong>:</p>
<pre><code class="language-csv">wk9-01,"Validation errors not announced by SR",T2_edit,"SR users can't identify validation errors",5,5,2,8,"analysis/summary.md#T2; pilots/P2-notes.md L12","Add role=alert + aria-describedby to error messages",true

wk9-03,"No-JS error summary not focusable",T2_edit,"Keyboard users can't navigate to error summary in no-JS mode",5,5,2,8,"analysis/summary.md#T2; pilots/P3-notes.md L10","Add tabindex=-1, auto-focus on page load",true

wk9-05,"Filter result count not announced",T1_filter,"SR users don't hear how many results remain after filtering",3,4,1,6,"pilots/P2-notes.md L8","Move result count into live region (role=status)",false

wk9-02,"Filter auto-search confuses some",T1_filter,"Some participants expected explicit Apply button",3,2,2,3,"pilots/P1-notes.md L6","Add visible Apply button or help text",false

wk9-04,"No-JS delete has no confirmation",T4_delete,"No-JS participants can't confirm before deleting (documented trade-off)",2,2,4,0,"pilots/P3-notes.md L12; wk08/docs/prototyping-constraints.md","Add /tasks/{id}/delete/confirm page",false
</code></pre>
<h3 id="step-3-rank-and-mark-candidates-5-min"><a class="header" href="#step-3-rank-and-mark-candidates-5-min">Step 3: Rank and mark candidates (5 min)</a></h3>
<p><strong>Sort by <code>score</code> descending</strong>.</p>
<p><strong>Mark top 2-3 items</strong> as <code>candidate_fix=true</code> (these are Priority 1 for Week 10 Lab 2).</p>
<p><strong>Criteria for Priority 1</strong>:</p>
<ul>
<li>Score ‚â•8</li>
<li>WCAG Level A or AA violation</li>
<li>Blocks task completion for disabled participants</li>
<li>Feasible to fix in 2-hour lab session</li>
</ul>
<p><strong>In example above</strong>: wk9-01 and wk9-03 both score 8, both relate to T2 edit, both fixable together ‚Üí <strong>Priority 1</strong>.</p>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
<code>analysis/prioritisation.csv</code> complete with scores</li>
<li><input disabled="" type="checkbox"/>
Issues ranked by score (highest first)</li>
<li><input disabled="" type="checkbox"/>
2-3 Priority 1 items marked <code>candidate_fix=true</code></li>
<li><input disabled="" type="checkbox"/>
Evidence links present for all items</li>
</ul>
<hr />
<h2 id="activity-e-draft-inclusive-redesign-brief-20-min"><a class="header" href="#activity-e-draft-inclusive-redesign-brief-20-min">Activity E: Draft Inclusive Redesign Brief (20 min)</a></h2>
<p><strong>Goal</strong>: Document planned fix with measurable goals and acceptance criteria.</p>
<h3 id="step-1-create-redesign-brief-document-5-min"><a class="header" href="#step-1-create-redesign-brief-document-5-min">Step 1: Create redesign brief document (5 min)</a></h3>
<p><strong>Create <code>wk10/lab-wk10/docs/redesign-brief.md</code></strong>:</p>
<pre><code class="language-markdown"># Inclusive Redesign Brief ‚Äî Week 10 Lab 2

**Target**: [Issue title from prioritisation.csv]
**Priority**: 1 (Score: X)
**Assignee**: [Your name/pair]
**Date**: 2025-10-20

---

## Problem Statement

[2-3 sentences describing the issue backed by data]

---

## Goal

[Measurable target improvement]

---

## Inclusion Impact

[Who benefits and why]

---

## Proposed Changes

[Specific implementation steps]

---

## Acceptance Criteria

[How will we know it's fixed?]

---

## Verification Plan

[Testing protocol]

---

## Risk &amp; Constraints

[Trade-offs, technical limitations]
</code></pre>
<h3 id="step-2-fill-in-sections-15-min"><a class="header" href="#step-2-fill-in-sections-15-min">Step 2: Fill in sections (15 min)</a></h3>
<p><strong>Using T2 edit accessibility issue as example</strong>:</p>
<pre><code class="language-markdown"># Inclusive Redesign Brief ‚Äî Week 10 Lab 2

**Target**: Validation errors not announced by screen readers (wk9-01, wk9-03)
**Priority**: 1 (Score: 8)
**Assignee**: [Your name]
**Date**: 2025-10-20

---

## Problem Statement

Task T2 (Edit Task) has 80% completion for JS-on participants and 0% completion for JS-off participants. Analysis shows:
- 33% error rate (2 validation errors in 6 attempts)
- Median time 1400ms with MAD 184ms (moderate variability)
- Qualitative evidence: "SR didn't announce error message" (P2), "Error summary not focusable" (P3)

**Root cause**: Validation error messages not accessible. HTMX path lacks `role="alert"`. No-JS path renders error summary but doesn't focus it or make it keyboard-navigable.

**WCAG violations**: 3.3.1 Error Identification (A), 4.1.3 Status Messages (AA), 3.2.1 On Focus (A)

---

## Goal

**Target metrics** (Week 10 Lab 2 verification):
- T2 completion rate ‚â•90% for all variants (JS-on, JS-off, keyboard-only, SR)
- T2 error rate &lt;10% (improved affordances reduce accidental blank submissions)
- Zero WCAG 3.3.1 / 4.1.3 violations on retest

**Success means**: Screen reader users hear validation errors immediately. Keyboard-only users can navigate to error summary with Tab. No-JS users see error summary on page load with focus.

---

## Inclusion Impact

**Who benefits**:
- **Screen reader users** (estimated 2-5% of UK population): Can identify and recover from errors independently
- **Keyboard-only users** (motor disabilities, power users): Can navigate to error without mouse
- **Cognitive disabilities**: Clear, announced errors reduce confusion and repeated mistakes
- **Low-bandwidth users** (no-JS fallback): Can complete tasks even with JS disabled

**Equity**: Current design excludes disabled participants‚Äîcompletion rate 0% for no-JS, SR users struggled. Fix restores parity.

---

## Proposed Changes

### Change 1: Add ARIA live region for HTMX errors

**File**: `src/main/kotlin/routes/Tasks.kt`

**Before**:
```kotlin
if (title.isBlank()) {
    val status = """&lt;div id="status" hx-swap-oob="true"&gt;Title is required.&lt;/div&gt;"""
    return@post call.respondText(status, ContentType.Text.Html, HttpStatusCode.BadRequest)
}
</code></pre>
<p><strong>After</strong>:</p>
<pre><code class="language-kotlin">if (title.isBlank()) {
    val status = """&lt;div id="status" role="alert" aria-live="assertive" hx-swap-oob="true"&gt;Title is required. Please enter at least one character.&lt;/div&gt;"""
    return@post call.respondText(status, ContentType.Text.Html, HttpStatusCode.BadRequest)
}
</code></pre>
<p><strong>Rationale</strong>: <code>role="alert"</code> + <code>aria-live="assertive"</code> ensures SR announces error immediately.</p>
<hr />
<h3 id="change-2-make-no-js-error-summary-keyboard-focusable"><a class="header" href="#change-2-make-no-js-error-summary-keyboard-focusable">Change 2: Make no-JS error summary keyboard-focusable</a></h3>
<p><strong>File</strong>: <code>templates/tasks/index.peb</code></p>
<p><strong>Before</strong>:</p>
<pre><code class="language-twig">{% if error %}
&lt;div class="error-summary" id="error-summary"&gt;
  &lt;h2&gt;There is a problem&lt;/h2&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href="#title"&gt;Title is required&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/div&gt;
{% endif %}
</code></pre>
<p><strong>After</strong>:</p>
<pre><code class="language-twig">{% if error %}
&lt;div class="error-summary" id="error-summary" tabindex="-1" role="alert" aria-live="assertive"&gt;
  &lt;h2&gt;There is a problem&lt;/h2&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href="#title"&gt;{% if msg == "too_long" %}Title is too long (max 200 characters){% else %}Title is required{% endif %}&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/div&gt;
&lt;script&gt;
  // Progressive enhancement: auto-focus error summary (no-JS users rely on visual scan)
  if (document.getElementById('error-summary')) {
    document.getElementById('error-summary').focus();
  }
&lt;/script&gt;
{% endif %}
</code></pre>
<p><strong>Rationale</strong>:</p>
<ul>
<li><code>tabindex="-1"</code> makes div focusable programmatically (not in natural tab order)</li>
<li><code>role="alert"</code> + <code>aria-live="assertive"</code> announces to SR on page load</li>
<li>Tiny <code>&lt;script&gt;</code> auto-focuses error (progressive enhancement‚Äîstill works if JS fails)</li>
</ul>
<hr />
<h3 id="change-3-link-input-to-error-message"><a class="header" href="#change-3-link-input-to-error-message">Change 3: Link input to error message</a></h3>
<p><strong>File</strong>: <code>templates/tasks/index.peb</code></p>
<p><strong>Update input</strong>:</p>
<pre><code class="language-twig">&lt;input id="title" name="title" type="text"
       {% if error == "title" %}aria-invalid="true" aria-describedby="title-error"{% endif %}
       required&gt;
{% if error == "title" %}
&lt;p id="title-error" class="error-message" role="alert"&gt;
  {% if msg == "too_long" %}Title is too long (max 200 characters){% else %}Title is required{% endif %}
&lt;/p&gt;
{% endif %}
</code></pre>
<p><strong>Rationale</strong>: <code>aria-describedby</code> links input to error message. SR reads error when focus lands on input.</p>
<hr />
<h2 id="acceptance-criteria"><a class="header" href="#acceptance-criteria">Acceptance Criteria</a></h2>
<h3 id="functional"><a class="header" href="#functional">Functional</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
Blank title submission triggers validation error (both HTMX and no-JS)</li>
<li><input disabled="" type="checkbox"/>
HTMX error appears in <code>#status</code> live region with <code>role="alert"</code></li>
<li><input disabled="" type="checkbox"/>
No-JS error summary appears at top of page</li>
<li><input disabled="" type="checkbox"/>
Error summary has <code>tabindex="-1"</code> and receives focus on page load</li>
</ul>
<h3 id="accessibility-wcag-22-level-aa"><a class="header" href="#accessibility-wcag-22-level-aa">Accessibility (WCAG 2.2 Level AA)</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
<strong>3.3.1 Error Identification (A)</strong>: Error described in text ‚úì</li>
<li><input disabled="" type="checkbox"/>
<strong>4.1.3 Status Messages (AA)</strong>: Error announced by SR without focus change ‚úì</li>
<li><input disabled="" type="checkbox"/>
<strong>3.2.1 On Focus (A)</strong>: Focus managed predictably (lands on error summary) ‚úì</li>
<li><input disabled="" type="checkbox"/>
<strong>1.3.1 Info &amp; Relationships (A)</strong>: <code>aria-describedby</code> links input to error ‚úì</li>
</ul>
<h3 id="testing-protocol"><a class="header" href="#testing-protocol">Testing Protocol</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
<strong>Keyboard-only</strong>: Tab to form, submit blank, Tab to error summary link, press Enter ‚Üí focus lands on <code>#title</code> input</li>
<li><input disabled="" type="checkbox"/>
<strong>Screen reader (NVDA/Orca)</strong>: Submit blank ‚Üí SR announces ‚ÄúAlert. Title is required. Please enter at least one character.‚Äù</li>
<li><input disabled="" type="checkbox"/>
<strong>No-JS</strong>: Disable JS, submit blank ‚Üí page reloads with error summary focused, Tab order correct</li>
<li><input disabled="" type="checkbox"/>
<strong>Re-run T2 pilot</strong>: 3 participants (1 SR, 1 keyboard, 1 no-JS), measure completion rate</li>
</ul>
<hr />
<h2 id="verification-plan"><a class="header" href="#verification-plan">Verification Plan</a></h2>
<h3 id="quantitative-week-10-lab-2"><a class="header" href="#quantitative-week-10-lab-2">Quantitative (Week 10 Lab 2)</a></h3>
<p>Re-run T2 (Edit Task) with 3 participants:</p>
<ol>
<li><strong>P6</strong>: Standard (HTMX, mouse, JS-on)</li>
<li><strong>P7</strong>: Keyboard-only + NVDA (SR)</li>
<li><strong>P8</strong>: No-JS</li>
</ol>
<p><strong>Measure</strong>:</p>
<ul>
<li>Completion rate (target: 3/3 = 100%)</li>
<li>Error rate (target: &lt;1 error across 3 attempts = &lt;33%)</li>
<li>Median time (expect similar to Week 9: ~1400ms for JS-on)</li>
</ul>
<p><strong>Document in</strong>: <code>wk10/lab-wk10/research/verification-notes.md</code></p>
<h3 id="qualitative"><a class="header" href="#qualitative">Qualitative</a></h3>
<ul>
<li>Capture SR output (transcript snippet) confirming error announcement</li>
<li>Screenshot of no-JS error summary with focus indicator visible</li>
<li>Note any remaining confusion or hesitation</li>
</ul>
<h3 id="backlog-update"><a class="header" href="#backlog-update">Backlog Update</a></h3>
<p>Mark wk9-01 and wk9-03 as <code>status=fixed</code>, append evidence links:</p>
<pre><code class="language-csv">wk9-01,...,fixed,"wk10/lab-wk10/research/verification-notes.md; wk10/lab-wk10/evidence/sr-error-announcement.png"
</code></pre>
<hr />
<h2 id="risk--constraints"><a class="header" href="#risk--constraints">Risk &amp; Constraints</a></h2>
<h3 id="technical-constraints"><a class="header" href="#technical-constraints">Technical Constraints</a></h3>
<ul>
<li><strong>No major refactor</strong>: Must stay within 2-hour lab session</li>
<li><strong>Server-first principle</strong>: Keep HTMX enhancement, ensure no-JS parity</li>
<li><strong>Template complexity</strong>: Adding <code>aria-*</code> attributes increases template size‚Äîacceptable trade-off for accessibility</li>
</ul>
<h3 id="potential-issues"><a class="header" href="#potential-issues">Potential Issues</a></h3>
<ul>
<li><strong>Progressive enhancement script</strong>: Tiny <code>&lt;script&gt;</code> auto-focuses error. If JS fails to load, user must visually scan for error summary‚Äî<strong>acceptable fallback</strong> (error still visible, focusable with Tab).</li>
<li><strong>Multiple errors</strong>: Currently handles one error field. If expanding to multiple fields, need error summary list‚Äî<strong>defer to future</strong> (out of scope for Week 10).</li>
</ul>
<h3 id="trade-offs-accepted"><a class="header" href="#trade-offs-accepted">Trade-offs Accepted</a></h3>
<ul>
<li><strong>No client-side validation</strong>: Sticking with server-side only. Could add <code>maxlength</code> attribute for instant feedback‚Äî<strong>defer</strong> (progressive enhancement for later).</li>
</ul>
<hr />
<h2 id="success-criteria-summary"><a class="header" href="#success-criteria-summary">Success Criteria Summary</a></h2>
<p><strong>Definition of Done</strong>:</p>
<ol>
<li>Code changes committed with tests passing</li>
<li>Verification pilots completed (n=3)</li>
<li>T2 completion rate ‚â•90% (all variants)</li>
<li>Zero WCAG 3.3.1 / 4.1.3 violations</li>
<li>Evidence captured (screenshots, SR transcripts, metrics)</li>
<li>Backlog updated (wk9-01, wk9-03 marked fixed)</li>
<li>assessment evidence pack updated with before/after data</li>
</ol>
<p><strong>If not met</strong>: Document blockers, revert changes, choose lower-priority fix.</p>
<pre><code>
‚úã **Stop and check**:
- [ ] Redesign brief complete with all sections
- [ ] Problem backed by Week 9 data
- [ ] Changes specific (file paths, before/after code)
- [ ] Acceptance criteria measurable
- [ ] Verification plan includes quantitative + qualitative testing

---

## Commit &amp; Reflect (10 min)

### Commit message

```bash
git add analysis wk10/lab-wk10/docs/redesign-brief.md backlog/backlog.csv

git commit -m "$(cat &lt;&lt;'EOF'
wk10s1: analysed metrics, prioritised fixes, drafted redesign brief

- Generated analysis/analysis.csv: medians, MAD, completion/error rates per task+js_mode
- Interpreted metrics with inclusion lens: T2 edit has 0% no-JS completion, 33% error rate
- Identified WCAG violations: 3.3.1, 4.1.3 (validation errors not announced/focusable)
- Prioritised backlog using (Impact+Inclusion)-Effort: wk9-01/wk9-03 score=8 (Priority 1)
- Drafted inclusive redesign brief targeting T2 validation error accessibility
- Proposed changes: role=alert for HTMX, tabindex=-1 + auto-focus for no-JS, aria-describedby linking
- Defined acceptance criteria: ‚â•90% completion, zero WCAG violations on retest

Key findings:
- T2 (Edit): 80% JS-on completion, 0% JS-off completion ‚Üí parity failure
- T2 error rate: 33% (blank submissions due to poor affordances)
- T1 (Filter): 100% completion but no-JS 71% slower (acceptable‚Äîfunctional parity maintained)

Ready for Week 10 Lab 2 implementation and verification.


EOF
)"
</code></pre>
<h3 id="reflection-questions-6"><a class="header" href="#reflection-questions-6">Reflection questions</a></h3>
<p><strong>Answer in <code>wk10/reflection.md</code></strong>:</p>
<ol>
<li>
<p><strong>Data interpretation</strong>: What surprised you most in the numbers? Were any findings unexpected based on Week 9 observations?</p>
</li>
<li>
<p><strong>Inclusion lens</strong>: How did the prioritisation framework change which issues you focused on? Would you have chosen differently without the Inclusion dimension?</p>
</li>
<li>
<p><strong>Trade-offs</strong>: Which issues did you deprioritise and why? How comfortable are you with those decisions?</p>
</li>
<li>
<p><strong>Redesign confidence</strong>: How confident are you that the proposed fix will achieve ‚â•90% completion? What uncertainties remain?</p>
</li>
<li>
<p><strong>Evidence chains</strong>: Can you trace wk9-01 from raw <code>metrics.csv</code> ‚Üí <code>analysis/summary.md</code> ‚Üí <code>prioritisation.csv</code> ‚Üí <code>redesign-brief.md</code>? Is anything missing?</p>
</li>
<li>
<p><strong>Week 10 Lab 2 readiness</strong>: What could go wrong during implementation? How will you mitigate?</p>
</li>
</ol>
<hr />
<h2 id="looking-ahead-week-10-lab-2"><a class="header" href="#looking-ahead-week-10-lab-2">Looking Ahead: Week 10 Lab 2</a></h2>
<p>Next session:</p>
<ul>
<li><strong>Implement</strong> Priority 1 fix (T2 validation error accessibility)</li>
<li><strong>Verify</strong> with 3 participants (SR, keyboard, no-JS)</li>
<li><strong>Measure</strong> completion rate, error rate, qualitative observations</li>
<li><strong>Update</strong> backlog with verification evidence</li>
<li><strong>Prepare</strong> assessment draft pack (before/after metrics, code diffs, evidence)</li>
</ul>
<p><strong>Before Lab 2</strong>:</p>
<ul>
<li>Review redesign brief (<code>wk10/lab-wk10/docs/redesign-brief.md</code>)</li>
<li>Refresh ARIA syntax (<code>role="alert"</code>, <code>aria-describedby</code>, <code>aria-live</code>)</li>
<li>Prepare verification pilot script (similar to Week 9 protocol)</li>
<li>Check that Week 9 data is committed (don‚Äôt lose baseline!)</li>
</ul>
<hr />
<h2 id="further-reading--resources-3"><a class="header" href="#further-reading--resources-3">Further Reading &amp; Resources</a></h2>
<h3 id="essential-3"><a class="header" href="#essential-3">Essential</a></h3>
<ul>
<li>Review <a href="wk10/../references/evaluation-metrics-quickref.html">Evaluation Metrics Quick Reference</a> (formulas reference)</li>
<li><a href="https://www.gov.uk/service-manual/measuring-success/using-data-to-improve-your-service">GOV.UK: Using data to improve your service</a></li>
</ul>
<h3 id="statistical-analysis"><a class="header" href="#statistical-analysis">Statistical Analysis</a></h3>
<ul>
<li><a href="https://measuringux.com/">Measuring UX</a> ‚Äî Quantitative UX metrics handbook</li>
<li><a href="https://hci-stats.com/">Statistics for HCI</a> ‚Äî Practical guide for small-sample HCI studies</li>
</ul>
<h3 id="prioritisation"><a class="header" href="#prioritisation">Prioritisation</a></h3>
<ul>
<li><a href="https://www.nngroup.com/articles/how-to-rate-the-severity-of-usability-problems/">Nielsen: Prioritising Web Usability Problems</a></li>
<li><a href="https://www.w3.org/WAI/test-evaluate/report/#prioritise">W3C: Prioritising Accessibility Issues</a></li>
<li><a href="https://www.gov.uk/service-manual/user-research/analyse-a-research-session#prioritise-findings">GOV.UK: Prioritising user research findings</a></li>
</ul>
<h3 id="inclusive-design"><a class="header" href="#inclusive-design">Inclusive Design</a></h3>
<ul>
<li><a href="https://www.microsoft.com/design/inclusive/">Microsoft Inclusive Design Toolkit</a></li>
<li><a href="https://www.w3.org/WAI/test-evaluate/involving-users/">W3C: Involving Users in Evaluating Web Accessibility</a></li>
</ul>
<h3 id="academic-1"><a class="header" href="#academic-1">Academic</a></h3>
<ul>
<li><strong>Lazar et al. (2017).</strong> <em>Research Methods in Human-Computer Interaction</em> (2nd ed.). Chapter 11: Statistical analysis</li>
<li><strong>Sauro &amp; Lewis (2016).</strong> <em>Quantifying the User Experience</em> (2nd ed.). Chapters 2-5: Metrics selection and interpretation</li>
</ul>
<hr />
<h2 id="glossary-summary-6"><a class="header" href="#glossary-summary-6">Glossary Summary</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Term</th><th>One-line definition</th></tr></thead><tbody>
<tr><td><strong>Descriptive statistics</strong></td><td>Summarize and describe main features of a dataset (median, range, count)</td></tr>
<tr><td><strong>Median</strong></td><td>Middle value in sorted dataset; 50th percentile; resistant to outliers</td></tr>
<tr><td><strong>MAD (Median Absolute Deviation)</strong></td><td>Robust measure of variability; median of</td></tr>
<tr><td><strong>Completion rate</strong></td><td>Proportion of task attempts that succeeded (effectiveness measure)</td></tr>
<tr><td><strong>Error rate</strong></td><td>Proportion of attempts that triggered validation errors</td></tr>
<tr><td><strong>Prioritisation framework</strong></td><td>Systematic method to rank backlog items by (Impact+Inclusion)-Effort</td></tr>
<tr><td><strong>Evidence chain</strong></td><td>Traceability from raw data ‚Üí analysis ‚Üí finding ‚Üí fix ‚Üí verification</td></tr>
<tr><td><strong>Impact</strong></td><td>How many people affected and how severely (1-5 scale)</td></tr>
<tr><td><strong>Inclusion</strong></td><td>Does issue disproportionately affect disabled people? (1-5 scale)</td></tr>
<tr><td><strong>Effort</strong></td><td>Time/complexity to implement fix (1-5 scale)</td></tr>
</tbody></table>
</div>
<hr />
<p><strong>Lab complete!</strong> You have data-driven insights, prioritised backlog, and a detailed redesign plan. Week 10 Lab 2 will implement and verify the fixes.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-10--lab-1--student-guide-analyse-metrics--prioritise-redesign"><a class="header" href="#week-10--lab-1--student-guide-analyse-metrics--prioritise-redesign">Week 10 ‚Ä¢ Lab 1 ‚Äî Student Guide: Analyse Metrics &amp; Prioritise Redesign</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-10-orange" alt="Week 10" />
<img src="https://img.shields.io/badge/Lab-1-green" alt="Lab 1" />
<img src="https://img.shields.io/badge/Type-Student_Guide-purple" alt="Guide" /></p>
<blockquote>
<p><strong>Purpose</strong>: Week 10 Lab 1 is about analysing your Week 9 pilot data, prioritising issues for redesign, and planning your Week 10 Lab 2 fixes.</p>
</blockquote>
<hr />
<h2 id="deliverables-4"><a class="header" href="#deliverables-4">Deliverables</a></h2>
<ul>
<li>‚úÖ <code>wk10/analysis/quantitative-summary.md</code> - Statistical analysis</li>
<li>‚úÖ <code>wk10/analysis/qualitative-themes.md</code> - Thematic coding</li>
<li>‚úÖ <code>wk10/redesign/priorities.md</code> - Prioritised redesign plan</li>
<li>‚úÖ Updated <code>backlog/backlog.csv</code> with Week 9 findings</li>
</ul>
<hr />
<h2 id="part-1-quantitative-analysis-30-minutes"><a class="header" href="#part-1-quantitative-analysis-30-minutes">Part 1: Quantitative Analysis (30 minutes)</a></h2>
<p><strong>Create</strong> <code>wk10/analysis/quantitative-summary.md</code>:</p>
<pre><code class="language-markdown"># Quantitative Analysis ‚Äî Week 10

## Task Success Rates
| Task | HTMX Success | No-JS Success | Overall |
|------|--------------|---------------|---------|
| T1: Filter &amp; Complete | 100% (3/3) | 100% (2/2) | 100% |
| T2: Add Task | 100% (3/3) | 100% (2/2) | 100% |
| T3: Edit Inline | 100% (3/3) | 50% (1/2) | 80% |
| T4: Delete | 100% (3/3) | 100% (2/2) | 100% |

**Interpretation**: T3 (edit inline) has 50% failure in no-JS mode. Priority issue.

## Mean Time-on-Task
[Add table]

## Error Rates
[Add table]

## Confidence Ratings
[Add table]

## Statistical Tests (if applicable)
- Mann-Whitney U test: HTMX vs No-JS times for T2
- Result: U = 2.5, p = 0.18 (not significant with n=5)
</code></pre>
<p><strong>Checklist</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Success rates calculated per task and mode</li>
<li><input disabled="" type="checkbox"/>
Mean times calculated</li>
<li><input disabled="" type="checkbox"/>
Error rates tallied</li>
<li><input disabled="" type="checkbox"/>
Confidence averages computed</li>
</ul>
<hr />
<h2 id="part-2-qualitative-themes-30-minutes"><a class="header" href="#part-2-qualitative-themes-30-minutes">Part 2: Qualitative Themes (30 minutes)</a></h2>
<p><strong>Create</strong> <code>wk10/analysis/qualitative-themes.md</code>:</p>
<pre><code class="language-markdown"># Qualitative Themes ‚Äî Week 10

## Theme 1: Confirmation Feedback Critical
**Frequency**: 4/5 participants
**Severity**: High
**Evidence**: [Quotes from pilot notes]
**Recommendation**: Add explicit success message in no-JS path

## Theme 2: Cancel Button Ambiguous
**Frequency**: 3/5
**Severity**: Medium
**Evidence**: [Quotes]
**Recommendation**: Change label to "Cancel (discard changes)"

## Theme 3: [Add more themes]
</code></pre>
<p><strong>Checklist</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
3-5 themes identified</li>
<li><input disabled="" type="checkbox"/>
Frequency and severity assigned</li>
<li><input disabled="" type="checkbox"/>
Evidence (quotes) linked</li>
<li><input disabled="" type="checkbox"/>
Recommendations listed</li>
</ul>
<hr />
<h2 id="part-3-prioritise-redesign-30-minutes"><a class="header" href="#part-3-prioritise-redesign-30-minutes">Part 3: Prioritise Redesign (30 minutes)</a></h2>
<p><strong>Create</strong> <code>wk10/redesign/priorities.md</code>:</p>
<pre><code class="language-markdown"># Redesign Priorities ‚Äî Week 10 Lab 2

## Priority 1: No Confirmation in No-JS (MUST FIX)
**Issue**: P3, P4 low confidence, had to verify task added
**Evidence**: `wk09/data/pilot-notes.md` L45-48, L89-92
**WCAG**: 4.1.3 Status Messages (AA)
**Fix**: Add success message to PRG redirect (query param or session flash)
**Effort**: 1-2 hours

## Priority 2: Edit Inline Fails in No-JS (MUST FIX)
**Issue**: P4 couldn't complete T3 in no-JS mode
**Evidence**: 50% failure rate
**WCAG**: 2.1.1 Keyboard (A) - parity required
**Fix**: Debug no-JS edit flow, ensure PRG works
**Effort**: 1 hour

## Priority 3: Cancel Button Label (SHOULD FIX)
**Issue**: 3/5 confused
**Evidence**: Hesitation, quotes
**WCAG**: 2.4.6 Headings and Labels (AA)
**Fix**: Change to "Cancel (discard changes)"
**Effort**: 10 minutes

## Deferred (Post-Assessment or Semester 2)
- Filter persistence across sessions
- Progress indicator
</code></pre>
<p><strong>Checklist</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
MUST FIX items identified (2-3 max for Lab 2 time)</li>
<li><input disabled="" type="checkbox"/>
SHOULD FIX items listed</li>
<li><input disabled="" type="checkbox"/>
Effort estimates provided</li>
<li><input disabled="" type="checkbox"/>
Deferred items noted</li>
</ul>
<hr />
<h2 id="commit--continue-8"><a class="header" href="#commit--continue-8">Commit &amp; Continue</a></h2>
<pre><code class="language-bash">git add wk10/
git commit -m "feat(wk10-lab1): analysis and redesign prioritisation

- Analysed quantitative data (success, times, errors, confidence)
- Identified 5 qualitative themes from pilot observations
- Prioritised 3 MUST FIX issues for Week 10 Lab 2
- Updated backlog with Week 9 findings

Ready for Week 10 Lab 2 redesign implementation."
</code></pre>
<p><strong>Next</strong>: Week 10 Lab 2 - Implement fixes, re-verify, package assessment.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-10--lab-2--inclusive-redesign-re-verification-task-2-packaging"><a class="header" href="#week-10--lab-2--inclusive-redesign-re-verification-task-2-packaging">Week 10 ‚Ä¢ Lab 2 ‚Äî Inclusive Redesign, Re-Verification, Task 2 Packaging</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-10-orange" alt="Week 10" />
<img src="https://img.shields.io/badge/Lab-2-green" alt="Lab 2" />
<img src="https://img.shields.io/badge/Status-Draft-yellow" alt="Status" /></p>
<hr />
<h2 id="before-lab-required-reading-10-mins-1"><a class="header" href="#before-lab-required-reading-10-mins-1">Before Lab: Required Reading (10 mins)</a></h2>
<p>üìñ <strong>Essential</strong></p>
<ul>
<li>Review your redesign brief (<code>wk10/lab-wk10/docs/redesign-brief.md</code>)</li>
<li>Review <a href="wk10/../references/assistive-testing-checklist.html">Assistive Testing Checklist</a></li>
<li>Skim the <a href="wk10/../references/screenshot-guide.html">Screenshot Evidence Guide</a></li>
<li><a href="https://www.w3.org/WAI/WCAG22/quickref/">WCAG 2.2 Quick Reference</a> (sections 3.3, 4.1)</li>
</ul>
<p>üìñ <strong>Contextual</strong>:</p>
<ul>
<li><a href="https://webaim.org/techniques/forms/">WebAIM: Creating Accessible Forms</a></li>
<li><a href="https://www.gov.uk/service-manual/helping-people-to-use-your-service/making-your-service-accessible-an-introduction">GOV.UK: Making your service accessible</a></li>
</ul>
<hr />
<h2 id="introduction-from-plan-to-implementation"><a class="header" href="#introduction-from-plan-to-implementation">Introduction: From Plan to Implementation</a></h2>
<p>Week 10 Lab 1 identified Priority 1 fixes through data analysis. <strong>Today you implement and verify those fixes</strong>.</p>
<p><strong>This lab is where HCI theory becomes practice</strong>:</p>
<ul>
<li><strong>Implementation</strong>: Server-first code + HTMX enhancements</li>
<li><strong>Verification</strong>: Rigorous accessibility testing (keyboard, SR, no-JS)</li>
<li><strong>Measurement</strong>: Before/after metrics proving improvement</li>
<li><strong>Documentation</strong>: Evidence chains for assessment</li>
</ul>
<p><strong>Why this matters</strong>:</p>
<ul>
<li><strong>assessment</strong>: Requires before/after metrics + code changes + verification evidence</li>
<li><strong>assessment portfolio (due end Week 10)</strong>: This fix becomes a case study (problem ‚Üí data ‚Üí fix ‚Üí verification)</li>
<li><strong>Professional practice</strong>: Inclusive design is iterative‚Äîimplement, test, measure, refine</li>
</ul>
<p><strong>Quality bar</strong>: Changes must improve accessibility <strong>without breaking existing functionality</strong>. Regression testing is critical.</p>
<hr />
<h2 id="learning-focus-9"><a class="header" href="#learning-focus-9">Learning Focus</a></h2>
<h3 id="lab-objectives-9"><a class="header" href="#lab-objectives-9">Lab Objectives</a></h3>
<p>By the end of this session, you will have:</p>
<ul>
<li>Implemented top 3 prioritised fixes (WCAG 2.2 AA)</li>
<li>Run regression testing (axe + manual keyboard, SR, no-JS)</li>
<li>Re-piloted with n=2 to verify improvements</li>
<li>Measured post-change metrics and compared to baseline</li>
<li>Documented evidence chains (code diffs, screenshots, metrics)</li>
<li>Packaged assessment submission with before/after data</li>
</ul>
<h3 id="learning-outcomes-addressed-9"><a class="header" href="#learning-outcomes-addressed-9">Learning Outcomes Addressed</a></h3>
<p>This lab contributes to the following module Learning Outcomes (<a href="wk10/../references/learning-outcomes.html">full definitions</a>):</p>
<ul>
<li><strong>LO4</strong>: Evaluate for accessibility ‚Äî evidenced by regression testing</li>
<li><strong>LO6</strong>: Apply iterative design ‚Äî evidenced by redesign ‚Üí re-verification cycle</li>
<li><strong>LO9</strong>: Apply inclusive design ‚Äî evidenced by WCAG-compliant redesign</li>
<li><strong>LO12</strong>: Demonstrate professionalism ‚Äî evidenced by evidence chains in documentation
Maps to WCAG: 2.2 AA (demonstrable compliance)</li>
</ul>
<hr />
<h2 id="key-concepts-8"><a class="header" href="#key-concepts-8">Key Concepts</a></h2>
<h3 id="regression-testing"><a class="header" href="#regression-testing">Regression Testing</a></h3>
<blockquote>
<p><strong>Regression Testing</strong> [GLOSSARY]</p>
<p>Verifying that new changes don‚Äôt break existing functionality. Critical when fixing accessibility issues.</p>
<p><strong>HCI context</strong>: Fixing one accessibility issue can inadvertently break another. Example:</p>
<ul>
<li>Fix: Add <code>role="alert"</code> to error messages (helps SR users)</li>
<li>Regression: Alert interrupts SR navigation mid-task (too assertive)</li>
<li>Solution: Use <code>aria-live="polite"</code> instead</li>
</ul>
<p><strong>Regression checklist covers</strong>:</p>
<ul>
<li>Keyboard navigation (tab order, focus indicators)</li>
<li>Screen reader announcements (live regions, labels)</li>
<li>No-JS parity (functionality without JavaScript)</li>
<li>Visual rendering (contrast, zoom, reflow)</li>
</ul>
<p><strong>Best practice</strong>: Test with same protocol used in Week 9 pilots‚Äîensures comparability.</p>
<p>üîó <a href="https://www.w3.org/WAI/test-evaluate/combined-expertise/">W3C: Regression Testing for Accessibility</a></p>
</blockquote>
<h3 id="beforeafter-metrics"><a class="header" href="#beforeafter-metrics">Before/After Metrics</a></h3>
<blockquote>
<p><strong>Before/After Metrics</strong> [GLOSSARY]</p>
<p>Quantitative comparison showing improvement from intervention. Core of evidence-based HCI.</p>
<p><strong>Requirement</strong>: Baseline (Week 9) + post-change (Week 10 Lab 2) measured identically.</p>
<p><strong>Example</strong>:</p>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>Before</th><th>After</th><th>Œî</th><th>Interpretation</th></tr></thead><tbody>
<tr><td>T2 completion (no-JS)</td><td>50%</td><td>100%</td><td>+50%</td><td>Fix restored parity</td></tr>
<tr><td>T2 error rate</td><td>33%</td><td>10%</td><td>-23%</td><td>Improved affordances</td></tr>
<tr><td>T2 median time (all)</td><td>1400ms</td><td>1250ms</td><td>-150ms</td><td>Faster (less confusion)</td></tr>
</tbody></table>
</div>
<p><strong>HCI connection</strong>: Before/after metrics demonstrate <strong>measurable impact</strong>‚Äînot just ‚Äúwe fixed it‚Äù but ‚Äúcompletion improved by 50%.‚Äù</p>
<p><strong>assessment requires</strong>: Table + narrative explaining significance (who benefits, why it matters).</p>
<p>üîó <a href="https://measuringux.com/before-after/">Measuring UX: Before/After Studies</a></p>
</blockquote>
<h3 id="accessible-error-handling"><a class="header" href="#accessible-error-handling">Accessible Error Handling</a></h3>
<blockquote>
<p><strong>Accessible Error Handling</strong> [GLOSSARY]</p>
<p>Validation errors must be perceivable, understandable, and recoverable for all participants.</p>
<p><strong>WCAG requirements</strong>:</p>
<ul>
<li><strong>3.3.1 Error Identification (A)</strong>: Errors identified in text and programmatically determinable</li>
<li><strong>3.3.3 Error Suggestion (AA)</strong>: Provide correction suggestions when known</li>
<li><strong>4.1.3 Status Messages (AA)</strong>: Messages announced without focus change</li>
</ul>
<p><strong>Best practices</strong>:</p>
<ul>
<li><strong>Inline errors</strong>: <code>aria-describedby</code> links input to error message</li>
<li><strong>Summary errors</strong>: Page-level alert with links to problem fields</li>
<li><strong>Live regions</strong>: <code>role="alert"</code> for HTMX, <code>aria-live="assertive"</code> for critical errors</li>
<li><strong>Focus management</strong>: Move focus to error summary (no-JS) or keep on input (HTMX)</li>
</ul>
<p><strong>Example (HTMX)</strong>:</p>
<pre><code class="language-html">&lt;!-- OOB status update --&gt;
&lt;div id="status" role="alert" aria-live="assertive" hx-swap-oob="true"&gt;
  Title is required. Please enter at least one character.
&lt;/div&gt;
</code></pre>
<p><strong>Example (no-JS)</strong>:</p>
<pre><code class="language-html">&lt;!-- Error summary at top of page --&gt;
&lt;div id="error-summary" role="alert" tabindex="-1"&gt;
  &lt;h2&gt;There is a problem&lt;/h2&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href="#title"&gt;Title is required&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/div&gt;
&lt;!-- Input with aria-describedby --&gt;
&lt;input id="title" aria-invalid="true" aria-describedby="title-error"&gt;
&lt;p id="title-error"&gt;Title is required. Please enter at least one character.&lt;/p&gt;
</code></pre>
<p>üîó <a href="https://design-system.service.gov.uk/components/error-message/">GOV.UK: Error Message Pattern</a></p>
</blockquote>
<h3 id="code-diffs-for-evidence"><a class="header" href="#code-diffs-for-evidence">Code Diffs for Evidence</a></h3>
<blockquote>
<p><strong>Code Diffs</strong> [GLOSSARY]</p>
<p>Side-by-side comparison showing what changed. Essential for assessment evidence.</p>
<p><strong>Format</strong>:</p>
<pre><code class="language-diff">- &lt;div id="status" hx-swap-oob="true"&gt;Title is required.&lt;/div&gt;
+ &lt;div id="status" role="alert" aria-live="assertive" hx-swap-oob="true"&gt;
+   Title is required. Please enter at least one character.
+ &lt;/div&gt;
</code></pre>
<p><strong>What to include</strong>:</p>
<ul>
<li>File path (e.g., <code>src/main/kotlin/routes/Tasks.kt:45</code>)</li>
<li>Before/after code (3-5 lines context)</li>
<li>Brief explanation of change and WCAG impact</li>
</ul>
<p><strong>Generate automatically</strong>:</p>
<pre><code class="language-bash">git diff wk9-baseline..HEAD -- templates/ &gt; wk10/assessment/04-key-diffs.md
</code></pre>
<p><strong>HCI connection</strong>: Diffs make fixes <strong>transparent and reproducible</strong>‚Äîassessors and peers can see exactly what changed.</p>
<p>üîó <a href="https://git-scm.com/docs/git-diff">Git: Generating Diffs</a></p>
</blockquote>
<hr />
<h2 id="activity-a-implement-priority-1-fix-40-min"><a class="header" href="#activity-a-implement-priority-1-fix-40-min">Activity A: Implement Priority 1 Fix (40 min)</a></h2>
<p><strong>Goal</strong>: Execute redesign plan from Week 10 Lab 1 brief.</p>
<h3 id="step-1-review-redesign-brief-5-min"><a class="header" href="#step-1-review-redesign-brief-5-min">Step 1: Review redesign brief (5 min)</a></h3>
<p>Open <code>wk10/lab-wk10/docs/redesign-brief.md</code> and confirm:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Problem statement clear (backed by Week 9 data)</li>
<li><input disabled="" type="checkbox"/>
Proposed changes specific (file paths, before/after code)</li>
<li><input disabled="" type="checkbox"/>
Acceptance criteria measurable</li>
<li><input disabled="" type="checkbox"/>
Verification plan defined</li>
</ul>
<p><strong>Assign roles</strong> (if pair programming):</p>
<ul>
<li><strong>Driver</strong>: Writes code</li>
<li><strong>Navigator</strong>: Reviews changes, runs tests, checks against brief</li>
</ul>
<p><strong>Swap after 20 min</strong>.</p>
<h3 id="step-2-implement-server-side-changes-15-min"><a class="header" href="#step-2-implement-server-side-changes-15-min">Step 2: Implement server-side changes (15 min)</a></h3>
<p><strong>Example: T2 edit validation error accessibility</strong></p>
<p><strong>File</strong>: <code>src/main/kotlin/routes/Tasks.kt</code></p>
<p><strong>Before</strong> (Week 9 baseline):</p>
<pre><code class="language-kotlin">post("/tasks/{id}/edit") {
    val id = call.parameters["id"]?.toIntOrNull() ?: return@post call.respond(HttpStatusCode.BadRequest)
    val title = call.receiveParameters()["title"].orEmpty().trim()

    if (title.isBlank()) {
        if (call.isHtmx()) {
            val status = """&lt;div id="status" hx-swap-oob="true"&gt;Title is required.&lt;/div&gt;"""
            return@post call.respondText(status, ContentType.Text.Html, HttpStatusCode.BadRequest)
        } else {
            return@post call.respondRedirect("/tasks/{id}/edit?error=title")
        }
    }

    // Success path...
}
</code></pre>
<p><strong>After</strong> (Week 10 fix):</p>
<pre><code class="language-kotlin">post("/tasks/{id}/edit") {
    val id = call.parameters["id"]?.toIntOrNull() ?: return@post call.respond(HttpStatusCode.BadRequest)
    val title = call.receiveParameters()["title"].orEmpty().trim()

    if (title.isBlank()) {
        if (call.isHtmx()) {
            // CHANGE: Added role="alert" + aria-live="assertive" for SR announcement
            val status = """&lt;div id="status" role="alert" aria-live="assertive" hx-swap-oob="true"&gt;
                Title is required. Please enter at least one character.
            &lt;/div&gt;"""
            return@post call.respondText(status, ContentType.Text.Html, HttpStatusCode.BadRequest)
        } else {
            // CHANGE: Redirect to edit page with error param (focus handled in template)
            return@post call.respondRedirect("/tasks?error=title&amp;edit_id=$id")
        }
    }

    // Success path unchanged
    repo.update(id, title)
    if (call.isHtmx()) {
        val item = PebbleRender.render("tasks/_item.peb", mapOf("t" to repo.get(id)))
        val status = """&lt;div id="status" role="status" aria-live="polite" hx-swap-oob="true"&gt;
            Updated "${repo.get(id)?.title}".
        &lt;/div&gt;"""
        call.respondText(item + status, ContentType.Text.Html)
    } else {
        call.respondRedirect("/tasks")
    }
}
</code></pre>
<p><strong>Key changes</strong>:</p>
<ol>
<li><strong>HTMX error</strong>: Added <code>role="alert"</code> + <code>aria-live="assertive"</code> ‚Üí SR announces immediately</li>
<li><strong>HTMX success</strong>: Changed to <code>role="status"</code> + <code>aria-live="polite"</code> ‚Üí less intrusive</li>
<li><strong>No-JS error</strong>: Redirect includes <code>edit_id</code> ‚Üí template can focus correct field</li>
</ol>
<h3 id="step-3-implement-template-changes-15-min"><a class="header" href="#step-3-implement-template-changes-15-min">Step 3: Implement template changes (15 min)</a></h3>
<p><strong>File</strong>: <code>templates/tasks/index.peb</code></p>
<p><strong>Add error summary</strong> (for no-JS path):</p>
<pre><code class="language-twig">{% if error %}
&lt;div id="error-summary" class="error-summary" role="alert" aria-live="assertive" tabindex="-1"&gt;
  &lt;h2&gt;There is a problem&lt;/h2&gt;
  &lt;ul&gt;
    {% if error == "title" %}
    &lt;li&gt;&lt;a href="#title"&gt;Title is required. Please enter at least one character.&lt;/a&gt;&lt;/li&gt;
    {% endif %}
  &lt;/ul&gt;
&lt;/div&gt;
&lt;script&gt;
  // Progressive enhancement: auto-focus error summary
  // Works even if JS loaded late; gracefully degrades if JS disabled after page load
  (function() {
    var errorSummary = document.getElementById('error-summary');
    if (errorSummary) {
      errorSummary.focus();
    }
  })();
&lt;/script&gt;
{% endif %}
</code></pre>
<p><strong>Update form input</strong> (link to error):</p>
<pre><code class="language-twig">&lt;label for="title"&gt;Task title&lt;/label&gt;
&lt;input id="title" name="title" type="text"
       {% if error == "title" %}
       aria-invalid="true"
       aria-describedby="title-hint title-error"
       {% else %}
       aria-describedby="title-hint"
       {% endif %}
       required&gt;

&lt;p id="title-hint" class="hint"&gt;Keep titles short and specific.&lt;/p&gt;

{% if error == "title" %}
&lt;p id="title-error" class="error-message" role="alert"&gt;
  Title is required. Please enter at least one character.
&lt;/p&gt;
{% endif %}
</code></pre>
<p><strong>Key changes</strong>:</p>
<ol>
<li><strong>Error summary</strong>: <code>role="alert"</code> + <code>tabindex="-1"</code> + auto-focus script</li>
<li><strong>Input</strong>: <code>aria-invalid="true"</code> when error present</li>
<li><strong>aria-describedby</strong>: Links input to both hint and error</li>
<li><strong>Inline error</strong>: <code>role="alert"</code> for immediate announcement</li>
</ol>
<h3 id="step-4-test-manually-5-min"><a class="header" href="#step-4-test-manually-5-min">Step 4: Test manually (5 min)</a></h3>
<p><strong>Start server</strong>: <code>./gradlew run</code></p>
<p><strong>Test HTMX path</strong>:</p>
<ol>
<li>Navigate to <code>/tasks</code></li>
<li>Click Edit on a task</li>
<li>Clear title field, click Save</li>
<li><strong>Expected</strong>: Status message appears immediately (‚ÄúTitle is required‚Ä¶‚Äù)</li>
<li><strong>Verify with SR</strong> (if available): Message should be announced without focus change</li>
</ol>
<p><strong>Test no-JS path</strong>:</p>
<ol>
<li>Disable JavaScript (DevTools ‚Üí Settings ‚Üí Disable JavaScript)</li>
<li>Hard refresh (Ctrl+Shift+R)</li>
<li>Click Edit on a task</li>
<li>Clear title, click Save</li>
<li><strong>Expected</strong>: Page reloads with error summary at top, summary has focus (visible outline)</li>
<li><strong>Verify</strong>: Tab order ‚Üí error summary link ‚Üí click link ‚Üí focus lands on <code>#title</code> input</li>
</ol>
<p><strong>Test keyboard</strong>:</p>
<ol>
<li>Tab through entire flow (Edit ‚Üí clear ‚Üí submit ‚Üí error summary ‚Üí error link ‚Üí input)</li>
<li><strong>Verify</strong>: All elements reachable, focus visible, no keyboard traps</li>
</ol>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
HTMX error path works (status appears, SR announces)</li>
<li><input disabled="" type="checkbox"/>
No-JS error path works (summary focused, link navigates to input)</li>
<li><input disabled="" type="checkbox"/>
Keyboard navigation smooth (no traps, focus visible)</li>
<li><input disabled="" type="checkbox"/>
No console errors</li>
</ul>
<hr />
<h2 id="activity-b-run-regression-checklist-20-min"><a class="header" href="#activity-b-run-regression-checklist-20-min">Activity B: Run Regression Checklist (20 min)</a></h2>
<p><strong>Goal</strong>: Verify fix didn‚Äôt break existing functionality or introduce new accessibility issues.</p>
<h3 id="step-1-download-regression-checklist-2-min"><a class="header" href="#step-1-download-regression-checklist-2-min">Step 1: Download regression checklist (2 min)</a></h3>
<p><strong>Create <code>wk10/lab-wk10/a11y/regression-checklist.csv</code></strong>:</p>
<pre><code class="language-csv">category,check,pass,notes
Keyboard,All interactive elements reachable with Tab,,
Keyboard,Focus order matches visual order,,
Keyboard,Focus indicators visible on all elements,,
Keyboard,No keyboard traps,,
Keyboard,Skip link functional,,
Screen Reader,All form labels announced,,
Screen Reader,Error messages announced (role=alert),,
Screen Reader,Success messages announced (role=status),,
Screen Reader,Live regions working (filter results count etc),,
Screen Reader,Headings navigable (H key in NVDA/Orca),,
Forms,Errors identified in text,,
Forms,Errors linked to inputs (aria-describedby),,
Forms,aria-invalid set when error present,,
Forms,Error suggestions provided (when applicable),,
No-JS,All tasks completable with JS disabled,,
No-JS,Error summary focusable and keyboard-navigable,,
No-JS,PRG pattern working (refresh doesn't duplicate),,
No-JS,Full page renders vs fragments (correct responses),,
Visual,Contrast meets WCAG AA (4.5:1 text),,
Visual,200% zoom: no horizontal scroll,,
Visual,Error messages visible (not colour-only),,
Visual,Focus indicators meet contrast requirements,,
</code></pre>
<h3 id="step-2-execute-checklist-15-min"><a class="header" href="#step-2-execute-checklist-15-min">Step 2: Execute checklist (15 min)</a></h3>
<p><strong>Work through each row systematically</strong>:</p>
<p><strong>Keyboard testing</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Tab from skip link ‚Üí forms ‚Üí buttons ‚Üí tasks ‚Üí pagination</li>
<li><input disabled="" type="checkbox"/>
Shift+Tab reverses order</li>
<li><input disabled="" type="checkbox"/>
Enter activates links/buttons, Space toggles checkboxes</li>
<li><input disabled="" type="checkbox"/>
Escape closes modals (if any)</li>
<li><input disabled="" type="checkbox"/>
Focus visible on all stops (blue outline or similar)</li>
</ul>
<p><strong>Screen reader testing</strong> (NVDA Windows / Orca Linux):</p>
<ul>
<li><input disabled="" type="checkbox"/>
Navigate headings with H key ‚Üí hears ‚ÄúTasks‚Äù, ‚ÄúAdd Task‚Äù, etc.</li>
<li><input disabled="" type="checkbox"/>
Forms mode (F key) ‚Üí lands on first input</li>
<li><input disabled="" type="checkbox"/>
Error submission ‚Üí hears ‚ÄúAlert. Title is required‚Ä¶‚Äù</li>
<li><input disabled="" type="checkbox"/>
Success submission ‚Üí hears ‚ÄúUpdated [title]‚Äù (or similar)</li>
<li><input disabled="" type="checkbox"/>
Filter results ‚Üí hears ‚ÄúShowing 3 tasks‚Äù (if live region present)</li>
</ul>
<p><strong>No-JS testing</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Disable JS, hard refresh</li>
<li><input disabled="" type="checkbox"/>
Add task ‚Üí works (PRG redirect)</li>
<li><input disabled="" type="checkbox"/>
Submit blank form ‚Üí error summary appears and focused</li>
<li><input disabled="" type="checkbox"/>
Click error link ‚Üí focus moves to input</li>
<li><input disabled="" type="checkbox"/>
Edit task ‚Üí works (full page reload)</li>
<li><input disabled="" type="checkbox"/>
Delete task ‚Üí works (no confirmation expected‚Äîdocumented trade-off)</li>
</ul>
<p><strong>Visual testing</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Use contrast checker (DevTools ‚Üí CSS Overview or extension)</li>
<li><input disabled="" type="checkbox"/>
Zoom to 200% (Ctrl/Cmd + plus) ‚Üí no horizontal scroll</li>
<li><input disabled="" type="checkbox"/>
Error states visible without colour (text, icons, position)</li>
</ul>
<h3 id="step-3-document-results-3-min"><a class="header" href="#step-3-document-results-3-min">Step 3: Document results (3 min)</a></h3>
<p><strong>Fill in <code>pass</code> column</strong>: <code>yes</code>, <code>no</code>, <code>n/a</code></p>
<p><strong>Fill in <code>notes</code> column</strong> for failures or concerns:</p>
<p><strong>Example</strong>:</p>
<pre><code class="language-csv">category,check,pass,notes
Screen Reader,Error messages announced (role=alert),yes,"NVDA announces immediately after submit"
No-JS,Error summary focusable and keyboard-navigable,yes,"Focus indicator visible, Tab order correct"
Visual,Focus indicators meet contrast requirements,no,"Blue outline has 2.8:1 contrast‚Äîneeds 3:1. Log backlog item wk10-07"
</code></pre>
<p><strong>If failures found</strong>:</p>
<ul>
<li><strong>Critical</strong> (blocks task completion): Fix immediately before proceeding</li>
<li><strong>High</strong> (accessibility barrier): Log backlog item, document in notes</li>
<li><strong>Medium/Low</strong>: Acceptable if documented in constraints/known issues</li>
</ul>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Regression checklist complete (all rows filled)</li>
<li><input disabled="" type="checkbox"/>
No critical failures (or fixed)</li>
<li><input disabled="" type="checkbox"/>
Evidence captured (screenshots if needed for failures)</li>
</ul>
<hr />
<h2 id="activity-c-collect-post-change-metrics-25-min"><a class="header" href="#activity-c-collect-post-change-metrics-25-min">Activity C: Collect Post-Change Metrics (25 min)</a></h2>
<p><strong>Goal</strong>: Run targeted pilots to measure improvement.</p>
<h3 id="step-1-prepare-verification-pilots-5-min"><a class="header" href="#step-1-prepare-verification-pilots-5-min">Step 1: Prepare verification pilots (5 min)</a></h3>
<p><strong>Minimal protocol</strong> (adapted from Week 9):</p>
<ul>
<li><strong>n=3 participants</strong> (yourself + 2 peers, or 3 quick runs with different variants)</li>
<li><strong>Focus on changed task</strong> (T2 edit in our example)</li>
<li><strong>Variants</strong>: 1√ó standard (HTMX), 1√ó keyboard/SR, 1√ó no-JS</li>
</ul>
<p><strong>Generate session IDs</strong>:</p>
<pre><code class="language-bash"># P6: Standard (HTMX, JS-on)
# P7: Keyboard + NVDA (SR)
# P8: No-JS
</code></pre>
<p><strong>Set cookies</strong>:</p>
<pre><code class="language-javascript">document.cookie = "sid=P6_post; path=/";
</code></pre>
<h3 id="step-2-run-verification-pilots-15-min"><a class="header" href="#step-2-run-verification-pilots-15-min">Step 2: Run verification pilots (15 min)</a></h3>
<p><strong>For each participant</strong>:</p>
<ol>
<li>Read consent (quick version: ‚ÄúTesting post-fix, ~5 min, can stop anytime‚Äù)</li>
<li>Navigate to <code>/tasks</code></li>
<li>Run T2 (Edit task): ‚ÄúChange ‚ÄòSubmit invoices‚Äô to ‚ÄòSubmit invoices by Friday‚Äô‚Äù</li>
<li><strong>Intentionally trigger error</strong> once (submit blank) to test error handling</li>
<li>Then complete successfully</li>
<li>Note completion (yes/no), errors (count), time (from logs), confidence (1-5)</li>
</ol>
<p><strong>Example pilot P7 (keyboard + SR)</strong>:</p>
<pre><code>P7_post (NVDA, keyboard-only):
- T2 attempt 1: Blank submission ‚Üí Error announced "Alert. Title is required..." ‚úì
- T2 attempt 2: Success ‚Üí "Updated Submit invoices by Friday" announced ‚úì
- Completion: yes
- Errors: 1 (intentional blank)
- Time: 1356ms (from metrics.csv)
- Confidence: 5
- Notes: "Error was clear this time, heard it immediately"
</code></pre>
<h3 id="step-3-analyse-post-change-data-5-min"><a class="header" href="#step-3-analyse-post-change-data-5-min">Step 3: Analyse post-change data (5 min)</a></h3>
<p><strong>Open <code>data/metrics.csv</code></strong>, filter for session IDs <code>P6_post</code>, <code>P7_post</code>, <code>P8_post</code>.</p>
<p><strong>Calculate same metrics as Week 9</strong>:</p>
<ul>
<li>Completion rate: 3/3 = 100% ‚úì (was 80% JS-on, 0% JS-off)</li>
<li>Error rate: 1/4 attempts = 25% (was 33%‚Äîslight improvement)</li>
<li>Median time (success only): median([1356, 1289, 3201]) = 1356ms
<ul>
<li>JS-on: 1322ms (was 1400ms‚Äîfaster)</li>
<li>JS-off: 3201ms (was N/A‚Äînow functional!)</li>
</ul>
</li>
</ul>
<p><strong>Update <code>analysis/summary.md</code></strong>:</p>
<pre><code class="language-markdown">## Before/After Comparison

### Task T2 (Edit Task)

| Metric | Before (Week 9) | After (Week 10) | Œî | Interpretation |
|--------|-----------------|-----------------|---|----------------|
| Completion (JS-on) | 4/5 (80%) | 2/2 (100%) | +20% | All participants succeeded |
| Completion (JS-off) | 0/1 (0%) | 1/1 (100%) | +100% | **Parity restored** |
| Completion (all) | 4/6 (67%) | 3/3 (100%) | +33% | Fix eliminated failures |
| Error rate (all) | 2/6 (33%) | 1/4 (25%) | -8% | Improved affordances |
| Median time (JS-on) | 1400ms | 1322ms | -78ms | Slightly faster (less confusion) |
| Median time (JS-off) | N/A | 3201ms | ‚Äî | Functional (expected slower) |

### Key Improvements

**Accessibility**:
- Screen reader users: Error messages now announced immediately (`role="alert"`)
- Keyboard-only users: Error summary keyboard-navigable (`tabindex="-1"`, auto-focus)
- No-JS users: Can now complete task (was blocked before)

**WCAG Compliance**:
- ‚úÖ 3.3.1 Error Identification (Level A): Errors identified in text and programmatically
- ‚úÖ 4.1.3 Status Messages (Level AA): Validation errors announced without focus change
- ‚úÖ 3.2.1 On Focus (Level A): Focus managed predictably (error summary ‚Üí input)

**Impact**:
- **Who benefits**: Estimated 2-5% UK population (SR users) + keyboard-only + no-JS users
- **Severity**: High ‚Üí Resolved (task was previously impossible for no-JS, difficult for SR)
</code></pre>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Post-change metrics collected (n=3 minimum)</li>
<li><input disabled="" type="checkbox"/>
Before/after comparison table complete</li>
<li><input disabled="" type="checkbox"/>
Narrative interpretation written</li>
<li><input disabled="" type="checkbox"/>
Evidence captured (SR transcript, screenshots)</li>
</ul>
<hr />
<h2 id="activity-d-package-assessment-evidence-bundle-20-min"><a class="header" href="#activity-d-package-assessment-evidence-bundle-20-min">Activity D: Package assessment Evidence Bundle (20 min)</a></h2>
<p><strong>Goal</strong>: Assemble all artefacts for Gradescope submission.</p>
<p><strong>Directory structure</strong>: <code>wk10/assessment/</code></p>
<h3 id="step-1-copycreate-core-documents-10-min"><a class="header" href="#step-1-copycreate-core-documents-10-min">Step 1: Copy/create core documents (10 min)</a></h3>
<p><strong>1. <code>01-redesign-brief.md</code></strong>:</p>
<ul>
<li>Copy from <code>wk10/lab-wk10/docs/redesign-brief.md</code></li>
<li>Update ‚ÄúSuccess Criteria Summary‚Äù section with actual results</li>
</ul>
<p><strong>2. <code>02-regression-checklist.csv</code></strong>:</p>
<ul>
<li>Copy from <code>wk10/lab-wk10/a11y/regression-checklist.csv</code></li>
<li>Ensure all rows filled with pass/notes</li>
</ul>
<p><strong>3. <code>03-before-after-summary.md</code></strong>:</p>
<ul>
<li>Copy before/after table from <code>analysis/summary.md</code></li>
<li>Add 2-3 paragraph narrative:
<ul>
<li>What changed (code + UX)</li>
<li>Who benefits (inclusion impact)</li>
<li>Evidence of improvement (completion +33%, parity restored)</li>
</ul>
</li>
</ul>
<p><strong>Example</strong>:</p>
<pre><code class="language-markdown"># Before/After Summary ‚Äî Task 2

## Problem Addressed

Task T2 (Edit Task) had 67% overall completion in Week 9 pilots, with 0% completion for no-JS participants. Root cause: validation errors not accessible to screen readers or keyboard users.

## Solution Implemented

Added accessible error handling:
- HTMX: `role="alert"` + `aria-live="assertive"` for immediate SR announcement
- No-JS: Error summary with `tabindex="-1"` + auto-focus on page load
- Both: `aria-describedby` linking inputs to error messages

## Results

[Insert before/after table from Activity C]

## Impact

Fix restored functional parity for no-JS users (0% ‚Üí 100% completion) and improved accessibility for screen reader and keyboard-only users. WCAG 2.2 Level AA compliance achieved (3.3.1, 4.1.3, 3.2.1).
</code></pre>
<p><strong>4. <code>04-key-diffs.md</code></strong>:</p>
<p>Generate code diffs:</p>
<pre><code class="language-bash">git diff wk9-baseline..HEAD -- templates/tasks/index.peb src/main/kotlin/routes/Tasks.kt &gt; wk10/assessment/04-key-diffs.md
</code></pre>
<p>Annotate with explanations:</p>
<pre><code class="language-markdown"># Key Code Changes ‚Äî Task 2

## File: `src/main/kotlin/routes/Tasks.kt` (Line 45)

### Before
```kotlin
val status = """&lt;div id="status" hx-swap-oob="true"&gt;Title is required.&lt;/div&gt;"""
</code></pre>
<h3 id="after"><a class="header" href="#after">After</a></h3>
<pre><code class="language-kotlin">val status = """&lt;div id="status" role="alert" aria-live="assertive" hx-swap-oob="true"&gt;
    Title is required. Please enter at least one character.
&lt;/div&gt;"""
</code></pre>
<p><strong>Change</strong>: Added <code>role="alert"</code> + <code>aria-live="assertive"</code></p>
<p><strong>Rationale</strong>: Ensures screen readers announce validation errors immediately without focus change (WCAG 4.1.3 Status Messages).</p>
<hr />
<h2 id="file-templatestasksindexpeb-line-23"><a class="header" href="#file-templatestasksindexpeb-line-23">File: <code>templates/tasks/index.peb</code> (Line 23)</a></h2>
<h3 id="before"><a class="header" href="#before">Before</a></h3>
<pre><code class="language-twig">{% if error %}
&lt;div class="alert"&gt;Could not save&lt;/div&gt;
{% endif %}
</code></pre>
<h3 id="after-1"><a class="header" href="#after-1">After</a></h3>
<pre><code class="language-twig">{% if error %}
&lt;div id="error-summary" class="error-summary" role="alert" aria-live="assertive" tabindex="-1"&gt;
  &lt;h2&gt;There is a problem&lt;/h2&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href="#title"&gt;Title is required. Please enter at least one character.&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/div&gt;
&lt;script&gt;
  (function() {
    var errorSummary = document.getElementById('error-summary');
    if (errorSummary) { errorSummary.focus(); }
  })();
&lt;/script&gt;
{% endif %}
</code></pre>
<p><strong>Changes</strong>:</p>
<ol>
<li>Structured error summary (heading + list of errors)</li>
<li><code>tabindex="-1"</code> makes div focusable programmatically</li>
<li>Auto-focus script (progressive enhancement)</li>
<li><code>role="alert"</code> announces to SR on page load</li>
</ol>
<p><strong>Rationale</strong>: No-JS users can now navigate to error summary with keyboard, fixing 0% completion rate (WCAG 3.3.1, 3.2.1).</p>
<pre><code>
### Step 2: Collect evidence artefacts (5 min)

**Create `05-evidence/` directory**:

</code></pre>
<p>wk10/assessment/05-evidence/
‚îú‚îÄ‚îÄ screenshots/
‚îÇ   ‚îú‚îÄ‚îÄ before-htmx-error.png (no role=alert visible in devtools)
‚îÇ   ‚îú‚îÄ‚îÄ after-htmx-error.png (role=alert visible)
‚îÇ   ‚îú‚îÄ‚îÄ before-nojs-error.png (error present but not focused)
‚îÇ   ‚îú‚îÄ‚îÄ after-nojs-error.png (error summary with focus outline)
‚îÇ   ‚îî‚îÄ‚îÄ annotations.md
‚îú‚îÄ‚îÄ sr-transcripts/
‚îÇ   ‚îú‚îÄ‚îÄ before-nvda.txt (‚ÄúTitle is required‚Äù not announced)
‚îÇ   ‚îî‚îÄ‚îÄ after-nvda.txt (‚ÄúAlert. Title is required‚Ä¶‚Äù announced)
‚îî‚îÄ‚îÄ metrics/
‚îú‚îÄ‚îÄ before-analysis.csv (copy of Week 9 analysis.csv)
‚îî‚îÄ‚îÄ after-analysis.csv (post-change metrics)</p>
<pre><code>
**Screenshot annotations.md**:
```markdown
# Evidence Annotations

## before-htmx-error.png
**Alt text**: "Browser devtools showing div#status with text 'Title is required' but no ARIA attributes"

**Context**: Week 9 baseline. Error appears visually but screen readers don't announce it.

## after-htmx-error.png
**Alt text**: "Browser devtools showing div#status with role=alert, aria-live=assertive, and text 'Title is required. Please enter at least one character.'"

**Context**: Week 10 fix. Error now has semantic markup for SR announcement.

## after-nojs-error.png
**Alt text**: "Task list page with error summary at top highlighted with blue focus outline. Error reads 'There is a problem' with link to title field."

**Context**: Week 10 fix, no-JS path. Error summary receives focus on page load, keyboard-navigable.
</code></pre>
<h3 id="step-3-create-readme-5-min"><a class="header" href="#step-3-create-readme-5-min">Step 3: Create README (5 min)</a></h3>
<p><strong>Create <code>wk10/assessment/README.md</code></strong>:</p>
<pre><code class="language-markdown"># COMP2850 HCI ‚Äî assessment Submission

**Student**: [Your name]
**Date**: 2025-10-22
**Module**: COMP2850 HCI

---

## Contents

1. **01-redesign-brief.md** ‚Äî Problem statement, proposed changes, acceptance criteria
2. **02-regression-checklist.csv** ‚Äî Accessibility verification (keyboard, SR, no-JS)
3. **03-before-after-summary.md** ‚Äî Quantitative metrics comparison (Week 9 vs Week 10)
4. **04-key-diffs.md** ‚Äî Annotated code changes with WCAG rationale
5. **05-evidence/** ‚Äî Screenshots, SR transcripts, metrics CSVs

---

## Summary

**Problem**: Task T2 (Edit Task) had 67% completion rate in Week 9 pilots (0% for no-JS). Validation errors not accessible to screen readers or keyboard users.

**Fix**: Added accessible error handling (`role="alert"`, `aria-describedby`, `tabindex="-1"`, auto-focus).

**Result**: 100% completion rate (all variants), WCAG 2.2 Level AA compliance (3.3.1, 4.1.3, 3.2.1).

**Impact**: Restored functional parity for no-JS users, improved accessibility for SR and keyboard-only users (estimated 2-5% UK population).

---

## Evidence Chain

1. **Raw data**: `05-evidence/metrics/before-analysis.csv` (Week 9 pilots)
2. **Analysis**: `03-before-after-summary.md` (completion 67% ‚Üí 100%)
3. **Prioritisation**: `01-redesign-brief.md` (Priority 1, Score 8)
4. **Implementation**: `04-key-diffs.md` (code changes with WCAG rationale)
5. **Verification**: `02-regression-checklist.csv` + `05-evidence/screenshots/` (post-change testing)
6. **Measurement**: `05-evidence/metrics/after-analysis.csv` (post-change pilots)

All files reference each other for full traceability.
</code></pre>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
All 5 core documents present in <code>task2/</code></li>
<li><input disabled="" type="checkbox"/>
Evidence artefacts organised in <code>05-evidence/</code></li>
<li><input disabled="" type="checkbox"/>
README.md complete with summary</li>
<li><input disabled="" type="checkbox"/>
All files sanitized (no PII)</li>
<li><input disabled="" type="checkbox"/>
File names match spec exactly</li>
</ul>
<hr />
<h2 id="commit--reflect-10-min-3"><a class="header" href="#commit--reflect-10-min-3">Commit &amp; Reflect (10 min)</a></h2>
<h3 id="commit-message-3"><a class="header" href="#commit-message-3">Commit message</a></h3>
<pre><code class="language-bash">git add templates/ src/main/kotlin/ data/metrics.csv analysis/ wk10/assessment/ wk10/lab-wk10/a11y/ backlog/backlog.csv

git commit -m "$(cat &lt;&lt;'EOF'
wk10s2: implemented inclusive redesign, verified, packaged Task 2

- Implemented Priority 1 fix: accessible validation error handling (T2 edit)
  - HTMX: Added role=alert + aria-live=assertive for SR announcement
  - No-JS: Added error summary with tabindex=-1 + auto-focus
  - Both: Added aria-describedby linking inputs to errors
- Completed accessibility regression checklist (21/22 pass, 1 contrast issue logged)
- Ran verification pilots (n=3): T2 completion 67% ‚Üí 100%, parity restored for no-JS
- Collected before/after metrics: completion +33%, error rate -8%, median time -78ms (JS-on)
- Packaged assessment bundle: brief, checklist, metrics, code diffs, evidence
- Updated backlog: wk9-01, wk9-03 marked fixed with verification evidence

Key results:
- No-JS users: 0% ‚Üí 100% completion (functional parity restored)
- SR users: Errors now announced immediately (WCAG 4.1.3 compliance)
- Keyboard users: Error summary keyboard-navigable (WCAG 3.2.1 compliance)
- All variants: WCAG 2.2 Level AA achieved (3.3.1, 4.1.3, 3.2.1)

Task 2 ready for submission.


EOF
)"
</code></pre>
<h3 id="reflection-questions-7"><a class="header" href="#reflection-questions-7">Reflection questions</a></h3>
<p><strong>Answer in <code>wk10/reflection.md</code></strong>:</p>
<ol>
<li>
<p><strong>Implementation challenges</strong>: What was harder than expected? Did you encounter unexpected regressions?</p>
</li>
<li>
<p><strong>Verification insights</strong>: Did post-change pilots reveal new issues? How confident are you in the ‚â•90% completion claim?</p>
</li>
<li>
<p><strong>Trade-offs</strong>: Did you make any compromises (e.g., auto-focus script requires JS)? How do you justify them?</p>
</li>
<li>
<p><strong>Before/after impact</strong>: Looking at the metrics table, which improvement matters most for inclusion? Why?</p>
</li>
<li>
<p><strong>Evidence quality</strong>: Is your evidence chain complete (data ‚Üí analysis ‚Üí fix ‚Üí verification)? What‚Äôs missing or weak?</p>
</li>
<li>
<p><strong>Assessment readiness</strong>: Can you present this fix in 5 minutes (problem ‚Üí data ‚Üí solution ‚Üí proof)? Practice your narrative.</p>
</li>
</ol>
<hr />
<h2 id="looking-ahead-week-11-optional-refinement-week-11-studio-crit-early-marking"><a class="header" href="#looking-ahead-week-11-optional-refinement-week-11-studio-crit-early-marking">Looking Ahead: Week 11 (Optional Refinement Week 11 Studio Crit Early Marking)</a></h2>
<p>Next week:</p>
<ul>
<li><strong>Lab 1</strong>: Present evidence chains to peers (5 min each)</li>
<li>Receive critique: Is evidence convincing? Are claims justified?</li>
<li>Give critique: Check peers‚Äô evidence chains, WCAG compliance</li>
<li><strong>Lab 2</strong>: Final refinements, portfolio assembly, submission prep</li>
</ul>
<p><strong>Before Week 11</strong>:</p>
<ul>
<li>Review assessment bundle‚Äîcan you explain every file?</li>
<li>Practice 5-min presentation (problem ‚Üí data ‚Üí fix ‚Üí verification)</li>
<li>Identify 1-2 backup issues (if your main fix gets critiqued)</li>
</ul>
<hr />
<h2 id="further-reading--resources-4"><a class="header" href="#further-reading--resources-4">Further Reading &amp; Resources</a></h2>
<h3 id="essential-4"><a class="header" href="#essential-4">Essential</a></h3>
<ul>
<li>Review <a href="wk10/../references/assistive-testing-checklist.html">Assistive Testing Checklist</a></li>
<li>Skim the <a href="wk10/../references/screenshot-guide.html">Screenshot Evidence Guide</a></li>
<li>Review <a href="wk10/../references/evaluation-metrics-quickref.html">Evaluation Metrics Quick Reference</a></li>
<li><a href="https://www.w3.org/WAI/WCAG22/quickref/">WCAG 2.2 Quick Reference</a></li>
</ul>
<h3 id="accessible-error-handling-1"><a class="header" href="#accessible-error-handling-1">Accessible Error Handling</a></h3>
<ul>
<li><a href="https://webaim.org/techniques/forms/">WebAIM: Creating Accessible Forms</a></li>
<li><a href="https://design-system.service.gov.uk/components/error-message/">GOV.UK: Error Message Pattern</a></li>
<li><a href="https://www.w3.org/WAI/ARIA/apg/patterns/alert/">ARIA Authoring Practices: Alert</a></li>
</ul>
<h3 id="beforeafter-studies"><a class="header" href="#beforeafter-studies">Before/After Studies</a></h3>
<ul>
<li><a href="https://measuringux.com/before-after/">Measuring UX: Before/After Studies</a></li>
<li><a href="https://www.nngroup.com/articles/measure-learnability/">Nielsen: Measuring Improvement</a></li>
</ul>
<h3 id="code-evidence"><a class="header" href="#code-evidence">Code Evidence</a></h3>
<ul>
<li><a href="https://git-scm.com/docs/git-diff">Git: Generating Diffs</a></li>
<li><a href="https://www.gov.uk/service-manual/service-standard/point-15-document-how-you-have-evaluated-your-service">GOV.UK: Documenting decisions</a></li>
</ul>
<h3 id="academic-2"><a class="header" href="#academic-2">Academic</a></h3>
<ul>
<li><strong>Lazar et al. (2017).</strong> <em>Research Methods in HCI</em> (2nd ed.). Chapter 12: Reporting results</li>
<li><strong>Sauro &amp; Lewis (2016).</strong> <em>Quantifying the User Experience</em> (2nd ed.). Chapter 9: Before/after comparisons</li>
</ul>
<hr />
<h2 id="glossary-summary-7"><a class="header" href="#glossary-summary-7">Glossary Summary</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Term</th><th>One-line definition</th></tr></thead><tbody>
<tr><td><strong>Regression testing</strong></td><td>Verifying new changes don‚Äôt break existing functionality</td></tr>
<tr><td><strong>Before/after metrics</strong></td><td>Quantitative comparison showing improvement from intervention</td></tr>
<tr><td><strong>Accessible error handling</strong></td><td>Errors perceivable, understandable, recoverable for all participants</td></tr>
<tr><td><strong>Code diffs</strong></td><td>Side-by-side comparison showing what changed (for evidence)</td></tr>
<tr><td><strong>role=‚Äúalert‚Äù</strong></td><td>ARIA role announcing content immediately to screen readers</td></tr>
<tr><td><strong>aria-live=‚Äúassertive‚Äù</strong></td><td>Live region that interrupts SR to announce urgent changes</td></tr>
<tr><td><strong>aria-describedby</strong></td><td>Links element to descriptive text (hints, errors)</td></tr>
<tr><td><strong>tabindex=‚Äú-1‚Äù</strong></td><td>Makes non-interactive element focusable programmatically (not in tab order)</td></tr>
<tr><td><strong>Progressive enhancement</strong></td><td>Baseline works without JS; JS adds enhancements</td></tr>
<tr><td><strong>Evidence chain</strong></td><td>Traceability from data ‚Üí analysis ‚Üí fix ‚Üí verification</td></tr>
</tbody></table>
</div>
<hr />
<p><strong>Lab complete!</strong> You have an implemented, verified, documented inclusive redesign ready for final assessment submission (due end Week 10).</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-10--lab-2--student-guide-redesign-re-verify--package-assessment"><a class="header" href="#week-10--lab-2--student-guide-redesign-re-verify--package-assessment">Week 10 ‚Ä¢ Lab 2 ‚Äî Student Guide: Redesign, Re-Verify &amp; Package assessment</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-10-orange" alt="Week 10" />
<img src="https://img.shields.io/badge/Lab-2-green" alt="Lab 2" />
<img src="https://img.shields.io/badge/Type-Student_Guide-purple" alt="Guide" /></p>
<blockquote>
<p><strong>Purpose</strong>: Week 10 Lab 2 is about implementing your priority redesigns from Lab 1, re-verifying with accessibility testing, and assembling your assessment submission package.</p>
</blockquote>
<hr />
<h2 id="deliverables-5"><a class="header" href="#deliverables-5">Deliverables</a></h2>
<ul>
<li>‚úÖ Priority fixes implemented (2-3 from wk10-lab1 priorities)</li>
<li>‚úÖ Re-verification evidence (<code>wk10/evidence/</code>)</li>
<li>‚úÖ assessment draft package (<code>wk10/assessment/</code>)</li>
<li>‚úÖ Updated backlog with ‚ÄúFixed‚Äù status</li>
</ul>
<hr />
<h2 id="part-1-implement-priority-fixes-60-minutes"><a class="header" href="#part-1-implement-priority-fixes-60-minutes">Part 1: Implement Priority Fixes (60 minutes)</a></h2>
<p>From <code>wk10/redesign/priorities.md</code>, implement your MUST FIX items.</p>
<h3 id="example-fix-1-add-no-js-confirmation"><a class="header" href="#example-fix-1-add-no-js-confirmation">Example Fix 1: Add No-JS Confirmation</a></h3>
<p><strong>Before</strong> (POST /tasks):</p>
<pre><code class="language-kotlin">// No-JS path - no confirmation shown
call.respondRedirect("/tasks")
</code></pre>
<p><strong>After</strong>:</p>
<pre><code class="language-kotlin">// No-JS path - add success message via query param
call.respondRedirect("/tasks?msg=task_added")
</code></pre>
<p><strong>In template</strong> (<code>tasks/index.peb</code>):</p>
<pre><code class="language-pebble">{% if msg == "task_added" %}
&lt;div role="alert" class="success"&gt;Task added successfully.&lt;/div&gt;
{% endif %}
</code></pre>
<h3 id="example-fix-2-clarify-cancel-button"><a class="header" href="#example-fix-2-clarify-cancel-button">Example Fix 2: Clarify Cancel Button</a></h3>
<p><strong>Before</strong>:</p>
<pre><code class="language-pebble">&lt;a href="/tasks"&gt;Cancel&lt;/a&gt;
</code></pre>
<p><strong>After</strong>:</p>
<pre><code class="language-pebble">&lt;a href="/tasks"&gt;Cancel (discard changes)&lt;/a&gt;
</code></pre>
<p><strong>Checklist per fix</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Code changed</li>
<li><input disabled="" type="checkbox"/>
Tested in browser (HTMX + no-JS)</li>
<li><input disabled="" type="checkbox"/>
Screenshot captured (before/after)</li>
</ul>
<hr />
<h2 id="part-2-re-verify-accessibility-30-minutes"><a class="header" href="#part-2-re-verify-accessibility-30-minutes">Part 2: Re-Verify Accessibility (30 minutes)</a></h2>
<p>After implementing fixes, re-run audits:</p>
<h3 id="axe-devtools-re-scan"><a class="header" href="#axe-devtools-re-scan">axe DevTools Re-Scan</a></h3>
<ol>
<li>Open <code>/tasks</code> page</li>
<li>Run axe scan</li>
<li>Compare to Week 7 report</li>
<li>Screenshot results</li>
</ol>
<h3 id="manual-wcag-re-check"><a class="header" href="#manual-wcag-re-check">Manual WCAG Re-Check</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
Keyboard navigation still works</li>
<li><input disabled="" type="checkbox"/>
Screen reader announces new messages</li>
<li><input disabled="" type="checkbox"/>
No-JS parity maintained</li>
</ul>
<p><strong>Document</strong> in <code>wk10/evidence/reverification.md</code>:</p>
<pre><code class="language-markdown"># Re-Verification ‚Äî Week 10

## axe DevTools
**Before**: 5 violations
**After**: 2 violations (fixed: labels, contrast, confirmation)
**Remaining**: Link purpose (deferred), zoom reflow (minor)

## Manual Testing
- ‚úÖ Keyboard: All fixes reachable via Tab
- ‚úÖ Screen reader: New success messages announced
- ‚úÖ No-JS: Confirmation now shown

## Regression Check
- ‚úÖ Previous fixes (Week 7) still work
- ‚úÖ No new issues introduced
</code></pre>
<p><strong>Checklist</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
axe re-scan complete</li>
<li><input disabled="" type="checkbox"/>
Manual testing done</li>
<li><input disabled="" type="checkbox"/>
Regression checked</li>
<li><input disabled="" type="checkbox"/>
Evidence documented</li>
</ul>
<hr />
<h2 id="part-3-assemble-assessment-package-40-minutes"><a class="header" href="#part-3-assemble-assessment-package-40-minutes">Part 3: Assemble Assessment Package (40 minutes)</a></h2>
<p><strong>Create</strong> <code>wk10/assessment/outline.md</code>:</p>
<pre><code class="language-markdown"># assessment Draft Outline

## Section 1: Redesign Rationale (20%)

### 1.1 Priority Selection
- [ ] Explain how priorities chosen (Week 9 data + severity + WCAG)
- [ ] Link to `wk10/redesign/priorities.md`

### 1.2 Evidence from Week 9
- [ ] Quantitative data showing issues (success rates, confidence)
- [ ] Qualitative quotes from participants
- [ ] WCAG criteria failed

---

## Section 2: Implementation (30%)

### 2.1 Fix 1: No-JS Confirmation
- [ ] Before code snippet
- [ ] After code snippet
- [ ] Screenshot comparison
- [ ] How it addresses WCAG 4.1.3

### 2.2 Fix 2: [Your fix]
[Repeat structure]

### 2.3 Trade-Offs
- [ ] What was sacrificed (e.g., URL gets query params, slightly longer)
- [ ] Why acceptable (better UX, WCAG compliance)

---

## Section 3: Verification (30%)

### 3.1 Re-Testing
- [ ] axe before/after comparison
- [ ] Manual WCAG checklist results
- [ ] Regression testing evidence

### 3.2 Accessibility Impact
- [ ] Who benefits (people using keyboard, no-JS, screen readers)
- [ ] Inclusion metrics improved

---

## Section 4: Reflection (20%)

### 4.1 Process Critique
- [ ] What worked well in redesign?
- [ ] Challenges faced?
- [ ] Time management

### 4.2 Future Work
- [ ] Deferred items from backlog
- [ ] If had more time, what next?

---

## Files to Include

- [ ] `wk10/redesign/priorities.md`
- [ ] Code snippets (before/after)
- [ ] `wk10/evidence/reverification.md`
- [ ] Screenshots from `wk10/evidence/`
- [ ] Updated `backlog/backlog.csv`

**Word count target**: ~2000-2500 words
</code></pre>
<p><strong>Checklist</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Assessment outline created</li>
<li><input disabled="" type="checkbox"/>
All sections listed</li>
<li><input disabled="" type="checkbox"/>
Files identified</li>
</ul>
<hr />
<h2 id="commit--continue-9"><a class="header" href="#commit--continue-9">Commit &amp; Continue</a></h2>
<pre><code class="language-bash">git add wk10/ src/ templates/
git commit -m "feat(wk10-lab2): priority fixes implemented and verified

- Fixed no-JS confirmation (added success message)
- Fixed edit inline no-JS failure (debugged PRG flow)
- Clarified Cancel button label
- Re-verified with axe and manual WCAG testing
- Created assessment draft outline

Ready for Week 11 studio crit and final submission."
</code></pre>
<p><strong>Next</strong>: Week 11 Lab 1 - Evidence-led studio crit.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-11--lab-1--evidence-led-studio-crit"><a class="header" href="#week-11--lab-1--evidence-led-studio-crit">Week 11 ‚Ä¢ Lab 1 ‚Äî Evidence-Led Studio Crit</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-11-orange" alt="Week 11" />
<img src="https://img.shields.io/badge/Lab-1-green" alt="Lab 1" />
<img src="https://img.shields.io/badge/Status-Draft-yellow" alt="Status" /></p>
<hr />
<h2 id="before-lab-required-reading-10-mins-2"><a class="header" href="#before-lab-required-reading-10-mins-2">Before Lab: Required Reading (10 mins)</a></h2>
<p>üìñ <strong>Essential</strong></p>
<ul>
<li><a href="https://www.ideo.com/blog/design-critique">IDEO: The Art of Critique</a> (5 min)</li>
<li>Review your assessment submission (submission-template.md with all sections complete)</li>
<li>Review your before/after metrics (Section 5: Verification Results)</li>
</ul>
<p>üìñ <strong>Quick reference</strong></p>
<ul>
<li><a href="wk11/../references/assistive-testing-checklist.html">Assistive Testing Checklist</a></li>
<li><a href="wk11/../references/evaluation-metrics-quickref.html">Evaluation Metrics Quick Reference</a></li>
</ul>
<hr />
<h2 id="introduction-from-evidence-to-narrative"><a class="header" href="#introduction-from-evidence-to-narrative">Introduction: From Evidence to Narrative</a></h2>
<p>You‚Äôve completed the HCI design cycle: audit ‚Üí pilot ‚Üí analyse ‚Üí redesign ‚Üí verify. <strong>Today you present that work to peers</strong>.</p>
<p><strong>This is not ‚Äúshow and tell‚Äù</strong>. Studio critique is:</p>
<ul>
<li><strong>Evidence-led</strong>: Every claim backed by data, screenshots, transcripts</li>
<li><strong>Reflective</strong>: Acknowledge limitations, trade-offs, remaining issues</li>
<li><strong>Actionable</strong>: Invite specific feedback, identify next steps</li>
</ul>
<p><strong>Why this matters</strong>:</p>
<ul>
<li><strong>Professional practice</strong>: Design reviews are standard in industry (Google, GOV.UK, Microsoft all use critique protocols)</li>
<li><strong>Accreditation</strong>: External panels assess evidence chains‚Äîthis is rehearsal</li>
<li><strong>Peer learning</strong>: Seeing 5-6 different solutions to same problem builds design vocabulary</li>
</ul>
<p><strong>Format</strong>: 15 min per team (5 min demo, 3 min metrics, 2 min accessibility proof, 5 min Q&amp;A). Tight timing forces clarity.</p>
<blockquote>
<p><strong>Visual</strong>: Evidence-led critique loop</p>
</blockquote>
<pre class="mermaid">graph TD
  Present[Evidence-led demo]
  Present --&gt; Feedback[Peer &amp; staff critique]
  Feedback --&gt; Notes[Crit notes &amp; backlog updates]
  Notes --&gt; Portfolio[Portfolio &amp; wrap-up]
  Portfolio --&gt; Plan[Semester 2 planning]
  Plan --&gt; Present
</pre>
<p><small>See <a href="wk11/../references/process-visuals.html#crit-loop">Process Visuals</a> for captioned steps.</small></p>
<hr />
<h2 id="learning-focus-10"><a class="header" href="#learning-focus-10">Learning Focus</a></h2>
<h3 id="lab-objectives-10"><a class="header" href="#lab-objectives-10">Lab Objectives</a></h3>
<p>By the end of this session, you will have:</p>
<ul>
<li>Presented evidence chains clearly (problem ‚Üí data ‚Üí fix ‚Üí verification)</li>
<li>Demonstrated accessibility improvements (keyboard, SR, no-JS)</li>
<li>Defended design decisions with data (before/after metrics)</li>
<li>Given/received peer feedback using structured rubric</li>
<li>Documented crit insights for portfolio</li>
</ul>
<h3 id="learning-outcomes-addressed-10"><a class="header" href="#learning-outcomes-addressed-10">Learning Outcomes Addressed</a></h3>
<p>This lab contributes to the following module Learning Outcomes (<a href="wk11/../references/learning-outcomes.html">full definitions</a>):</p>
<ul>
<li><strong>LO11</strong>: Collaborate in teams ‚Äî evidenced by peer critique participation</li>
<li><strong>LO12</strong>: Demonstrate professionalism ‚Äî evidenced by constructive feedback + respectful critique
Maps to WCAG: 2.2 AA (demonstrating compliance)</li>
</ul>
<hr />
<h2 id="key-concepts-9"><a class="header" href="#key-concepts-9">Key Concepts</a></h2>
<h3 id="design-critique"><a class="header" href="#design-critique">Design Critique</a></h3>
<blockquote>
<p><strong>Design Critique</strong> (<a href="wk11/../references/glossary.html">Glossary</a>)</p>
<p>Structured peer review of design work. <strong>Not personal feedback</strong>‚Äîfocuses on work, evidence, impact.</p>
<p><strong>Characteristics</strong></p>
<ul>
<li><strong>Specific</strong>: ‚ÄúError summary not keyboard-focusable‚Äù (good) vs ‚Äúerrors bad‚Äù (vague)</li>
<li><strong>Constructive</strong>: Suggest alternatives, not just problems</li>
<li><strong>Evidence-based</strong>: Reference data, WCAG, observations (not opinions)</li>
<li><strong>Respectful</strong>: Assume positive intent, acknowledge constraints</li>
</ul>
<p><strong>Format</strong> (this module)</p>
<ul>
<li>Presenter shows work + evidence</li>
<li>Audience asks clarifying questions</li>
<li>Audience offers critique: ‚ÄúI noticed X, have you considered Y?‚Äù</li>
<li>Presenter notes feedback (doesn‚Äôt defend in real-time)</li>
</ul>
<p><strong>HCI Connection</strong>: Critique improves design through <strong>external perspective</strong>‚Äîyou‚Äôre too close to your work to see all issues.</p>
<p><strong>Not a critique</strong></p>
<ul>
<li>‚ÄúI don‚Äôt like the colour‚Äù (subjective preference without rationale)</li>
<li>‚ÄúThis sucks‚Äù (not constructive)</li>
<li>‚ÄúYou should have‚Ä¶‚Äù (hindsight, not helpful)</li>
</ul>
<p><strong>Good critique</strong></p>
<ul>
<li>‚ÄúThe error message says ‚ÄòTitle required‚Äô but doesn‚Äôt explain the max length constraint. Pilot P3 hit this‚Äîcould you add that info?‚Äù</li>
</ul>
<p>üîó <a href="https://dschool.stanford.edu/resources/the-art-of-critique">Design Thinking: Critique vs Criticism</a></p>
</blockquote>
<h3 id="evidence-led-presentation"><a class="header" href="#evidence-led-presentation">Evidence-Led Presentation</a></h3>
<blockquote>
<p><strong>Evidence-Led Presentation</strong> (<a href="wk11/../references/glossary.html">Glossary</a>)</p>
<p>Presentation style where every claim is backed by artifacts (data, screenshots, quotes).</p>
<p><strong>Structure</strong></p>
<ol>
<li><strong>Problem</strong>: ‚ÄúT2 edit had 67% completion (0% no-JS)‚Äù ‚Üê metric</li>
<li><strong>Root cause</strong>: ‚ÄúValidation errors not announced to SR‚Äù ‚Üê pilot quote + WCAG reference</li>
<li><strong>Fix</strong>: ‚ÄúAdded <code>role=alert</code>‚Äù ‚Üê code diff</li>
<li><strong>Verification</strong>: ‚ÄúPost-change: 100% completion‚Äù ‚Üê after-metrics + screenshot</li>
</ol>
<p><strong>What NOT to do</strong></p>
<ul>
<li>‚ÄúWe made it better‚Äù (vague‚Äîbetter how?)</li>
<li>‚ÄúUsers struggled‚Äù (who? how many? with what?)</li>
<li>‚ÄúFixed accessibility‚Äù (which criteria? verified how?)</li>
</ul>
<p><strong>HCI Connection</strong>: Evidence separates <strong>opinion</strong> from <strong>fact</strong>. Stakeholders can question interpretation, but not the data.</p>
<p><strong>Academic context</strong>: External examiners check evidence chains. Missing evidence ‚Üí lower marks, even if work was good.</p>
<p>üîó <a href="https://gds.blog.gov.uk/2016/11/18/what-we-mean-when-we-say-show-the-thing/">GOV.UK: Show the thing</a></p>
</blockquote>
<h3 id="accessibility-demonstration"><a class="header" href="#accessibility-demonstration">Accessibility Demonstration</a></h3>
<blockquote>
<p><strong>Accessibility Demonstration</strong> (<a href="wk11/../references/glossary.html">Glossary</a>)</p>
<p>Live proof that inclusive design works. <strong>Show, don‚Äôt tell</strong>.</p>
<p><strong>Examples</strong></p>
<ul>
<li><strong>Keyboard</strong>: Tab through form ‚Üí submit error ‚Üí Tab to error link ‚Üí press Enter ‚Üí focus lands on input</li>
<li><strong>Screen reader</strong>: Turn on NVDA/Orca ‚Üí navigate to form ‚Üí submit error ‚Üí SR announces ‚ÄúAlert. Title is required‚Äù</li>
<li><strong>No-JS</strong>: Disable JavaScript ‚Üí submit form ‚Üí error summary appears and focused</li>
</ul>
<p><strong>Why live demo?</strong> Screenshots can be faked. Live demo proves system works right now.</p>
<p><strong>Backup plan</strong>: If live demo fails (demo gremlins), have <strong>video recording</strong> or <strong>annotated screenshots</strong> ready.</p>
<p><strong>What to show</strong></p>
<ul>
<li>Before state (broken or suboptimal)</li>
<li>After state (fixed)</li>
<li>Evidence it meets WCAG (checklist row, transcript)</li>
</ul>
<p><strong>Common mistakes</strong></p>
<ul>
<li>Only showing HTMX path (ignoring no-JS)</li>
<li>Not narrating what‚Äôs happening (‚ÄúI‚Äôm pressing Tab, now I‚Äôm on the error link‚Ä¶‚Äù)</li>
<li>Assuming audience sees what you see (make focus indicators obvious, zoom in if needed)</li>
</ul>
<p>üîó <a href="https://webaim.org/articles/demos/">WebAIM: Demonstrating Accessibility</a></p>
</blockquote>
<h3 id="constructive-feedback"><a class="header" href="#constructive-feedback">Constructive Feedback</a></h3>
<blockquote>
<p><strong>Constructive Feedback</strong> (<a href="wk11/../references/glossary.html">Glossary</a>)</p>
<p>Feedback that helps recipient improve. Has three parts: observation + impact + suggestion.</p>
<p><strong>Formula</strong></p>
<ol>
<li><strong>Observation</strong>: ‚ÄúI noticed X‚Äù (specific, factual)</li>
<li><strong>Impact</strong>: ‚ÄúThis might affect Y‚Äù (consequence, not judgment)</li>
<li><strong>Suggestion</strong>: ‚ÄúHave you considered Z?‚Äù (alternative, not mandate)</li>
</ol>
<p><strong>Example (good)</strong></p>
<ul>
<li>Observation: ‚ÄúYour error summary uses <code>aria-live=assertive</code>, which I saw announced in your SR demo‚Äù</li>
<li>Impact: ‚ÄúIn my testing, <code>assertive</code> interrupted mid-sentence when I was reading other content‚Äù</li>
<li>Suggestion: ‚ÄúHave you tested with <code>aria-live=polite</code> to see if it‚Äôs less disruptive? Might be a good trade-off if errors aren‚Äôt time-critical.‚Äù</li>
</ul>
<p><strong>Example (bad)</strong></p>
<ul>
<li>‚ÄúYou should use <code>polite</code> not <code>assertive</code>‚Äù ‚Üê prescriptive, no context</li>
</ul>
<p><strong>Receiving feedback</strong></p>
<ul>
<li><strong>Listen</strong>: Don‚Äôt defend immediately (note it, reflect later)</li>
<li><strong>Clarify</strong>: ‚ÄúCan you show me where you saw that?‚Äù</li>
<li><strong>Thank</strong>: Even if you disagree, feedback is effort</li>
</ul>
<p>üîó <a href="https://www.radicalcandor.com/">Kim Scott: Radical Candor</a> ‚Äî Framework for constructive feedback</p>
</blockquote>
<hr />
<h2 id="activity-a-prepare-presentation-20-min"><a class="header" href="#activity-a-prepare-presentation-20-min">Activity A: Prepare Presentation (20 min)</a></h2>
<p><strong>Goal</strong>: Assemble evidence into clear 5-slide narrative.</p>
<h3 id="step-1-create-presentation-outline-5-min"><a class="header" href="#step-1-create-presentation-outline-5-min">Step 1: Create presentation outline (5 min)</a></h3>
<p><strong>Use Markdown slides</strong> (e.g., Marp) or <strong>simple slide deck</strong> (Google Slides, PowerPoint).</p>
<p><strong>5-slide structure</strong>:</p>
<ol>
<li><strong>Title slide</strong> ‚Äî Project name, team, date</li>
<li><strong>Problem + Evidence</strong> ‚Äî What was broken? (metrics, quotes, WCAG violations)</li>
<li><strong>Solution</strong> ‚Äî What changed? (code diff, screenshots)</li>
<li><strong>Verification</strong> ‚Äî How do we know it worked? (after-metrics, regression checklist)</li>
<li><strong>Next Steps</strong> ‚Äî What remains? (backlog, Semester 2 plans)</li>
</ol>
<p><strong>Example</strong>:</p>
<p><strong>Slide 2: Problem + Evidence</strong></p>
<pre><code># Problem: Validation Errors Not Accessible

**Week 9 Findings**:
- T2 (Edit Task): 67% completion overall, 0% completion (no-JS)
- Pilot P3: "Gave up after 2 validation errors‚Äîcouldn't find error summary"
- Pilot P2 (NVDA): "SR didn't announce error message"

**Root Cause**:
- HTMX path: Missing `role=alert` (WCAG 4.1.3 violation)
- No-JS path: Error summary not keyboard-focusable (WCAG 3.2.1 violation)

**Impact**: Screen reader users, keyboard-only users, no-JS users excluded

[Screenshot: error summary with no focus indicator]
</code></pre>
<h3 id="step-2-select-key-evidence-artifacts-10-min"><a class="header" href="#step-2-select-key-evidence-artifacts-10-min">Step 2: Select key evidence artifacts (10 min)</a></h3>
<p><strong>From your <code>evidence/</code> folder (Section 6 of assessment)</strong>:</p>
<p><strong>Screenshots</strong> (3-4 max):</p>
<ul>
<li>Before: Error present but not accessible (no <code>role=alert</code> in devtools)</li>
<li>After: Error with <code>role=alert</code> visible in devtools</li>
<li>No-JS before: Error summary without focus</li>
<li>No-JS after: Error summary with focus outline</li>
</ul>
<p><strong>Metrics table</strong>:</p>
<pre><code>| Metric | Before | After | Œî |
|--------|--------|-------|---|
| T2 completion (no-JS) | 0% | 100% | +100% |
| T2 completion (all) | 67% | 100% | +33% |
| T2 error rate | 33% | 25% | -8% |
</code></pre>
<p><strong>Code diff</strong> (1 key change):</p>
<pre><code class="language-diff">- val status = """&lt;div id="status" hx-swap-oob="true"&gt;Title is required.&lt;/div&gt;"""
+ val status = """&lt;div id="status" role="alert" aria-live="assertive" hx-swap-oob="true"&gt;
+   Title is required. Please enter at least one character.
+ &lt;/div&gt;"""
</code></pre>
<p><strong>SR transcript snippet</strong>:</p>
<pre><code>Before: [form submitted, no announcement]
After: "Alert. Title is required. Please enter at least one character."
</code></pre>
<h3 id="step-3-prepare-live-demo-script-5-min"><a class="header" href="#step-3-prepare-live-demo-script-5-min">Step 3: Prepare live demo script (5 min)</a></h3>
<p><strong>Create <code>wk11/crit/demo-script.md</code></strong>:</p>
<pre><code class="language-markdown"># Live Demo Script ‚Äî Week 11 Studio Crit

**Timing**: 5 minutes

---

## Setup (30 seconds)
- Navigate to `/tasks`
- Show both browser windows: one with JS enabled, one with JS disabled (or toggle DevTools setting)
- Narrate: "I'll show the HTMX path first, then no-JS path"

---

## Demo 1: HTMX Error Handling (2 min)

**Steps**:
1. Click "Edit" on task "Submit invoices"
2. Clear title field (backspace)
3. Click "Save"
4. **Narrate**: "Notice status message appears: 'Title is required. Please enter at least one character.'"
5. Open DevTools Elements panel ‚Üí show `&lt;div id="status" role="alert" aria-live="assertive"&gt;`
6. **Narrate**: "The `role=alert` ensures screen readers announce this immediately"
7. (If SR available) Turn on NVDA/Orca, repeat steps 1-3
8. **Narrate**: "NVDA announces: 'Alert. Title is required...'"

**Evidence reference**: `05-evidence/sr-transcripts/after-nvda.txt`

---

## Demo 2: No-JS Error Handling (2 min)

**Steps**:
1. Disable JavaScript (DevTools ‚Üí Settings ‚Üí Disable JavaScript, hard refresh)
2. Click "Edit" on same task
3. Clear title, click "Save"
4. **Narrate**: "Page reloads. Notice error summary at top with focus outline‚Äîit's automatically focused."
5. Press Tab ‚Üí focus moves to error link ("Title is required")
6. Press Enter ‚Üí focus moves to `#title` input
7. **Narrate**: "Keyboard-only users can now navigate to the error and fix it. Before, this wasn't possible."

**Evidence reference**: `05-evidence/screenshots/after-nojs-error.png`

---

## Demo 3: Success Path (30 seconds)

**Steps**:
1. (Still in no-JS mode) Type new title: "Submit invoices by Friday"
2. Click "Save"
3. **Narrate**: "Full page reload, task updated. PRG pattern maintains history."
4. Show updated task in list

---

## Backup (if demo fails)

**Video**: `wk11/crit/demo-recording.mp4` (pre-recorded screen capture with narration)

**Screenshots**: Walk through annotated screenshots in `05-evidence/screenshots/` with narration
</code></pre>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
5-slide outline complete</li>
<li><input disabled="" type="checkbox"/>
Evidence artifacts selected (screenshots, metrics, diffs)</li>
<li><input disabled="" type="checkbox"/>
Live demo script written with narration</li>
<li><input disabled="" type="checkbox"/>
Backup plan ready (video or annotated screenshots)</li>
</ul>
<hr />
<h2 id="activity-b-studio-critique-session-60-min"><a class="header" href="#activity-b-studio-critique-session-60-min">Activity B: Studio Critique Session (60 min)</a></h2>
<p><strong>Format</strong>: 5-6 teams √ó 15 min each</p>
<h3 id="presenter-role-when-its-your-turn"><a class="header" href="#presenter-role-when-its-your-turn">Presenter Role (when it‚Äôs your turn)</a></h3>
<p><strong>Timing breakdown</strong>:</p>
<ul>
<li><strong>0:00-0:30</strong>: Introduce problem (1 slide)</li>
<li><strong>0:30-5:00</strong>: Live demo (narrated, following script)</li>
<li><strong>5:00-8:00</strong>: Show metrics + evidence (slides 2-4)</li>
<li><strong>8:00-10:00</strong>: Accessibility proof (regression checklist, SR transcript)</li>
<li><strong>10:00-15:00</strong>: Q&amp;A + critique</li>
</ul>
<p><strong>Presenting tips</strong>:</p>
<ul>
<li><strong>Narrate everything</strong>: ‚ÄúI‚Äôm pressing Tab, now I‚Äôm on the error link‚Ä¶‚Äù</li>
<li><strong>Point to evidence</strong>: ‚ÄúThis is documented in line 23 of our regression checklist‚Ä¶‚Äù</li>
<li><strong>Acknowledge limitations</strong>: ‚ÄúWe didn‚Äôt have time to fix wk9-02 (filter UX)‚Äîit‚Äôs in our Semester 2 backlog‚Äù</li>
<li><strong>Invite questions</strong>: ‚ÄúWhat would you like me to clarify?‚Äù</li>
</ul>
<p><strong>During Q&amp;A</strong>:</p>
<ul>
<li><strong>Don‚Äôt defend</strong>: Listen, note feedback, say ‚Äúgood point, I‚Äôll check that‚Äù</li>
<li><strong>Clarify if needed</strong>: ‚ÄúCan you show me which screenshot you‚Äôre referring to?‚Äù</li>
<li><strong>Thank reviewers</strong>: Even if feedback stings, they‚Äôre helping you improve</li>
</ul>
<p><strong>Note feedback</strong> in <code>wk11/crit/feedback-received.md</code>:</p>
<pre><code class="language-markdown">## Feedback from Studio Crit ‚Äî 2025-10-25

### Team Alpha
- **Q**: "Have you tested with VoiceOver (macOS) or just NVDA?"
- **Response**: Only tested NVDA. Should add VoiceOver testing to backlog.
- **Action**: Create backlog item wk11-01: "Verify SR compatibility with VoiceOver"

### Team Beta
- **Observation**: "Your `aria-live=assertive` interrupted my SR mid-sentence during filter demo"
- **Suggestion**: "Try `aria-live=polite` for non-critical messages?"
- **Response**: Good catch. Will test polite vs assertive for status messages.
- **Action**: Update wk10/lab-wk10/docs/redesign-brief.md notes section

### Staff
- **Q**: "Why did you prioritise T2 over T1 when T1 had higher error rate?"
- **Response**: T2 had 0% no-JS completion (complete block) vs T1 100% completion (just slower). Prioritised exclusion over efficiency.
- **Validation**: Staff agreed with prioritization framework logic.
</code></pre>
<h3 id="reviewer-role-when-watching-others"><a class="header" href="#reviewer-role-when-watching-others">Reviewer Role (when watching others)</a></h3>
<p><strong>Use <code>wk11/crit/peer-feedback-TEAM_NAME.md</code> template</strong>:</p>
<pre><code class="language-markdown"># Peer Feedback ‚Äî Team [Name]

**Reviewer**: [Your name]
**Date**: 2025-10-25

---

## Summary

**Problem addressed**: [One sentence]

**Solution**: [One sentence]

**Evidence quality**: [Rating 1-5, brief justification]

---

## Strengths (What worked well)

1. [Specific observation with evidence reference]
2. [Specific observation with evidence reference]
3. [Specific observation with evidence reference]

**Example**:
- Clear before/after metrics table showing 67% ‚Üí 100% completion
- Live SR demo proved `role=alert` works (heard announcement)
- Regression checklist complete (21/22 pass‚Äîimpressive)

---

## Questions / Concerns

1. [Specific question or observation]
2. [Specific question or observation]

**Example**:
- Q: "You mentioned error rate dropped from 33% to 25%. Is that still high? What's causing remaining errors?"
- Concern: "Screenshot shows error summary but I didn't see it tested with keyboard in live demo. Can you Tab to it?"

---

## Suggestions (Constructive)

Use formula: Observation + Impact + Suggestion

1. [Observation] ‚Üí [Impact] ‚Üí [Suggestion]
2. [Observation] ‚Üí [Impact] ‚Üí [Suggestion]

**Example**:
- **Observation**: Error message says "Title is required" but pilot P2 submitted blank because they didn't see the input had focus.
- **Impact**: Focus indicator might be too subtle (low contrast).
- **Suggestion**: Have you checked focus indicator contrast with WCAG contrast checker? Might need to increase from blue (#0000ff) to darker blue (#0000aa) for 3:1 ratio against white background.

---

## Backlog / Next Steps

What should this team consider for Semester 2?

- [Item 1]
- [Item 2]

**Example**:
- Test with VoiceOver (macOS) and JAWS (Windows) to verify SR compatibility beyond NVDA
- Add client-side validation hints (maxlength counter) as progressive enhancement
- Investigate why 25% error rate persists‚Äîmight be focus management issue

---

## Overall Assessment

**Evidence chain completeness**: [Rating 1-5]
- 5 = Complete traceability (data ‚Üí analysis ‚Üí fix ‚Üí verification)
- 3 = Some gaps (e.g., missing SR transcript or before metrics)
- 1 = Weak evidence (claims not backed by data)

**Inclusion impact**: [Rating 1-5]
- 5 = Clear who benefits, why, backed by pilot observations
- 3 = General statements ("helps disabled people") without specifics
- 1 = No inclusion lens evident

**WCAG compliance**: [Pass/Partial/Fail]
- Pass = Demonstrated compliance (checklist, live demo)
- Partial = Some criteria met, gaps acknowledged
- Fail = Claims compliance but no evidence

**Recommended grade** (if this were assessment submission): [Estimate 0-100]

**Justification**: [2-3 sentences linking grade to evidence quality, inclusion impact, WCAG compliance]
</code></pre>
<p><strong>Reviewer tips</strong>:</p>
<ul>
<li><strong>Be specific</strong>: Reference line numbers, file names, WCAG criteria</li>
<li><strong>Be kind</strong>: Assume positive intent, acknowledge constraints</li>
<li><strong>Be useful</strong>: Suggest alternatives, not just problems</li>
<li><strong>Be brief</strong>: They have limited time to read feedback‚Äîbullet points better than essays</li>
</ul>
<p>‚úã <strong>Stop and check</strong> (after all presentations):</p>
<ul>
<li><input disabled="" type="checkbox"/>
Presented your work (or scheduled if absent)</li>
<li><input disabled="" type="checkbox"/>
Filled peer feedback forms for 3-5 teams</li>
<li><input disabled="" type="checkbox"/>
Noted feedback received in your own feedback-received.md</li>
<li><input disabled="" type="checkbox"/>
Identified action items for Week 11 Lab 2</li>
</ul>
<hr />
<h2 id="activity-c-post-crit-reflection-and-backlog-update-15-min"><a class="header" href="#activity-c-post-crit-reflection-and-backlog-update-15-min">Activity C: Post-Crit Reflection and Backlog Update (15 min)</a></h2>
<p><strong>Goal</strong>: Process feedback and update backlog.</p>
<h3 id="step-1-review-feedback-received-5-min"><a class="header" href="#step-1-review-feedback-received-5-min">Step 1: Review feedback received (5 min)</a></h3>
<p><strong>Open <code>wk11/crit/feedback-received.md</code></strong> and identify themes:</p>
<p><strong>Categorize</strong>:</p>
<ul>
<li><strong>Critical</strong>: Issues that invalidate claims (e.g., ‚ÄúYou said 100% completion but didn‚Äôt test with SR‚Äù)</li>
<li><strong>High priority</strong>: Valid suggestions that would significantly improve work</li>
<li><strong>Medium</strong>: Nice-to-haves, future work</li>
<li><strong>Low/Out-of-scope</strong>: Interesting but not actionable this semester</li>
</ul>
<p><strong>Example categorization</strong>:</p>
<pre><code class="language-markdown">## Feedback Themes

### Critical (Address before assessment submission)
- Team Beta: "aria-live=assertive too intrusive" ‚Üí Test polite vs assertive
- Staff: "No evidence of VoiceOver testing" ‚Üí Either test or document limitation

### High Priority (Semester 2)
- Team Alpha: "Focus indicator contrast 2.8:1 (below 3:1)" ‚Üí Log backlog item, fix early Sem 2
- Team Gamma: "Error rate still 25%‚Äîwhy?" ‚Üí Investigate root cause (focus management?)

### Medium
- Team Delta: "Add maxlength counter" ‚Üí Progressive enhancement, nice-to-have

### Low/Out-of-Scope
- Team Epsilon: "Redesign entire UI with dark mode" ‚Üí Out of scope for this module
</code></pre>
<h3 id="step-2-update-backlog-5-min"><a class="header" href="#step-2-update-backlog-5-min">Step 2: Update backlog (5 min)</a></h3>
<p><strong>Add new items</strong> to <code>backlog/backlog.csv</code>:</p>
<pre><code class="language-csv">wk11-01,11,high,a11y,"Verify SR compatibility with VoiceOver (macOS)",,"open","wk11/crit/feedback-received.md Team Alpha","Test with VoiceOver, document findings",false

wk11-02,11,medium,a11y,"Focus indicator contrast below WCAG AAA (2.8:1)",1.4.11,open,"wk11/crit/feedback-received.md Team Beta; WCAG 2.2 Focus Appearance","Increase focus outline to darker blue (#0000aa) for 3:1 contrast",true

wk11-03,11,high,ux,"Remaining 25% error rate on T2‚Äîinvestigate cause",,"open","submission-template.md Section 5 Part B; wk11/crit/feedback-received.md Staff","Run additional pilot focusing on error triggers, check focus management",false
</code></pre>
<p><strong>Mark completed feedback actions</strong>:</p>
<pre><code class="language-csv">wk9-01,9,high,a11y,"Validation errors not announced by SR",4.1.3,fixed,"data/metrics.csv; evidence/sr-transcripts/after-nvda.txt","Addressed in Week 10 Lab 2: added role=alert + aria-live=assertive",true
</code></pre>
<h3 id="step-3-write-reflection-5-min"><a class="header" href="#step-3-write-reflection-5-min">Step 3: Write reflection (5 min)</a></h3>
<p><strong>Update <code>wk11/reflection.md</code></strong>:</p>
<pre><code class="language-markdown"># Week 11 Lab 1 Reflection ‚Äî Studio Crit

## Presentation Experience

**What went well**:
- Live demo worked smoothly (both HTMX and no-JS paths)
- Metrics table clearly showed 67% ‚Üí 100% improvement
- Audience understood the inclusion impact (no-JS users excluded ‚Üí now included)

**What was challenging**:
- Nerves made me rush through SR demo‚Äîshould have slowed down to let audience hear announcement
- Didn't anticipate VoiceOver compatibility question‚Äîassumed NVDA coverage was sufficient
- Q&amp;A revealed gap: didn't investigate why error rate only improved to 25% (not &lt;10% as hoped)

## Feedback Received

**Most valuable critique**:
Team Beta's observation about `aria-live=assertive` being too intrusive. I experienced this myself during testing but dismissed it‚Äîtheir feedback validated my concern. Will test `polite` alternative.

**Most surprising critique**:
Staff asked why I prioritised T2 over T1 when T1 had higher error rate. I explained: T2 had 0% no-JS completion (exclusion) vs T1 100% completion (efficiency). Staff agreed but noted I should have made this explicit in presentation. Lesson: state prioritization criteria upfront.

**Hardest to hear**:
Team Alpha noted focus indicator contrast issue (2.8:1, below 3:1). I checked this in Week 8 but forgot to fix it. Embarrassing oversight‚Äîlogged wk11-02 to address.

## Changes for assessment Submission

Based on feedback:
1. **Add VoiceOver testing note** to `02-regression-checklist.csv`: "Tested with NVDA (Windows) and Orca (Linux). VoiceOver (macOS) not tested‚Äîrecommend for Semester 2."
2. **Investigate `aria-live=polite`** alternative: Run quick test, update `01-redesign-brief.md` notes if polite works better
3. **Document focus indicator issue**: Add note to `03-before-after-summary.md`: "Known issue: focus indicator contrast 2.8:1 (WCAG AAA). Logged wk11-02 for Semester 2 fix."

## Giving Feedback

**Teams I reviewed**: Alpha, Beta, Gamma

**Most interesting observation**:
Team Gamma used UMUX-Lite subjective measure (2 questions, 1-7 scale). We didn't‚Äîmight add for Semester 2 to capture perceived usability alongside objective metrics.

**Common pattern**:
3/5 teams struggled with no-JS demos (forgot to disable JS, or JS disabled but cached). Reinforces importance of verification scripts like `wk08/lab-w8/scripts/nojs-check.md`.

## Next Steps

**Before Lab 2** (Final submissions):
1. Test `aria-live=polite` vs `assertive` (30 min)
2. Add VoiceOver limitation note to regression checklist (5 min)
3. Document focus indicator issue in before-after summary (10 min)
4. Final proofread of assessment bundle (30 min)

**Semester 2 priorities** (based on backlog):
- Fix focus indicator contrast (wk11-02)
- Investigate remaining error rate (wk11-03)
- Test VoiceOver compatibility (wk11-01)
- Add progressive enhancement hints (maxlength counter, real-time char count)
</code></pre>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Feedback themes identified and categorized</li>
<li><input disabled="" type="checkbox"/>
Backlog updated with new items from critique</li>
<li><input disabled="" type="checkbox"/>
Reflection written (what went well, challenges, changes for submission)</li>
<li><input disabled="" type="checkbox"/>
Action items for Week 11 Lab 2 clear</li>
</ul>
<hr />
<h2 id="commit--reflect-5-min"><a class="header" href="#commit--reflect-5-min">Commit &amp; Reflect (5 min)</a></h2>
<h3 id="commit-message-4"><a class="header" href="#commit-message-4">Commit message</a></h3>
<pre><code class="language-bash">git add wk11/crit/ backlog/backlog.csv wk11/reflection.md

git commit -m "$(cat &lt;&lt;'EOF'
wk11s1: studio crit completed, feedback processed

- Presented inclusive redesign with live demo (HTMX + no-JS paths)
- Demonstrated accessibility improvements: role=alert SR announcement, keyboard-navigable error summary
- Showed before/after metrics: T2 completion 67% ‚Üí 100%, no-JS parity restored
- Received feedback from 3 peer teams + staff (documented in feedback-received.md)
- Identified critical action items: test aria-live=polite, document VoiceOver limitation, note focus contrast issue
- Provided constructive feedback to 3 peer teams (Alpha, Beta, Gamma)
- Updated backlog with new items: wk11-01 (VoiceOver testing), wk11-02 (focus contrast), wk11-03 (error rate investigation)
- Reflected on presentation experience and critique process

Key takeaways:
- Evidence-led presentation effective (audience understood inclusion impact from metrics)
- Need to slow down during SR demos (rushed, hard for audience to hear)
- Prioritization criteria should be explicit upfront (T2 exclusion vs T1 efficiency)
- Focus indicator contrast oversight embarrassing but fixable (logged for Semester 2)

Ready for Week 11 Lab 2 final refinements and submission prep.


EOF
)"
</code></pre>
<hr />
<h2 id="looking-ahead-week-11-lab-2"><a class="header" href="#looking-ahead-week-11-lab-2">Looking Ahead: Week 11 Lab 2</a></h2>
<p>Final session:</p>
<ul>
<li><strong>Polish assessment &amp; 2</strong> based on crit feedback</li>
<li><strong>Assemble portfolio</strong> with evidence chains</li>
<li><strong>Practice submission</strong> process (Gradescope upload, file check)</li>
<li><strong>Module reflection</strong> and Semester 2 planning</li>
</ul>
<p><strong>Before Lab 2</strong>:</p>
<ul>
<li>Address critical feedback (test polite, document limitations)</li>
<li>Final proofread all submission files</li>
<li>Check Gradescope submission requirements (file formats, naming)</li>
</ul>
<hr />
<h2 id="further-reading--resources-5"><a class="header" href="#further-reading--resources-5">Further Reading &amp; Resources</a></h2>
<h3 id="essential-5"><a class="header" href="#essential-5">Essential</a></h3>
<ul>
<li>Review assessment bundle for gaps</li>
<li><a href="https://www.ideo.com/blog/design-critique">IDEO: The Art of Critique</a></li>
</ul>
<h3 id="presentation-skills"><a class="header" href="#presentation-skills">Presentation Skills</a></h3>
<ul>
<li><a href="https://gds.blog.gov.uk/2016/11/18/what-we-mean-when-we-say-show-the-thing/">GOV.UK: Show the thing</a></li>
<li><a href="https://www.nngroup.com/articles/presenting-findings/">Nielsen: Presenting Usability Findings</a></li>
</ul>
<h3 id="constructive-feedback-1"><a class="header" href="#constructive-feedback-1">Constructive Feedback</a></h3>
<ul>
<li><a href="https://www.radicalcandor.com/">Kim Scott: Radical Candor</a></li>
<li><a href="https://hbr.org/2019/03/the-feedback-fallacy">Harvard Business Review: The Feedback Fallacy</a></li>
</ul>
<h3 id="accessibility-demonstration-1"><a class="header" href="#accessibility-demonstration-1">Accessibility Demonstration</a></h3>
<ul>
<li><a href="https://webaim.org/articles/demos/">WebAIM: Demonstrating Accessibility</a></li>
<li><a href="https://www.deque.com/blog/screen-reader-demonstration-best-practices/">Deque: Screen Reader Demo Best Practices</a></li>
</ul>
<hr />
<h2 id="glossary-summary-8"><a class="header" href="#glossary-summary-8">Glossary Summary</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Term</th><th>One-line definition</th></tr></thead><tbody>
<tr><td><strong>Design critique</strong></td><td>Structured peer review of design work; focuses on evidence, not person</td></tr>
<tr><td><strong>Evidence-led presentation</strong></td><td>Every claim backed by artifacts (data, screenshots, quotes)</td></tr>
<tr><td><strong>Accessibility demonstration</strong></td><td>Live proof that inclusive design works (show, don‚Äôt tell)</td></tr>
<tr><td><strong>Constructive feedback</strong></td><td>Observation + Impact + Suggestion (not just criticism)</td></tr>
<tr><td><strong>Studio crit</strong></td><td>Group critique session common in design education and practice</td></tr>
<tr><td><strong>Before/after comparison</strong></td><td>Showing improvement through quantitative metrics</td></tr>
<tr><td><strong>Regression checklist</strong></td><td>Systematic verification that fixes didn‚Äôt break other features</td></tr>
<tr><td><strong>Evidence chain</strong></td><td>Traceability from data ‚Üí analysis ‚Üí fix ‚Üí verification</td></tr>
<tr><td><strong>Backlog refinement</strong></td><td>Updating backlog based on new feedback and discoveries</td></tr>
</tbody></table>
</div>
<hr />
<p><strong>Lab complete!</strong> You‚Äôve presented your work with evidence, received constructive critique, and prepared for assessment refinement in Week 11 Lab 2.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-11--lab-1--student-guide-evidence-led-studio-crit"><a class="header" href="#week-11--lab-1--student-guide-evidence-led-studio-crit">Week 11 ‚Ä¢ Lab 1 ‚Äî Student Guide: Evidence-Led Studio Crit</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-11-orange" alt="Week 11" />
<img src="https://img.shields.io/badge/Lab-1-green" alt="Lab 1" />
<img src="https://img.shields.io/badge/Type-Student_Guide-purple" alt="Guide" /></p>
<blockquote>
<p><strong>Purpose</strong>: Week 11 Lab 1 is a peer critique session where you present your work (Week 6-10 journey), receive feedback, and refine your submissions before final deadline.</p>
</blockquote>
<hr />
<h2 id="deliverables-6"><a class="header" href="#deliverables-6">Deliverables</a></h2>
<ul>
<li>‚úÖ Crit presentation (5-7 minutes)</li>
<li>‚úÖ Peer feedback notes (<code>wk11/crit/feedback-received.md</code>)</li>
<li>‚úÖ Action plan from feedback (<code>wk11/crit/action-plan.md</code>)</li>
</ul>
<hr />
<h2 id="part-1-prepare-crit-presentation-30-minutes"><a class="header" href="#part-1-prepare-crit-presentation-30-minutes">Part 1: Prepare Crit Presentation (30 minutes)</a></h2>
<p><strong>Create</strong> <code>wk11/crit/presentation-outline.md</code>:</p>
<pre><code class="language-markdown"># Studio Crit Presentation Outline

## Slide 1: Overview (30 seconds)
**What I built**: Task manager with server-first architecture, HTMX progressive enhancement, WCAG 2.2 AA compliance

**Key features**: Add, edit, delete tasks + dual-mode (HTMX/no-JS) + accessibility (keyboard, screen reader)

---

## Slide 2: Needs-Finding (Week 6) (1 minute)
**Process**: Peer interviews ‚Üí 5 job stories ‚Üí inclusive backlog

**Example insight**: "When I submit a form, I want confirmation it worked so I don't refresh to check" (4/5 participants)

---

## Slide 3: Implementation Journey (Weeks 7-8) (1.5 minutes)
**Week 7**: Inline edit, ethics documentation, accessibility audit (axe + manual)

**Week 8**: Pagination, filtering, template partials

**Key challenge**: Maintaining dual-path parity (HTMX vs no-JS)

---

## Slide 4: Evaluation (Week 9) (1.5 minutes)
**Method**: 5 task-based pilots (3 HTMX, 2 no-JS)

**Quantitative**: 100% success on 3/4 tasks, 80% on inline edit (no-JS issue)

**Qualitative**: "Confirmation feedback critical" (4/5 participants)

**Screenshot**: Show pilot setup or data table

---

## Slide 5: Redesign (Week 10) (1.5 minutes)
**Priority fixes**:
1. Added no-JS confirmation message (‚Üí confidence improved)
2. Fixed edit inline no-JS failure (‚Üí 100% success)
3. Clarified Cancel button label

**Before/After**: Screenshot comparison

---

## Slide 6: Reflection &amp; Questions (1 minute)
**What I learned**: Dual-path architecture is hard but essential for inclusion

**Trade-off I'd revisit**: Delete confirmation (no-JS has none - would add confirmation page if more time)

**Question for peers**: How did you handle no-JS error messages?

---

**Total**: ~7 minutes (leave 3 min for questions)
</code></pre>
<p><strong>Checklist</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Presentation outline written (6 slides max)</li>
<li><input disabled="" type="checkbox"/>
Screenshots selected</li>
<li><input disabled="" type="checkbox"/>
Practice run (time yourself)</li>
</ul>
<hr />
<h2 id="part-2-givereceive-feedback-30-minutes"><a class="header" href="#part-2-givereceive-feedback-30-minutes">Part 2: Give/Receive Feedback (30 minutes)</a></h2>
<h3 id="during-others-presentations"><a class="header" href="#during-others-presentations">During Others‚Äô Presentations</a></h3>
<p><strong>Take notes</strong> in <code>wk11/crit/feedback-to-give.md</code>:</p>
<pre><code class="language-markdown"># Feedback for [Peer Name]

## Strengths
- [What worked well? Specific examples]

## Questions
- [Clarifications needed]

## Suggestions
- [Constructive improvements, backed by WCAG or research]

---

**Feedback format**: "I noticed [observation]. Have you considered [suggestion]? This could help with [benefit]."

**Example**: "I noticed your delete has no confirmation in no-JS mode. Have you considered adding a /confirm page? This would meet WCAG 3.3.4 Error Prevention."
</code></pre>
<h3 id="when-receiving-feedback"><a class="header" href="#when-receiving-feedback">When Receiving Feedback</a></h3>
<p><strong>Record</strong> in <code>wk11/crit/feedback-received.md</code>:</p>
<pre><code class="language-markdown"># Feedback Received ‚Äî Studio Crit

## From: [Peer 1]
**Strength**: "Dual-path architecture thoroughly documented"

**Question**: "How did you test screen reader with no-JS mode?"

**Suggestion**: "Consider adding focus management after delete (where does focus go?)"

---

## From: [Peer 2]
[Repeat]

---

## From: Staff
[Note any staff feedback]
</code></pre>
<p><strong>Checklist</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Gave feedback to 2-3 peers</li>
<li><input disabled="" type="checkbox"/>
Recorded all feedback received</li>
<li><input disabled="" type="checkbox"/>
Noted actionable items</li>
</ul>
<hr />
<h2 id="part-3-create-action-plan-20-minutes"><a class="header" href="#part-3-create-action-plan-20-minutes">Part 3: Create Action Plan (20 minutes)</a></h2>
<p><strong>Create</strong> <code>wk11/crit/action-plan.md</code>:</p>
<pre><code class="language-markdown"># Action Plan from Studio Crit

## High Priority (Do Before Submission)
- [ ] **Focus management after delete** (Peer 1 suggestion)
  - Current: Focus lost after delete
  - Fix: Move focus to next task or "Add Task" button
  - Effort: 30 min
  - Deadline: [Date]

- [ ] **Screen reader testing documentation** (Peer 1 question)
  - Add NVDA output to evidence folder
  - Test no-JS path explicitly
  - Effort: 20 min

---

## Medium Priority (If Time Permits)
- [ ] **Delete confirmation page for no-JS** (Peer 2)
  - Would improve WCAG 3.3.4 compliance
  - Effort: 1-2 hours
  - If not done: Document as future work in assessment

---

## Low Priority (Noted for Portfolio)
- [ ] **Progress indicator** (multiple peers mentioned)
  - Nice-to-have, not WCAG requirement
  - Defer to portfolio "future enhancements" section

---

## Not Actioning (With Rationale)
- **[Suggestion]**: [Why not implementing - time, scope, or disagreement with reasoning]
</code></pre>
<p><strong>Checklist</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Action items prioritised</li>
<li><input disabled="" type="checkbox"/>
Deadlines set for high-priority items</li>
<li><input disabled="" type="checkbox"/>
Rationale provided for deferred/rejected items</li>
</ul>
<hr />
<h2 id="commit--continue-10"><a class="header" href="#commit--continue-10">Commit &amp; Continue</a></h2>
<pre><code class="language-bash">git add wk11/
git commit -m "feat(wk11-lab1): studio crit presentation and feedback

- Prepared 7-minute presentation covering Weeks 6-10 journey
- Received feedback from 3 peers + staff
- Created action plan with prioritised improvements
- High-priority: focus management, SR testing documentation

Ready for final refinements in Week 11 Lab 2."
</code></pre>
<p><strong>Next</strong>: Week 11 Lab 2 - Final wrap-up, portfolio, submission readiness.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-11--lab-2-wrap-up-portfolio--submission-readiness"><a class="header" href="#week-11--lab-2-wrap-up-portfolio--submission-readiness">Week 11 ‚Ä¢ Lab 2: Wrap-up, Portfolio &amp; Submission Readiness</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-11-orange" alt="Week 11" />
<img src="https://img.shields.io/badge/Lab-2-green" alt="Lab 2" />
<img src="https://img.shields.io/badge/Status-Draft-yellow" alt="Status" /></p>
<hr />
<h2 id="terminology-note-4"><a class="header" href="#terminology-note-4">Terminology Note</a></h2>
<p>Throughout COMP2850 we use <strong>people-centred language</strong> (e.g., ‚Äúperson using a screen reader‚Äù) rather than deficit-based terms (e.g., ‚Äúblind user‚Äù). This reflects contemporary inclusive-design practice and acknowledges that disability arises from environmental barriers, not individual impairment.</p>
<hr />
<h2 id="pre-reading-4"><a class="header" href="#pre-reading-4">Pre-reading</a></h2>
<p><strong>Essential</strong></p>
<ul>
<li><a href="https://design-system.service.gov.uk/patterns/validation/">GOV.UK Design System: Form validation</a></li>
<li><a href="https://hypermedia.systems/hypermedia-on-the-web/#_practical_patterns">hypermedia.systems, Ch. 9: Practical Patterns</a></li>
</ul>
<p><strong>Recommended</strong></p>
<ul>
<li><a href="https://www.cs.umd.edu/~ben/papers/">Shneiderman et al. (2016). <em>Designing the User Interface</em>, Ch. 15: Evaluation &amp; Iteration</a></li>
<li><a href="https://www.w3.org/WAI/WCAG22/quickref/?currentsidebar=%23col_customize&amp;levels=aaa">W3C (2024). WCAG 2.2 AA Quick Reference</a></li>
<li><a href="https://www.leeds.ac.uk/arts/info/125218/academic_skills/149/reflective_writing">Academic Skills Centre: Reflective Writing</a></li>
</ul>
<hr />
<h2 id="introduction-4"><a class="header" href="#introduction-4">Introduction</a></h2>
<h3 id="context-4"><a class="header" href="#context-4">Context</a></h3>
<p>This final lab brings your HCI project to completion. Over the past six weeks you have:</p>
<ol>
<li><strong>Needs-finding</strong> (Week 6): Identified stakeholder needs with informed consent</li>
<li><strong>Ethics overlay</strong> (Week 7): Built a privacy-by-design feature</li>
<li><strong>Accessibility audit</strong> (Week 7): Identified and fixed WCAG 2.2 AA violations</li>
<li><strong>Constraint exploration</strong> (Week 8): Verified no-JS parity</li>
<li><strong>Evaluation</strong> (Week 9): Ran task-based pilots and collected metrics</li>
<li><strong>Analysis</strong> (Week 10): Prioritised redesign with (Impact + Inclusion) ‚Äì Effort</li>
<li><strong>Redesign &amp; verification</strong> (Week 10): Fixed priority issues and re-tested</li>
<li><strong>Studio critique</strong> (Week 11 Lab 1): Presented evidence and received peer feedback</li>
</ol>
<p>Today you will <strong>polish your work</strong>, <strong>assemble a portfolio</strong> showing complete evidence chains, and <strong>prepare for Gradescope submission</strong>. This lab emphasises <strong>traceability</strong>: every claim you make must be backed by evidence (code, metrics, screenshots, pilot notes), and every artefact must link to the design decision it supports.</p>
<h3 id="why-this-matters-5"><a class="header" href="#why-this-matters-5">Why This Matters</a></h3>
<p><strong>Professionally</strong>, portfolios demonstrate your ability to:</p>
<ul>
<li>Execute a complete HCI process (needs-finding ‚Üí evaluation ‚Üí iteration)</li>
<li>Communicate design rationale with evidence</li>
<li>Integrate accessibility and ethics from the start (not as afterthoughts)</li>
<li>Manage traceability in complex projects</li>
</ul>
<p><strong>Academically</strong>, reflective portfolios are a recognised pedagogy for consolidating learning (Carson et al., 2020). Research shows that students who explicitly connect theory (e.g., WCAG success criteria) to practice (e.g., code fixes) develop deeper understanding than those who treat labs as discrete tasks.</p>
<h2 id="learning-focus-11"><a class="header" href="#learning-focus-11">Learning Focus</a></h2>
<h3 id="lab-objectives-11"><a class="header" href="#lab-objectives-11">Lab Objectives</a></h3>
<p>By the end of this session, you will have:</p>
<ul>
<li>Assembled a portfolio showing complete evidence chains (raw data ‚Üí analysis ‚Üí fix ‚Üí verification)</li>
<li>Produced reflective writing linking theory (WCAG, privacy principles) to practice (code, metrics)</li>
<li>Reviewed all evidence chains across Tasks 1 &amp; 2</li>
<li>Completed self-assessment against all 13 Learning Outcomes</li>
<li>Verified Gradescope submission readiness (file structure, size limits, naming conventions)</li>
<li>Integrated peer critique feedback into backlog</li>
<li>Finalised portfolio with reflections</li>
</ul>
<h3 id="learning-outcomes-addressed-11"><a class="header" href="#learning-outcomes-addressed-11">Learning Outcomes Addressed</a></h3>
<p>This lab contributes to the following module Learning Outcomes (<a href="wk11/../references/learning-outcomes.html">full definitions</a>):</p>
<ul>
<li><strong>LO12</strong>: Demonstrate professionalism ‚Äî evidenced by complete, honest self-assessment</li>
<li><strong>All 13 LOs</strong> ‚Äî evidenced by portfolio demonstrating cumulative achievement across Weeks 6-11</li>
</ul>
<hr />
<h2 id="key-concepts-10"><a class="header" href="#key-concepts-10">Key Concepts</a></h2>
<h3 id="1-evidence-chain"><a class="header" href="#1-evidence-chain">1. Evidence Chain</a></h3>
<p>An <strong>evidence chain</strong> is a traceable path from raw data through analysis and decision-making to implementation and verification. In HCI, evidence chains demonstrate that design decisions are grounded in observation, not assumption.</p>
<p><strong>Example (accessible error handling)</strong>:</p>
<ol>
<li><strong>Raw data</strong>: Pilot P3 (SR user) took 127 seconds on T3 (add task); pilot notes: ‚ÄúP3 didn‚Äôt hear validation error‚Äù</li>
<li><strong>Analysis</strong>: Median for sighted pilots = 18 s; P3 MAD = 109 s outlier</li>
<li><strong>Finding</strong>: ‚ÄúValidation errors not announced by screen readers‚Äù ‚Üí backlog item</li>
<li><strong>Fix</strong>: Added <code>role="alert" aria-live="assertive"</code> to error div (commit abc123)</li>
<li><strong>Verification</strong>: Re-ran P3 with NVDA; time reduced to 22 s; pilot confirmed ‚Äúerror announced immediately‚Äù</li>
</ol>
<p><strong>Traceability requirements</strong>:</p>
<ul>
<li>Every finding must cite pilot ID, task code, and metric</li>
<li>Every fix must cite commit hash and file path</li>
<li>Every verification must cite pilot ID, assistive tech, and outcome</li>
</ul>
<h3 id="2-reflective-writing"><a class="header" href="#2-reflective-writing">2. Reflective Writing</a></h3>
<p><strong>Reflective writing</strong> connects theory to practice by answering:</p>
<ul>
<li><strong>What</strong> did I do? (Description)</li>
<li><strong>Why</strong> did I do it? (Theory/rationale)</li>
<li><strong>How</strong> did it work? (Evidence)</li>
<li><strong>What</strong> did I learn? (Insight)</li>
</ul>
<p><strong>Example (Week 7 inline edit)</strong>:</p>
<blockquote>
<p><strong>What</strong>: I implemented an accessible inline edit using HTMX‚Äôs <code>hx-target</code> and <code>hx-swap="outerHTML"</code>.
<strong>Why</strong>: This approach supports progressive enhancement (WCAG 2.1.1 Keyboard Access) because the edit form is server-rendered, so keyboard and mouse interactions are identical.
<strong>How</strong>: Manual keyboard testing confirmed that Tab navigated to the ‚ÄúEdit‚Äù button, Enter activated it, and focus moved to the title input without page refresh. NVDA announced ‚ÄúEdit task, button‚Äù and ‚ÄúTitle, edit, [existing value]‚Äù correctly.
<strong>What I learned</strong>: Server-first patterns simplify accessibility because you don‚Äôt need custom ARIA or JavaScript focus management‚Äîthe browser handles it. However, I initially forgot to add <code>aria-live="polite"</code> to the success message, which meant SR users didn‚Äôt hear confirmation. After adding it (commit xyz789), NVDA announced ‚ÄúTask updated‚Äù automatically.</p>
</blockquote>
<p><strong>Good reflective writing</strong>:</p>
<ul>
<li>Cites specific code (file paths, line numbers, commit hashes)</li>
<li>Links to theory (WCAG success criteria, HTMX docs, academic sources)</li>
<li>Includes evidence (screenshots, pilot quotes, metrics)</li>
<li>Identifies mistakes and corrections (not just successes)</li>
</ul>
<h3 id="3-portfolio-structure"><a class="header" href="#3-portfolio-structure">3. Portfolio Structure</a></h3>
<p>A <strong>portfolio</strong> is an organised collection of artefacts (code, docs, evidence) with accompanying reflection. For COMP2850, your portfolio includes:</p>
<ol>
<li><strong>Code repository</strong> (GitLab/GitHub): All commits from Week 6‚Äì11</li>
<li><strong>Evidence directory</strong>: Organised by week (<code>evidence/wk6/</code>, <code>evidence/wk7/</code>, etc.)</li>
<li><strong>assessment package</strong> (Gradescope): Consent, pilot data, findings, backlog</li>
<li><strong>assessment package</strong> (Gradescope): Prioritisation, fix commits, verification, reflection</li>
<li><strong>README</strong> or <strong>reflection doc</strong>: Narrative tying everything together</li>
</ol>
<p><strong>Portfolio quality indicators</strong>:</p>
<ul>
<li>‚úÖ Every claim has a citation (pilot ID, commit, screenshot)</li>
<li>‚úÖ Evidence is organised and easy to navigate</li>
<li>‚úÖ Code is clean (no commented-out blocks, no TODO markers)</li>
<li>‚úÖ Reflection demonstrates learning (mistakes acknowledged, theory applied)</li>
<li>‚ùå Missing evidence (e.g., ‚ÄúP2 struggled‚Äù with no pilot notes)</li>
<li>‚ùå Orphaned artefacts (e.g., screenshot with no context)</li>
<li>‚ùå Copy-paste from labs without adaptation</li>
</ul>
<h3 id="4-submission-readiness"><a class="header" href="#4-submission-readiness">4. Submission Readiness</a></h3>
<p><strong>Gradescope</strong> has technical requirements:</p>
<ul>
<li><strong>File size limit</strong>: 100 MB per submission (compress screenshots if needed)</li>
<li><strong>File naming</strong>: Use consistent, descriptive names (e.g., <code>P1_task3_console.png</code>, not <code>Screenshot 2025-01-15.png</code>)</li>
<li><strong>Directory structure</strong>: Flat or shallow hierarchy (Gradescope doesn‚Äôt preserve nested folders well)</li>
<li><strong>PDF compilation</strong>: Reflection and analysis docs should be PDF (not .docx or .md)</li>
</ul>
<p><strong>Pre-submission checklist</strong>:</p>
<ol>
<li>Run <code>du -sh evidence/</code> to check total size</li>
<li>Verify all screenshots are legible (minimum 1280√ó720 resolution)</li>
<li>Test PDF rendering (check fonts, images, code blocks)</li>
<li>Confirm commit hashes are correct (use <code>git log --oneline</code>)</li>
<li>Spell-check and proofread all written work</li>
</ol>
<hr />
<h2 id="activity-1-polish-assessment-based-on-critique-feedback"><a class="header" href="#activity-1-polish-assessment-based-on-critique-feedback">Activity 1: Polish assessment Based on Critique Feedback</a></h2>
<p><strong>Time</strong>: 30 minutes
<strong>Materials</strong>: Studio crit feedback (Lab 1), assessment draft package (Week 9)</p>
<h3 id="step-1-review-critique-feedback"><a class="header" href="#step-1-review-critique-feedback">Step 1: Review Critique Feedback</a></h3>
<p>Open your studio crit feedback notes. Look for <strong>suggestions</strong> that apply to <strong>assessment</strong> (evaluation and instrumentation). Common themes:</p>
<ul>
<li><strong>Pilot protocol clarity</strong>: ‚ÄúI wasn‚Äôt sure if consent was verbal or signed‚Äù ‚Üí add screenshot of consent script</li>
<li><strong>Metrics interpretation</strong>: ‚ÄúMedian looks fine, but no discussion of MAD outliers‚Äù ‚Üí add MAD analysis</li>
<li><strong>Evidence completeness</strong>: ‚ÄúP3 notes mention ‚Äòstruggled with SR‚Äô but no specifics‚Äù ‚Üí add verbatim quotes, timestamps</li>
<li><strong>Backlog traceability</strong>: ‚ÄúBacklog item #7 says ‚Äòfix validation‚Äô but doesn‚Äôt cite pilot data‚Äù ‚Üí add pilot ID and metric</li>
</ul>
<h3 id="step-2-update-assessment-files"><a class="header" href="#step-2-update-assessment-files">Step 2: Update assessment Files</a></h3>
<p>Your assessment package should include:</p>
<pre><code>task1/
‚îú‚îÄ‚îÄ consent-script.md          # Informed consent protocol
‚îú‚îÄ‚îÄ pilot-protocol.md          # Step-by-step task execution guide
‚îú‚îÄ‚îÄ metrics.csv                # Raw data (from data/metrics.csv)
‚îú‚îÄ‚îÄ pilot-notes/               # Qualitative observations
‚îÇ   ‚îú‚îÄ‚îÄ P1_notes.md
‚îÇ   ‚îú‚îÄ‚îÄ P2_notes.md
‚îÇ   ‚îú‚îÄ‚îÄ P3_notes.md
‚îÇ   ‚îî‚îÄ‚îÄ P4_notes.md
‚îú‚îÄ‚îÄ analysis.md                # Median, MAD, error rate, completion rate
‚îú‚îÄ‚îÄ findings.md                # Synthesised insights with evidence
‚îú‚îÄ‚îÄ backlog-update.md          # New items added to product backlog
‚îî‚îÄ‚îÄ reflection-task1.pdf       # Reflective writing (compiled)
</code></pre>
<p><strong>Action</strong>: For each critique suggestion, update the relevant file. Example:</p>
<p><strong>Before</strong> (<code>findings.md</code>):</p>
<pre><code class="language-markdown">3. Validation errors not visible to screen reader users.
</code></pre>
<p><strong>After</strong> (<code>findings.md</code>):</p>
<pre><code class="language-markdown">3. **Validation errors not announced by screen readers** (Priority 1)
   - **Evidence**: Pilot P3 (NVDA, keyboard) took 127 s on T3 (add task); median = 18 s, MAD = 10 s ‚Üí P3 is 10.9 MAD outlier. Pilot notes (line 14): "P3 submitted blank form three times; NVDA did not announce 'Title is required' error."
   - **Root cause**: Error div lacks `role="alert"` and `aria-live` region.
   - **Impact**: WCAG 4.1.3 (Status Messages) failure; SR users cannot recover from validation errors.
   - **Backlog item**: #7 "Add role=alert to validation error div" (Priority 1, Effort: 2)
</code></pre>
<h3 id="step-3-compress-and-verify"><a class="header" href="#step-3-compress-and-verify">Step 3: Compress and Verify</a></h3>
<ol>
<li>
<p><strong>Compress screenshots</strong>: If <code>pilot-notes/</code> includes large PNGs, compress them:</p>
<pre><code class="language-bash"># Using ImageMagick (if available)
mogrify -resize 1920x1080 -quality 85 pilot-notes/*.png

# Or use online tool: https://tinypng.com/
</code></pre>
</li>
<li>
<p><strong>Check total size</strong>:</p>
<pre><code class="language-bash">du -sh task1/
# Should be &lt; 50 MB for assessment alone
</code></pre>
</li>
<li>
<p><strong>Verify PDF compilation</strong>: Convert <code>reflection-task1.md</code> to PDF:</p>
<pre><code class="language-bash">pandoc reflection-task1.md -o reflection-task1.pdf --pdf-engine=xelatex

# Or use Markdown preview ‚Üí print to PDF in your editor
</code></pre>
</li>
<li>
<p><strong>Test readability</strong>: Open <code>reflection-task1.pdf</code> and check:</p>
<ul>
<li>Code blocks are formatted (monospace font, syntax highlighting preserved)</li>
<li>Screenshots are legible (not pixelated)</li>
<li>Fonts render correctly (no missing glyphs)</li>
</ul>
</li>
</ol>
<p><strong>Stop and check</strong>: Open <code>findings.md</code>. For each finding, verify:</p>
<ul>
<li>‚úÖ Pilot ID cited</li>
<li>‚úÖ Task code cited (T1, T2, T3, T4)</li>
<li>‚úÖ Metric cited (median, MAD, error rate, or qualitative quote)</li>
<li>‚úÖ WCAG criterion or privacy principle cited (if applicable)</li>
<li>‚úÖ Backlog item ID cross-referenced</li>
</ul>
<hr />
<h2 id="activity-2-assemble-assessment-portfolio"><a class="header" href="#activity-2-assemble-assessment-portfolio">Activity 2: Assemble assessment Portfolio</a></h2>
<p><strong>Time</strong>: 40 minutes
<strong>Materials</strong>: assessment draft (Week 10), regression checklist, verification pilot data, critique feedback</p>
<h3 id="step-1-review-assessment-requirements"><a class="header" href="#step-1-review-assessment-requirements">Step 1: Review assessment Requirements</a></h3>
<p>assessment focuses on <strong>redesign</strong> and <strong>verification</strong>. Your package must show:</p>
<ol>
<li><strong>Prioritisation rationale</strong>: How you scored issues with (Impact + Inclusion) ‚Äì Effort</li>
<li><strong>Implementation evidence</strong>: Commit hashes, before/after code diffs, WCAG mapping</li>
<li><strong>Regression testing</strong>: Proof that fixes didn‚Äôt break existing features</li>
<li><strong>Verification pilots</strong>: Re-ran same tasks with same assistive tech; metrics improved</li>
<li><strong>Reflection</strong>: What you learned about inclusive redesign</li>
</ol>
<h3 id="step-2-organise-assessment-files"><a class="header" href="#step-2-organise-assessment-files">Step 2: Organise assessment Files</a></h3>
<pre><code>task2/
‚îú‚îÄ‚îÄ prioritisation.md          # Scoring matrix with rationale
‚îú‚îÄ‚îÄ fixes/                     # One file per priority issue
‚îÇ   ‚îú‚îÄ‚îÄ fix01-validation-alert.md
‚îÇ   ‚îú‚îÄ‚îÄ fix02-focus-visible.md
‚îÇ   ‚îî‚îÄ‚îÄ fix03-error-summary.md
‚îú‚îÄ‚îÄ commits.md                 # List of all fix commits with hashes
‚îú‚îÄ‚îÄ regression-checklist.pdf   # Completed checklist (from Week 10)
‚îú‚îÄ‚îÄ verification/              # Re-test data
‚îÇ   ‚îú‚îÄ‚îÄ metrics-after.csv
‚îÇ   ‚îú‚îÄ‚îÄ P3_retest_notes.md
‚îÇ   ‚îî‚îÄ‚îÄ P3_retest_nvda.png     # Screenshot of NVDA announcing error
‚îú‚îÄ‚îÄ wcag-compliance.md         # Mapping fixes ‚Üí WCAG success criteria
‚îî‚îÄ‚îÄ reflection-task2.pdf       # Reflective writing
</code></pre>
<h3 id="step-3-write-fix-documentation"><a class="header" href="#step-3-write-fix-documentation">Step 3: Write Fix Documentation</a></h3>
<p>For each priority issue, create a <code>fix##-description.md</code> file. Use this template:</p>
<pre><code class="language-markdown"># Fix 01: Validation Errors Not Announced by Screen Readers

## Problem Statement
**Evidence**: Pilot P3 (NVDA, keyboard) took 127 s on T3 (add task); median = 18 s. Pilot notes: "P3 didn't hear error message."
**Impact**: WCAG 4.1.3 (Status Messages) failure. SR users cannot recover from validation errors.
**Priority score**: (5 Impact + 5 Inclusion) ‚Äì 2 Effort = 8 (Priority 1)

## Solution
Added `role="alert"` and `aria-live="assertive"` to error div for HTMX path; added error summary for no-JS path.

### Before (Commit 7a3f9b2)
```kotlin
// routes/Tasks.kt, line 45
if (title.isBlank()) {
    if (call.isHtmx()) {
        val status = """&lt;div id="status" hx-swap-oob="true"&gt;Title is required.&lt;/div&gt;"""
        return@post call.respondText(status, ContentType.Text.Html, HttpStatusCode.BadRequest)
    }
    // No-JS path omitted for brevity
}
</code></pre>
<h3 id="after-commit-c8d1e4f"><a class="header" href="#after-commit-c8d1e4f">After (Commit c8d1e4f)</a></h3>
<pre><code class="language-kotlin">// routes/Tasks.kt, line 45
if (title.isBlank()) {
    if (call.isHtmx()) {
        val status = """&lt;div id="status" role="alert" aria-live="assertive" hx-swap-oob="true"&gt;
            Title is required. Please enter at least one character.
        &lt;/div&gt;"""
        return@post call.respondText(status, ContentType.Text.Html, HttpStatusCode.BadRequest)
    }
    // No-JS: redirect to /tasks?error=title, error-summary.peb includes role=alert
}
</code></pre>
<h3 id="wcag-mapping"><a class="header" href="#wcag-mapping">WCAG Mapping</a></h3>
<ul>
<li><strong>4.1.3 Status Messages (AA)</strong>: Error is now programmatically announced to SR users without focus change.</li>
<li><strong>3.3.1 Error Identification (A)</strong>: Error message explicitly states what went wrong and how to fix it.</li>
</ul>
<h2 id="verification-2"><a class="header" href="#verification-2">Verification</a></h2>
<p><strong>Re-test</strong>: Pilot P3, NVDA 2024.1, keyboard-only, JS-on
<strong>Result</strong>: Time reduced to 22 s (within 1 MAD of median). NVDA announced ‚ÄúTitle is required‚Äù immediately after form submission. P3 confirmed: ‚ÄúMuch better‚ÄîI heard the error straight away.‚Äù</p>
<p><strong>Regression</strong>: Keyboard, mouse, no-JS paths all tested; no regressions (see <code>regression-checklist.pdf</code>).</p>
<h2 id="reflection"><a class="header" href="#reflection">Reflection</a></h2>
<p>This fix taught me that <strong>announcements require explicit ARIA roles</strong>. I initially assumed HTMX‚Äôs OOB swap would be enough, but SR users rely on live regions to detect dynamic changes. The fix was simple (2 lines), but the impact was huge (10.9 MAD outlier ‚Üí within normal range). This reinforces the principle that <strong>accessibility is often low-effort if designed in from the start</strong>, but expensive to retrofit.</p>
<hr />
<p><strong>Commit</strong>: c8d1e4f
<strong>Files changed</strong>: <code>routes/Tasks.kt</code> (line 45‚Äì52), <code>views/error-summary.peb</code> (added)
<strong>Evidence</strong>: <code>verification/P3_retest_nvda.png</code>, <code>verification/P3_retest_notes.md</code></p>
<pre><code>
**Repeat for all priority fixes** (typically 3‚Äì5 issues).

### Step 4: Complete Regression Checklist

Your regression checklist from Week 10 Lab 2 should be converted to PDF. If incomplete, fill it out now:

| Test | Path | Tool | Result | Notes |
|------|------|------|--------|-------|
| T1 (Filter) | HTMX, mouse | Chrome | ‚úÖ Pass | Filters apply instantly; status updates in #status div |
| T1 (Filter) | No-JS | Chrome | ‚úÖ Pass | Form submission triggers full-page reload; filters persist in query string |
| T2 (Edit) | HTMX, keyboard | Firefox + NVDA | ‚úÖ Pass | Tab to "Edit", Enter activates; focus moves to input; NVDA announces "Title, edit, [value]" |
| T3 (Add) | HTMX, keyboard | Firefox + NVDA | ‚úÖ Pass | Blank submission triggers alert; NVDA announces error |
| T3 (Add) | No-JS | Chrome | ‚úÖ Pass | Redirect to /tasks?error=title; error summary shown with focus on heading |
| T4 (Delete) | HTMX, mouse | Chrome | ‚úÖ Pass | OOB swap removes `&lt;li&gt;`; status confirms deletion |

**Save as PDF**: `regression-checklist.pdf`

### Step 5: Update WCAG Compliance Doc

Create `wcag-compliance.md` mapping all fixes to WCAG 2.2 AA criteria:

```markdown
# WCAG 2.2 AA Compliance Summary

## Level A (Baseline)
- **1.3.1 Info &amp; Relationships**: Semantic HTML (`&lt;button&gt;`, `&lt;label&gt;`, `&lt;ul&gt;`) used throughout; verified with axe DevTools.
- **2.1.1 Keyboard**: All interactive elements accessible via Tab/Enter/Space; no keyboard traps (tested with Firefox + NVDA).
- **3.3.1 Error Identification**: Validation errors explicitly describe problem and solution ("Title is required. Please enter at least one character.").
- **4.1.2 Name, Role, Value**: All form inputs have associated labels; buttons have accessible names.

## Level AA (Target)
- **1.4.3 Contrast (Minimum)**: Error text (`#d32f2f`) on white background = 5.2:1 (tested with Colour Contrast Analyser).
- **2.4.7 Focus Visible**: Custom focus outline (3px solid `#1976d2`) added to all interactive elements (CSS line 45).
- **3.3.3 Error Suggestion**: Validation messages include corrective hint ("Please enter at least one character").
- **4.1.3 Status Messages**: Alerts use `role="alert" aria-live="assertive"`; success messages use `aria-live="polite"`.

## Fixes Mapped to Criteria
| Fix | WCAG Criterion | Commit | Verification |
|-----|---------------|--------|-------------|
| Validation alert | 4.1.3 (AA) | c8d1e4f | P3 retest (NVDA announced error) |
| Focus visible | 2.4.7 (AA) | b9a2c3d | Keyboard-only pilot (focus outline visible) |
| Error summary (no-JS) | 3.3.1 (A) | e7f8a1b | No-JS pilot (error list shown, focus on heading) |

---
**Reference**: [WCAG 2.2 Quick Reference](https://www.w3.org/WAI/WCAG22/quickref/)
</code></pre>
<h3 id="step-6-write-assessment-reflection"><a class="header" href="#step-6-write-assessment-reflection">Step 6: Write assessment Reflection</a></h3>
<p>Your <code>reflection-task2.md</code> should answer:</p>
<ol>
<li><strong>What redesign approach did you take?</strong> (Prioritisation framework, fix strategy)</li>
<li><strong>Why these fixes?</strong> (Link to evidence: metrics, pilot quotes, WCAG criteria)</li>
<li><strong>How did you verify impact?</strong> (Re-test results, regression checks)</li>
<li><strong>What did you learn?</strong> (Insights about accessibility, trade-offs, server-first architecture)</li>
</ol>
<p><strong>Example structure</strong> (aim for 800‚Äì1,000 words):</p>
<pre><code class="language-markdown"># assessment Reflection: Inclusive Redesign

## Overview
After analysing pilot data from Week 9, I identified 8 accessibility and usability issues. Using the (Impact + Inclusion) ‚Äì Effort prioritisation framework, I focused on the top 3 issues that disproportionately affected screen reader users and keyboard-only users...

## Prioritisation Rationale
I scored each issue on three dimensions:
- **Impact** (1‚Äì5): How much does this block task completion?
- **Inclusion** (1‚Äì5): Does this disproportionately affect people using assistive tech?
- **Effort** (1‚Äì5): How complex is the fix?

The highest-scoring issue was "Validation errors not announced by SR" (Priority: 8). Pilot P3 took 127 s on T3 (median = 18 s), and pilot notes (line 14) stated: "P3 didn't hear error; submitted blank form three times." This is a WCAG 4.1.3 failure (Status Messages) and blocks task completion entirely for SR users...

## Implementation
I implemented three priority fixes:

### Fix 1: Validation Alerts (Commit c8d1e4f)
**Problem**: Error div lacked `role="alert"` and `aria-live` region.
**Solution**: Added `role="alert" aria-live="assertive"` to HTMX error swap (routes/Tasks.kt:47); added error summary with `role="alert"` for no-JS path (views/error-summary.peb).
**Theory**: WCAG 4.1.3 requires status messages to be programmatically announced. ARIA live regions solve this without moving focus (which would disrupt flow).
**Result**: P3 retest reduced time to 22 s (within 1 MAD); NVDA announced error immediately...

[Continue for Fix 2, Fix 3]

## Verification &amp; Regression
I re-ran Pilot P3 with the same tasks (T1‚ÄìT4), assistive tech (NVDA 2024.1), and input method (keyboard-only). Time on T3 dropped from 127 s to 22 s, and P3 confirmed "error announced immediately" (see verification/P3_retest_notes.md).

I also completed a regression checklist covering HTMX, no-JS, keyboard, and mouse paths (see regression-checklist.pdf). No regressions were detected...

## Learning &amp; Trade-offs
This project taught me that **server-first architecture simplifies accessibility** because HTML is semantic by default, and the browser handles focus/tab order/SR announcements. However, I discovered one trade-off: HTMX's OOB swaps don't trigger live region announcements unless you explicitly add `role="alert"`. This is documented in hypermedia.systems (Ch. 9), but I missed it initially.

I also learned that **prioritisation frameworks are essential** when time is limited. I could have fixed all 8 issues, but focusing on the top 3 (total effort: 6 hours) yielded the biggest impact (removed all SR blockers). The remaining 5 issues are in my backlog for Semester 2...

## Conclusion
By grounding decisions in pilot data (median, MAD, qualitative notes) and WCAG criteria, I built an inclusive task manager that works identically with/without JS, with/without a mouse, and with/without a screen reader. This process reinforced that accessibility is not a feature‚Äîit's a design constraint that improves usability for everyone.
</code></pre>
<p><strong>Save as</strong>: <code>reflection-task2.md</code> ‚Üí compile to <code>reflection-task2.pdf</code>.</p>
<p><strong>Stop and check</strong>: Open <code>task2/fixes/</code>. For each fix file, verify:</p>
<ul>
<li>‚úÖ Problem statement cites pilot data (ID, task, metric)</li>
<li>‚úÖ Solution includes before/after code with commit hash</li>
<li>‚úÖ WCAG criterion mapped</li>
<li>‚úÖ Verification evidence cited (retest pilot, screenshot)</li>
<li>‚úÖ Reflection identifies learning or trade-off</li>
</ul>
<hr />
<h2 id="activity-3-final-repository--evidence-review"><a class="header" href="#activity-3-final-repository--evidence-review">Activity 3: Final Repository &amp; Evidence Review</a></h2>
<p><strong>Time</strong>: 20 minutes
<strong>Materials</strong>: Git log, <code>evidence/</code> directory, README</p>
<h3 id="step-1-review-commit-history"><a class="header" href="#step-1-review-commit-history">Step 1: Review Commit History</a></h3>
<p>Run <code>git log --oneline --since="2025-01-01"</code> to see all commits from Weeks 6‚Äì11. Check for:</p>
<ul>
<li>‚úÖ Descriptive commit messages (e.g., ‚ÄúAdd role=alert to validation error (WCAG 4.1.3)‚Äù not ‚Äúfix bug‚Äù)</li>
<li>‚úÖ Consistent branch strategy (e.g., all work on <code>main</code>, or feature branches merged cleanly)</li>
<li>‚ùå Merge conflicts left unresolved</li>
<li>‚ùå Sensitive data in history (e.g., API keys, database passwords)</li>
</ul>
<p>If you find issues, clean them up now:</p>
<pre><code class="language-bash"># Amend last commit message
git commit --amend -m "Add ARIA live region to error div (WCAG 4.1.3)"

# Rebase to clean up history (use with caution)
git rebase -i HEAD~5  # Interactive rebase for last 5 commits
</code></pre>
<p><strong>Create <code>commits.md</code></strong> for assessment package:</p>
<pre><code class="language-markdown"># Commit Log: assessment Fixes

| Commit | Date | Description | Files |
|--------|------|-------------|-------|
| c8d1e4f | 2025-01-10 | Add role=alert to validation error (WCAG 4.1.3) | routes/Tasks.kt, views/error-summary.peb |
| b9a2c3d | 2025-01-11 | Add focus-visible outline (WCAG 2.4.7) | static/style.css |
| e7f8a1b | 2025-01-12 | Add error summary for no-JS path (WCAG 3.3.1) | views/error-summary.peb, routes/Tasks.kt |

**Full log**: `git log --oneline --since="2025-01-06" --until="2025-01-12"`
</code></pre>
<h3 id="step-2-audit-evidence-directory"><a class="header" href="#step-2-audit-evidence-directory">Step 2: Audit Evidence Directory</a></h3>
<p>Your <code>evidence/</code> folder should be organised by week:</p>
<pre><code>evidence/
‚îú‚îÄ‚îÄ wk6/
‚îÇ   ‚îú‚îÄ‚îÄ consent-screenshot.png
‚îÇ   ‚îî‚îÄ‚îÄ backlog-before.png
‚îú‚îÄ‚îÄ wk7/
‚îÇ   ‚îú‚îÄ‚îÄ axe-audit-before.png
‚îÇ   ‚îú‚îÄ‚îÄ axe-audit-after.png
‚îÇ   ‚îî‚îÄ‚îÄ inline-edit-demo.png
‚îú‚îÄ‚îÄ wk8/
‚îÇ   ‚îú‚îÄ‚îÄ nojs-verification.png
‚îÇ   ‚îî‚îÄ‚îÄ dual-path-trace.md
‚îú‚îÄ‚îÄ wk9/
‚îÇ   ‚îú‚îÄ‚îÄ P1_console.png
‚îÇ   ‚îú‚îÄ‚îÄ P2_console.png
‚îÇ   ‚îú‚îÄ‚îÄ P3_nvda_console.png
‚îÇ   ‚îú‚îÄ‚îÄ P4_nojs_console.png
‚îÇ   ‚îî‚îÄ‚îÄ metrics.csv
‚îú‚îÄ‚îÄ wk10/
‚îÇ   ‚îú‚îÄ‚îÄ prioritisation-matrix.png
‚îÇ   ‚îú‚îÄ‚îÄ fix01-before.png
‚îÇ   ‚îú‚îÄ‚îÄ fix01-after.png
‚îÇ   ‚îî‚îÄ‚îÄ regression-checklist.pdf
‚îî‚îÄ‚îÄ wk11/
    ‚îú‚îÄ‚îÄ crit-slides.pdf
    ‚îú‚îÄ‚îÄ P3_retest_nvda.png
    ‚îî‚îÄ‚îÄ reflection-final.pdf
</code></pre>
<p><strong>Action</strong>: For each directory, check:</p>
<ol>
<li><strong>File naming</strong>: Descriptive, not generic (e.g., <code>P3_nvda_console.png</code> not <code>screenshot.png</code>)</li>
<li><strong>Legibility</strong>: Open each image; confirm text is readable (min 1280√ó720)</li>
<li><strong>Context</strong>: Create a <code>README.md</code> in each week‚Äôs folder explaining what each file is</li>
</ol>
<p><strong>Example</strong> (<code>evidence/wk9/README.md</code>):</p>
<pre><code class="language-markdown"># Week 9 Evidence: Evaluation &amp; Pilots

- **P1_console.png**: Browser console for Pilot 1 (HTMX, mouse, JS-on); shows Logger entries for T3, T1, T2, T4.
- **P2_console.png**: Browser console for Pilot 2 (HTMX, keyboard, JS-on).
- **P3_nvda_console.png**: Combined screenshot showing NVDA speech viewer + browser console for Pilot 3 (SR, keyboard, JS-on). Note NVDA did NOT announce validation error (fixed in Week 10).
- **P4_nojs_console.png**: Browser console for Pilot 4 (no-JS, mouse); shows full-page reloads on form submit.
- **metrics.csv**: Raw data exported from `data/metrics.csv` after all pilots completed.
</code></pre>
<h3 id="step-3-update-repository-readme"><a class="header" href="#step-3-update-repository-readme">Step 3: Update Repository README</a></h3>
<p>Your main <code>README.md</code> should provide a <strong>portfolio navigation guide</strong>. Example:</p>
<pre><code class="language-markdown"># COMP2850 HCI: Task Manager with Privacy by Design

**Student**: [Your Name]
**Module**: COMP2850 Human-Computer Interaction, University of Leeds
**Academic Year**: 2024/25

---

## Project Overview

This repository contains a **task manager web application** built with **Kotlin/Ktor + HTMX**, demonstrating:
- **Privacy by design**: Anonymous session IDs, no PII collected, UK GDPR compliance
- **WCAG 2.2 AA compliance**: Accessible to keyboard, screen reader, and no-JS users
- **Server-first architecture**: HTML rendered server-side, progressive enhancement with HTMX
- **Evidence-led design**: Evaluated via task-based pilots (n=4); redesigned based on metrics

---

## Portfolio Structure

### Code &amp; Application
- **`src/`**: Kotlin/Ktor routes, models, utilities
- **`views/`**: Pebble templates (HTML)
- **`static/`**: CSS, JS (minimal), HTMX library
- **`data/`**: Anonymised session + metrics CSVs
- **`test/`**: Unit tests (not covered in labs)

### Evidence (by week)
- **`evidence/wk6/`**: Needs-finding, consent protocol, backlog initialisation
- **`evidence/wk7/`**: Ethics overlay (session IDs), accessibility audit (axe DevTools), inline edit fix
- **`evidence/wk8/`**: No-JS verification, dual-path routing, trade-offs doc
- **`evidence/wk9/`**: Pilot protocol, raw metrics, pilot notes, qualitative findings
- **`evidence/wk10/`**: Prioritisation matrix, fix commits, regression checklist, verification pilots
- **`evidence/wk11/`**: Studio crit slides, peer feedback, final reflection

### Gradescope Submissions
- **`task1/`**: Evaluation package (consent, pilots, analysis, findings, backlog)
- **`task2/`**: Redesign package (prioritisation, fixes, verification, reflection)

---

## Key Features

1. **Privacy by Design** (Week 6‚Äì7)
   - Anonymous session IDs (12-char hex) stored in cookies
   - No usernames, emails, or PII collected
   - Data stored in local CSV (not cloud database) with UK GDPR justification

2. **WCAG 2.2 AA Compliance** (Week 7, 10)
   - Semantic HTML (`&lt;button&gt;`, `&lt;label&gt;`, `&lt;ul&gt;`)
   - Keyboard accessible (Tab, Enter, Space)
   - Screen reader tested (NVDA 2024.1, VoiceOver)
   - Error handling: `role="alert" aria-live="assertive"`
   - Focus visible: Custom outline (3px solid #1976d2)

3. **Server-First + HTMX** (Week 6, 8)
   - All state managed server-side (tasks stored in `data/tasks.csv`)
   - HTMX handles dynamic updates (`hx-post`, `hx-target`, `hx-swap`)
   - No-JS parity: All features work with JS disabled (verified in Week 8)

4. **Evaluation &amp; Iteration** (Week 9‚Äì10)
   - Task-based pilots (n=4): T1 (filter), T2 (edit), T3 (add), T4 (delete)
   - Metrics: Median = 18 s, MAD = 10 s; P3 (SR) outlier = 127 s
   - Prioritised fixes: (Impact + Inclusion) ‚Äì Effort scoring
   - Verification: P3 retest reduced to 22 s (within 1 MAD)

---

## Running the Application

```bash
# Prerequisites: JDK 21+, Gradle 8+
./gradlew run

# Application starts on http://localhost:8080/tasks
</code></pre>
<p><strong>Test with different modes</strong>:</p>
<ul>
<li><strong>HTMX + mouse</strong>: Default behaviour (Chrome, Firefox)</li>
<li><strong>HTMX + keyboard</strong>: Tab to navigate, Enter/Space to activate</li>
<li><strong>Screen reader</strong>: NVDA (Windows), VoiceOver (macOS)</li>
<li><strong>No-JS</strong>: Disable JS in browser DevTools (F12 ‚Üí Settings ‚Üí Disable JavaScript)</li>
</ul>
<hr />
<h2 id="commit-highlights"><a class="header" href="#commit-highlights">Commit Highlights</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Commit</th><th>Week</th><th>Description</th></tr></thead><tbody>
<tr><td>abc123</td><td>6</td><td>Initial scaffold: routes, Pebble templates, HTMX setup</td></tr>
<tr><td>def456</td><td>6</td><td>Add session ID generation + cookie storage</td></tr>
<tr><td>ghi789</td><td>7</td><td>Add Logger for metrics instrumentation</td></tr>
<tr><td>jkl012</td><td>7</td><td>Fix inline edit accessibility (focus + ARIA)</td></tr>
<tr><td>mno345</td><td>8</td><td>Add dual-path validation (HTMX + no-JS)</td></tr>
<tr><td>pqr678</td><td>10</td><td>Add role=alert to error div (WCAG 4.1.3)</td></tr>
<tr><td>stu901</td><td>10</td><td>Add focus-visible outline (WCAG 2.4.7)</td></tr>
</tbody></table>
</div>
<p><strong>Full log</strong>: <code>git log --oneline</code></p>
<hr />
<h2 id="references-1"><a class="header" href="#references-1">References</a></h2>
<ul>
<li><strong>HTMX</strong>: <a href="https://hypermedia.systems/">hypermedia.systems</a> (Carson Gross, 2023)</li>
<li><strong>WCAG 2.2</strong>: <a href="https://www.w3.org/WAI/WCAG22/quickref/">W3C Quick Reference</a></li>
<li><strong>Privacy by Design</strong>: <a href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/">ICO Guide</a></li>
<li><strong>Ktor</strong>: <a href="https://ktor.io/">ktor.io</a></li>
<li><strong>Pebble Templates</strong>: <a href="https://pebbletemplates.io/">pebbletemplates.io</a></li>
</ul>
<hr />
<h2 id="acknowledgements"><a class="header" href="#acknowledgements">Acknowledgements</a></h2>
<ul>
<li><strong>Module staff</strong>: Dr. [Name], teaching assistants</li>
<li><strong>Peers</strong>: Studio crit feedback from [Team Names]</li>
<li><strong>Tools</strong>: axe DevTools, NVDA, Colour Contrast Analyser, curl</li>
</ul>
<hr />
<p><strong>Licence</strong>: Academic work for COMP2850 (not for redistribution)</p>
<pre><code>
**Stop and check**: Open `README.md` in your repo. Verify:
- ‚úÖ Project overview explains what you built and why
- ‚úÖ Portfolio structure lists all key directories
- ‚úÖ Running instructions work (test with `./gradlew run`)
- ‚úÖ Commit highlights cite key milestones
- ‚úÖ References cite all external sources (HTMX, WCAG, academic papers)

---

## Activity 4: Practice Gradescope Submission

**Time**: 20 minutes
**Materials**: assessment and assessment packages, Gradescope test environment (if available)

### Step 1: Check File Size Limits

Gradescope has a **100 MB limit per submission**. Check your package sizes:

```bash
du -sh task1/
du -sh task2/

# If over 50 MB, identify large files
du -ah task1/ | sort -rh | head -n 10
du -ah task2/ | sort -rh | head -n 10
</code></pre>
<p><strong>Common culprits</strong>:</p>
<ul>
<li>Uncompressed screenshots (5‚Äì10 MB each)</li>
<li>Video recordings (not required; remove or compress heavily)</li>
<li>Database dumps (not required; use <code>metrics.csv</code> only)</li>
</ul>
<p><strong>Compression tips</strong>:</p>
<pre><code class="language-bash"># Compress PNGs with ImageMagick
mogrify -resize 1920x1080 -quality 85 task1/**/*.png task2/**/*.png

# Or use online tool: https://tinypng.com/

# Compress PDFs with Ghostscript
gs -sDEVICE=pdfwrite -dCompatibilityLevel=1.4 -dPDFSETTINGS=/screen \
   -dNOPAUSE -dQUIET -dBATCH \
   -sOutputFile=reflection-compressed.pdf reflection-task1.pdf
</code></pre>
<h3 id="step-2-create-submission-zips"><a class="header" href="#step-2-create-submission-zips">Step 2: Create Submission ZIPs</a></h3>
<p>Gradescope typically requires a <strong>single ZIP per task</strong>. Create them:</p>
<pre><code class="language-bash"># assessment
cd task1/
zip -r ../task1-submission.zip .
cd ..

# assessment
cd task2/
zip -r ../task2-submission.zip .
cd ..

# Verify contents
unzip -l task1-submission.zip
unzip -l task2-submission.zip
</code></pre>
<p><strong>Check</strong>:</p>
<ul>
<li>‚úÖ All required files present (consent, pilots, analysis, reflection)</li>
<li>‚úÖ No extra files (e.g., <code>.DS_Store</code>, <code>Thumbs.db</code>, <code>__MACOSX/</code>)</li>
<li>‚úÖ File paths are flat or shallow (Gradescope doesn‚Äôt always preserve deep nesting)</li>
</ul>
<h3 id="step-3-test-upload-dry-run"><a class="header" href="#step-3-test-upload-dry-run">Step 3: Test Upload (Dry Run)</a></h3>
<p>If Gradescope has a <strong>draft/test assignment</strong>, upload your ZIPs there. Otherwise, do a local dry run:</p>
<ol>
<li>
<p><strong>Simulate grader view</strong>: Extract your ZIP in a temp directory and navigate it as if you‚Äôre a marker:</p>
<pre><code class="language-bash">mkdir /tmp/grader-test
cd /tmp/grader-test
unzip ~/comp2850/task1-submission.zip

# Open files in order:
# 1. consent-script.md
# 2. pilot-protocol.md
# 3. analysis.md
# 4. findings.md
# 5. reflection-task1.pdf
</code></pre>
</li>
<li>
<p><strong>Check cross-references</strong>: Do all citations work? (e.g., ‚ÄúSee P3_notes.md line 14‚Äù ‚Üí open that file and verify line 14 exists)</p>
</li>
<li>
<p><strong>Verify PDFs</strong>: Open <code>reflection-task1.pdf</code> and <code>reflection-task2.pdf</code>:</p>
<ul>
<li>‚úÖ Code blocks formatted correctly</li>
<li>‚úÖ Screenshots embedded and legible</li>
<li>‚úÖ Page numbers visible (if multi-page)</li>
<li>‚úÖ No truncated text or missing images</li>
</ul>
</li>
</ol>
<h3 id="step-4-pre-submission-checklist"><a class="header" href="#step-4-pre-submission-checklist">Step 4: Pre-Submission Checklist</a></h3>
<p>Print this checklist and tick off each item:</p>
<p><strong>assessment (Evaluation)</strong></p>
<ul>
<li><input disabled="" type="checkbox"/>
<code>consent-script.md</code> includes informed consent protocol</li>
<li><input disabled="" type="checkbox"/>
<code>pilot-protocol.md</code> includes step-by-step task execution guide</li>
<li><input disabled="" type="checkbox"/>
<code>metrics.csv</code> is anonymised (no real names, emails)</li>
<li><input disabled="" type="checkbox"/>
<code>pilot-notes/</code> includes 4 files (P1, P2, P3, P4) with timestamps and quotes</li>
<li><input disabled="" type="checkbox"/>
<code>analysis.md</code> includes median, MAD, error rate, completion rate</li>
<li><input disabled="" type="checkbox"/>
<code>findings.md</code> synthesises insights with pilot citations</li>
<li><input disabled="" type="checkbox"/>
<code>backlog-update.md</code> lists new items added, with priority scores</li>
<li><input disabled="" type="checkbox"/>
<code>reflection-task1.pdf</code> compiled, readable, includes code examples and theory links</li>
<li><input disabled="" type="checkbox"/>
Total size &lt; 50 MB</li>
<li><input disabled="" type="checkbox"/>
All commit hashes correct (<code>git log --oneline</code> to verify)</li>
</ul>
<p><strong>assessment (Redesign)</strong></p>
<ul>
<li><input disabled="" type="checkbox"/>
<code>prioritisation.md</code> includes scoring matrix with rationale</li>
<li><input disabled="" type="checkbox"/>
<code>fixes/</code> directory includes one file per priority issue (typically 3‚Äì5)</li>
<li><input disabled="" type="checkbox"/>
<code>commits.md</code> lists all fix commits with hashes and files changed</li>
<li><input disabled="" type="checkbox"/>
<code>regression-checklist.pdf</code> completed and signed off</li>
<li><input disabled="" type="checkbox"/>
<code>verification/</code> includes retest data (metrics, pilot notes, screenshots)</li>
<li><input disabled="" type="checkbox"/>
<code>wcag-compliance.md</code> maps fixes to WCAG 2.2 success criteria</li>
<li><input disabled="" type="checkbox"/>
<code>reflection-task2.pdf</code> compiled, readable, includes before/after code and learning insights</li>
<li><input disabled="" type="checkbox"/>
Total size &lt; 50 MB</li>
<li><input disabled="" type="checkbox"/>
All WCAG criteria correctly cited (check against <a href="https://www.w3.org/WAI/WCAG22/quickref/">W3C Quick Reference</a>)</li>
</ul>
<p><strong>Repository</strong></p>
<ul>
<li><input disabled="" type="checkbox"/>
<code>README.md</code> includes portfolio navigation and running instructions</li>
<li><input disabled="" type="checkbox"/>
<code>evidence/</code> organised by week with descriptive file names</li>
<li><input disabled="" type="checkbox"/>
Commit history clean (no sensitive data, descriptive messages)</li>
<li><input disabled="" type="checkbox"/>
Application runs locally (<code>./gradlew run</code> works)</li>
</ul>
<h3 id="step-5-backup-strategy"><a class="header" href="#step-5-backup-strategy">Step 5: Backup Strategy</a></h3>
<p>Before assessment refinement:</p>
<ol>
<li>
<p><strong>Tag your repository</strong>:</p>
<pre><code class="language-bash">git tag -a v1.0-task1 -m "assessment submission (2025-01-15)"
git tag -a v1.0-task2 -m "assessment submission (2025-01-17)"
git push origin --tags
</code></pre>
</li>
<li>
<p><strong>Create backup ZIPs</strong> with date stamps:</p>
<pre><code class="language-bash">cp task1-submission.zip task1-submission-2025-01-15.zip
cp task2-submission.zip task2-submission-2025-01-17.zip
</code></pre>
</li>
<li>
<p><strong>Upload to cloud</strong> (optional but recommended):</p>
<ul>
<li>University OneDrive, Google Drive, or Dropbox</li>
<li>Keeps a timestamped copy in case Gradescope has issues</li>
</ul>
</li>
</ol>
<p><strong>Stop and check</strong>: Unzip <code>task1-submission.zip</code> and <code>task2-submission.zip</code> in a temp directory. Open <code>reflection-task1.pdf</code> and <code>reflection-task2.pdf</code>. For each:</p>
<ul>
<li>‚úÖ All pages render correctly</li>
<li>‚úÖ Code blocks use monospace font</li>
<li>‚úÖ Screenshots are legible (text readable at 100% zoom)</li>
<li>‚úÖ File size &lt; 20 MB each</li>
</ul>
<hr />
<h2 id="activity-5-module-reflection--semester-2-planning"><a class="header" href="#activity-5-module-reflection--semester-2-planning">Activity 5: Module Reflection &amp; Semester 2 Planning</a></h2>
<p><strong>Time</strong>: 20 minutes
<strong>Materials</strong>: Lab notes from Weeks 6‚Äì11, backlog, peer feedback</p>
<h3 id="step-1-self-assessment--learning-outcomes"><a class="header" href="#step-1-self-assessment--learning-outcomes">Step 1: Self-Assessment ‚Äî Learning Outcomes</a></h3>
<p>Review your evidence against all <strong>13 HCI Learning Outcomes</strong> you‚Äôve addressed across Weeks 6-11. Rate your confidence (1 = not confident, 5 = very confident) and note where the evidence lives.</p>
<p>See <a href="wk11/../references/learning-outcomes.html">Learning Outcomes Reference</a> for full LO definitions.</p>
<div class="table-wrapper"><table><thead><tr><th>LO</th><th>Outcome</th><th>Confidence (1‚Äì5)</th><th>Evidence Location</th></tr></thead><tbody>
<tr><td><strong>LO1</strong></td><td>Differentiate people-centred methods</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W6 L2 job stories, W9 L1 eval plan</td></tr>
<tr><td><strong>LO2</strong></td><td>Design and conduct needs-finding</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W6 L2 consent protocol</td></tr>
<tr><td><strong>LO3</strong></td><td>Analyse ethical implications</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W7 L1 consent modal, privacy audit</td></tr>
<tr><td><strong>LO4</strong></td><td>Evaluate for accessibility</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W7 L2 axe audit, WCAG map</td></tr>
<tr><td><strong>LO5</strong></td><td>Create prototypes</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W8 L1 HTMX features</td></tr>
<tr><td><strong>LO6</strong></td><td>Apply iterative design</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W9 L2 pilots ‚Üí W10 L2 redesign</td></tr>
<tr><td><strong>LO7</strong></td><td>Analyse design constraints</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W8 L2 no-JS trade-offs doc</td></tr>
<tr><td><strong>LO8</strong></td><td>Design and execute evaluation</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W9 L1 metrics + W9 L2 pilots</td></tr>
<tr><td><strong>LO9</strong></td><td>Apply inclusive design</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W7 L2 fix, W10 L2 redesign</td></tr>
<tr><td><strong>LO10</strong></td><td>Critique societal impacts</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W7 L1 ethics reflection</td></tr>
<tr><td><strong>LO11</strong></td><td>Collaborate in teams</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W9 L2 peer pilots, W11 L1 crit</td></tr>
<tr><td><strong>LO12</strong></td><td>Demonstrate professionalism</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>All labs: consent, citations</td></tr>
<tr><td><strong>LO13</strong></td><td>Integrate HCI with SE</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W8 L1 Ktor patterns, W9 L1 instrumentation</td></tr>
</tbody></table>
</div>
<p><strong>Confidence scale</strong>: 1 = Not confident, 3 = Moderately confident, 5 = Very confident</p>
<p><strong>Reflection prompt</strong>:</p>
<ol>
<li>For each LO, locate your evidence (code, docs, reflections)</li>
<li>Note any gaps ‚Äî do you have weak evidence for any LO?</li>
<li>For any outcome rated &lt; 4, what would help you improve? (More practice, more reading, more feedback?)</li>
</ol>
<h3 id="step-2-identify-key-insights"><a class="header" href="#step-2-identify-key-insights">Step 2: Identify Key Insights</a></h3>
<p>Write <strong>3‚Äì5 bullet points</strong> summarising what you learned:</p>
<p><strong>Example</strong>:</p>
<ul>
<li><strong>Server-first simplifies accessibility</strong>: By rendering HTML server-side, I avoided complex ARIA management and focus trapping. This reinforced that progressive enhancement (start with HTML, add JS sparingly) is faster and more robust than JS-heavy SPAs.</li>
<li><strong>Evidence changes everything</strong>: Before Week 9 pilots, I thought my task manager was ‚Äúfine‚Äù. Metrics revealed a 10.9 MAD outlier for SR users, forcing me to confront assumptions. Quantitative + qualitative data is essential for inclusive design.</li>
<li><strong>Prioritisation is a skill</strong>: I wanted to fix all 8 issues, but (Impact + Inclusion) ‚Äì Effort scoring helped me focus on the 3 that mattered most. This taught me that good design isn‚Äôt about perfection‚Äîit‚Äôs about impact per unit of effort.</li>
<li><strong>Accessibility is iterative</strong>: My first fix (adding <code>role="alert"</code>) didn‚Äôt work because I forgot <code>aria-live</code>. After reading WCAG 4.1.3 and testing with NVDA, I corrected it. This trial-and-error process is normal and valuable.</li>
<li><strong>Reflection cements learning</strong>: Writing 1,500 words about my redesign forced me to connect theory (WCAG) to practice (code) in a way that coding alone didn‚Äôt. Research shows that portfolios deepen understanding.</li>
</ul>
<h3 id="step-3-update-backlog-for-semester-2"><a class="header" href="#step-3-update-backlog-for-semester-2">Step 3: Update Backlog for Semester 2</a></h3>
<p>Your product backlog should include:</p>
<ol>
<li><strong>Unfinished Week 11 items</strong> (deprioritised due to time)</li>
<li><strong>Peer feedback</strong> (from studio crit)</li>
<li><strong>New ideas</strong> (from reflection or further reading)</li>
</ol>
<p><strong>Example</strong> (backlog extract):</p>
<div class="table-wrapper"><table><thead><tr><th>ID</th><th>Description</th><th>Priority</th><th>Effort</th><th>Notes</th></tr></thead><tbody>
<tr><td>#8</td><td>Add keyboard shortcut hints (e.g., ‚ÄúPress / to focus search‚Äù)</td><td>P2</td><td>3</td><td>Feedback from peer review; improves discoverability</td></tr>
<tr><td>#9</td><td>Implement undo for task deletion</td><td>P2</td><td>4</td><td>Not in scope for assessment, but valuable for real users</td></tr>
<tr><td>#10</td><td>Add dark mode toggle (WCAG 1.4.3 compliance)</td><td>P3</td><td>5</td><td>Low priority; contrast already meets AA</td></tr>
<tr><td>#11</td><td>Explore HTMX websockets for real-time collaboration</td><td>P4</td><td>8</td><td>Stretch goal; requires learning new HTMX feature</td></tr>
<tr><td>#12</td><td>Add automated a11y tests (axe-core in CI/CD pipeline)</td><td>P1</td><td>6</td><td>High priority; prevents regressions in future work</td></tr>
</tbody></table>
</div>
<p><strong>Action</strong>: Add these items to your <code>backlog.md</code> or issue tracker (GitLab/GitHub Issues).</p>
<h3 id="step-4-write-final-reflection-optional-but-recommended"><a class="header" href="#step-4-write-final-reflection-optional-but-recommended">Step 4: Write Final Reflection (Optional but Recommended)</a></h3>
<p>If you have time, write a <strong>500-word final reflection</strong> summarising your journey from Week 6 to Week 11. Save as <code>evidence/wk11/reflection-final.md</code>.</p>
<p><strong>Prompts</strong>:</p>
<ul>
<li>What was the most challenging part of this module?</li>
<li>What surprised you about HCI or accessibility?</li>
<li>How will you apply these skills in future projects (Semester 2, internships, career)?</li>
<li>What would you do differently if you started again?</li>
</ul>
<p><strong>Example</strong> (first 150 words):</p>
<blockquote>
<p>The most challenging part of COMP2850 was shifting from ‚Äúcode-first‚Äù to ‚Äúpeople-first‚Äù thinking. In previous modules (COMP1721, COMP2811), I optimised for elegance (clean OOP, efficient algorithms). In COMP2850, I learned that <strong>usability trumps elegance</strong>. My first instinct was to build a React SPA with complex state management, but the server-first + HTMX approach forced me to prioritise simplicity and robustness. This felt uncomfortable at first‚ÄîI kept wanting to add JS‚Äîbut Week 9 pilots proved that simpler is often better. Pilot P4 (no-JS) completed tasks just as fast as Pilot P1 (HTMX + mouse), which validated the ‚Äúhypermedia as the engine of application state‚Äù philosophy from Carson Gross.</p>
<p>The biggest surprise was how <strong>cheap</strong> accessibility fixes are if you design them in from the start. Adding <code>role="alert"</code> took 2 minutes; adding it <em>after</em> building 500 lines of validation logic took 2 hours (because I had to refactor the error-handling architecture). This taught me‚Ä¶</p>
</blockquote>
<h3 id="step-5-plan-semester-2-goals"><a class="header" href="#step-5-plan-semester-2-goals">Step 5: Plan Semester 2 Goals</a></h3>
<p>COMP2850 continues in Semester 2 with advanced topics. Based on your Week 6‚Äì11 experience, set <strong>3 goals</strong>:</p>
<p><strong>Example</strong>:</p>
<ol>
<li>
<p><strong>Goal 1 (Technical)</strong>: Learn HTMX websockets to add real-time collaboration (backlog #11).</p>
<ul>
<li><strong>How</strong>: Read hypermedia.systems Ch. 11; build a prototype with 2-person task sharing.</li>
<li><strong>Why</strong>: Real-time features are common in industry (Google Docs, Figma); want to understand how to build them accessibly.</li>
</ul>
</li>
<li>
<p><strong>Goal 2 (Research)</strong>: Conduct a formal usability study (n=8, IRB approval) comparing HTMX vs React for accessibility.</p>
<ul>
<li><strong>How</strong>: Replicate Week 9 protocol with 4 HTMX pilots + 4 React pilots; compare median time + SR usability.</li>
<li><strong>Why</strong>: Interested in HCI research as a career; want to publish at CHI or ASSETS.</li>
</ul>
</li>
<li>
<p><strong>Goal 3 (Professional)</strong>: Contribute accessibility fixes to an open-source project.</p>
<ul>
<li><strong>How</strong>: Find a project with open a11y issues (e.g., on GitHub ‚Äúgood first issue‚Äù + ‚Äúaccessibility‚Äù labels); submit PR.</li>
<li><strong>Why</strong>: Build portfolio, gain experience with real-world codebases, give back to community.</li>
</ul>
</li>
</ol>
<p><strong>Action</strong>: Write these goals in <code>evidence/wk11/semester2-goals.md</code> or a personal notebook.</p>
<p><strong>Stop and check</strong>: Open your backlog (<code>backlog.md</code> or issue tracker). Verify:</p>
<ul>
<li>‚úÖ All incomplete items from Week 6‚Äì11 are listed</li>
<li>‚úÖ Peer feedback suggestions are added (with priority scores)</li>
<li>‚úÖ Semester 2 stretch goals are identified</li>
<li>‚úÖ Each item has a priority (P1‚ÄìP4) and effort estimate (1‚Äì8)</li>
</ul>
<hr />
<h2 id="semester-2-roadmap-building-on-your-foundation"><a class="header" href="#semester-2-roadmap-building-on-your-foundation">Semester 2 Roadmap: Building on Your Foundation</a></h2>
<p><strong>Overview</strong>: In Semester 1 (Weeks 6‚Äì11), you built a <strong>privacy-by-design task manager</strong> with WCAG 2.2 AA compliance, evaluated it with task-based pilots, and iterated based on evidence. Semester 2 builds on this foundation by introducing <strong>advanced HCI topics</strong>: multi-user collaboration, AI-assisted features, performance optimisation, and scaling to production. This section previews key features, technical topics, and skills development paths for Semester 2.</p>
<hr />
<h3 id="features-roadmap"><a class="header" href="#features-roadmap">Features Roadmap</a></h3>
<p>The following features represent typical Semester 2 enhancements. Your backlog (from Activity 5, Step 3) should prioritise 3‚Äì5 of these based on your learning goals.</p>
<div class="table-wrapper"><table><thead><tr><th>Feature</th><th>Description</th><th>HCI Concepts</th><th>Technical Skills</th><th>WCAG Considerations</th></tr></thead><tbody>
<tr><td><strong>1. Pagination</strong></td><td>Display 10 tasks per page with ‚ÄúPrevious/Next‚Äù navigation</td><td>Information architecture, cognitive load</td><td>Query string parameters, server-side pagination logic</td><td>WCAG 2.4.1 (Bypass Blocks), 2.4.8 (Location)</td></tr>
<tr><td><strong>2. Tag/Category System</strong></td><td>Add multiple tags per task; filter by tag</td><td>Metadata schema, faceted search</td><td>Many-to-many relationships (CSV join table or SQLite)</td><td>WCAG 4.1.2 (Name, Role, Value) for tag buttons</td></tr>
<tr><td><strong>3. Search &amp; Autocomplete</strong></td><td>Full-text search across task titles; suggest as you type</td><td>Search UX patterns, latency perception</td><td>HTMX debouncing, server-side text search</td><td>WCAG 4.1.3 (Status Messages) for result count</td></tr>
<tr><td><strong>4. Multi-User (Sessions)</strong></td><td>Multiple users with separate task lists (no login, session-based)</td><td>Privacy vs collaboration trade-offs</td><td>Session isolation, CSV partitioning by session ID</td><td>WCAG 3.3.8 (Accessible Authentication - Minimum)</td></tr>
<tr><td><strong>5. Real-Time Updates</strong></td><td>When User A adds a task, User B‚Äôs list auto-updates (via WebSockets)</td><td>Shared awareness, CSCW principles</td><td>HTMX WebSockets extension, Ktor WebSocket plugin</td><td>WCAG 4.1.3 (announce updates via live regions)</td></tr>
<tr><td><strong>6. AI Task Suggestions</strong></td><td>LLM generates task breakdowns (e.g., ‚ÄúWrite essay‚Äù ‚Üí sub-tasks)</td><td>AI transparency, user agency</td><td>OpenAI API integration, prompt engineering</td><td>WCAG 3.3.2 (Labels or Instructions) for AI disclaimers</td></tr>
<tr><td><strong>7. Offline Mode (PWA)</strong></td><td>Service worker caches app; tasks sync when online</td><td>Network resilience, progressive web apps</td><td>Service Worker API, IndexedDB, background sync</td><td>WCAG 3.2.4 (Consistent Identification) across online/offline</td></tr>
<tr><td><strong>8. Accessibility Dashboard</strong></td><td>Real-time WCAG compliance score; lighthouse metrics</td><td>Automated testing limits, developer tools</td><td>axe-core integration, CI/CD pipeline</td><td>Meta-accessibility: ensuring dashboard itself is accessible</td></tr>
<tr><td><strong>9. Dark Mode</strong></td><td>User-selectable theme (light/dark/high-contrast)</td><td>Personalisation, sensory preferences</td><td>CSS custom properties, <code>prefers-colour-scheme</code> media query</td><td>WCAG 1.4.3 (Contrast - Minimum) across all themes</td></tr>
<tr><td><strong>10. Export &amp; Import</strong></td><td>Download tasks as JSON/CSV/PDF; import from Todoist/Trello</td><td>Data portability, interoperability</td><td>CSV/JSON serialisation, PDF generation (iText/PDFKit)</td><td>WCAG 1.1.1 (ensure exported PDFs are tagged/accessible)</td></tr>
</tbody></table>
</div>
<p><strong>Prioritisation guidance</strong>: If your Semester 1 evaluation identified <strong>performance issues</strong> (e.g., slow search), prioritise pagination + search (features 1, 3). If you‚Äôre interested in <strong>AI/ethics</strong>, prioritise feature 6 + transparency documentation. If you want to explore <strong>real-time collaboration</strong>, prioritise features 4‚Äì5.</p>
<hr />
<h3 id="technical-topics-semester-2-lectureslabs"><a class="header" href="#technical-topics-semester-2-lectureslabs">Technical Topics (Semester 2 Lectures/Labs)</a></h3>
<p>Semester 2 typically covers these advanced HCI topics. Your portfolio work will align with one or more:</p>
<ol>
<li>
<p><strong>Computer-Supported Cooperative Work (CSCW)</strong></p>
<ul>
<li><strong>What</strong>: Design patterns for multi-user collaboration (conflict resolution, awareness, turn-taking)</li>
<li><strong>Application</strong>: Features 4‚Äì5 (multi-user, real-time updates)</li>
<li><strong>Reading</strong>: Grudin (1994) ‚ÄúCSCW: History and Focus‚Äù; Schmidt &amp; Bannon (1992) ‚ÄúTaking CSCW Seriously‚Äù</li>
</ul>
</li>
<li>
<p><strong>AI &amp; Automation Ethics</strong></p>
<ul>
<li><strong>What</strong>: Transparency, explainability, user agency when integrating AI features</li>
<li><strong>Application</strong>: Feature 6 (AI task suggestions) with clear disclaimers (‚ÄúAI-generated; verify before relying on‚Äù)</li>
<li><strong>Reading</strong>: Shneiderman (2022) ‚ÄúHuman-Centered AI‚Äù; EU AI Act principles</li>
</ul>
</li>
<li>
<p><strong>Performance &amp; Perceived Responsiveness</strong></p>
<ul>
<li><strong>What</strong>: Optimising server response time, perceptual speed tricks (skeleton screens, optimistic UI)</li>
<li><strong>Application</strong>: Features 1, 3 (pagination, search) with &lt;100ms response targets</li>
<li><strong>Reading</strong>: Nielsen (1993) ‚ÄúResponse Times: The 3 Important Limits‚Äù</li>
</ul>
</li>
<li>
<p><strong>Progressive Web Apps (PWAs)</strong></p>
<ul>
<li><strong>What</strong>: Offline-first architecture, service workers, installable web apps</li>
<li><strong>Application</strong>: Feature 7 (offline mode) with background sync when network returns</li>
<li><strong>Reading</strong>: MDN Web Docs: Service Worker API; ‚ÄúOffline Cookbook‚Äù patterns</li>
</ul>
</li>
<li>
<p><strong>Inclusive AI &amp; Assistive Tech Integration</strong></p>
<ul>
<li><strong>What</strong>: Ensuring AI features work with screen readers, voice input, switch access</li>
<li><strong>Application</strong>: Feature 6 (AI suggestions) with ARIA announcements, feature 8 (a11y dashboard) accessible to all</li>
<li><strong>Reading</strong>: W3C (2024) ‚ÄúAI &amp; Accessibility Research Symposium‚Äù</li>
</ul>
</li>
<li>
<p><strong>Scaling to Production</strong></p>
<ul>
<li><strong>What</strong>: Database migration (CSV ‚Üí PostgreSQL), caching (Redis), deployment (Docker, Railway, Fly.io)</li>
<li><strong>Application</strong>: All features; moving from prototype to production-ready app</li>
<li><strong>Reading</strong>: Ktor docs on Database integration; Railway deployment guides</li>
</ul>
</li>
</ol>
<p><strong>Study path</strong>: If you‚Äôre interested in <strong>research</strong>, focus on topics 1‚Äì2 (CSCW, AI ethics) and design a formal study. If you‚Äôre interested in <strong>industry</strong>, focus on topics 3, 6 (performance, scaling) and build a production deployment. If you‚Äôre interested in <strong>accessibility advocacy</strong>, focus on topics 5, 8 (inclusive AI, a11y tooling).</p>
<hr />
<h3 id="backlog-integration"><a class="header" href="#backlog-integration">Backlog Integration</a></h3>
<p>Your <strong>product backlog</strong> (from Activity 5, Step 3) should now include:</p>
<ol>
<li><strong>Incomplete Semester 1 items</strong> (e.g., backlog #8‚Äì12 from Activity 5 example)</li>
<li><strong>Peer feedback</strong> (from Week 11 Lab 1 studio crit)</li>
<li><strong>Semester 2 feature candidates</strong> (select 3‚Äì5 from table above)</li>
</ol>
<p><strong>Example integrated backlog</strong> (stored in <code>backlog.md</code> or issue tracker):</p>
<div class="table-wrapper"><table><thead><tr><th>ID</th><th>Description</th><th>Priority</th><th>Effort</th><th>Notes</th><th>Semester</th></tr></thead><tbody>
<tr><td>#1</td><td>‚úÖ CRUD operations (add, edit, delete tasks)</td><td>P1</td><td>8</td><td>Complete (Week 6)</td><td>S1</td></tr>
<tr><td>#2</td><td>‚úÖ HTMX dual-mode (JS-on vs no-JS)</td><td>P1</td><td>10</td><td>Complete (Week 6, 8)</td><td>S1</td></tr>
<tr><td>#3</td><td>‚úÖ Validation error alerts (WCAG 4.1.3)</td><td>P1</td><td>2</td><td>Complete (Week 10)</td><td>S1</td></tr>
<tr><td>#8</td><td>Add keyboard shortcut hints</td><td>P2</td><td>3</td><td>Peer feedback (Week 11)</td><td>S1</td></tr>
<tr><td>#9</td><td>Implement undo for task deletion</td><td>P2</td><td>4</td><td>Deferred from Week 10</td><td>S1</td></tr>
<tr><td>#12</td><td>Add automated a11y tests (axe-core CI/CD)</td><td>P1</td><td>6</td><td>High priority for S2; prevents regressions</td><td><strong>S2</strong></td></tr>
<tr><td>#13</td><td><strong>Pagination</strong> (10 tasks/page)</td><td>P2</td><td>5</td><td>Improves performance for 100+ tasks</td><td><strong>S2</strong></td></tr>
<tr><td>#14</td><td><strong>Tag system</strong> (filter by category)</td><td>P2</td><td>8</td><td>Requested in Week 6 needs-finding</td><td><strong>S2</strong></td></tr>
<tr><td>#15</td><td><strong>Search with autocomplete</strong></td><td>P3</td><td>6</td><td>Nice-to-have; low priority vs pagination</td><td><strong>S2</strong></td></tr>
<tr><td>#16</td><td><strong>AI task breakdown</strong> (LLM integration)</td><td>P4</td><td>10</td><td>Stretch goal; requires OpenAI API + ethics review</td><td><strong>S2</strong></td></tr>
</tbody></table>
</div>
<p><strong>Priority formula (from Week 10)</strong>: <code>(Impact + Inclusion) - Effort</code></p>
<p><strong>Action</strong>: Open your <code>backlog.md</code> (or create it in your repo root) and add Semester 2 features with priority scores.</p>
<hr />
<h3 id="skills-development-path"><a class="header" href="#skills-development-path">Skills Development Path</a></h3>
<p>To successfully implement Semester 2 features, you‚Äôll need to develop these skills progressively:</p>
<h4 id="path-1-full-stack-developer-features-15-7"><a class="header" href="#path-1-full-stack-developer-features-15-7">Path 1: Full-Stack Developer (Features 1‚Äì5, 7)</a></h4>
<p><strong>Goal</strong>: Build production-ready, scalable web app</p>
<div class="table-wrapper"><table><thead><tr><th>Skill</th><th>When to Learn</th><th>Resources</th><th>Application</th></tr></thead><tbody>
<tr><td><strong>SQL basics</strong> (PostgreSQL)</td><td>Week 1‚Äì2 (S2)</td><td>Ktor Database docs, PostgreSQL tutorial</td><td>Replace CSV with relational DB (features 1, 2, 4)</td></tr>
<tr><td><strong>Indexing &amp; query optimisation</strong></td><td>Week 3‚Äì4 (S2)</td><td>PostgreSQL EXPLAIN, indexing strategies</td><td>Feature 3 (search); ensure &lt;100ms response</td></tr>
<tr><td><strong>WebSockets (HTMX extension)</strong></td><td>Week 5‚Äì6 (S2)</td><td>hypermedia.systems Ch. 11; Ktor WebSocket plugin</td><td>Feature 5 (real-time updates)</td></tr>
<tr><td><strong>Service Workers &amp; PWA</strong></td><td>Week 7‚Äì8 (S2)</td><td>MDN Service Worker guide; Workbox library</td><td>Feature 7 (offline mode)</td></tr>
<tr><td><strong>Deployment (Docker, Railway)</strong></td><td>Week 9‚Äì10 (S2)</td><td>Railway docs; Ktor deployment guide</td><td>Production hosting</td></tr>
</tbody></table>
</div>
<h4 id="path-2-hci-researcher-features-6-8"><a class="header" href="#path-2-hci-researcher-features-6-8">Path 2: HCI Researcher (Features 6, 8)</a></h4>
<p><strong>Goal</strong>: Conduct formal usability studies; publish research</p>
<div class="table-wrapper"><table><thead><tr><th>Skill</th><th>When to Learn</th><th>Resources</th><th>Application</th></tr></thead><tbody>
<tr><td><strong>Formal study design</strong> (IRB, informed consent)</td><td>Week 1‚Äì2 (S2)</td><td>University ethics committee guidelines</td><td>Replicate Week 9 protocol with n=8+ participants</td></tr>
<tr><td><strong>Statistical analysis</strong> (t-tests, ANOVA)</td><td>Week 3‚Äì4 (S2)</td><td>R/Python (scipy.stats); ‚ÄúStatistics for HCI‚Äù course</td><td>Compare median task times across conditions (HTMX vs React)</td></tr>
<tr><td><strong>Qualitative coding</strong> (thematic analysis)</td><td>Week 5‚Äì6 (S2)</td><td>Braun &amp; Clarke (2006) thematic analysis guide</td><td>Analyse pilot quotes from Week 9</td></tr>
<tr><td><strong>AI transparency frameworks</strong></td><td>Week 7‚Äì8 (S2)</td><td>EU AI Act, Shneiderman (2020) Human-Centered AI</td><td>Feature 6 (AI suggestions) with user control</td></tr>
<tr><td><strong>Academic writing</strong> (CHI, ASSETS format)</td><td>Week 9‚Äì10 (S2)</td><td>CHI paper examples; ACM SIGCHI templates</td><td>Write 4-page paper on findings; submit to CHI LBW</td></tr>
</tbody></table>
</div>
<h4 id="path-3-accessibility-specialist-features-89"><a class="header" href="#path-3-accessibility-specialist-features-89">Path 3: Accessibility Specialist (Features 8‚Äì9)</a></h4>
<p><strong>Goal</strong>: Become expert in WCAG, audit tools, inclusive design</p>
<div class="table-wrapper"><table><thead><tr><th>Skill</th><th>When to Learn</th><th>Resources</th><th>Application</th></tr></thead><tbody>
<tr><td><strong>Automated testing</strong> (axe-core, Pa11y)</td><td>Week 1‚Äì2 (S2)</td><td>axe-core npm docs, Pa11y CI integration</td><td>Feature 8 (a11y dashboard); CI/CD pipeline</td></tr>
<tr><td><strong>Manual SR testing</strong> (NVDA, JAWS, VoiceOver)</td><td>Week 3‚Äì4 (S2)</td><td>WebAIM screen reader guides; NVDA user guide</td><td>Re-test all features with 3 SR users</td></tr>
<tr><td><strong>ARIA patterns</strong> (tabs, modals, tooltips)</td><td>Week 5‚Äì6 (S2)</td><td>W3C ARIA Authoring Practices Guide (APG)</td><td>Add modal dialogs, tooltips (with role=dialog, aria-labelledby)</td></tr>
<tr><td><strong>Colour contrast &amp; theming</strong></td><td>Week 7‚Äì8 (S2)</td><td>Colour Contrast Analyser, CSS custom properties</td><td>Feature 9 (dark mode); ensure 4.5:1 in all themes</td></tr>
<tr><td><strong>A11y advocacy &amp; training</strong></td><td>Week 9‚Äì10 (S2)</td><td>Write blog posts, give talks</td><td>Contribute to open-source projects; teach others</td></tr>
</tbody></table>
</div>
<p><strong>Choose your path</strong> based on career goals, then add relevant skills to your Semester 2 learning plan.</p>
<hr />
<h3 id="motivation-why-continue"><a class="header" href="#motivation-why-continue">Motivation: Why Continue?</a></h3>
<p>You‚Äôve invested 6 weeks (Weeks 6‚Äì11) building a solid foundation. Here‚Äôs why Semester 2 matters:</p>
<h4 id="1-portfolio-differentiation"><a class="header" href="#1-portfolio-differentiation">1. <strong>Portfolio Differentiation</strong></a></h4>
<p>Most CS students can build a CRUD app. Few can demonstrate:</p>
<ul>
<li><strong>Evidence-led iteration</strong> (pilot data ‚Üí prioritised fixes ‚Üí verification)</li>
<li><strong>WCAG 2.2 AA compliance</strong> (tested with real assistive tech)</li>
<li><strong>Privacy by design</strong> (UK GDPR, no PII, transparent data practices)</li>
<li><strong>Server-first architecture</strong> (progressive enhancement, no-JS parity)</li>
</ul>
<p>Semester 2 features (pagination, search, AI integration) add <strong>complexity</strong> while maintaining <strong>accessibility</strong>‚Äîa rare combination that employers and grad schools value.</p>
<h4 id="2-research-opportunities"><a class="header" href="#2-research-opportunities">2. <strong>Research Opportunities</strong></a></h4>
<p>Your Week 9 pilots produced <strong>publishable data</strong>. With a larger sample (n=8+, IRB approval), you could submit to:</p>
<ul>
<li><strong>CHI</strong> (ACM Conference on Human Factors in Computing Systems) - Late-Breaking Work track</li>
<li><strong>ASSETS</strong> (ACM SIGACCESS Conference on Computers and Accessibility)</li>
<li><strong>University undergraduate research conferences</strong> (Leeds Laidlaw, national showcases)</li>
</ul>
<p><strong>Example research question</strong> (from your Semester 1 work):</p>
<blockquote>
<p>‚ÄúDo server-first architectures (HTMX) improve screen reader usability compared to client-side SPAs (React)? A comparative task-based study (n=16, between-subjects).‚Äù</p>
</blockquote>
<p>This extends your Week 9 methodology and could lead to co-authorship with module staff.</p>
<h4 id="3-industry-readiness"><a class="header" href="#3-industry-readiness">3. <strong>Industry Readiness</strong></a></h4>
<p>Employers look for:</p>
<ul>
<li><strong>End-to-end ownership</strong>: Requirements ‚Üí design ‚Üí implementation ‚Üí evaluation ‚Üí iteration</li>
<li><strong>Cross-functional skills</strong>: Code (Kotlin/Ktor), design (WCAG), research (pilots), writing (reflection)</li>
<li><strong>Trade-off reasoning</strong>: ‚ÄúI prioritised X over Y because [evidence]‚Äù</li>
</ul>
<p>Semester 2 features demonstrate <strong>production thinking</strong>:</p>
<ul>
<li>Feature 1 (pagination): ‚ÄúI scaled to 10,000 tasks with acceptable latency‚Äù</li>
<li>Feature 5 (real-time): ‚ÄúI implemented WebSockets while maintaining SR compatibility‚Äù</li>
<li>Feature 6 (AI): ‚ÄúI integrated LLMs with transparent disclaimers and user override‚Äù</li>
</ul>
<p>These are <strong>STAR interview stories</strong> (Situation, Task, Action, Result) that differentiate you from peers.</p>
<h4 id="4-personal-mastery"><a class="header" href="#4-personal-mastery">4. <strong>Personal Mastery</strong></a></h4>
<p>COMP2850 is hard. You‚Äôve learned:</p>
<ul>
<li><strong>Server-first thinking</strong> (hypermedia as engine of state)</li>
<li><strong>Inclusive design</strong> (start with HTML, add ARIA only when needed)</li>
<li><strong>Evidence-based iteration</strong> (metrics &gt; intuition)</li>
</ul>
<p>Semester 2 is where you <strong>master</strong> these principles by applying them to harder problems (multi-user, real-time, AI). Mastery comes from deliberate practice, not from moving to a new topic.</p>
<hr />
<h3 id="concrete-next-steps-week-12"><a class="header" href="#concrete-next-steps-week-12">Concrete Next Steps (Week 12+)</a></h3>
<p><strong>Before Semester 2 starts</strong> (Winter break or Week 12):</p>
<ol>
<li>
<p><strong>Choose 3 features</strong> from the roadmap table (lines 911‚Äì920)</p>
<ul>
<li>Pick based on career interest (full-stack, research, or a11y specialist path)</li>
<li>Add to backlog with priority scores (Impact + Inclusion - Effort)</li>
</ul>
</li>
<li>
<p><strong>Learn 1 new skill</strong> from your chosen path</p>
<ul>
<li>Full-stack: Complete PostgreSQL tutorial (replace CSV in 1 feature)</li>
<li>Research: Read 3 CHI papers on accessibility evaluation methods</li>
<li>A11y: Master one ARIA pattern (modal dialog, tabs, or tooltips)</li>
</ul>
</li>
<li>
<p><strong>Refine your portfolio</strong></p>
<ul>
<li>Convert <code>README.md</code> to a static site (GitHub Pages, GitLab Pages)</li>
<li>Add ‚ÄúSemester 2 Roadmap‚Äù section citing your chosen features</li>
<li>Share with peers/mentors for feedback</li>
</ul>
</li>
<li>
<p><strong>Find a collaborator</strong> (optional)</p>
<ul>
<li>Pair with a peer who chose a complementary path</li>
<li>Example: You (full-stack) + peer (a11y specialist) = feature 5 (real-time) with SR testing</li>
</ul>
</li>
<li>
<p><strong>Set a measurable goal</strong></p>
<ul>
<li>Example: ‚ÄúBy Week 8 (S2), I will deploy a production instance with 100 real users and collect SUS scores‚Äù</li>
<li>Example: ‚ÄúBy Week 10 (S2), I will submit a 4-page paper to CHI LBW‚Äù</li>
</ul>
</li>
</ol>
<p><strong>During Semester 2</strong>:</p>
<ul>
<li><strong>Weeks 1‚Äì4</strong>: Implement features 1‚Äì2 (pagination + one stretch feature)</li>
<li><strong>Weeks 5‚Äì8</strong>: Implement feature 3 or 4 (search or multi-user)</li>
<li><strong>Weeks 9‚Äì10</strong>: Evaluate, iterate, and document (repeat Week 9‚Äì10 process)</li>
<li><strong>Week 11‚Äì12</strong>: Final portfolio assembly, research paper (if applicable), deployment</li>
</ul>
<p><strong>After Semester 2</strong>:</p>
<ul>
<li><strong>Showcase</strong>: Present at university research fair, publish blog post, submit to open-source conferences (FOSDEM, etc.)</li>
<li><strong>Job applications</strong>: Use portfolio as centerpiece of CV; link to live deployment</li>
<li><strong>Grad school</strong>: Use research paper as writing sample for HCI MSc/PhD applications</li>
</ul>
<hr />
<h3 id="resources"><a class="header" href="#resources">Resources</a></h3>
<p><strong>Backlog Management</strong></p>
<ul>
<li><strong>GitHub Issues/Projects</strong>: Free issue tracker with labels, milestones, priorities</li>
<li><strong>GitLab Issue Boards</strong>: Kanban-style backlog (drag-and-drop prioritisation)</li>
<li><strong>Notion/Trello</strong>: If you prefer visual boards over code-based trackers</li>
</ul>
<p><strong>Learning Paths</strong></p>
<ul>
<li><strong>Full-stack</strong>: <a href="https://ktor.io/">Ktor Docs</a>, <a href="https://www.postgresqltutorial.com/">PostgreSQL Tutorial</a>, <a href="https://docs.railway.app/">Railway Deploy Guide</a></li>
<li><strong>Research</strong>: <a href="https://chi2025.acm.org/">CHI 2025 Call for Papers</a>, <a href="https://assets25.sigaccess.org/">ASSETS 2025</a>, <a href="https://www.nngroup.com/articles/">UX Research Methods by NNGroup</a></li>
<li><strong>A11y</strong>: <a href="https://www.w3.org/WAI/ARIA/apg/">W3C ARIA Authoring Practices Guide</a>, <a href="https://www.npmjs.com/package/axe-core">axe-core npm</a>, <a href="https://dequeuniversity.com/">Deque University</a></li>
</ul>
<p><strong>Inspiration (Real-World Examples)</strong></p>
<ul>
<li><strong>Linear</strong> (task manager): Server-first with real-time (demonstrates feature 5)</li>
<li><strong>Basecamp</strong> (project management): No-JS baseline, progressive enhancement (demonstrates feature 2)</li>
<li><strong>GOV.UK Design System</strong>: WCAG AAA components, open-source (demonstrates feature 8‚Äì9)</li>
</ul>
<hr />
<p><strong>Semester 2 begins soon‚Äîyour foundation is strong. Choose your path, set measurable goals, and keep building with evidence and empathy.</strong></p>
<hr />
<h2 id="glossary-summary-9"><a class="header" href="#glossary-summary-9">Glossary Summary</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Term</th><th>Definition</th><th>Example/Context</th></tr></thead><tbody>
<tr><td><strong>Evidence chain</strong></td><td>Traceable path from raw data ‚Üí analysis ‚Üí fix ‚Üí verification</td><td>P3 pilot notes ‚Üí WCAG violation ‚Üí code commit ‚Üí retest</td></tr>
<tr><td><strong>Reflective writing</strong></td><td>Connecting theory to practice by answering What/Why/How/Learning</td><td>‚ÄúI added role=alert (WCAG 4.1.3) because P3 didn‚Äôt hear errors‚Äù</td></tr>
<tr><td><strong>Portfolio</strong></td><td>Organised collection of artefacts with accompanying reflection</td><td>Code repo + evidence/ + assessment/2 packages + README</td></tr>
<tr><td><strong>Traceability</strong></td><td>Ability to link every claim to supporting evidence</td><td>‚ÄúP3 took 127 s (see metrics.csv row 47)‚Äù</td></tr>
<tr><td><strong>Gradescope</strong></td><td>Submission platform with file size/format requirements</td><td>100 MB limit, PDF preferred, flat directory structure</td></tr>
<tr><td><strong>Commit hash</strong></td><td>Unique identifier for a Git commit</td><td><code>c8d1e4f</code> (first 7 chars of SHA-1)</td></tr>
<tr><td><strong>Regression testing</strong></td><td>Verifying fixes didn‚Äôt break existing features</td><td>Keyboard, SR, no-JS paths all retested after validation fix</td></tr>
<tr><td><strong>Backlog</strong></td><td>Prioritised list of unfinished or future work</td><td>‚ÄúAdd undo feature‚Äù (P2, Effort: 4)</td></tr>
<tr><td><strong>WCAG compliance doc</strong></td><td>Mapping fixes to WCAG 2.2 success criteria</td><td>Fix 01 ‚Üí 4.1.3 Status Messages (AA)</td></tr>
<tr><td><strong>Compression</strong></td><td>Reducing file size (images, PDFs) to meet submission limits</td><td>PNG: 8 MB ‚Üí 2 MB via TinyPNG; PDF: 15 MB ‚Üí 5 MB via Ghostscript</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="reflection-questions-8"><a class="header" href="#reflection-questions-8">Reflection Questions</a></h2>
<ol>
<li>
<p><strong>Evidence chains</strong>: Choose one finding from your Week 9 analysis. Trace the complete evidence chain from raw data (pilot ID, task, metric) to fix (commit hash) to verification (retest result). Is any link in the chain missing or weak?</p>
</li>
<li>
<p><strong>Reflective writing quality</strong>: Reread your assessment and assessment reflections. For each, identify:</p>
<ul>
<li>One place where you cited theory (WCAG, privacy principle, academic source)</li>
<li>One place where you described a mistake and correction</li>
<li>One place where you connected learning to future practice</li>
</ul>
</li>
<li>
<p><strong>Portfolio organisation</strong>: Imagine you are a marker with 50 portfolios to grade. Open your <code>README.md</code> and <code>evidence/</code> directory. Can you find any specific artefact (e.g., ‚ÄúP3 retest screenshot‚Äù) in &lt; 30 seconds? If not, what would improve navigation?</p>
</li>
<li>
<p><strong>Submission readiness</strong>: If Gradescope rejects your ZIP due to file size, which files would you compress first? Why?</p>
</li>
<li>
<p><strong>Semester 2 planning</strong>: Of the 3 goals you set in Activity 5, which excites you most? Which scares you most? Why?</p>
</li>
</ol>
<hr />
<h2 id="further-reading-3"><a class="header" href="#further-reading-3">Further Reading</a></h2>
<p><strong>Reflective practice</strong></p>
<ul>
<li>Moon, J. A. (2004). <em>A Handbook of Reflective and Experiential Learning: Theory and Practice</em>. Routledge.</li>
</ul>
<p><strong>Evidence-based design</strong></p>
<ul>
<li>Shneiderman, B., Plaisant, C., Cohen, M., Jacobs, S., Elmqvist, N., &amp; Diakopoulos, N. (2016). <em>Designing the User Interface: Strategies for Effective Human-Computer Interaction</em> (6th ed.). Pearson. (Ch. 4: Evaluation)</li>
</ul>
<p><strong>Portfolio assessment</strong></p>
<ul>
<li>Paulson, F. L., Paulson, P. R., &amp; Meyer, C. A. (1991). ‚ÄúWhat Makes a Portfolio a Portfolio?‚Äù <em>Educational Leadership</em>, 48(5), 60‚Äì63. <a href="https://www.ascd.org/el/articles/what-makes-a-portfolio-a-portfolio">https://www.ascd.org/el/articles/what-makes-a-portfolio-a-portfolio</a></li>
</ul>
<p><strong>Accessibility compliance</strong></p>
<ul>
<li>W3C (2024). <em>How to Meet WCAG (Quick Reference)</em>. <a href="https://www.w3.org/WAI/WCAG22/quickref/">https://www.w3.org/WAI/WCAG22/quickref/</a></li>
<li>GOV.UK (2024). <em>Making Your Service Accessible</em>. <a href="https://www.gov.uk/service-manual/helping-people-to-use-your-service/making-your-service-accessible-an-introduction">https://www.gov.uk/service-manual/helping-people-to-use-your-service/making-your-service-accessible-an-introduction</a></li>
</ul>
<p><strong>Server-first architecture</strong></p>
<ul>
<li>Gross, C., Stepinski, A., &amp; Ak≈üim≈üek, D. (2023). <em>Hypermedia Systems</em>. <a href="https://hypermedia.systems/">https://hypermedia.systems/</a> (Ch. 9: Practical Patterns; Ch. 11: Websockets)</li>
</ul>
<hr />
<h2 id="lab-checklist-3"><a class="header" href="#lab-checklist-3">Lab Checklist</a></h2>
<p>Before leaving lab, confirm:</p>
<ul>
<li><input disabled="" type="checkbox"/>
<strong>assessment polished</strong>: Critique feedback incorporated; evidence complete; reflection compiled to PDF</li>
<li><input disabled="" type="checkbox"/>
<strong>assessment assembled</strong>: Fix docs written; regression checklist completed; verification data organised; reflection compiled to PDF</li>
<li><input disabled="" type="checkbox"/>
<strong>Repository tidy</strong>: Commit history clean; <code>README.md</code> updated; <code>evidence/</code> organised by week</li>
<li><input disabled="" type="checkbox"/>
<strong>Submission ready</strong>: <code>task1-submission.zip</code> and <code>task2-submission.zip</code> created; file sizes &lt; 50 MB each; PDFs legible</li>
<li><input disabled="" type="checkbox"/>
<strong>Backlog updated</strong>: Peer feedback + Semester 2 goals added; priorities assigned</li>
<li><input disabled="" type="checkbox"/>
<strong>Final reflection written</strong>: 500-word summary of Weeks 6‚Äì11 journey (optional but recommended)</li>
<li><input disabled="" type="checkbox"/>
<strong>Backup created</strong>: Repository tagged (<code>v1.0-task1</code>, <code>v1.0-task2</code>); ZIPs backed up to cloud</li>
</ul>
<hr />
<h2 id="next-steps-3"><a class="header" href="#next-steps-3">Next Steps</a></h2>
<ol>
<li><strong>Gradescope submission</strong>: Upload <code>task1-submission.zip</code> and <code>task2-submission.zip</code> by the deadline (check Minerva for exact date/time).</li>
<li><strong>Peer review</strong> (if required): Some modules assign post-submission peer review; check Minerva announcements.</li>
<li><strong>Semester 2 prep</strong>: Review your backlog and Semester 2 goals; prioritise 1‚Äì2 items to start over break.</li>
<li><strong>Portfolio showcase</strong>: Consider converting your <code>README.md</code> to a static site (e.g., GitHub Pages) to show potential employers.</li>
<li><strong>Celebrate</strong>: You‚Äôve completed a rigorous HCI project with evaluation, iteration, and evidence chains. Well done!</li>
</ol>
<hr />
<h2 id="acknowledgements-1"><a class="header" href="#acknowledgements-1">Acknowledgements</a></h2>
<p>This lab draws on:</p>
<ul>
<li><strong>GOV.UK Design System</strong> for accessible error handling patterns</li>
<li><strong>hypermedia.systems (Gross et al., 2023)</strong> for server-first architecture guidance</li>
<li><strong>WCAG 2.2</strong> for accessibility compliance mapping</li>
<li><strong>University of Leeds Academic Skills Centre</strong> for reflective writing frameworks</li>
</ul>
<hr />
<p><strong>Lab authored by</strong>: COMP2850 Teaching Team, University of Leeds
<strong>Last updated</strong>: 2025-01-14
<strong>Licence</strong>: Academic use only (not for redistribution)</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-11--lab-2--student-guide-wrap-up-portfolio--submission"><a class="header" href="#week-11--lab-2--student-guide-wrap-up-portfolio--submission">Week 11 ‚Ä¢ Lab 2 ‚Äî Student Guide: Wrap-Up, Portfolio &amp; Submission</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-11-orange" alt="Week 11" />
<img src="https://img.shields.io/badge/Lab-2-green" alt="Lab 2" />
<img src="https://img.shields.io/badge/Type-Student_Guide-purple" alt="Guide" /></p>
<blockquote>
<p><strong>Purpose</strong>: Week 11 Lab 2 is about final refinements from studio crit feedback, assembling your portfolio, and ensuring assessment &amp; assessment are ready for review.</p>
</blockquote>
<hr />
<h2 id="deliverables-7"><a class="header" href="#deliverables-7">Deliverables</a></h2>
<ul>
<li>‚úÖ Crit action items completed</li>
<li>‚úÖ assessment assessment refinement (<code>submission-template.md + evidence/</code>)</li>
<li>‚úÖ assessment assessment refinement (<code>submission-template.md + evidence/</code>)</li>
<li>‚úÖ Portfolio assembled (<code>wk11/portfolio/</code>)</li>
<li>‚úÖ Submission checklist verified</li>
</ul>
<hr />
<h2 id="part-1-complete-crit-action-items-30-minutes"><a class="header" href="#part-1-complete-crit-action-items-30-minutes">Part 1: Complete Crit Action Items (30 minutes)</a></h2>
<p>From <code>wk11/crit/action-plan.md</code>, complete high-priority items:</p>
<h3 id="example-add-focus-management-after-delete"><a class="header" href="#example-add-focus-management-after-delete">Example: Add Focus Management After Delete</a></h3>
<p><strong>Code change</strong> (<code>TaskRoutes.kt</code>):</p>
<pre><code class="language-kotlin">post("/tasks/{id}/delete") {
    // ... delete logic ...

    if (call.isHtmx()) {
        // Instead of empty response, return focus hint
        val status = """
            &lt;div id="status" hx-swap-oob="true"&gt;Task deleted.&lt;/div&gt;
            &lt;script&gt;document.getElementById('title')?.focus()&lt;/script&gt;
        """
        call.respondText(status, ContentType.Text.Html)
    } else {
        call.respondRedirect("/tasks")
    }
}
</code></pre>
<p><strong>Document</strong> in <code>wk11/refinements.md</code>:</p>
<pre><code class="language-markdown"># Post-Crit Refinements

## 1. Focus Management After Delete
**Issue**: Focus lost after delete (Peer 1 feedback)
**Fix**: Move focus to "Add Task" input
**Evidence**: Screenshot + NVDA test showing focus announcement
**Time**: 25 minutes
</code></pre>
<p><strong>Checklist</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
All high-priority actions completed</li>
<li><input disabled="" type="checkbox"/>
Retested with accessibility tools</li>
<li><input disabled="" type="checkbox"/>
Documented in refinements file</li>
</ul>
<hr />
<h2 id="part-2-finalize-assessment-30-minutes"><a class="header" href="#part-2-finalize-assessment-30-minutes">Part 2: Finalize assessment (30 minutes)</a></h2>
<p><strong>Copy</strong> <code>wk09/assessment/</code> ‚Üí <code>submission-template.md + evidence/</code></p>
<h3 id="final-checks"><a class="header" href="#final-checks">Final Checks</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
<strong>Section 1 (Evaluation Plan)</strong>: Tasks, metrics, protocol complete</li>
<li><input disabled="" type="checkbox"/>
<strong>Section 2 (Findings)</strong>: Quant tables + qual themes + accessibility observations</li>
<li><input disabled="" type="checkbox"/>
<strong>Section 3 (Evidence Chains)</strong>: All findings link data ‚Üí backlog ‚Üí WCAG</li>
<li><input disabled="" type="checkbox"/>
<strong>Section 4 (Reflection)</strong>: Process critique + limitations + next steps</li>
<li><input disabled="" type="checkbox"/>
<strong>Word count</strong>: 2500-3000 words</li>
<li><input disabled="" type="checkbox"/>
<strong>References</strong>: All WCAG, academic sources cited</li>
<li><input disabled="" type="checkbox"/>
<strong>Evidence folder</strong>: Screenshots, pilot notes, CSV data</li>
</ul>
<h3 id="quality-check"><a class="header" href="#quality-check">Quality Check</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
No ‚Äúuser/users‚Äù terminology (person-first language throughout)</li>
<li><input disabled="" type="checkbox"/>
UK spelling (organised, analyse, centre, colour)</li>
<li><input disabled="" type="checkbox"/>
All screenshots labeled and referenced in text</li>
<li><input disabled="" type="checkbox"/>
Tables formatted consistently</li>
<li><input disabled="" type="checkbox"/>
Backlog CSV included</li>
</ul>
<p><strong>Create</strong> <code>submission-template.md + evidence/submission-checklist.md</code>:</p>
<pre><code class="language-markdown"># assessment Submission Checklist

- [ ] Main document: PDF, 2500-3000 words
- [ ] Appendix A: Evaluation protocol (`wk09/research/protocol.md`)
- [ ] Appendix B: Pilot notes (`wk09/data/pilot-notes.md`)
- [ ] Appendix C: Evidence folder (screenshots, SR output)
- [ ] Appendix D: Updated backlog CSV
- [ ] All files uploaded to Gradescope
- [ ] Submitted before deadline: [YYYY-MM-DD HH:MM]
</code></pre>
<hr />
<h2 id="part-3-finalize-assessment-30-minutes"><a class="header" href="#part-3-finalize-assessment-30-minutes">Part 3: Finalize assessment (30 minutes)</a></h2>
<p><strong>Copy</strong> <code>wk10/assessment/</code> ‚Üí <code>submission-template.md + evidence/</code></p>
<h3 id="final-checks-1"><a class="header" href="#final-checks-1">Final Checks</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
<strong>Section 1 (Redesign Rationale)</strong>: Priority selection + Week 9 evidence</li>
<li><input disabled="" type="checkbox"/>
<strong>Section 2 (Implementation)</strong>: Before/after code + screenshots + WCAG mapping</li>
<li><input disabled="" type="checkbox"/>
<strong>Section 3 (Verification)</strong>: axe re-scan + manual WCAG + regression testing</li>
<li><input disabled="" type="checkbox"/>
<strong>Section 4 (Reflection)</strong>: Process critique + trade-offs + future work</li>
<li><input disabled="" type="checkbox"/>
<strong>Word count</strong>: 2000-2500 words</li>
<li><input disabled="" type="checkbox"/>
<strong>Code snippets</strong>: Syntax-highlighted, properly formatted</li>
<li><input disabled="" type="checkbox"/>
<strong>Evidence folder</strong>: Before/after screenshots, axe reports</li>
</ul>
<h3 id="quality-check-1"><a class="header" href="#quality-check-1">Quality Check</a></h3>
<p>Same as assessment plus:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Code changes clearly explained</li>
<li><input disabled="" type="checkbox"/>
Trade-offs justified</li>
<li><input disabled="" type="checkbox"/>
WCAG criteria explicitly referenced</li>
</ul>
<hr />
<h2 id="part-4-assemble-portfolio-40-minutes"><a class="header" href="#part-4-assemble-portfolio-40-minutes">Part 4: Assemble Portfolio (40 minutes)</a></h2>
<p><strong>Create</strong> <code>wk11/portfolio/README.md</code>:</p>
<pre><code class="language-markdown"># COMP2850 HCI Portfolio ‚Äî [Your Name]

## Overview

This portfolio documents my HCI journey from Week 6 (needs-finding) to Week 11 (studio crit). Key themes: dual-path architecture, accessibility (WCAG 2.2 AA), evaluation-driven redesign.

---

## Week-by-Week Highlights

### Week 6: Foundations
- **Lab 1**: Built server-first task manager with HTMX progressive enhancement
- **Lab 2**: Conducted peer interviews, created 5 job stories, built inclusive backlog
- **Key learning**: Person-first language, privacy-by-design

### Week 7: Accessibility
- **Lab 1**: Implemented inline edit with accessible focus management
- **Lab 2**: Ran axe audit (found 5 violations), fixed 3 priority issues
- **Key learning**: WCAG 2.2 AA compliance requires systematic auditing

### Week 8: Scaling (student guide used)
- Pagination, filtering, template partials
- Bug fix: Add Task form target changed for pagination

### Week 9: Evaluation
- **Lab 1**: Created evaluation plan (4 tasks, 7 metrics, ethics protocol)
- **Lab 2**: Ran 5 pilots, analysed findings, drafted assessment
- **Key learning**: Small sample (n=5) still reveals critical usability issues

### Week 10: Redesign
- **Lab 1**: Prioritised 3 fixes based on Week 9 data
- **Lab 2**: Implemented fixes, re-verified, drafted assessment
- **Key learning**: Trade-offs inevitable (e.g., no-JS delete confirmation deferred)

### Week 11: Synthesis
- **Lab 1**: Studio crit, received peer feedback, created action plan
- **Lab 2**: Final refinements, submission prep

---

## Key Artefacts

- **Backlog**: `backlog/backlog.csv` (evolved from Week 6 to Week 11)
- **Evidence**: `wk*/evidence/` folders (screenshots, axe reports, pilot notes)
- **Code**: Git commits show incremental development
- **Documentation**: Protocol, task scenarios, findings analysis

---

## Reflection

**Biggest challenge**: Maintaining dual-path parity (HTMX vs no-JS) while adding features

**Most rewarding**: Week 9 pilots - seeing real people use my prototype and learning from their struggles

**What I'd do differently**: Start instrumentation earlier (Week 7) to capture more longitudinal data

**Professional growth**: Understanding that accessibility isn't a checklist - it's about inclusion from day one

---

## Future Enhancements (Semester 2)

- Progress indicator (motivational feedback)
- Filter persistence across sessions (reduce cognitive load)
- Delete confirmation page for no-JS (WCAG 3.3.4)
- Automated no-JS tests (Playwright)

---

**Repository**: [Link to your Git repo if public]
**Gradescope**: assessment [submission link], assessment [submission link]
</code></pre>
<p><strong>Checklist</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Portfolio README written</li>
<li><input disabled="" type="checkbox"/>
Week highlights summarised</li>
<li><input disabled="" type="checkbox"/>
Key artefacts listed</li>
<li><input disabled="" type="checkbox"/>
Reflection thoughtful</li>
</ul>
<hr />
<h2 id="part-5-final-submission-checklist-20-minutes"><a class="header" href="#part-5-final-submission-checklist-20-minutes">Part 5: Final Submission Checklist (20 minutes)</a></h2>
<p><strong>Create</strong> <code>wk11/FINAL-SUBMISSION-CHECKLIST.md</code>:</p>
<pre><code class="language-markdown"># FINAL SUBMISSION CHECKLIST

## assessment: Evaluation &amp; Findings
- [ ] Main document (PDF): 2500-3000 words
- [ ] All 4 sections complete
- [ ] Evidence folder included
- [ ] Uploaded to Gradescope
- [ ] Deadline: [YYYY-MM-DD HH:MM]

## assessment: Redesign &amp; Verification
- [ ] Main document (PDF): 2000-2500 words
- [ ] Before/after code + screenshots
- [ ] Evidence folder included
- [ ] Uploaded to Gradescope
- [ ] Deadline: [YYYY-MM-DD HH:MM]

## Portfolio (Optional)
- [ ] README.md comprehensive
- [ ] Week highlights documented
- [ ] Reflection included

## Git Repository
- [ ] All code committed
- [ ] No sensitive data (check .gitignore)
- [ ] README with setup instructions
- [ ] Tags: `week6-baseline`, `week10-final`

## Quality Assurance
- [ ] Person-first language throughout
- [ ] UK spelling
- [ ] All WCAG references correct (e.g., 2.1.1 not 2.11)
- [ ] Screenshots labeled and captioned
- [ ] Code snippets syntax-highlighted

## Final Checks
- [ ] Printed/saved backup copy
- [ ] Submission confirmation email received
- [ ] Celebrated completion! üéâ
</code></pre>
<hr />
<h2 id="commit--celebrate"><a class="header" href="#commit--celebrate">Commit &amp; Celebrate</a></h2>
<pre><code class="language-bash">git add wk11/ wk*/task*-final/
git commit -m "feat(wk11-lab2): assessment refinement ready

- Completed post-crit action items (focus management)
- Finalized assessment (evaluation &amp; findings)
- Finalized assessment (redesign &amp; verification)
- Assembled portfolio with week-by-week highlights
- All quality checks passed

COMP2850 HCI complete!"

git tag week11-final-submission
git push --tags
</code></pre>
<p><strong>Congratulations on completing COMP2850 HCI!</strong> üéì</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="comp2850-hci-combined-evaluation--redesign-assessment"><a class="header" href="#comp2850-hci-combined-evaluation--redesign-assessment">COMP2850 HCI: Combined Evaluation &amp; Redesign Assessment</a></h1>
<p><strong>Academic Year</strong>: 2025-26
<strong>Assessment Type</strong>: Coursework (Pass/Fail with 0-100 grading)
<strong>Timeline</strong>: Weeks 9-11 (Launch Week 9, Due end Week 10)
<strong>Pass Threshold</strong>: 40/100 marks</p>
<hr />
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p><strong>What</strong>: Evidence-based portfolio combining evaluation and redesign in a single submission</p>
<p><strong>Why</strong>: Demonstrate HCI competence through rigorous evaluation ‚Üí data-driven redesign ‚Üí verified improvement</p>
<p><strong>How</strong>: Run peer pilots (n=2 min), collect metrics, implement accessibility fixes, verify with regression testing</p>
<p><strong>Format</strong>: Evidence artifacts (CSV, tables, code diffs, screenshots) + minimal prose (~100-200 words)</p>
<hr />
<h2 id="timeline"><a class="header" href="#timeline">Timeline</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Week</th><th>Phase</th><th>Activity</th><th>Deliverable</th></tr></thead><tbody>
<tr><td><strong>Week 9 Lab 1</strong></td><td>Launch</td><td>Assessment introduced, instrumentation setup</td><td>Logger.kt working</td></tr>
<tr><td><strong>Week 9 Lab 2</strong></td><td>Evaluation</td><td>Run n=2-4 peer pilots, collect metrics</td><td>metrics.csv complete</td></tr>
<tr><td><strong>Week 10 Lab 1</strong></td><td>Analysis</td><td>Analyse data, prioritise fixes</td><td>findings-table.csv complete</td></tr>
<tr><td><strong>Week 10 Lab 2</strong></td><td>Redesign</td><td>Implement 1-3 fixes, regression test, re-pilot n=1</td><td>Peer review draft</td></tr>
<tr><td><strong>End Week 10</strong></td><td><strong>Submission</strong></td><td><strong>Submit complete portfolio to Gradescope</strong></td><td><strong>Final portfolio (pass/fail)</strong></td></tr>
<tr><td><strong>Week 11</strong></td><td>Refinement (optional)</td><td>Final polish if needed, early marking available in labs</td><td>‚Äî</td></tr>
</tbody></table>
</div>
<p><strong>Deadline</strong>: <strong>End of Week 10</strong> ‚Äî We strongly encourage submission by this date.</p>
<p><strong>Week 11</strong>: Labs available for final questions and early marking for those who submit. Use this time for refinement if needed, but aim to complete by end of Week 10.</p>
<p><strong>Total student time</strong>: 12-15 hours across Weeks 9-10</p>
<hr />
<h2 id="learning-outcomes-assessed-all-13"><a class="header" href="#learning-outcomes-assessed-all-13">Learning Outcomes Assessed (All 13)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>LO</th><th>Outcome</th><th>Evidence Location</th></tr></thead><tbody>
<tr><td><strong>LO1</strong></td><td>Differentiate methodologies</td><td>Task design rationale (protocol.md)</td></tr>
<tr><td><strong>LO2</strong></td><td>Needs-finding</td><td>Tasks linked to Week 6 job stories (protocol.md)</td></tr>
<tr><td><strong>LO3</strong></td><td>Ethical implications</td><td>Consent process, PII handling (evidence/README.md)</td></tr>
<tr><td><strong>LO4</strong></td><td>Accessibility evaluation</td><td>Regression checklist (verification.csv)</td></tr>
<tr><td><strong>LO5</strong></td><td>Prototyping</td><td>Code implementation (implementation-diffs.md)</td></tr>
<tr><td><strong>LO6</strong></td><td>Iterative design</td><td>Evaluation ‚Üí redesign flow (entire portfolio)</td></tr>
<tr><td><strong>LO7</strong></td><td>Design constraints</td><td>No-JS parity analysis (verification.csv)</td></tr>
<tr><td><strong>LO8</strong></td><td>Evaluation execution</td><td>Pilot data (metrics.csv, pilot-notes/)</td></tr>
<tr><td><strong>LO9</strong></td><td>Inclusive design</td><td>WCAG compliance (verification.csv, findings-table.csv)</td></tr>
<tr><td><strong>LO10</strong></td><td>Societal critique</td><td>Systemic barriers (findings-table.csv ‚Äúinclusion‚Äù column)</td></tr>
<tr><td><strong>LO11</strong></td><td>Collaboration</td><td>Peer pilots, peer review (pilot-notes/, peer-review.md)</td></tr>
<tr><td><strong>LO12</strong></td><td>Professionalism</td><td>Evidence chains, honest reporting (findings-table.csv)</td></tr>
<tr><td><strong>LO13</strong></td><td>HCI+SE integration</td><td>Server instrumentation, routing (metrics.csv, diffs)</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="deliverables-6-files--evidence-folder"><a class="header" href="#deliverables-6-files--evidence-folder">Deliverables (6 Files + Evidence Folder)</a></h2>
<p>Students submit <strong>ONE</strong> complete portfolio containing:</p>
<h3 id="1-protocol-tasksmd-bullet-format-minimal-prose"><a class="header" href="#1-protocol-tasksmd-bullet-format-minimal-prose">1. <code>protocol-tasks.md</code> (Bullet format, minimal prose)</a></h3>
<p><strong>Content</strong>:</p>
<ul>
<li>4-5 evaluation tasks (scenario, action, success, target time)</li>
<li>Consent script (verbatim, with rights/withdrawal)</li>
<li>Link to Week 6 job stories (LO2 evidence)</li>
</ul>
<p><strong>Format</strong>: Bullet lists, no essay paragraphs</p>
<p><strong>Example</strong>:</p>
<pre><code class="language-markdown">## Task 3: Add Task
- **Scenario**: Track new deadline "Buy milk"
- **Action**: Add task with title "Buy milk"
- **Success**: Task appears in list, no errors
- **Target**: &lt;10 seconds
- **Linked to**: Week 6 Job Story #2 ("quickly add tasks")
</code></pre>
<p><strong>Word count</strong>: ~50-100 words (just scenario context)</p>
<hr />
<h3 id="2-findings-tablecsv-evidence-chains-as-structured-data"><a class="header" href="#2-findings-tablecsv-evidence-chains-as-structured-data">2. <code>findings-table.csv</code> (Evidence chains as structured data)</a></h3>
<p><strong>Content</strong>: Each finding as a row with evidence sources</p>
<p><strong>Columns</strong>:</p>
<pre><code class="language-csv">finding,data_source,observation,wcag,impact,inclusion,effort,priority
SR errors not announced,metrics.csv L47-49 + P2 notes 14:23,"P2: 'didn't hear error'",3.3.1 Level A,5,5,3,7
Keyboard trap on filter,P3 notes 09:12 + screenshot-02.png,"Tab stuck after filter button",2.1.1 Level A,4,5,2,7
</code></pre>
<p><strong>Formula</strong>: <code>Priority = (Impact + Inclusion) - Effort</code></p>
<p><strong>Word count</strong>: 0 (pure data, quotes in observation column)</p>
<hr />
<h3 id="3-metricscsv-raw-pilot-data-from-loggerkt"><a class="header" href="#3-metricscsv-raw-pilot-data-from-loggerkt">3. <code>metrics.csv</code> (Raw pilot data from Logger.kt)</a></h3>
<p><strong>Content</strong>: Server-side instrumentation output</p>
<p><strong>Format</strong>: Standard Week 9 Lab 1 schema</p>
<pre><code class="language-csv">ts_iso,session_id,request_id,task_code,step,outcome,ms,http_status,js_mode
2025-11-22T14:18:23.456Z,P1_a7f3,req_001,T1_add,success,,890,200,on
2025-11-22T14:19:02.123Z,P2_9d2e,req_003,T2_edit,validation_error,blank_title,0,400,on
</code></pre>
<p><strong>Requirements</strong>:</p>
<ul>
<li>n=2 minimum participants (n=4 ideal)</li>
<li>Anonymous session IDs (P1_xxxx, P2_xxxx format)</li>
<li>All 9 columns present</li>
<li>No PII (no names, emails, student IDs)</li>
</ul>
<p><strong>Word count</strong>: 0 (data only)</p>
<hr />
<h3 id="4-implementation-diffsmd-beforeafter-code-minimal-narrative"><a class="header" href="#4-implementation-diffsmd-beforeafter-code-minimal-narrative">4. <code>implementation-diffs.md</code> (Before/after code, minimal narrative)</a></h3>
<p><strong>Content</strong>: 1-3 fixes with code changes</p>
<p><strong>Format</strong>: Before snippet ‚Üí After snippet ‚Üí Impact statement</p>
<p><strong>Example</strong>:</p>
<pre><code class="language-markdown">## Fix 1: Accessible Error Announcement

**Before** (routes/TaskRoutes.kt:45):
```kotlin
val error = "Title required"  // ‚ùå No ARIA
call.respondText(error, ContentType.Text.Html)
</code></pre>
<p><strong>After</strong> (routes/TaskRoutes.kt:45):</p>
<pre><code class="language-kotlin">val error = """&lt;span role="alert" aria-live="assertive"&gt;Title required&lt;/span&gt;"""  // ‚úÖ ARIA
call.respondText(error, ContentType.Text.Html)
</code></pre>
<p><strong>Impact</strong>: SR users now hear validation errors (WCAG 3.3.1 Level A pass)
<strong>Verification</strong>: verification.csv row 12 shows pass</p>
<p>[1-3 fixes total]</p>
<pre><code>
**Word count**: ~50-100 words (just "Impact" statements)

---

### 5. `verification.csv` (Regression + before/after as data)

**Part A: Regression Checklist (20 checks)**
```csv
check,criterion,level,result,notes
Keyboard nav,2.1.1 Keyboard,A,pass,All features work via Tab/Enter
Error ID,3.3.1 Error identification,A,pass,Errors have role=alert (FIXED)
Status msgs,4.1.3 Status messages,AA,pass,Status div has role=status
No-JS parity,Full feature parity,‚Äî,pass,POST-Redirect-GET working
Contrast,1.4.3 Contrast minimum,AA,pass,All text 7.1:1 (AAA)
...
[20 rows total across: Keyboard(5), Forms(3), Dynamic(3), No-JS(3), Visual(3), Semantic(3)]
</code></pre>
<p><strong>Part B: Before/After Comparison</strong></p>
<pre><code class="language-csv">metric,before_wk9,after_wk10,change,target_met
SR error detection,0/2 (0%),2/2 (100%),+100%,‚úÖ
Validation error rate,33%,0%,-33%,‚úÖ
Median time T2 edit,1400ms,1150ms,-250ms,‚úÖ
WCAG 3.3.1 pass,fail,pass,‚Äî,‚úÖ
</code></pre>
<p><strong>Word count</strong>: 0 (data + checkmarks only)</p>
<hr />
<h3 id="6-evidence-screenshots-pilot-notes-minimal-annotations"><a class="header" href="#6-evidence-screenshots-pilot-notes-minimal-annotations">6. <code>evidence/</code> (Screenshots, pilot notes, minimal annotations)</a></h3>
<p><strong>Structure</strong>:</p>
<pre><code>evidence/
‚îú‚îÄ‚îÄ screenshots/
‚îÇ   ‚îú‚îÄ‚îÄ before-sr-error.png
‚îÇ   ‚îú‚îÄ‚îÄ after-sr-error.png
‚îÇ   ‚îú‚îÄ‚îÄ regression-axe-report.png
‚îÇ   ‚îî‚îÄ‚îÄ annotations.csv (filename, alt_text, context)
‚îú‚îÄ‚îÄ pilot-notes/
‚îÇ   ‚îú‚îÄ‚îÄ P1-notes.md (timestamped observations, quotes)
‚îÇ   ‚îú‚îÄ‚îÄ P2-notes.md
‚îÇ   ‚îî‚îÄ‚îÄ consent-log.md (optional: "P1 consented 14:05, P2 consented 14:22")
‚îî‚îÄ‚îÄ README.md (privacy statement, evidence chain index)
</code></pre>
<p><strong>Requirements</strong>:</p>
<ul>
<li>All screenshots cropped/blurred (no PII)</li>
<li>Pilot notes timestamped (for evidence chain links)</li>
<li>annotations.csv provides alt text + context</li>
</ul>
<p><strong>Word count</strong>: ~50 words (alt text in annotations.csv)</p>
<hr />
<h2 id="total-word-count-100-200-words"><a class="header" href="#total-word-count-100-200-words">Total Word Count: ~100-200 words</a></h2>
<p><strong>Where minimal prose appears</strong>:</p>
<ul>
<li>Task scenarios (50-100 words)</li>
<li>Impact statements (50-100 words)</li>
<li>Alt text annotations (50 words)</li>
</ul>
<p><strong>Everything else</strong>: CSV data, tables, code, checklists (0 prose)</p>
<hr />
<h2 id="participant-requirements-flexible"><a class="header" href="#participant-requirements-flexible">Participant Requirements (Flexible)</a></h2>
<p><strong>Evaluation Phase</strong> (Week 9):</p>
<ul>
<li><strong>Minimum</strong>: n=2 peer pilots</li>
<li><strong>Ideal</strong>: n=4 peer pilots</li>
<li><strong>Variant requirement</strong>: At least 1 non-standard variant (keyboard-only OR screen reader OR no-JS)</li>
</ul>
<p><strong>Verification Phase</strong> (Week 10):</p>
<ul>
<li><strong>Minimum</strong>: n=1 re-pilot (must use appropriate variant for fix ‚Äî e.g., SR user if fixing SR issue)</li>
<li><strong>Ideal</strong>: n=2 re-pilots (better comparison)</li>
</ul>
<p><strong>Rationale</strong>:</p>
<ul>
<li>n=2 shows pattern (not anecdotal)</li>
<li>Flexible for scheduling/availability</li>
<li>Quality over quantity (1 SR user &gt; 4 mouse users if fixing SR accessibility)</li>
</ul>
<hr />
<h2 id="pass-criteria-must-meet-all"><a class="header" href="#pass-criteria-must-meet-all">Pass Criteria (Must Meet ALL)</a></h2>
<p>‚úÖ <strong>Evidence Complete</strong>:</p>
<ul>
<li>metrics.csv present with n=2+ participants</li>
<li>findings-table.csv has 3+ findings with evidence sources</li>
<li>verification.csv has all 20 regression checks completed</li>
<li>implementation-diffs.md shows 1-3 code changes</li>
</ul>
<p>‚úÖ <strong>Evidence Chains</strong>:</p>
<ul>
<li>findings-table.csv ‚Äúdata_source‚Äù column links to metrics.csv line numbers OR pilot notes timestamps</li>
<li>implementation-diffs.md references findings from findings-table.csv</li>
<li>verification.csv shows before/after metrics for implemented fixes</li>
</ul>
<p>‚úÖ <strong>WCAG Compliance</strong>:</p>
<ul>
<li>verification.csv shows no Level A violations remaining</li>
<li>At least 1 WCAG criterion improved (fail ‚Üí pass)</li>
</ul>
<p>‚úÖ <strong>Professional Practice</strong>:</p>
<ul>
<li>No PII violations (screenshots cropped, session IDs anonymous)</li>
<li>Honest reporting (if fix didn‚Äôt improve metrics, limitation acknowledged in verification.csv notes)</li>
<li>No-JS parity maintained (verification.csv shows both paths functional)</li>
</ul>
<hr />
<h2 id="fail-triggers-any-one-causes-fail"><a class="header" href="#fail-triggers-any-one-causes-fail">Fail Triggers (Any ONE Causes Fail)</a></h2>
<p>‚ùå <strong>Fabrication</strong> (automatic 0 marks):</p>
<ul>
<li>Data too perfect (all success, no errors, unrealistic times)</li>
<li>No pilot notes (pilots didn‚Äôt happen)</li>
<li>Metrics contradict claims (e.g., findings say n=4 but CSV shows n=2)</li>
</ul>
<p>‚ùå <strong>Severe PII Violations</strong> (-10 marks + ethics fail):</p>
<ul>
<li>Names, emails, student IDs visible in screenshots</li>
<li>Identifiable session IDs (real names used)</li>
<li>Participant consent not documented</li>
</ul>
<p>‚ùå <strong>Major Gaps</strong> (0 marks for missing section):</p>
<ul>
<li>n&lt;2 participants OR no metrics.csv</li>
<li>No regression checklist OR &lt;10 checks completed</li>
<li>No redesign implemented OR no code diffs shown</li>
<li>No before/after comparison</li>
</ul>
<hr />
<h2 id="grading-scale-passfail-outcome-0-100-marks"><a class="header" href="#grading-scale-passfail-outcome-0-100-marks">Grading Scale (Pass/Fail Outcome, 0-100 Marks)</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Mark Range</th><th>Grade Descriptor</th><th>Outcome</th></tr></thead><tbody>
<tr><td><strong>70-100</strong></td><td><strong>Excellent (First)</strong>: All evidence chains rigorous and complete. WCAG compliance thoroughly verified. Thoughtful prioritisation. Professional documentation. Honest limitations acknowledged.</td><td><strong>PASS</strong></td></tr>
<tr><td><strong>60-69</strong></td><td><strong>Very Good (2:1)</strong>: Strong evidence chains with minor gaps. WCAG mostly verified. Good prioritisation. Professional documentation with minor issues.</td><td><strong>PASS</strong></td></tr>
<tr><td><strong>50-59</strong></td><td><strong>Good (2:2)</strong>: Evidence chains present but incomplete. Some WCAG compliance. Basic prioritisation. Adequate documentation.</td><td><strong>PASS</strong></td></tr>
<tr><td><strong>40-49</strong></td><td><strong>Adequate (3rd)</strong>: Weak evidence chains. Minimal WCAG compliance. Ad-hoc prioritisation. Documentation has issues but meets minimum.</td><td><strong>PASS</strong></td></tr>
<tr><td><strong>0-39</strong></td><td><strong>Fail</strong>: No evidence chains OR fabrication OR severe PII violations OR major gaps. Does not meet minimum standard.</td><td><strong>FAIL</strong></td></tr>
</tbody></table>
</div>
<p><strong>Students receive</strong>:</p>
<ol>
<li><strong>Mark</strong>: e.g., ‚Äú67/100‚Äù</li>
<li><strong>Grade descriptor</strong>: e.g., ‚Äú2:1 standard - Very Good‚Äù</li>
<li><strong>Outcome</strong>: ‚ÄúPASS‚Äù or ‚ÄúFAIL‚Äù</li>
<li><strong>Feedback</strong>: Where criteria met/missed</li>
</ol>
<hr />
<h2 id="peer-review-week-10-lab-2"><a class="header" href="#peer-review-week-10-lab-2">Peer Review (Week 10 Lab 2)</a></h2>
<p><strong>Format</strong>: In-lab structured session, 2 mins per peer</p>
<p><strong>Checklist</strong>:</p>
<pre><code class="language-markdown">## Evidence Check (2 mins)
- [ ] ‚úÖ / ‚ùå ‚Äî metrics.csv present and opens
- [ ] ‚úÖ / ‚ùå ‚Äî findings-table.csv has data (3+ rows)
- [ ] ‚úÖ / ‚ùå ‚Äî verification.csv complete (20 checks)
- [ ] ‚úÖ / ‚ùå ‚Äî implementation-diffs.md shows code changes
- [ ] ‚úÖ / ‚ùå ‚Äî No PII visible in screenshots

**On track to pass?** Yes / No / Borderline
**If No/Borderline, missing:** ___________
</code></pre>
<p><strong>Process</strong>:</p>
<ol>
<li>Form groups of 4 (20 groups per 80-student lab)</li>
<li>Each student reviews 2 peers (4 mins total)</li>
<li>Give structured feedback (1 min per peer)</li>
<li>Staff circulate, answer questions, flag at-risk students</li>
</ol>
<hr />
<h2 id="staff-marking-5-minutes-per-portfolio"><a class="header" href="#staff-marking-5-minutes-per-portfolio">Staff Marking (5 Minutes Per Portfolio)</a></h2>
<p><strong>Decision tree</strong>:</p>
<ol>
<li>
<p><strong>Quick checks</strong> (1 min):</p>
<ul>
<li>6 files present?</li>
<li>CSV files open?</li>
<li>Spot-check 2-3 screenshots for PII</li>
</ul>
</li>
<li>
<p><strong>Pass criteria</strong> (2 mins):</p>
<ul>
<li>metrics.csv: n=2+? Columns correct?</li>
<li>findings-table.csv: Links to data sources?</li>
<li>verification.csv: 20 checks complete? WCAG Level A pass?</li>
<li>implementation-diffs.md: Code changes shown?</li>
</ul>
</li>
<li>
<p><strong>Fail triggers</strong> (1 min):</p>
<ul>
<li>Fabrication indicators? (too perfect, no notes, contradictions)</li>
<li>PII violations? (checked in step 1)</li>
<li>Major gaps? (n&lt;2, no regression, no redesign)</li>
</ul>
</li>
<li>
<p><strong>Assign mark</strong> (1 min):</p>
<ul>
<li>70-100: Excellent (complete, rigorous, professional)</li>
<li>60-69: Very good (strong with minor gaps)</li>
<li>50-59: Good (adequate with issues)</li>
<li>40-49: Pass (meets minimum)</li>
<li>0-39: Fail (below minimum OR trigger present)</li>
</ul>
</li>
</ol>
<hr />
<h2 id="alignment-to-mdbook-content"><a class="header" href="#alignment-to-mdbook-content">Alignment to Mdbook Content</a></h2>
<p><strong>Week 9 Lab 1</strong>: Server-side instrumentation (Logger.kt) ‚Üí produces metrics.csv
<strong>Week 9 Lab 2</strong>: Pilot execution, data collection ‚Üí produces pilot-notes/, metrics.csv
<strong>Week 10 Lab 1</strong>: Data analysis (Analyse.kt script provided) ‚Üí produces findings-table.csv
<strong>Week 10 Lab 2</strong>: Implementation + regression testing ‚Üí produces diffs + verification.csv</p>
<p><strong>Perfect alignment</strong> ‚úÖ ‚Äî students use exact labs content to complete assessment</p>
<hr />
<h2 id="common-questions"><a class="header" href="#common-questions">Common Questions</a></h2>
<p><strong>Q: Can I use n=2 participants instead of n=4?</strong>
A: Yes. n=2 is minimum acceptable. n=4 is ideal (shows stronger patterns) but not required.</p>
<p><strong>Q: Do I need to write essays?</strong>
A: No. This is evidence-based. Total prose: ~100-200 words (task scenarios, impact statements, alt text). Rest is CSV/tables/code.</p>
<p><strong>Q: What if my fix doesn‚Äôt improve metrics?</strong>
A: Document honestly in verification.csv notes column. Analyse why (sample size? wrong fix? needs iteration?). Honesty valued over perfect results.</p>
<p><strong>Q: Can I pilot with friends?</strong>
A: Yes, if they consent. Peer pilots are ideal. Just document consent process.</p>
<p><strong>Q: What if I can‚Äôt find participants?</strong>
A: Post in module discussion forum. Coordinate with lab peers. TAs can help connect students needing participants.</p>
<p><strong>Q: Can I use AI tools (e.g., ChatGPT, Claude, Copilot)?</strong>
A: Yes for code generation (must cite: ‚ÄúGenerated with X‚Äù). No for analysis/findings (must be your own thinking).</p>
<hr />
<p><strong>Version</strong>: 1.0 Final
<strong>Last updated</strong>: 22 November 2025
<strong>For use</strong>: Academic Year 2025-26</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="comp2850-hci-assessment-evaluation--redesign-portfolio"><a class="header" href="#comp2850-hci-assessment-evaluation--redesign-portfolio">COMP2850 HCI Assessment: Evaluation &amp; Redesign Portfolio</a></h1>
<p><strong>Student</strong>: [Your name and student ID]
<strong>Submission date</strong>: [DD/MM/YYYY]
<strong>Academic Year</strong>: 2025-26</p>
<hr />
<h2 id="privacy--ethics-statement"><a class="header" href="#privacy--ethics-statement">Privacy &amp; Ethics Statement</a></h2>
<ul>
<li><input disabled="" type="checkbox"/>
I confirm all participant data is anonymous (session IDs use P1_xxxx format, not real names)</li>
<li><input disabled="" type="checkbox"/>
I confirm all screenshots are cropped/blurred to remove PII (no names, emails, student IDs visible)</li>
<li><input disabled="" type="checkbox"/>
I confirm all participants gave informed consent</li>
<li><input disabled="" type="checkbox"/>
I confirm this work is my own (AI tools used for code generation are cited below)</li>
</ul>
<p><strong>AI tools used</strong> (if any): [e.g., ‚ÄúGitHub Copilot for route handler boilerplate (lines 45-67 in diffs)‚Äù]</p>
<hr />
<h2 id="1-protocol--tasks"><a class="header" href="#1-protocol--tasks">1. Protocol &amp; Tasks</a></h2>
<h3 id="link-to-needs-finding-lo2"><a class="header" href="#link-to-needs-finding-lo2">Link to Needs-Finding (LO2)</a></h3>
<p><strong>Week 6 Job Story #1</strong>:</p>
<blockquote>
<p>[Paste your Week 6 job story here - the one that informed your first task]</p>
</blockquote>
<p><strong>How Task 1 tests this</strong>:
[1 sentence explaining link]</p>
<hr />
<h3 id="evaluation-tasks-4-5-tasks"><a class="header" href="#evaluation-tasks-4-5-tasks">Evaluation Tasks (4-5 tasks)</a></h3>
<h4 id="task-1-t1-task-name"><a class="header" href="#task-1-t1-task-name">Task 1 (T1): [Task Name]</a></h4>
<ul>
<li><strong>Scenario</strong>: [Brief context - what user needs to do]</li>
<li><strong>Action</strong>: [Specific instruction - what to tell participant]</li>
<li><strong>Success</strong>: [Observable outcome - how you know it worked]</li>
<li><strong>Target time</strong>: [e.g., &lt;10 seconds]</li>
<li><strong>Linked to</strong>: [Week 6 Job Story #X]</li>
</ul>
<h4 id="task-2-t2-task-name"><a class="header" href="#task-2-t2-task-name">Task 2 (T2): [Task Name]</a></h4>
<ul>
<li><strong>Scenario</strong>:</li>
<li><strong>Action</strong>:</li>
<li><strong>Success</strong>:</li>
<li><strong>Target time</strong>:</li>
<li><strong>Linked to</strong>:</li>
</ul>
<h4 id="task-3-t3-task-name"><a class="header" href="#task-3-t3-task-name">Task 3 (T3): [Task Name]</a></h4>
<ul>
<li><strong>Scenario</strong>:</li>
<li><strong>Action</strong>:</li>
<li><strong>Success</strong>:</li>
<li><strong>Target time</strong>:</li>
<li><strong>Linked to</strong>:</li>
</ul>
<p>[Add Tasks 4-5 as needed]</p>
<hr />
<h3 id="consent-script-read-verbatim"><a class="header" href="#consent-script-read-verbatim">Consent Script (Read Verbatim)</a></h3>
<p><strong>Introduction</strong>:
‚ÄúThank you for participating in my HCI evaluation. This will take about 15 minutes. I‚Äôm testing my task management interface, not you. There are no right or wrong answers.‚Äù</p>
<p><strong>Rights</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
‚ÄúYour participation is voluntary. You can stop at any time without giving a reason.‚Äù</li>
<li><input disabled="" type="checkbox"/>
‚ÄúYour data will be anonymous. I‚Äôll use a code (like P1) instead of your name.‚Äù</li>
<li><input disabled="" type="checkbox"/>
‚ÄúI may take screenshots and notes. I‚Äôll remove any identifying information.‚Äù</li>
<li><input disabled="" type="checkbox"/>
‚ÄúDo you consent to participate?‚Äù [Wait for verbal yes]</li>
</ul>
<p><strong>Recorded consent timestamp</strong>: [e.g., ‚ÄúP1 consented 22/11/2025 14:05‚Äù]</p>
<hr />
<h2 id="2-findings-table"><a class="header" href="#2-findings-table">2. Findings Table</a></h2>
<p><strong>Instructions</strong>: Fill in this table with 3-5 findings from your pilots. Link each finding to data sources.</p>
<div class="table-wrapper"><table><thead><tr><th>Finding</th><th>Data Source</th><th>Observation (Quote/Timestamp)</th><th>WCAG</th><th>Impact (1-5)</th><th>Inclusion (1-5)</th><th>Effort (1-5)</th><th>Priority</th></tr></thead><tbody>
<tr><td>SR errors not announced</td><td>metrics.csv L47-49 + P2 notes 14:23</td><td>P2: ‚ÄúI didn‚Äôt hear any error‚Äù</td><td>3.3.1 Level A</td><td>5</td><td>5</td><td>3</td><td>7</td></tr>
<tr><td>[Your finding 2]</td><td>[Link to metrics.csv line OR pilot notes]</td><td>[Participant quote + timestamp]</td><td>[WCAG criterion]</td><td>[1-5]</td><td>[1-5]</td><td>[1-5]</td><td>[Score]</td></tr>
<tr><td>[Your finding 3]</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td>[Your finding 4]</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr>
<tr><td>[Your finding 5]</td><td></td><td></td><td></td><td></td><td></td><td></td><td></td></tr>
</tbody></table>
</div>
<p><strong>Priority formula</strong>: (Impact + Inclusion) - Effort</p>
<p><strong>Top 3 priorities for redesign</strong>:</p>
<ol>
<li>[Finding #X - Priority score Y]</li>
<li>[Finding #X - Priority score Y]</li>
<li>[Finding #X - Priority score Y]</li>
</ol>
<hr />
<h2 id="3-pilot-metrics-metricscsv"><a class="header" href="#3-pilot-metrics-metricscsv">3. Pilot Metrics (metrics.csv)</a></h2>
<p><strong>Instructions</strong>: Paste your raw CSV data here OR attach metrics.csv file</p>
<pre><code class="language-csv">ts_iso,session_id,request_id,task_code,step,outcome,ms,http_status,js_mode
2025-11-22T14:18:23.456Z,P1_a7f3,req_001,T1_add,success,,890,200,on
[Your metrics data here - all rows from Logger.kt output]
</code></pre>
<p><strong>Participant summary</strong>:</p>
<ul>
<li><strong>P1</strong>: [Variant - e.g., ‚ÄúStandard mouse + HTMX‚Äù]</li>
<li><strong>P2</strong>: [Variant - e.g., ‚ÄúKeyboard-only, HTMX-on‚Äù]</li>
<li><strong>P3</strong> (if applicable): [Variant]</li>
<li><strong>P4</strong> (if applicable): [Variant]</li>
</ul>
<p><strong>Total participants</strong>: [n=2, 3, or 4]</p>
<hr />
<h2 id="4-implementation-diffs"><a class="header" href="#4-implementation-diffs">4. Implementation Diffs</a></h2>
<p><strong>Instructions</strong>: Show before/after code for 1-3 fixes. Link each to findings table.</p>
<h3 id="fix-1-fix-name"><a class="header" href="#fix-1-fix-name">Fix 1: [Fix Name]</a></h3>
<p><strong>Addresses finding</strong>: [Finding #X from table above]</p>
<p><strong>Before</strong> ([file path:line number]):</p>
<pre><code class="language-kotlin">// ‚ùå Problem code
[Paste your original code here]
</code></pre>
<p><strong>After</strong> ([file path:line number]):</p>
<pre><code class="language-kotlin">// ‚úÖ Fixed code
[Paste your improved code here]
</code></pre>
<p><strong>What changed</strong>: [1 sentence - what you added/removed/modified]</p>
<p><strong>Why</strong>: [1 sentence - which WCAG criterion or usability issue this fixes]</p>
<p><strong>Impact</strong>: [1-2 sentences - how this improves UX, who benefits]</p>
<hr />
<h3 id="fix-2-fix-name"><a class="header" href="#fix-2-fix-name">Fix 2: [Fix Name]</a></h3>
<p><strong>Addresses finding</strong>: [Finding #X]</p>
<p><strong>Before</strong>:</p>
<pre><code class="language-kotlin">[Original code]
</code></pre>
<p><strong>After</strong>:</p>
<pre><code class="language-kotlin">[Fixed code]
</code></pre>
<p><strong>What changed</strong>:</p>
<p><strong>Why</strong>:</p>
<p><strong>Impact</strong>:</p>
<hr />
<p>[Add Fix 3 if applicable]</p>
<hr />
<h2 id="5-verification-results"><a class="header" href="#5-verification-results">5. Verification Results</a></h2>
<h3 id="part-a-regression-checklist-20-checks"><a class="header" href="#part-a-regression-checklist-20-checks">Part A: Regression Checklist (20 checks)</a></h3>
<p><strong>Instructions</strong>: Test all 20 criteria. Mark pass/fail/n/a + add notes.</p>
<div class="table-wrapper"><table><thead><tr><th>Check</th><th>Criterion</th><th>Level</th><th>Result</th><th>Notes</th></tr></thead><tbody>
<tr><td><strong>Keyboard (5)</strong></td><td></td><td></td><td></td><td></td></tr>
<tr><td>K1</td><td>2.1.1 All actions keyboard accessible</td><td>A</td><td>[pass/fail]</td><td>[e.g., ‚ÄúTested Tab/Enter on all buttons‚Äù]</td></tr>
<tr><td>K2</td><td>2.4.7 Focus visible</td><td>AA</td><td>[pass/fail]</td><td>[e.g., ‚Äú2px blue outline on all interactive elements‚Äù]</td></tr>
<tr><td>K3</td><td>No keyboard traps</td><td>A</td><td>[pass/fail]</td><td>[e.g., ‚ÄúCan Tab through filter, edit, delete without traps‚Äù]</td></tr>
<tr><td>K4</td><td>Logical tab order</td><td>A</td><td>[pass/fail]</td><td>[e.g., ‚ÄúTop to bottom, left to right‚Äù]</td></tr>
<tr><td>K5</td><td>Skip links present</td><td>AA</td><td>[pass/fail/n/a]</td><td>[e.g., ‚ÄúSkip to main content works‚Äù]</td></tr>
<tr><td><strong>Forms (3)</strong></td><td></td><td></td><td></td><td></td></tr>
<tr><td>F1</td><td>3.3.2 Labels present</td><td>A</td><td>[pass/fail]</td><td>[e.g., ‚ÄúAll inputs have <label> or aria-label‚Äù]</td></tr>
<tr><td>F2</td><td>3.3.1 Errors identified</td><td>A</td><td>[pass/fail]</td><td>[e.g., ‚ÄúErrors have role=alert (FIXED in Fix #1)‚Äù]</td></tr>
<tr><td>F3</td><td>4.1.2 Name/role/value</td><td>A</td><td>[pass/fail]</td><td>[e.g., ‚ÄúAll form controls have accessible names‚Äù]</td></tr>
<tr><td><strong>Dynamic (3)</strong></td><td></td><td></td><td></td><td></td></tr>
<tr><td>D1</td><td>4.1.3 Status messages</td><td>AA</td><td>[pass/fail]</td><td>[e.g., ‚ÄúStatus div has role=status‚Äù]</td></tr>
<tr><td>D2</td><td>Live regions work</td><td>AA</td><td>[pass/fail]</td><td>[e.g., ‚ÄúTested with NVDA, announces ‚ÄòTask added‚Äô‚Äù]</td></tr>
<tr><td>D3</td><td>Focus management</td><td>A</td><td>[pass/fail]</td><td>[e.g., ‚ÄúFocus moves to error summary after submit‚Äù]</td></tr>
<tr><td><strong>No-JS (3)</strong></td><td></td><td></td><td></td><td></td></tr>
<tr><td>N1</td><td>Full feature parity</td><td>‚Äî</td><td>[pass/fail]</td><td>[e.g., ‚ÄúAll CRUD ops work without JS‚Äù]</td></tr>
<tr><td>N2</td><td>POST-Redirect-GET</td><td>‚Äî</td><td>[pass/fail]</td><td>[e.g., ‚ÄúNo double-submit on refresh‚Äù]</td></tr>
<tr><td>N3</td><td>Errors visible</td><td>A</td><td>[pass/fail]</td><td>[e.g., ‚ÄúError summary shown in no-JS mode‚Äù]</td></tr>
<tr><td><strong>Visual (3)</strong></td><td></td><td></td><td></td><td></td></tr>
<tr><td>V1</td><td>1.4.3 Contrast minimum</td><td>AA</td><td>[pass/fail]</td><td>[e.g., ‚ÄúAll text 7.1:1 (AAA) via CCA‚Äù]</td></tr>
<tr><td>V2</td><td>1.4.4 Resize text</td><td>AA</td><td>[pass/fail]</td><td>[e.g., ‚Äú200% zoom, no content loss‚Äù]</td></tr>
<tr><td>V3</td><td>1.4.11 Non-text contrast</td><td>AA</td><td>[pass/fail]</td><td>[e.g., ‚ÄúFocus indicator 4.5:1‚Äù]</td></tr>
<tr><td><strong>Semantic (3)</strong></td><td></td><td></td><td></td><td></td></tr>
<tr><td>S1</td><td>1.3.1 Headings hierarchy</td><td>A</td><td>[pass/fail]</td><td>[e.g., ‚Äúh1 ‚Üí h2 ‚Üí h3, no skips‚Äù]</td></tr>
<tr><td>S2</td><td>2.4.1 Bypass blocks</td><td>A</td><td>[pass/fail]</td><td>[e.g., ‚Äú<main> landmark, <nav> for filter‚Äù]</td></tr>
<tr><td>S3</td><td>1.1.1 Alt text</td><td>A</td><td>[pass/fail]</td><td>[e.g., ‚ÄúNo images in interface OR all have alt‚Äù]</td></tr>
</tbody></table>
</div>
<p><strong>Summary</strong>: [X/20 pass], [Y/20 fail]
<strong>Critical failures</strong> (if any): [List any Level A fails]</p>
<hr />
<h3 id="part-b-beforeafter-comparison"><a class="header" href="#part-b-beforeafter-comparison">Part B: Before/After Comparison</a></h3>
<p><strong>Instructions</strong>: Compare Week 9 baseline (pre-fix) to Week 10 (post-fix). Show improvement.</p>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>Before (Week 9, n=X)</th><th>After (Week 10, n=Y)</th><th>Change</th><th>Target Met?</th></tr></thead><tbody>
<tr><td>SR error detection</td><td>[e.g., 0/2 (0%)]</td><td>[e.g., 2/2 (100%)]</td><td>[e.g., +100%]</td><td>[‚úÖ/‚ùå]</td></tr>
<tr><td>Validation error rate</td><td>[e.g., 33%]</td><td>[e.g., 0%]</td><td>[e.g., -33%]</td><td>[‚úÖ/‚ùå]</td></tr>
<tr><td>Median time [Task X]</td><td>[e.g., 1400ms]</td><td>[e.g., 1150ms]</td><td>[e.g., -250ms]</td><td>[‚úÖ/‚ùå]</td></tr>
<tr><td>WCAG [criterion] pass</td><td>[fail]</td><td>[pass]</td><td>[‚Äî ]</td><td>[‚úÖ/‚ùå]</td></tr>
</tbody></table>
</div>
<p><strong>Re-pilot details</strong>:</p>
<ul>
<li><strong>P5</strong> (post-fix): [Variant - e.g., ‚ÄúScreen reader user, NVDA + keyboard‚Äù] - [Date piloted]</li>
<li><strong>P6</strong> (if applicable): [Variant] - [Date]</li>
</ul>
<p><strong>Limitations / Honest reporting</strong>:
[If metrics didn‚Äôt improve or only modestly: explain why. Small sample size? Wrong fix? Needs more iteration? Be honest - valued over perfect results.]</p>
<hr />
<h2 id="6-evidence-folder-contents"><a class="header" href="#6-evidence-folder-contents">6. Evidence Folder Contents</a></h2>
<p><strong>Instructions</strong>: List all files in your evidence/ folder. Provide context.</p>
<h3 id="screenshots"><a class="header" href="#screenshots">Screenshots</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Filename</th><th>What it shows</th><th>Context/Link to finding</th></tr></thead><tbody>
<tr><td>before-sr-error.png</td><td>Error message without role=‚Äúalert‚Äù</td><td>Finding #1 - SR errors not announced</td></tr>
<tr><td>after-sr-error.png</td><td>Error message WITH role=‚Äúalert‚Äù added</td><td>Fix #1 verification</td></tr>
<tr><td>regression-axe-report.png</td><td>axe DevTools showing 0 violations</td><td>Verification Part A</td></tr>
<tr><td>[your-screenshot-3.png]</td><td>[Description]</td><td>[Which finding/fix this supports]</td></tr>
</tbody></table>
</div>
<p><strong>PII check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
All screenshots cropped to show only relevant UI</li>
<li><input disabled="" type="checkbox"/>
Browser bookmarks/tabs not visible</li>
<li><input disabled="" type="checkbox"/>
Participant names/emails blurred or not visible</li>
</ul>
<hr />
<h3 id="pilot-notes"><a class="header" href="#pilot-notes">Pilot Notes</a></h3>
<p><strong>Instructions</strong>: Attach pilot notes as separate files (P1-notes.md, P2-notes.md, etc.). Summarize key observations here.</p>
<p><strong>P1</strong> ([ Variant - e.g., ‚ÄúStandard mouse + HTMX‚Äù]):</p>
<ul>
<li><strong>Key observation 1</strong>: [Quote + timestamp - e.g., ‚ÄúStruggled with filter button (09:47)‚Äù]</li>
<li><strong>Key observation 2</strong>: [Quote + timestamp]</li>
</ul>
<p><strong>P2</strong> ([Variant]):</p>
<ul>
<li><strong>Key observation 1</strong>: [Quote + timestamp]</li>
<li><strong>Key observation 2</strong>: [Quote + timestamp]</li>
</ul>
<p>[Repeat for P3, P4 if applicable]</p>
<hr />
<h2 id="evidence-chain-example-full-trace"><a class="header" href="#evidence-chain-example-full-trace">Evidence Chain Example (Full Trace)</a></h2>
<p><strong>Instructions</strong>: Pick ONE finding and show complete evidence trail from data ‚Üí fix ‚Üí verification.</p>
<p><strong>Finding selected</strong>: [e.g., ‚ÄúFinding #1 - SR errors not announced‚Äù]</p>
<p><strong>Evidence trail</strong>:</p>
<ol>
<li><strong>Data</strong>: metrics.csv lines 47-49 show P2 (SR user) triggered validation_error 3 times</li>
<li><strong>Observation</strong>: P2 pilot notes timestamp 14:23 - Quote: ‚ÄúI don‚Äôt know if it worked, didn‚Äôt hear anything‚Äù</li>
<li><strong>Screenshot</strong>: before-sr-error.png shows error message has no role=‚Äúalert‚Äù or aria-live</li>
<li><strong>WCAG</strong>: 3.3.1 Error Identification (Level A) violation - errors not programmatically announced</li>
<li><strong>Prioritisation</strong>: findings-table.csv row 1 - Priority score 7 (Impact 5 + Inclusion 5 - Effort 3)</li>
<li><strong>Fix</strong>: implementation-diffs.md Fix #1 - Added role=‚Äúalert‚Äù + aria-live=‚Äúassertive‚Äù to error span</li>
<li><strong>Verification</strong>: verification.csv Part A row F2 - 3.3.1 now PASS (tested with NVDA)</li>
<li><strong>Before/after</strong>: verification.csv Part B - SR error detection improved from 0% to 100%</li>
<li><strong>Re-pilot</strong>: P5 (SR user) pilot notes - ‚ÄúHeard error announcement immediately, corrected and succeeded‚Äù</li>
</ol>
<p><strong>Complete chain</strong>: Data ‚Üí Observation ‚Üí Interpretation ‚Üí Fix ‚Üí Verification ‚úÖ</p>
<hr />
<h2 id="submission-checklist"><a class="header" href="#submission-checklist">Submission Checklist</a></h2>
<p>Before submitting, verify:</p>
<p><strong>Files</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
This completed template (submission-template.md)</li>
<li><input disabled="" type="checkbox"/>
metrics.csv (or pasted into Section 3)</li>
<li><input disabled="" type="checkbox"/>
Pilot notes (P1-notes.md, P2-notes.md, etc. OR summarised in Section 6)</li>
<li><input disabled="" type="checkbox"/>
Screenshots folder (all images referenced above)</li>
<li><input disabled="" type="checkbox"/>
Privacy statement signed (top of document)</li>
</ul>
<p><strong>Evidence chains</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
findings-table.csv links to metrics.csv lines AND/OR pilot notes timestamps</li>
<li><input disabled="" type="checkbox"/>
implementation-diffs.md references findings from table</li>
<li><input disabled="" type="checkbox"/>
verification.csv Part B shows before/after for fixes</li>
</ul>
<p><strong>Quality</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
No PII in screenshots (checked twice!)</li>
<li><input disabled="" type="checkbox"/>
Session IDs anonymous (P1_xxxx format, not real names)</li>
<li><input disabled="" type="checkbox"/>
Honest reporting (limitations acknowledged if metrics didn‚Äôt improve)</li>
<li><input disabled="" type="checkbox"/>
WCAG criteria cited specifically (e.g., ‚Äú3.3.1‚Äù not just ‚Äúaccessibility‚Äù)</li>
</ul>
<p><strong>Pass criteria met</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
n=2+ participants (metrics.csv has 2+ session IDs)</li>
<li><input disabled="" type="checkbox"/>
3+ findings with evidence (findings-table.csv complete)</li>
<li><input disabled="" type="checkbox"/>
1-3 fixes implemented (implementation-diffs.md shows code)</li>
<li><input disabled="" type="checkbox"/>
Regression complete (verification.csv has 20 checks)</li>
<li><input disabled="" type="checkbox"/>
Before/after shown (verification.csv Part B has data)</li>
</ul>
<hr />
<p><strong>Ready to submit?</strong> Upload this file + evidence folder to Gradescope by end of Week 10.</p>
<p><strong>Estimated completion time</strong>: 12-15 hours across Weeks 9-11</p>
<p><strong>Good luck!</strong> üéØ</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="comp2850-hci-assessment-faq"><a class="header" href="#comp2850-hci-assessment-faq">COMP2850 HCI: Assessment FAQ</a></h1>
<p><strong>Academic Year</strong>: 2025-26
<strong>Assessment</strong>: Combined Evaluation &amp; Redesign Portfolio
<strong>Timeline</strong>: Weeks 9-11</p>
<hr />
<h2 id="general-questions"><a class="header" href="#general-questions">General Questions</a></h2>
<h3 id="q-what-am-i-submitting"><a class="header" href="#q-what-am-i-submitting">Q: What am I submitting?</a></h3>
<p><strong>A</strong>: One complete portfolio with these files:</p>
<ol>
<li><strong>submission-template.md</strong> ‚Äî Single markdown file (all sections filled in)</li>
<li><strong>evidence/</strong> folder ‚Äî Screenshots (no PII), pilot notes</li>
</ol>
<p>Total word count: ~100-200 words (evidence-based, not essay!)</p>
<h3 id="q-when-is-the-deadline"><a class="header" href="#q-when-is-the-deadline">Q: When is the deadline?</a></h3>
<p><strong>A</strong>: End of Week 10 (submit via Gradescope)</p>
<p>Timeline:</p>
<ul>
<li><strong>Week 9</strong>: Run peer pilots, collect metrics.csv</li>
<li><strong>Week 10</strong>: Implement fixes, regression test, peer review</li>
<li><strong>Week 11</strong>: Incorporate feedback, final polish, submit</li>
</ul>
<h3 id="q-is-this-passfail"><a class="header" href="#q-is-this-passfail">Q: Is this pass/fail?</a></h3>
<p><strong>A</strong>: Yes, pass/fail <strong>outcome</strong> (40% threshold), but you also receive a <strong>0-100 mark</strong> for formative feedback showing quality level:</p>
<ul>
<li>70-100: First (excellent)</li>
<li>60-69: 2:1 (very good)</li>
<li>50-59: 2:2 (good)</li>
<li>40-49: 3rd (minimum pass)</li>
<li>0-39: Fail</li>
</ul>
<hr />
<h2 id="participants--pilots"><a class="header" href="#participants--pilots">Participants &amp; Pilots</a></h2>
<h3 id="q-how-many-participants-do-i-need"><a class="header" href="#q-how-many-participants-do-i-need">Q: How many participants do I need?</a></h3>
<p><strong>A</strong>: Minimum n=2, ideal n=4</p>
<p><strong>Why n=2 minimum?</strong> Shows pattern (not anecdotal evidence)
<strong>Why not require n=4?</strong> Flexible for scheduling/availability</p>
<p><strong>Variant requirement</strong>: At least 1 non-standard variant (keyboard-only OR screen reader OR no-JS)</p>
<h3 id="q-can-i-pilot-with-friends"><a class="header" href="#q-can-i-pilot-with-friends">Q: Can I pilot with friends?</a></h3>
<p><strong>A</strong>: Yes, if they consent! Peer pilots are ideal. Just document consent process (read script verbatim, record timestamp).</p>
<h3 id="q-what-if-i-cant-find-participants"><a class="header" href="#q-what-if-i-cant-find-participants">Q: What if I can‚Äôt find participants?</a></h3>
<p><strong>A</strong>:</p>
<ul>
<li>Post in module discussion forum (‚Äúseeking pilot participants‚Äù)</li>
<li>Coordinate with lab peers</li>
<li>Ask TAs to help connect students</li>
<li>Pilots can happen outside lab time (just by Week 9 deadline)</li>
</ul>
<h3 id="q-can-i-test-on-the-same-participants-for-re-pilots-verification"><a class="header" href="#q-can-i-test-on-the-same-participants-for-re-pilots-verification">Q: Can I test on the same participants for re-pilots (verification)?</a></h3>
<p><strong>A</strong>: Yes, if they consent. They‚Äôre now ‚Äúexpert users‚Äù ‚Äî document this limitation in verification.csv notes.</p>
<h3 id="q-what-if-i-only-get-n1-participant"><a class="header" href="#q-what-if-i-only-get-n1-participant">Q: What if I only get n=1 participant?</a></h3>
<p><strong>A</strong>: That‚Äôs below minimum. Run at least 1 more pilot. n=2 is required to show pattern. If genuinely stuck despite effort, talk to TA about extension.</p>
<hr />
<h2 id="what-to-submit"><a class="header" href="#what-to-submit">What to Submit</a></h2>
<h3 id="q-do-i-need-to-write-essays"><a class="header" href="#q-do-i-need-to-write-essays">Q: Do I need to write essays?</a></h3>
<p><strong>A</strong>: No! This is evidence-based. Total prose: ~100-200 words (task scenarios, impact statements, alt text). Everything else is CSV, tables, code diffs, checklists.</p>
<p>Example:</p>
<ul>
<li>‚ùå Essay: ‚ÄúI improved accessibility by conducting rigorous WCAG evaluations and implementing comprehensive ARIA enhancements across multiple interface components‚Ä¶‚Äù</li>
<li>‚úÖ Evidence: findings-table.csv ‚Üí implementation-diffs.md ‚Üí verification.csv (data ‚Üí fix ‚Üí verification)</li>
</ul>
<h3 id="q-what-files-do-i-submit"><a class="header" href="#q-what-files-do-i-submit">Q: What files do I submit?</a></h3>
<p><strong>A</strong>:</p>
<ol>
<li><strong>submission-template.md</strong> (completed) ‚Äî One file with all sections</li>
<li><strong>evidence/</strong> folder containing:
<ul>
<li>Screenshots (before/after, no PII)</li>
<li>Pilot notes (P1-notes.md, P2-notes.md, etc.)</li>
</ul>
</li>
</ol>
<p>metrics.csv can be pasted into submission-template.md Section 3 OR attached separately.</p>
<h3 id="q-how-do-i-scrub-pii"><a class="header" href="#q-how-do-i-scrub-pii">Q: How do I scrub PII?</a></h3>
<p><strong>A</strong>: Before submission:</p>
<ul>
<li>Crop screenshots to show only relevant UI (no browser bookmarks, tabs, usernames)</li>
<li>Use anonymous session IDs (P1_xxxx format, not real names)</li>
<li>Blur any visible names, emails, student IDs</li>
<li>Check pilot notes use participant codes (P1, P2) not names</li>
</ul>
<p><strong>Critical</strong>: Severe PII violations (names/emails visible) = automatic fail.</p>
<hr />
<h2 id="evidence--data"><a class="header" href="#evidence--data">Evidence &amp; Data</a></h2>
<h3 id="q-what-if-my-data-is-too-messy-lots-of-errors"><a class="header" href="#q-what-if-my-data-is-too-messy-lots-of-errors">Q: What if my data is ‚Äútoo messy‚Äù (lots of errors)?</a></h3>
<p><strong>A</strong>: That‚Äôs <strong>good</strong> data! Real evaluation shows errors, confusion, failures. Report honestly.</p>
<p>Fabricated data (100% success, no errors, unrealistic times) is a fail trigger. Authentic data (even messy) is valued.</p>
<h3 id="q-what-if-my-fix-didnt-improve-metrics"><a class="header" href="#q-what-if-my-fix-didnt-improve-metrics">Q: What if my fix didn‚Äôt improve metrics?</a></h3>
<p><strong>A</strong>: Document honestly! Analyse why:</p>
<ul>
<li>Small sample size (n=2 may not show clear improvement)</li>
<li>Wrong fix (addressed symptom not root cause)</li>
<li>Need more iteration</li>
</ul>
<p>In verification.csv notes, write: ‚ÄúFix did not improve metrics, likely because [small n / wrong diagnosis / needs different approach].‚Äù</p>
<p><strong>Honest reporting is professional practice</strong> (LO12). Fabricating improvement is fail.</p>
<h3 id="q-my-metricscsv-is-huge-200-rows-do-i-submit-it-all"><a class="header" href="#q-my-metricscsv-is-huge-200-rows-do-i-submit-it-all">Q: My metrics.csv is huge (200+ rows). Do I submit it all?</a></h3>
<p><strong>A</strong>: Yes! Paste all rows in submission-template.md Section 3 OR attach as separate file. Staff use this to verify patterns.</p>
<p>If truly massive (500+ rows), attach as separate file and note in template: ‚ÄúSee attached metrics.csv‚Äù.</p>
<hr />
<h2 id="technical-questions"><a class="header" href="#technical-questions">Technical Questions</a></h2>
<h3 id="q-loggerkt-isnt-working-help"><a class="header" href="#q-loggerkt-isnt-working-help">Q: Logger.kt isn‚Äôt working. Help!</a></h3>
<p><strong>Common issues</strong>:</p>
<ol>
<li><strong>File not created</strong>: Check project root for metrics.csv. If missing, check Logger.kt init block.</li>
<li><strong>No rows appearing</strong>: Check you‚Äôre calling Logger.log() in route handlers.</li>
<li><strong>JS mode always ‚Äúon‚Äù</strong>: Check HX-Request header detection (<code>call.request.headers["HX-Request"] == "true"</code>).</li>
<li><strong>Doesn‚Äôt work in no-JS mode</strong>: Logger.kt is server-side (should work). Check routing ‚Äî are no-JS requests reaching your POST handler?</li>
</ol>
<p><strong>Still stuck?</strong> Ask in lab or module forum with specific error message.</p>
<h3 id="q-can-i-use-ai-tools-chatgpt-claude-copilot"><a class="header" href="#q-can-i-use-ai-tools-chatgpt-claude-copilot">Q: Can I use AI tools (ChatGPT, Claude, Copilot)?</a></h3>
<p><strong>A</strong>: Yes for code generation (must cite in submission).
<strong>No</strong> for analysis/findings (must be your own thinking).</p>
<p>Example citation in submission-template.md Privacy Statement:</p>
<blockquote>
<p>‚ÄúAI tools used: GitHub Copilot for route handler boilerplate (implementation-diffs.md Fix #1, lines 45-67)‚Äù</p>
</blockquote>
<h3 id="q-what-if-i-break-my-prototype-while-implementing-fixes"><a class="header" href="#q-what-if-i-break-my-prototype-while-implementing-fixes">Q: What if I break my prototype while implementing fixes?</a></h3>
<p><strong>A</strong>: Use git! Commit working baseline before making changes:</p>
<pre><code class="language-bash">git add .
git commit -m "Baseline before fixes (Week 10)"
</code></pre>
<p>If fix breaks things:</p>
<pre><code class="language-bash">git checkout [filename]  # Revert specific file
</code></pre>
<p>Or start fix on a branch:</p>
<pre><code class="language-bash">git checkout -b fix-sr-errors
</code></pre>
<hr />
<h2 id="grading--quality"><a class="header" href="#grading--quality">Grading &amp; Quality</a></h2>
<h3 id="q-what-makes-a-first-70"><a class="header" href="#q-what-makes-a-first-70">Q: What makes a First (70+)?</a></h3>
<p><strong>Characteristics</strong>:</p>
<ul>
<li>All evidence chains rigorous and complete (can trace 3+ findings from data ‚Üí fix ‚Üí verification)</li>
<li>WCAG compliance thorough (20/20 regression checks, no Level A violations)</li>
<li>Professional documentation (no PII, honest reporting of limitations)</li>
<li>Code fixes target root causes, well-integrated</li>
<li>Before/after metrics show measurable improvement (or honest analysis)</li>
</ul>
<p><strong>Example</strong>: Finding #1 traceable: metrics.csv L47-49 ‚Üí pilot notes P2 14:23 ‚Üí findings table ‚Üí Fix #1 diffs ‚Üí verification.csv 3.3.1 pass ‚Üí before/after 0% ‚Üí 100%.</p>
<h3 id="q-whats-the-minimum-to-pass-40"><a class="header" href="#q-whats-the-minimum-to-pass-40">Q: What‚Äôs the minimum to pass (40)?</a></h3>
<p><strong>Minimum requires</strong>:</p>
<ul>
<li>n=2 participants (verified in metrics.csv)</li>
<li>3 findings with some data sources (even if vague)</li>
<li>1 fix with code diff shown</li>
<li>Partial regression (at least 10/20 checks, ideally 20)</li>
<li>No fabrication, no severe PII violations</li>
</ul>
<h3 id="q-do-i-need-to-fix-all-my-findings"><a class="header" href="#q-do-i-need-to-fix-all-my-findings">Q: Do I need to fix ALL my findings?</a></h3>
<p><strong>A</strong>: No! Focus on 1-3 high-priority issues. Quality over quantity.</p>
<p><strong>Good approach</strong>:</p>
<ul>
<li>Prioritise using (Impact + Inclusion) - Effort</li>
<li>Select top 2-3 fixes</li>
<li>Verify thoroughly</li>
</ul>
<p><strong>Bad approach</strong>:</p>
<ul>
<li>Try to fix 8 issues</li>
<li>Half-finish all of them</li>
<li>Poor verification</li>
</ul>
<h3 id="q-can-i-introduce-new-features"><a class="header" href="#q-can-i-introduce-new-features">Q: Can I introduce new features?</a></h3>
<p><strong>A</strong>: No. This is <strong>redesign</strong>, not new feature development. Fix existing usability issues only.</p>
<hr />
<h2 id="peer-review-week-10-lab-2-1"><a class="header" href="#peer-review-week-10-lab-2-1">Peer Review (Week 10 Lab 2)</a></h2>
<h3 id="q-what-is-peer-review"><a class="header" href="#q-what-is-peer-review">Q: What is peer review?</a></h3>
<p><strong>A</strong>: Structured in-lab session (15 mins) where groups of 4 review each other‚Äôs portfolios using a checklist. Focus: Are files present? n=2+? 3+ findings? PII scrubbed?</p>
<p><strong>Not graded</strong>. Helps you catch gaps before final submission.</p>
<h3 id="q-what-if-my-peer-gives-me-conflicting-feedback"><a class="header" href="#q-what-if-my-peer-gives-me-conflicting-feedback">Q: What if my peer gives me conflicting feedback?</a></h3>
<p><strong>A</strong>: Peer review is formative (not binding). Consider their perspective ‚Äî if they couldn‚Äôt find your evidence in 2 minutes, staff might struggle too. Make links clearer.</p>
<h3 id="q-what-if-i-disagree-with-my-peers-assessment"><a class="header" href="#q-what-if-i-disagree-with-my-peers-assessment">Q: What if I disagree with my peer‚Äôs assessment?</a></h3>
<p><strong>A</strong>: That‚Äôs fine. Use feedback to improve, but trust your own judgment. If peer says ‚Äúmissing files‚Äù but you have them, double-check file names match submission-template.md references.</p>
<hr />
<h2 id="common-pitfalls"><a class="header" href="#common-pitfalls">Common Pitfalls</a></h2>
<h3 id="pitfall-1-trying-to-fix-everything"><a class="header" href="#pitfall-1-trying-to-fix-everything">Pitfall 1: Trying to fix everything</a></h3>
<p><strong>Problem</strong>: 8 issues identified, try to fix all, run out of time
<strong>Solution</strong>: Prioritise 2-3 high-priority fixes using (Impact + Inclusion) - Effort</p>
<h3 id="pitfall-2-vague-data-sources"><a class="header" href="#pitfall-2-vague-data-sources">Pitfall 2: Vague data sources</a></h3>
<p><strong>Problem</strong>: findings-table.csv says ‚Äúpilot observations‚Äù instead of specific sources
<strong>Solution</strong>: Use metrics.csv line numbers (e.g., ‚ÄúL47-49‚Äù) or pilot notes timestamps (e.g., ‚ÄúP2 notes 14:23‚Äù)</p>
<h3 id="pitfall-3-no-beforeafter-comparison"><a class="header" href="#pitfall-3-no-beforeafter-comparison">Pitfall 3: No before/after comparison</a></h3>
<p><strong>Problem</strong>: ‚ÄúI fixed it‚Äù (no metrics showing improvement)
<strong>Solution</strong>: Run 1-2 re-pilots after fixes, compare to baseline (verification.csv Part B)</p>
<h3 id="pitfall-4-pii-in-screenshots"><a class="header" href="#pitfall-4-pii-in-screenshots">Pitfall 4: PII in screenshots</a></h3>
<p><strong>Problem</strong>: Participant names, emails visible in evidence
<strong>Solution</strong>: Crop/blur before submission. Check twice! Automatic fail if not corrected.</p>
<h3 id="pitfall-5-incomplete-regression"><a class="header" href="#pitfall-5-incomplete-regression">Pitfall 5: Incomplete regression</a></h3>
<p><strong>Problem</strong>: Only 5/20 WCAG checks completed
<strong>Solution</strong>: Complete all 20 checks using Assistive Testing Checklist. If time-limited, minimum ~10 checks for pass.</p>
<hr />
<h2 id="specific-scenarios"><a class="header" href="#specific-scenarios">Specific Scenarios</a></h2>
<h3 id="q-my-participant-completed-all-tasks-perfectly-no-errors-is-that-ok"><a class="header" href="#q-my-participant-completed-all-tasks-perfectly-no-errors-is-that-ok">Q: My participant completed all tasks perfectly (no errors). Is that OK?</a></h3>
<p><strong>A</strong>: Unusual but possible (expert user, very simple tasks). Make sure:</p>
<ul>
<li>You have pilot notes (quotes, observations, timestamps)</li>
<li>You can explain their session if asked</li>
<li>You‚Äôre testing appropriate participants (not HCI experts who know the answers)</li>
</ul>
<p>If data seems ‚Äútoo perfect‚Äù (100% success, all times &lt;5s), that‚Äôs a red flag for fabrication.</p>
<h3 id="q-i-have-3-findings-but-theyre-all-minor-eg-button-label-typos-will-i-fail"><a class="header" href="#q-i-have-3-findings-but-theyre-all-minor-eg-button-label-typos-will-i-fail">Q: I have 3 findings but they‚Äôre all minor (e.g., button label typos). Will I fail?</a></h3>
<p><strong>A</strong>: Depends. If all findings are trivial and don‚Äôt address accessibility/usability, marks will be lower (50-60 range). Better approach:</p>
<ul>
<li>Use WCAG regression checklist to find violations</li>
<li>Review pilot notes for participant confusion/errors</li>
<li>Look for patterns in metrics.csv (validation errors, high times)</li>
</ul>
<h3 id="q-my-re-pilot-metrics-are-worse-than-baseline-failed-fix"><a class="header" href="#q-my-re-pilot-metrics-are-worse-than-baseline-failed-fix">Q: My re-pilot metrics are worse than baseline. Failed fix?</a></h3>
<p><strong>A</strong>: Potentially, but document honestly! In verification.csv notes:</p>
<ul>
<li>‚ÄúMetrics worse ‚Äî possible regression introduced by fix‚Äù</li>
<li>‚ÄúNeed to investigate unintended side effects‚Äù</li>
<li>‚ÄúMay require different approach‚Äù</li>
</ul>
<p>Honest analysis valued. Fabricating improvement is fail.</p>
<h3 id="q-i-only-implemented-1-fix-is-that-enough"><a class="header" href="#q-i-only-implemented-1-fix-is-that-enough">Q: I only implemented 1 fix. Is that enough?</a></h3>
<p><strong>A</strong>: Yes, if:</p>
<ul>
<li>Fix is substantial (addresses major usability/accessibility issue)</li>
<li>Thoroughly verified (regression + before/after)</li>
<li>Well-documented (code diff + rationale)</li>
</ul>
<p>1 fix done well &gt; 3 fixes half-finished.</p>
<hr />
<h2 id="extensions--special-circumstances"><a class="header" href="#extensions--special-circumstances">Extensions &amp; Special Circumstances</a></h2>
<h3 id="q-what-if-im-sick-during-week-9-pilots"><a class="header" href="#q-what-if-im-sick-during-week-9-pilots">Q: What if I‚Äôm sick during Week 9 pilots?</a></h3>
<p><strong>A</strong>: Request extension via standard university process. Provide evidence (e.g., medical note). Module leader will assess.</p>
<p>Pilots can happen outside lab time, so reschedule if possible.</p>
<h3 id="q-can-i-get-extra-time-for-disability"><a class="header" href="#q-can-i-get-extra-time-for-disability">Q: Can I get extra time for disability?</a></h3>
<p><strong>A</strong>: Yes, if registered with Disability Services. Contact module leader with your Support Plan.</p>
<p>Example accommodations:</p>
<ul>
<li>Extended deadline</li>
<li>Alternative pilot formats (remote, asynchronous)</li>
<li>Reduced participant requirement (check with module leader)</li>
</ul>
<h3 id="q-what-happens-if-i-submit-late"><a class="header" href="#q-what-happens-if-i-submit-late">Q: What happens if I submit late?</a></h3>
<p><strong>A</strong>: Standard university late penalties apply (check Student Handbook). Exceptions for documented extensions only.</p>
<hr />
<h2 id="after-submission"><a class="header" href="#after-submission">After Submission</a></h2>
<h3 id="q-when-do-i-get-my-mark"><a class="header" href="#q-when-do-i-get-my-mark">Q: When do I get my mark?</a></h3>
<p><strong>A</strong>: Marks released according to university assessment timeline (typically 3-4 weeks after deadline). Check VLE announcements.</p>
<h3 id="q-can-i-see-my-marked-portfolio"><a class="header" href="#q-can-i-see-my-marked-portfolio">Q: Can I see my marked portfolio?</a></h3>
<p><strong>A</strong>: Yes, feedback available via Gradescope. Staff provide:</p>
<ul>
<li>Mark (0-100)</li>
<li>Grade (First/2:1/2:2/3rd/Fail)</li>
<li>Outcome (PASS/FAIL)</li>
<li>Feedback (2-3 sentences on strengths/gaps)</li>
</ul>
<h3 id="q-what-if-i-fail"><a class="header" href="#q-what-if-i-fail">Q: What if I fail?</a></h3>
<p><strong>A</strong>: Options depend on circumstances:</p>
<ul>
<li><strong>Borderline fail</strong> (35-39): May be offered resubmission with specific requirements</li>
<li><strong>Clear fail</strong> (&lt;35): Likely need to retake assessment</li>
<li><strong>Fabrication/ethics violation</strong>: Serious academic misconduct (refer to university process)</li>
</ul>
<p>Contact module leader to discuss next steps.</p>
<h3 id="q-can-i-appeal-my-mark"><a class="header" href="#q-can-i-appeal-my-mark">Q: Can I appeal my mark?</a></h3>
<p><strong>A</strong>: Yes, via standard university appeals process. Grounds for appeal:</p>
<ul>
<li>Procedural irregularity</li>
<li>Extenuating circumstances not previously disclosed</li>
<li>Evidence of bias</li>
</ul>
<p><strong>Not grounds for appeal</strong>: ‚ÄúI think I deserved higher‚Äù or ‚ÄúI worked really hard‚Äù. Marks based on evidence-based rubric.</p>
<hr />
<h2 id="quick-reference-timeline"><a class="header" href="#quick-reference-timeline">Quick Reference: Timeline</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Week</th><th>What to Do</th><th>Deadline</th></tr></thead><tbody>
<tr><td><strong>Week 9 Lab 1</strong></td><td>Assessment launches, Logger.kt setup</td><td>‚Äî</td></tr>
<tr><td><strong>Week 9 Lab 2</strong></td><td>Run n=2-4 peer pilots, collect metrics.csv</td><td>End Week 9</td></tr>
<tr><td><strong>Week 10 Lab 1</strong></td><td>Analyse data, prioritise fixes</td><td>‚Äî</td></tr>
<tr><td><strong>Week 10 Lab 2</strong></td><td>Implement fixes, regression test, peer review</td><td>End Week 10</td></tr>
<tr><td><strong>Week 11</strong></td><td>Incorporate feedback, final polish</td><td>‚Äî</td></tr>
<tr><td><strong>End Week 10</strong></td><td><strong>Submit to Gradescope</strong></td><td><strong>FINAL DEADLINE</strong></td></tr>
</tbody></table>
</div>
<hr />
<h2 id="still-have-questions"><a class="header" href="#still-have-questions">Still Have Questions?</a></h2>
<p><strong>In labs</strong>: Ask lecturer or TA
<strong>Module forum</strong>: Post questions (check existing threads first)
<strong>Office hours</strong>: See VLE for times
<strong>Email</strong>: Module leader (allow 2-3 days for response)</p>
<p><strong>Good luck with your assessment!</strong> üìä</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="comp2850-hci-combined-assessment-rubric"><a class="header" href="#comp2850-hci-combined-assessment-rubric">COMP2850 HCI: Combined Assessment Rubric</a></h1>
<p><strong>Academic Year</strong>: 2025-26
<strong>Assessment Type</strong>: Coursework (Pass/Fail with 0-100 grading)
<strong>Pass Threshold</strong>: 40/100 marks
<strong>Marking Time</strong>: 5 minutes per portfolio</p>
<hr />
<h2 id="quick-reference-5-minute-marking-decision-tree"><a class="header" href="#quick-reference-5-minute-marking-decision-tree">Quick Reference: 5-Minute Marking Decision Tree</a></h2>
<p><strong>Step 1: Files Present? (30 seconds)</strong></p>
<ul>
<li><input disabled="" type="checkbox"/>
submission-template.md (completed)</li>
<li><input disabled="" type="checkbox"/>
metrics.csv (or pasted in template)</li>
<li><input disabled="" type="checkbox"/>
evidence/ folder (screenshots, pilot notes)</li>
</ul>
<p>If NO ‚Üí <strong>FAIL (0-39)</strong> - Major gap</p>
<p><strong>Step 2: Minimum Evidence? (1 minute)</strong></p>
<ul>
<li><input disabled="" type="checkbox"/>
metrics.csv has n=2+ participants (check session IDs)</li>
<li><input disabled="" type="checkbox"/>
findings-table.csv has 3+ findings with data sources</li>
<li><input disabled="" type="checkbox"/>
implementation-diffs.md shows 1-3 code changes</li>
<li><input disabled="" type="checkbox"/>
verification.csv has 20 regression checks</li>
</ul>
<p>If NO ‚Üí <strong>FAIL (0-39)</strong> - Major gap</p>
<p><strong>Step 3: Fail Triggers? (1 minute)</strong></p>
<ul>
<li><input disabled="" type="checkbox"/>
Data too perfect? (all success, no errors, unrealistic times)</li>
<li><input disabled="" type="checkbox"/>
No pilot notes? (pilots didn‚Äôt happen)</li>
<li><input disabled="" type="checkbox"/>
PII violations? (names/emails in screenshots, identifiable session IDs)</li>
<li><input disabled="" type="checkbox"/>
Metrics contradict claims? (e.g., says n=4 but CSV shows n=2)</li>
</ul>
<p>If YES ‚Üí <strong>FAIL (0-39)</strong> - Fabrication or severe violation</p>
<p><strong>Step 4: Evidence Chains? (1.5 minutes)</strong></p>
<ul>
<li><input disabled="" type="checkbox"/>
findings-table.csv links to metrics.csv lines OR pilot notes timestamps</li>
<li><input disabled="" type="checkbox"/>
implementation-diffs.md references findings from table</li>
<li><input disabled="" type="checkbox"/>
verification.csv Part B shows before/after for fixes</li>
</ul>
<p><strong>Step 5: WCAG Compliance? (1 minute)</strong></p>
<ul>
<li><input disabled="" type="checkbox"/>
verification.csv shows no Level A violations remaining</li>
<li><input disabled="" type="checkbox"/>
At least 1 WCAG criterion improved (fail ‚Üí pass)</li>
</ul>
<p><strong>Step 6: Assign Mark (30 seconds)</strong></p>
<div class="table-wrapper"><table><thead><tr><th>Evidence Quality</th><th>Grade</th><th>Mark Range</th></tr></thead><tbody>
<tr><td><strong>Excellent</strong>: Complete chains, rigorous verification, professional, honest</td><td><strong>First (1st)</strong></td><td>70-100</td></tr>
<tr><td><strong>Very Good</strong>: Strong chains, minor gaps, professional</td><td><strong>2:1</strong></td><td>60-69</td></tr>
<tr><td><strong>Good</strong>: Adequate chains, some issues</td><td><strong>2:2</strong></td><td>50-59</td></tr>
<tr><td><strong>Adequate</strong>: Weak chains, meets minimum</td><td><strong>3rd</strong></td><td>40-49</td></tr>
<tr><td><strong>Fail</strong>: No chains OR fabrication OR major gaps</td><td><strong>Fail</strong></td><td>0-39</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="detailed-criteria-100-marks"><a class="header" href="#detailed-criteria-100-marks">Detailed Criteria (100 Marks)</a></h2>
<h3 id="1-evidence-complete-20-marks"><a class="header" href="#1-evidence-complete-20-marks">1. Evidence Complete (20 marks)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Criterion</th><th>Excellent (17-20)</th><th>Good (13-16)</th><th>Adequate (10-12)</th><th>Weak (0-9)</th></tr></thead><tbody>
<tr><td><strong>Files present</strong></td><td>All 6 files + evidence folder complete</td><td>5-6 files, minor gaps</td><td>4 files, significant gaps</td><td>&lt;4 files</td></tr>
<tr><td><strong>Metrics data</strong></td><td>n=4 participants, all columns, anonymous IDs</td><td>n=3, all columns</td><td>n=2, all columns</td><td>n&lt;2 OR missing columns</td></tr>
<tr><td><strong>Findings</strong></td><td>5+ findings, all with sources</td><td>4 findings, all sources</td><td>3 findings, some sources</td><td>&lt;3 findings</td></tr>
<tr><td><strong>Implementation</strong></td><td>3 fixes, clear diffs</td><td>2 fixes, clear diffs</td><td>1 fix, clear diff</td><td>No diffs</td></tr>
</tbody></table>
</div>
<p><strong>LOs assessed</strong>: LO8 (evaluation execution), LO13 (instrumentation)</p>
<hr />
<h3 id="2-evidence-chains-30-marks"><a class="header" href="#2-evidence-chains-30-marks">2. Evidence Chains (30 marks)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Criterion</th><th>Excellent (25-30)</th><th>Good (19-24)</th><th>Adequate (13-18)</th><th>Weak (0-12)</th></tr></thead><tbody>
<tr><td><strong>Data ‚Üí Finding</strong></td><td>All findings link to metrics.csv lines OR pilot notes timestamps</td><td>Most findings linked</td><td>Some findings linked</td><td>No links</td></tr>
<tr><td><strong>Finding ‚Üí Fix</strong></td><td>All fixes reference specific findings from table</td><td>Most fixes reference findings</td><td>Some fixes reference findings</td><td>No references</td></tr>
<tr><td><strong>Fix ‚Üí Verification</strong></td><td>Before/after metrics for all fixes</td><td>Before/after for most fixes</td><td>Before/after for some fixes</td><td>No before/after</td></tr>
<tr><td><strong>Traceable</strong></td><td>Can follow complete chain for 3+ findings</td><td>Can follow 2 chains</td><td>Can follow 1 chain</td><td>No complete chains</td></tr>
</tbody></table>
</div>
<p><strong>LOs assessed</strong>: LO6 (iterative design), LO12 (professionalism)</p>
<hr />
<h3 id="3-wcag-compliance-20-marks"><a class="header" href="#3-wcag-compliance-20-marks">3. WCAG Compliance (20 marks)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Criterion</th><th>Excellent (17-20)</th><th>Good (13-16)</th><th>Adequate (10-12)</th><th>Weak (0-9)</th></tr></thead><tbody>
<tr><td><strong>Regression</strong></td><td>All 20 checks complete, pass/documented fail</td><td>18-19 checks complete</td><td>15-17 checks complete</td><td>&lt;15 checks</td></tr>
<tr><td><strong>Level A pass</strong></td><td>No Level A violations</td><td>1 Level A violation</td><td>2 Level A violations</td><td>3+ violations</td></tr>
<tr><td><strong>Improvement</strong></td><td>3+ WCAG criteria improved</td><td>2 criteria improved</td><td>1 criterion improved</td><td>No improvement</td></tr>
<tr><td><strong>Verification</strong></td><td>axe DevTools + SR + manual</td><td>2 test methods</td><td>1 test method</td><td>No verification</td></tr>
</tbody></table>
</div>
<p><strong>LOs assessed</strong>: LO4 (accessibility evaluation), LO9 (inclusive design)</p>
<hr />
<h3 id="4-professional-practice-15-marks"><a class="header" href="#4-professional-practice-15-marks">4. Professional Practice (15 marks)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Criterion</th><th>Excellent (13-15)</th><th>Good (10-12)</th><th>Adequate (7-9)</th><th>Weak (0-6)</th></tr></thead><tbody>
<tr><td><strong>Privacy</strong></td><td>No PII, anonymous IDs, consent documented</td><td>No PII, anonymous IDs</td><td>Minor PII slip, correctable</td><td>PII violations</td></tr>
<tr><td><strong>Honesty</strong></td><td>Limitations acknowledged if metrics didn‚Äôt improve</td><td>Some limitations noted</td><td>No limitations noted</td><td>Fabricated data</td></tr>
<tr><td><strong>No-JS parity</strong></td><td>Both paths fully functional, documented</td><td>Both paths functional</td><td>One path partial</td><td>No-JS broken</td></tr>
<tr><td><strong>Documentation</strong></td><td>Clear, concise, well-structured</td><td>Mostly clear</td><td>Adequate structure</td><td>Unclear/messy</td></tr>
</tbody></table>
</div>
<p><strong>LOs assessed</strong>: LO3 (ethical implications), LO7 (design constraints), LO11 (collaboration)</p>
<hr />
<h3 id="5-design-rationale-15-marks"><a class="header" href="#5-design-rationale-15-marks">5. Design Rationale (15 marks)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Criterion</th><th>Excellent (13-15)</th><th>Good (10-12)</th><th>Adequate (7-9)</th><th>Weak (0-6)</th></tr></thead><tbody>
<tr><td><strong>Task design</strong></td><td>Tasks linked to Week 6 job stories, clear scenarios</td><td>Tasks linked, adequate scenarios</td><td>Tasks present, weak links</td><td>No task rationale</td></tr>
<tr><td><strong>Prioritisation</strong></td><td>(Impact + Inclusion) - Effort formula applied, justified</td><td>Formula applied</td><td>Priority assigned</td><td>No prioritisation</td></tr>
<tr><td><strong>Fix rationale</strong></td><td>Clear ‚Äúwhat changed‚Äù + ‚Äúwhy‚Äù + ‚Äúimpact‚Äù for each fix</td><td>Rationale for most fixes</td><td>Rationale for some fixes</td><td>No rationale</td></tr>
<tr><td><strong>Code quality</strong></td><td>Fixes target root cause, minimal changes</td><td>Fixes work, reasonable approach</td><td>Fixes work, over-engineered</td><td>Fixes don‚Äôt work</td></tr>
</tbody></table>
</div>
<p><strong>LOs assessed</strong>: LO1 (methodologies), LO2 (needs-finding), LO5 (prototyping), LO13 (HCI+SE integration)</p>
<hr />
<h2 id="grade-descriptors"><a class="header" href="#grade-descriptors">Grade Descriptors</a></h2>
<h3 id="70-100-first-class-excellent"><a class="header" href="#70-100-first-class-excellent">70-100: First Class (Excellent)</a></h3>
<p><strong>Characteristics</strong>:</p>
<ul>
<li>All evidence chains rigorous and complete</li>
<li>WCAG compliance thoroughly verified (20/20 checks, no Level A violations)</li>
<li>Thoughtful prioritisation with clear rationale</li>
<li>Professional documentation (no PII, honest reporting)</li>
<li>Limitations acknowledged if metrics didn‚Äôt improve</li>
<li>Code fixes target root causes, well-integrated</li>
</ul>
<p><strong>Typical portfolio</strong>:</p>
<ul>
<li>n=4 participants, 5+ findings, 3 fixes, complete regression</li>
<li>Every finding traceable: data ‚Üí observation ‚Üí fix ‚Üí verification</li>
<li>Before/after metrics show measurable improvement</li>
<li>Screenshots and SR transcripts support claims</li>
<li>Honest analysis of what worked and what didn‚Äôt</li>
</ul>
<p><strong>LO coverage</strong>: All 13 LOs demonstrated to high standard</p>
<p><strong>Outcome</strong>: <strong>PASS</strong></p>
<hr />
<h3 id="60-69-21-very-good"><a class="header" href="#60-69-21-very-good">60-69: 2:1 (Very Good)</a></h3>
<p><strong>Characteristics</strong>:</p>
<ul>
<li>Strong evidence chains with minor gaps</li>
<li>WCAG mostly verified (18-19/20 checks, no critical failures)</li>
<li>Good prioritisation with some justification</li>
<li>Professional documentation with minor issues</li>
<li>Some limitations noted</li>
<li>Code fixes work, reasonable approach</li>
</ul>
<p><strong>Typical portfolio</strong>:</p>
<ul>
<li>n=3-4 participants, 4 findings, 2 fixes, mostly complete regression</li>
<li>Most findings traceable, 1-2 weak links</li>
<li>Before/after metrics present, improvement shown</li>
<li>Some supporting evidence (screenshots OR SR transcripts)</li>
<li>Mostly honest, minor gaps in reflection</li>
</ul>
<p><strong>LO coverage</strong>: All 13 LOs demonstrated, minor gaps</p>
<p><strong>Outcome</strong>: <strong>PASS</strong></p>
<hr />
<h3 id="50-59-22-good"><a class="header" href="#50-59-22-good">50-59: 2:2 (Good)</a></h3>
<p><strong>Characteristics</strong>:</p>
<ul>
<li>Evidence chains present but incomplete</li>
<li>Some WCAG compliance (15-17/20 checks, 1-2 Level A violations)</li>
<li>Basic prioritisation, limited justification</li>
<li>Adequate documentation, some issues</li>
<li>Limitations not well-documented</li>
<li>Code fixes work but may be over-engineered</li>
</ul>
<p><strong>Typical portfolio</strong>:</p>
<ul>
<li>n=2-3 participants, 3 findings, 1-2 fixes, partial regression</li>
<li>Some findings traceable, weak chains</li>
<li>Before/after metrics partial or limited improvement</li>
<li>Limited supporting evidence</li>
<li>Some honesty, but gaps in analysis</li>
</ul>
<p><strong>LO coverage</strong>: Most LOs demonstrated, some gaps</p>
<p><strong>Outcome</strong>: <strong>PASS</strong></p>
<hr />
<h3 id="40-49-third-class-adequate"><a class="header" href="#40-49-third-class-adequate">40-49: Third Class (Adequate)</a></h3>
<p><strong>Characteristics</strong>:</p>
<ul>
<li>Weak evidence chains, many gaps</li>
<li>Minimal WCAG compliance (&lt;15/20 checks, 2-3 Level A violations)</li>
<li>Ad-hoc prioritisation, no clear justification</li>
<li>Documentation has issues but meets minimum</li>
<li>No limitations acknowledged</li>
<li>Code fixes minimal or unclear impact</li>
</ul>
<p><strong>Typical portfolio</strong>:</p>
<ul>
<li>n=2 participants, 3 findings, 1 fix, incomplete regression</li>
<li>Few traceable chains, mostly assertions</li>
<li>Before/after metrics minimal or absent</li>
<li>Little supporting evidence</li>
<li>Limited honesty or reflection</li>
</ul>
<p><strong>LO coverage</strong>: Some LOs demonstrated, significant gaps</p>
<p><strong>Outcome</strong>: <strong>PASS</strong> (meets minimum standard)</p>
<hr />
<h3 id="0-39-fail"><a class="header" href="#0-39-fail">0-39: Fail</a></h3>
<p><strong>Characteristics</strong>:</p>
<ul>
<li>No evidence chains OR fabrication OR severe PII violations OR major gaps</li>
<li>Does not meet minimum standard</li>
</ul>
<p><strong>Automatic fail triggers</strong>:</p>
<ul>
<li><strong>Fabrication</strong> (0 marks): Data too perfect, no pilot notes, contradictions</li>
<li><strong>Severe PII violations</strong> (0 marks): Names/emails/student IDs visible</li>
<li><strong>Major gaps</strong> (0 marks): n&lt;2 OR no metrics.csv OR no regression (&lt;10 checks) OR no redesign</li>
</ul>
<p><strong>Typical portfolio</strong>:</p>
<ul>
<li>Missing files, incomplete data</li>
<li>No traceable evidence chains</li>
<li>WCAG not addressed</li>
<li>Unprofessional presentation</li>
<li>Ethical violations</li>
</ul>
<p><strong>LO coverage</strong>: Insufficient demonstration</p>
<p><strong>Outcome</strong>: <strong>FAIL</strong></p>
<hr />
<h2 id="learning-outcomes-mapping"><a class="header" href="#learning-outcomes-mapping">Learning Outcomes Mapping</a></h2>
<div class="table-wrapper"><table><thead><tr><th>LO</th><th>Outcome</th><th>Evidence Location</th><th>Criteria Section</th></tr></thead><tbody>
<tr><td><strong>LO1</strong></td><td>Differentiate methodologies</td><td>protocol-tasks.md (task design rationale)</td><td>Design Rationale</td></tr>
<tr><td><strong>LO2</strong></td><td>Needs-finding</td><td>protocol-tasks.md (links to Week 6 job stories)</td><td>Design Rationale</td></tr>
<tr><td><strong>LO3</strong></td><td>Ethical implications</td><td>Privacy statement, consent, PII handling</td><td>Professional Practice</td></tr>
<tr><td><strong>LO4</strong></td><td>Accessibility evaluation</td><td>verification.csv (regression checklist)</td><td>WCAG Compliance</td></tr>
<tr><td><strong>LO5</strong></td><td>Prototyping</td><td>implementation-diffs.md (code)</td><td>Design Rationale</td></tr>
<tr><td><strong>LO6</strong></td><td>Iterative design</td><td>Evaluation ‚Üí redesign flow (entire portfolio)</td><td>Evidence Chains</td></tr>
<tr><td><strong>LO7</strong></td><td>Design constraints</td><td>verification.csv (no-JS parity)</td><td>Professional Practice</td></tr>
<tr><td><strong>LO8</strong></td><td>Evaluation execution</td><td>metrics.csv, pilot notes</td><td>Evidence Complete</td></tr>
<tr><td><strong>LO9</strong></td><td>Inclusive design</td><td>verification.csv (WCAG), findings (inclusion column)</td><td>WCAG Compliance</td></tr>
<tr><td><strong>LO10</strong></td><td>Societal critique</td><td>findings-table.csv (‚Äúinclusion‚Äù column)</td><td>Design Rationale</td></tr>
<tr><td><strong>LO11</strong></td><td>Collaboration</td><td>Peer pilots, peer review documentation</td><td>Professional Practice</td></tr>
<tr><td><strong>LO12</strong></td><td>Professionalism</td><td>Evidence chains, honest reporting</td><td>Evidence Chains</td></tr>
<tr><td><strong>LO13</strong></td><td>HCI+SE integration</td><td>Server instrumentation (Logger.kt), routing</td><td>Evidence Complete</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="common-patterns-by-grade-band"><a class="header" href="#common-patterns-by-grade-band">Common Patterns by Grade Band</a></h2>
<h3 id="first-70-what-sets-them-apart"><a class="header" href="#first-70-what-sets-them-apart">First (70+): What Sets Them Apart</a></h3>
<p><strong>Evidence chains</strong>:</p>
<ul>
<li>Can trace complete path for 3+ findings: data ‚Üí observation ‚Üí interpretation ‚Üí fix ‚Üí verification</li>
<li>Data sources specific (e.g., ‚Äúmetrics.csv L47-49 + P2 notes 14:23‚Äù)</li>
<li>Before/after metrics show clear improvement (or honest analysis of why not)</li>
</ul>
<p><strong>WCAG compliance</strong>:</p>
<ul>
<li>20/20 regression checks complete</li>
<li>Multiple test methods (axe + SR + manual keyboard)</li>
<li>No Level A violations, most Level AA pass</li>
</ul>
<p><strong>Professional practice</strong>:</p>
<ul>
<li>Screenshots cropped/blurred (no PII)</li>
<li>Session IDs anonymous (P1_xxxx format)</li>
<li>Honest limitations (e.g., ‚Äúsmall sample size, n=4 not statistically robust‚Äù)</li>
<li>No-JS parity maintained</li>
</ul>
<p><strong>Code quality</strong>:</p>
<ul>
<li>Fixes target root causes (e.g., ‚Äúadded role=‚Äòalert‚Äô to error span‚Äù)</li>
<li>Minimal changes, well-integrated</li>
<li>Clear ‚Äúwhat/why/impact‚Äù for each fix</li>
</ul>
<hr />
<h3 id="21-60-69-strong-with-minor-gaps"><a class="header" href="#21-60-69-strong-with-minor-gaps">2:1 (60-69): Strong with Minor Gaps</a></h3>
<p><strong>Evidence chains</strong>:</p>
<ul>
<li>Can trace 2 complete chains, 1-2 weak links</li>
<li>Data sources mostly specific</li>
<li>Before/after metrics present, improvement shown</li>
</ul>
<p><strong>WCAG compliance</strong>:</p>
<ul>
<li>18-19/20 checks complete</li>
<li>2 test methods (axe + manual)</li>
<li>No critical Level A violations</li>
</ul>
<p><strong>Professional practice</strong>:</p>
<ul>
<li>No PII violations</li>
<li>Some limitations noted</li>
<li>No-JS mostly functional</li>
</ul>
<p><strong>Code quality</strong>:</p>
<ul>
<li>Fixes work, reasonable approach</li>
<li>Some rationale provided</li>
</ul>
<hr />
<h3 id="22-50-59-adequate-with-issues"><a class="header" href="#22-50-59-adequate-with-issues">2:2 (50-59): Adequate with Issues</a></h3>
<p><strong>Evidence chains</strong>:</p>
<ul>
<li>Can trace 1 complete chain</li>
<li>Data sources vague (e.g., ‚Äúpilot observations‚Äù)</li>
<li>Before/after metrics partial</li>
</ul>
<p><strong>WCAG compliance</strong>:</p>
<ul>
<li>15-17/20 checks complete</li>
<li>1 test method (axe only)</li>
<li>1-2 Level A violations</li>
</ul>
<p><strong>Professional practice</strong>:</p>
<ul>
<li>Minor PII issues (correctable)</li>
<li>Limitations not documented</li>
<li>No-JS partial</li>
</ul>
<p><strong>Code quality</strong>:</p>
<ul>
<li>Fixes work but over-engineered</li>
<li>Limited rationale</li>
</ul>
<hr />
<h3 id="3rd-40-49-minimum-standard"><a class="header" href="#3rd-40-49-minimum-standard">3rd (40-49): Minimum Standard</a></h3>
<p><strong>Evidence chains</strong>:</p>
<ul>
<li>Few complete chains, mostly assertions</li>
<li>Data sources absent or weak</li>
<li>Before/after metrics minimal</li>
</ul>
<p><strong>WCAG compliance</strong>:</p>
<ul>
<li>&lt;15/20 checks complete</li>
<li>No systematic testing</li>
<li>2-3 Level A violations</li>
</ul>
<p><strong>Professional practice</strong>:</p>
<ul>
<li>Documentation issues</li>
<li>No reflection</li>
<li>No-JS functional but undocumented</li>
</ul>
<p><strong>Code quality</strong>:</p>
<ul>
<li>Minimal fixes, unclear impact</li>
</ul>
<hr />
<h3 id="fail-0-39-below-minimum"><a class="header" href="#fail-0-39-below-minimum">Fail (0-39): Below Minimum</a></h3>
<p><strong>Automatic triggers</strong>:</p>
<ul>
<li>Fabrication (data too perfect, no notes, contradictions)</li>
<li>Severe PII violations (names visible, identifiable IDs)</li>
<li>Major gaps (n&lt;2, no metrics, no regression, no redesign)</li>
</ul>
<p><strong>Or insufficient evidence</strong>:</p>
<ul>
<li>No traceable chains</li>
<li>No WCAG verification</li>
<li>Unprofessional</li>
</ul>
<hr />
<h2 id="marking-workflow-5-minutes"><a class="header" href="#marking-workflow-5-minutes">Marking Workflow (5 Minutes)</a></h2>
<p><strong>Minute 1: Quick checks</strong></p>
<ul>
<li>Files present? CSV opens? Spot-check 2-3 screenshots for PII</li>
</ul>
<p><strong>Minute 2: Pass criteria</strong></p>
<ul>
<li>metrics.csv: n=2+? Columns correct?</li>
<li>findings-table.csv: Links to data sources?</li>
<li>verification.csv: 20 checks? WCAG Level A pass?</li>
<li>implementation-diffs.md: Code changes shown?</li>
</ul>
<p><strong>Minute 3: Fail triggers</strong></p>
<ul>
<li>Fabrication? (too perfect, no notes, contradictions)</li>
<li>PII violations? (checked in step 1)</li>
<li>Major gaps? (n&lt;2, no regression, no redesign)</li>
</ul>
<p><strong>Minute 4: Quality assessment</strong></p>
<ul>
<li>Evidence chains: Complete (70+), Strong (60-69), Adequate (50-59), Weak (40-49)?</li>
<li>WCAG: Thorough (70+), Mostly (60-69), Some (50-59), Minimal (40-49)?</li>
<li>Professional: Excellent (70+), Good (60-69), Adequate (50-59), Issues (40-49)?</li>
</ul>
<p><strong>Minute 5: Assign mark</strong></p>
<ul>
<li>70-100: Excellent (complete, rigorous, professional)</li>
<li>60-69: Very good (strong with minor gaps)</li>
<li>50-59: Good (adequate with issues)</li>
<li>40-49: Pass (meets minimum)</li>
<li>0-39: Fail (below minimum OR trigger present)</li>
</ul>
<p><strong>Record</strong>:</p>
<ul>
<li>Mark: [0-100]</li>
<li>Grade: [First/2:1/2:2/3rd/Fail]</li>
<li>Outcome: [PASS/FAIL]</li>
<li>Brief feedback: [2-3 sentences on strengths/gaps]</li>
</ul>
<hr />
<h2 id="feedback-template"><a class="header" href="#feedback-template">Feedback Template</a></h2>
<h3 id="for-first-70"><a class="header" href="#for-first-70">For First (70+)</a></h3>
<blockquote>
<p><strong>Mark</strong>: [70-100]/100
<strong>Grade</strong>: First Class
<strong>Outcome</strong>: PASS</p>
<p><strong>Strengths</strong>: Excellent evidence chains with complete traceability. Thorough WCAG verification with no Level A violations. Professional documentation with honest reporting of limitations. Code fixes are well-integrated and target root causes.</p>
<p><strong>To improve further</strong>: [Any minor suggestions]</p>
</blockquote>
<hr />
<h3 id="for-21-60-69"><a class="header" href="#for-21-60-69">For 2:1 (60-69)</a></h3>
<blockquote>
<p><strong>Mark</strong>: [60-69]/100
<strong>Grade</strong>: 2:1 (Very Good)
<strong>Outcome</strong>: PASS</p>
<p><strong>Strengths</strong>: Strong evidence chains with clear links from data to fixes. Good WCAG verification. Professional presentation.</p>
<p><strong>To improve</strong>: [Specific gaps - e.g., ‚ÄúComplete all 20 regression checks‚Äù or ‚ÄúAdd before/after metrics for all fixes‚Äù]</p>
</blockquote>
<hr />
<h3 id="for-22-50-59"><a class="header" href="#for-22-50-59">For 2:2 (50-59)</a></h3>
<blockquote>
<p><strong>Mark</strong>: [50-59]/100
<strong>Grade</strong>: 2:2 (Good)
<strong>Outcome</strong>: PASS</p>
<p><strong>Strengths</strong>: Evidence chains present. Basic WCAG compliance demonstrated.</p>
<p><strong>To improve</strong>: Strengthen evidence chains with specific data source links (e.g., metrics.csv line numbers). Complete full regression checklist. Add before/after metrics to show measurable improvement.</p>
</blockquote>
<hr />
<h3 id="for-3rd-40-49"><a class="header" href="#for-3rd-40-49">For 3rd (40-49)</a></h3>
<blockquote>
<p><strong>Mark</strong>: [40-49]/100
<strong>Grade</strong>: Third Class
<strong>Outcome</strong>: PASS (minimum standard)</p>
<p><strong>Strengths</strong>: Meets minimum requirements with n=2+ participants and basic evidence.</p>
<p><strong>To improve</strong>: Build complete evidence chains (data ‚Üí finding ‚Üí fix ‚Üí verification). Complete all 20 WCAG regression checks. Provide clear rationale for prioritisation and fixes. Document limitations and reflect on what worked/didn‚Äôt work.</p>
</blockquote>
<hr />
<h3 id="for-fail-0-39"><a class="header" href="#for-fail-0-39">For Fail (0-39)</a></h3>
<blockquote>
<p><strong>Mark</strong>: [0-39]/100
<strong>Grade</strong>: Fail
<strong>Outcome</strong>: FAIL</p>
<p><strong>Issue</strong>: [Fabrication / Severe PII violation / Major gaps - specify]</p>
<p><strong>Required for resubmission</strong>: [Specific requirements to meet minimum standard]</p>
</blockquote>
<hr />
<h2 id="borderline-cases"><a class="header" href="#borderline-cases">Borderline Cases</a></h2>
<h3 id="39-vs-40-fail-vs-pass"><a class="header" href="#39-vs-40-fail-vs-pass">39 vs 40 (Fail vs Pass)</a></h3>
<p><strong>40 minimum requires</strong>:</p>
<ul>
<li>n=2 participants (verified in metrics.csv)</li>
<li>3 findings with some data sources</li>
<li>1 fix with code diff shown</li>
<li>Partial regression (at least 10/20 checks)</li>
<li>No fabrication, no severe PII violations</li>
</ul>
<p>If any missing ‚Üí 39 or below (fail)</p>
<hr />
<h3 id="49-vs-50-3rd-vs-22"><a class="header" href="#49-vs-50-3rd-vs-22">49 vs 50 (3rd vs 2:2)</a></h3>
<p><strong>50 minimum requires</strong>:</p>
<ul>
<li>Evidence chains present (can trace 1 complete chain)</li>
<li>WCAG addressed (15-17/20 checks)</li>
<li>Before/after metrics partial</li>
<li>Professional presentation</li>
</ul>
<p>If evidence chains mostly absent ‚Üí 49 or below</p>
<hr />
<h3 id="59-vs-60-22-vs-21"><a class="header" href="#59-vs-60-22-vs-21">59 vs 60 (2:2 vs 2:1)</a></h3>
<p><strong>60 minimum requires</strong>:</p>
<ul>
<li>Strong evidence chains (can trace 2 complete chains)</li>
<li>WCAG mostly verified (18-19/20 checks)</li>
<li>Before/after metrics present</li>
<li>Professional with minor issues only</li>
</ul>
<p>If chains weak or WCAG gaps significant ‚Üí 59 or below</p>
<hr />
<h3 id="69-vs-70-21-vs-first"><a class="header" href="#69-vs-70-21-vs-first">69 vs 70 (2:1 vs First)</a></h3>
<p><strong>70 minimum requires</strong>:</p>
<ul>
<li>All evidence chains rigorous and complete (3+ traceable)</li>
<li>WCAG thorough (20/20 checks, no Level A violations)</li>
<li>Honest reporting of limitations</li>
<li>Professional throughout</li>
</ul>
<p>If not rigorous or gaps present ‚Üí 69 or below</p>
<hr />
<h2 id="version-control"><a class="header" href="#version-control">Version Control</a></h2>
<p><strong>Version</strong>: 1.0 Final
<strong>Last updated</strong>: 22 November 2025
<strong>For use</strong>: Academic Year 2025-26
<strong>Aligned to</strong>: <code>combined-assessment-FINAL.md</code>
<strong>Marking time</strong>: 5 minutes per portfolio</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="glossary"><a class="header" href="#glossary">Glossary</a></h1>
<p>Quick reference for technical terms, acronyms, and HCI concepts used throughout COMP2850.</p>
<p><strong>Categories</strong>: <img src="https://img.shields.io/badge/Accessibility-a11y-purple" alt="Accessibility" /> <img src="https://img.shields.io/badge/Architecture-Design-blue" alt="Architecture" /> <img src="https://img.shields.io/badge/HCI-UX-orange" alt="HCI" /> <img src="https://img.shields.io/badge/HTTP-Protocol-red" alt="HTTP" /> <img src="https://img.shields.io/badge/HTMX-Hypermedia-green" alt="HTMX" /> <img src="https://img.shields.io/badge/Module-COMP2850-darkblue" alt="Module" /> <img src="https://img.shields.io/badge/Tools-Tech-grey" alt="Tools" /> <img src="https://img.shields.io/badge/Web_Tech-HTML%2FCSS%2FJS-yellow" alt="Web Tech" /></p>
<p><strong><a href="references/glossary.html#acronyms-quick-reference">Jump to Acronyms Quick Reference ‚Üì</a></strong></p>
<hr />
<h3 id="accessibility"><a class="header" href="#accessibility">Accessibility (a11y)</a></h3>
<p><img src="https://img.shields.io/badge/Accessibility-a11y-purple" alt="Accessibility" /></p>
<p><strong>Definition</strong>: Practice of designing products usable by people with disabilities (visual, auditory, motor, cognitive). ‚Äúa11y‚Äù is numeronym (a + 11 letters + y).</p>
<p><strong>Core principles (POUR)</strong>:</p>
<ul>
<li><strong>Perceivable</strong> - Can see/hear content (alt text, captions, contrast)</li>
<li><strong>Operable</strong> - Can use keyboard/mouse/voice (keyboard nav, focus indicators)</li>
<li><strong>Understandable</strong> - Clear language, predictable behaviour, error messages</li>
<li><strong>Robust</strong> - Works with assistive technologies (semantic HTML, ARIA)</li>
</ul>
<p><strong>Used in COMP2850</strong>: WCAG 2.2 AA compliance is mandatory from Week 6.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#wcag">WCAG</a>, <a href="references/glossary.html#aria">ARIA</a>, <a href="references/glossary.html#semantic-html">Semantic HTML</a></p>
<hr />
<h3 id="ajax"><a class="header" href="#ajax">AJAX</a></h3>
<p><img src="https://img.shields.io/badge/Web_Tech-HTML%2FCSS%2FJS-yellow" alt="Web Tech" /></p>
<p><strong>Full name</strong>: Asynchronous JavaScript and XML</p>
<p><strong>Definition</strong>: Technique for updating parts of a web page without a full reload. The browser sends a request in the background (via JavaScript), receives a response, and updates the DOM.</p>
<p><strong>History</strong>: Name comes from early 2000s when XML was common. Modern AJAX typically uses JSON or HTML.</p>
<p><strong>Used in COMP2850</strong>: HTMX uses AJAX under the hood, but you write HTML attributes instead of JavaScript <code>XMLHttpRequest</code> or <code>fetch()</code> code.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#htmx">HTMX</a>, <a href="references/glossary.html#dom">DOM</a></p>
<hr />
<h3 id="aria"><a class="header" href="#aria">ARIA</a></h3>
<p><img src="https://img.shields.io/badge/Accessibility-a11y-purple" alt="Accessibility" /></p>
<p><strong>Full name</strong>: Accessible Rich Internet Applications</p>
<p><strong>Definition</strong>: Set of HTML attributes that provide semantic information to assistive technologies (screen readers, voice control). Includes roles (<code>role="alert"</code>), properties (<code>aria-label</code>), and states (<code>aria-expanded</code>).</p>
<p><strong>When to use</strong>: Only when semantic HTML isn‚Äôt sufficient. <strong>First rule of ARIA</strong>: Don‚Äôt use ARIA if you can use semantic HTML instead.</p>
<p><strong>Used in COMP2850</strong>: <code>role="status"</code>, <code>aria-live="polite"</code>, <code>aria-label</code> for context-specific buttons.</p>
<p><strong>Reference</strong>: <a href="https://www.w3.org/WAI/ARIA/apg/">WAI-ARIA Authoring Practices</a></p>
<p><strong>See also</strong>: <a href="references/glossary.html#aria-live-region">ARIA Live Region</a>, <a href="references/glossary.html#semantic-html">Semantic HTML</a></p>
<hr />
<h3 id="aria-live-region"><a class="header" href="#aria-live-region">ARIA Live Region</a></h3>
<p><img src="https://img.shields.io/badge/Accessibility-a11y-purple" alt="Accessibility" /></p>
<p><strong>Definition</strong>: Element that screen readers monitor for changes and announce automatically, without moving focus.</p>
<p><strong>Why it matters</strong>: HTMX updates the page dynamically. Without live regions, screen reader users don‚Äôt know anything changed.</p>
<p><strong>Attributes</strong>:</p>
<ul>
<li><code>role="status"</code> or <code>role="alert"</code> - What type of announcement</li>
<li><code>aria-live="polite"</code> - Wait for user to pause before announcing</li>
<li><code>aria-live="assertive"</code> - Interrupt immediately (errors only)</li>
</ul>
<p><strong>Example</strong>:</p>
<pre><code class="language-html">&lt;div id="status" role="status" aria-live="polite" class="visually-hidden"&gt;
  Task added successfully
&lt;/div&gt;
</code></pre>
<p><strong>Used in COMP2850</strong>: Every HTMX action must update a live region via OOB swap.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#oob-swap">OOB Swap</a>, <a href="references/glossary.html#screen-reader">Screen Reader</a></p>
<hr />
<h3 id="css"><a class="header" href="#css">CSS</a></h3>
<p><img src="https://img.shields.io/badge/Web_Tech-HTML%2FCSS%2FJS-yellow" alt="Web Tech" /></p>
<p><strong>Full name</strong>: Cascading Style Sheets</p>
<p><strong>Definition</strong>: Language for styling HTML (colors, fonts, layout, animations, etc.).</p>
<p><strong>Used in COMP2850</strong>: Pico CSS framework for baseline styles, custom CSS for accessibility (skip links, focus indicators).</p>
<hr />
<h3 id="dom"><a class="header" href="#dom">DOM</a></h3>
<p><img src="https://img.shields.io/badge/Web_Tech-HTML%2FCSS%2FJS-yellow" alt="Web Tech" /></p>
<p><strong>Full name</strong>: Document Object Model</p>
<p><strong>Definition</strong>: Tree-like representation of an HTML document in memory. The browser parses HTML into the DOM, which JavaScript can then read and manipulate.</p>
<p><strong>Key concepts</strong>:</p>
<ul>
<li><strong>Nodes</strong>: Each element, attribute, and piece of text is a node in the tree</li>
<li><strong>Manipulation</strong>: JavaScript can add, remove, or change nodes (e.g., <code>document.getElementById()</code>)</li>
<li><strong>HTMX updates</strong>: HTMX modifies the DOM by swapping HTML fragments without full page reload</li>
</ul>
<p><strong>Example</strong>: <code>&lt;ul id="tasks"&gt;&lt;li&gt;Task 1&lt;/li&gt;&lt;/ul&gt;</code> becomes a tree: <code>ul</code> (parent) ‚Üí <code>li</code> (child) ‚Üí text node ‚ÄúTask 1‚Äù</p>
<p><strong>Why it matters</strong>: Understanding the DOM helps debug HTMX swaps and accessibility issues (screen readers navigate the DOM tree).</p>
<p><strong>See also</strong>: <a href="references/glossary.html#htmx">HTMX</a>, <a href="references/glossary.html#ajax">AJAX</a>, <a href="references/glossary.html#html">HTML</a></p>
<hr />
<h3 id="evaluation"><a class="header" href="#evaluation">Evaluation</a></h3>
<p><img src="https://img.shields.io/badge/HCI-UX-orange" alt="HCI" /></p>
<p><strong>Definition</strong>: Process of measuring how well an interface meets user needs and usability goals.</p>
<p><strong>Types</strong>:</p>
<ul>
<li><strong>Formative</strong> - During design/development to guide iteration</li>
<li><strong>Summative</strong> - After release to measure success</li>
</ul>
<p><strong>Metrics (COMP2850)</strong>:</p>
<ul>
<li><strong>Utility</strong> - Does it solve the problem?</li>
<li><strong>Efficiency</strong> - How quickly can people complete tasks?</li>
<li><strong>Learnability</strong> - How quickly can new users learn it?</li>
<li><strong>Satisfaction</strong> - How pleasant is it to use?</li>
<li><strong>Affect</strong> - Emotional response (confidence, frustration)</li>
</ul>
<p><strong>Used in COMP2850</strong>: Week 9 peer pilots, Week 10 analysis.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#task-based-evaluation">Task-Based Evaluation</a></p>
<hr />
<h3 id="focus-indicator"><a class="header" href="#focus-indicator">Focus Indicator</a></h3>
<p><img src="https://img.shields.io/badge/Accessibility-a11y-purple" alt="Accessibility" /></p>
<p><strong>Definition</strong>: Visual outline or highlight that shows which element currently has keyboard focus.</p>
<p><strong>Why it matters</strong>: WCAG 2.4.7 (Focus Visible). Keyboard users need to see where they are on the page.</p>
<p><strong>Requirements</strong>: Minimum 3:1 contrast ratio against background, 2px minimum thickness (WCAG 2.2).</p>
<p><strong>Example</strong>: Browser default blue outline, or custom CSS <code>outline: 3px solid #0066A1;</code>.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#accessibility">Accessibility</a>, <a href="references/glossary.html#wcag">WCAG</a></p>
<hr />
<h3 id="fragment"><a class="header" href="#fragment">Fragment</a></h3>
<p><img src="https://img.shields.io/badge/HTMX-Hypermedia-green" alt="HTMX" /></p>
<p><strong>Definition</strong>: A partial HTML snippet (e.g., <code>&lt;li&gt;New item&lt;/li&gt;</code> or <code>&lt;div&gt;...&lt;/div&gt;</code>) returned by the server, rather than a complete page with <code>&lt;html&gt;</code>, <code>&lt;head&gt;</code>, <code>&lt;body&gt;</code>.</p>
<p><strong>Used in COMP2850</strong>: When HTMX makes a request, the server detects <code>HX-Request: true</code> header and returns a fragment instead of the full page.</p>
<p><strong>Example</strong>: Server renders <code>tasks/_item.peb</code> (just the <code>&lt;li&gt;</code>) instead of <code>tasks/index.peb</code> (full page).</p>
<p><strong>See also</strong>: <a href="references/glossary.html#htmx">HTMX</a>, <a href="references/glossary.html#template-factoring">Template Factoring</a>, <a href="references/glossary.html#partial">Partial</a></p>
<hr />
<h3 id="hateoas"><a class="header" href="#hateoas">HATEOAS</a></h3>
<p><img src="https://img.shields.io/badge/Architecture-Design-blue" alt="Architecture" /></p>
<p><strong>Full name</strong>: Hypermedia As The Engine Of Application State</p>
<p><strong>Definition</strong>: REST principle where the server‚Äôs responses include hyperlinks/forms that tell the client what actions are possible next. The client doesn‚Äôt need hardcoded URLs.</p>
<p><strong>Example</strong>: Task list HTML includes <code>&lt;form action="/tasks" method="post"&gt;</code> (server tells client ‚Äúyou can add tasks here‚Äù).</p>
<p><strong>See also</strong>: <a href="references/glossary.html#hypermedia">Hypermedia</a></p>
<hr />
<h3 id="heuristics"><a class="header" href="#heuristics">Heuristics</a></h3>
<p><img src="https://img.shields.io/badge/HCI-UX-orange" alt="HCI" /></p>
<p><strong>Definition</strong>: General rules or principles for evaluating interface usability, not strict guidelines.</p>
<p><strong>Examples</strong>:</p>
<ul>
<li><strong>Nielsen‚Äôs 10 Usability Heuristics</strong> (visibility of status, user control, consistency, error prevention, etc.)</li>
<li><strong>Shneiderman‚Äôs 8 Golden Rules</strong> (consistency, shortcuts, feedback, closure, error handling, etc.)</li>
</ul>
<p><strong>Used in COMP2850</strong>: Week 7 accessibility audit uses heuristics + WCAG.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#wcag">WCAG</a>, <a href="references/glossary.html#accessibility">Accessibility</a></p>
<hr />
<h3 id="html"><a class="header" href="#html">HTML</a></h3>
<p><img src="https://img.shields.io/badge/Web_Tech-HTML%2FCSS%2FJS-yellow" alt="Web Tech" /></p>
<p><strong>Full name</strong>: HyperText Markup Language</p>
<p><strong>Definition</strong>: Standard markup language for web pages. Defines structure and semantics (headings, paragraphs, forms, links, etc.).</p>
<p><strong>Why it matters</strong>: Semantic HTML (using correct tags like <code>&lt;nav&gt;</code>, <code>&lt;main&gt;</code>, <code>&lt;button&gt;</code>) is essential for accessibility.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#semantic-html">Semantic HTML</a></p>
<hr />
<h3 id="htmx"><a class="header" href="#htmx">HTMX</a></h3>
<p><img src="https://img.shields.io/badge/HTMX-Hypermedia-green" alt="HTMX" /></p>
<p><strong>Definition</strong>: JavaScript library that extends HTML with attributes (<code>hx-get</code>, <code>hx-post</code>, <code>hx-target</code>, <code>hx-swap</code>) to enable AJAX requests and DOM updates without writing JavaScript.</p>
<p><strong>Key idea</strong>: Server sends HTML fragments (not JSON), HTMX swaps them into the page.</p>
<p><strong>Example</strong>: <code>&lt;button hx-get="/tasks/123" hx-target="#content"&gt;Load&lt;/button&gt;</code> ‚Üí Click ‚Üí AJAX GET ‚Üí Server returns HTML ‚Üí HTMX replaces <code>#content</code>.</p>
<p><strong>Why it matters</strong>: Simpler than React/Vue, accessible by default, progressive enhancement friendly.</p>
<p><strong>Documentation</strong>: <a href="https://htmx.org/">htmx.org</a> | <a href="https://hypermedia.systems/">hypermedia.systems</a></p>
<p><strong>See also</strong>: <a href="references/glossary.html#ajax">AJAX</a>, <a href="references/glossary.html#oob-swap">OOB Swap</a>, <a href="references/glossary.html#progressive-enhancement">Progressive Enhancement</a></p>
<hr />
<h3 id="http-methods"><a class="header" href="#http-methods">HTTP Methods</a></h3>
<p><img src="https://img.shields.io/badge/HTTP-Protocol-red" alt="HTTP" /></p>
<p><strong>Definition</strong>: Verbs that indicate the type of request being made to the server.</p>
<p><strong>Common methods</strong>:</p>
<ul>
<li><strong>GET</strong> - Retrieve data (safe, idempotent, cacheable)</li>
<li><strong>POST</strong> - Create new resource or submit data</li>
<li><strong>PUT</strong> - Update/replace entire resource</li>
<li><strong>PATCH</strong> - Partial update</li>
<li><strong>DELETE</strong> - Remove resource</li>
</ul>
<p><strong>Used in COMP2850</strong>: GET for viewing, POST for forms (add/edit/delete). HTMX supports all methods.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#prg">PRG</a></p>
<hr />
<h3 id="http-status-codes"><a class="header" href="#http-status-codes">HTTP Status Codes</a></h3>
<p><img src="https://img.shields.io/badge/HTTP-Protocol-red" alt="HTTP" /></p>
<p><strong>Definition</strong>: 3-digit codes indicating the result of an HTTP request.</p>
<p><strong>Common codes</strong>:</p>
<ul>
<li><strong>200 OK</strong> - Success</li>
<li><strong>201 Created</strong> - Resource created successfully</li>
<li><strong>303 See Other</strong> - Redirect after POST (PRG pattern)</li>
<li><strong>400 Bad Request</strong> - Client error (validation failed)</li>
<li><strong>404 Not Found</strong> - Resource doesn‚Äôt exist</li>
<li><strong>500 Internal Server Error</strong> - Server error</li>
</ul>
<p><strong>Used in COMP2850</strong>: 303 for PRG redirects, 201 for successful creation, 400 for validation errors.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#prg">PRG</a></p>
<hr />
<h3 id="hx-swap"><a class="header" href="#hx-swap">hx-swap</a></h3>
<p><img src="https://img.shields.io/badge/HTMX-Hypermedia-green" alt="HTMX" /></p>
<p><strong>Definition</strong>: HTMX attribute specifying <strong>how</strong> to insert the server‚Äôs response into the target.</p>
<p><strong>Common values</strong>:</p>
<ul>
<li><code>innerHTML</code> (default) - Replace target‚Äôs contents</li>
<li><code>outerHTML</code> - Replace target itself</li>
<li><code>beforeend</code> - Append to target (inside, at end)</li>
<li><code>afterend</code> - Insert after target (outside)</li>
<li><code>beforebegin</code> - Insert before target (outside)</li>
</ul>
<p><strong>Example</strong>: <code>hx-swap="beforeend"</code> ‚Üí append new task to list.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#hx-target">hx-target</a>, <a href="references/glossary.html#htmx">HTMX</a></p>
<hr />
<h3 id="hx-target"><a class="header" href="#hx-target">hx-target</a></h3>
<p><img src="https://img.shields.io/badge/HTMX-Hypermedia-green" alt="HTMX" /></p>
<p><strong>Definition</strong>: HTMX attribute specifying which element to update with the server‚Äôs response. Uses CSS selector syntax.</p>
<p><strong>Example</strong>: <code>hx-target="#task-list"</code> ‚Üí response goes into element with <code>id="task-list"</code>.</p>
<p><strong>Default</strong>: If not specified, targets the element that triggered the request.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#hx-swap">hx-swap</a>, <a href="references/glossary.html#htmx">HTMX</a></p>
<hr />
<h3 id="hx-trigger"><a class="header" href="#hx-trigger">hx-trigger</a></h3>
<p><img src="https://img.shields.io/badge/HTMX-Hypermedia-green" alt="HTMX" /></p>
<p><strong>Definition</strong>: HTMX attribute specifying what event triggers the AJAX request.</p>
<p><strong>Examples</strong>:</p>
<ul>
<li><code>hx-trigger="click"</code> (default for buttons)</li>
<li><code>hx-trigger="submit"</code> (default for forms)</li>
<li><code>hx-trigger="keyup changed delay:300ms"</code> (debounced search)</li>
<li><code>hx-trigger="revealed"</code> (lazy load when scrolled into view)</li>
</ul>
<p><strong>See also</strong>: <a href="references/glossary.html#htmx">HTMX</a></p>
<hr />
<h3 id="hypermedia"><a class="header" href="#hypermedia">Hypermedia</a></h3>
<p><img src="https://img.shields.io/badge/Architecture-Design-blue" alt="Architecture" /></p>
<p><strong>Definition</strong>: Media (HTML) that contains hyperlinks and forms as controls for navigating and manipulating application state. The server tells the client what actions are available via links (<code>&lt;a&gt;</code>) and forms (<code>&lt;form&gt;</code>).</p>
<p><strong>Why it matters</strong>: Follows REST/HATEOAS principles. The UI is the API. No separate JSON API needed.</p>
<p><strong>Used in COMP2850</strong>: We build hypermedia systems following <a href="https://hypermedia.systems/">hypermedia.systems</a>.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#htmx">HTMX</a>, <a href="references/glossary.html#rest">REST</a>, <a href="references/glossary.html#hateoas">HATEOAS</a></p>
<hr />
<h3 id="javascript"><a class="header" href="#javascript">JavaScript</a></h3>
<p><img src="https://img.shields.io/badge/Web_Tech-HTML%2FCSS%2FJS-yellow" alt="Web Tech" /></p>
<p><strong>Definition</strong>: Programming language that runs in the browser to add interactivity.</p>
<p><strong>Used in COMP2850</strong>: Minimal JavaScript via HTMX library. All features must work without JavaScript (progressive enhancement).</p>
<p><strong>See also</strong>: <a href="references/glossary.html#progressive-enhancement">Progressive Enhancement</a>, <a href="references/glossary.html#htmx">HTMX</a></p>
<hr />
<h3 id="job-stories"><a class="header" href="#job-stories">Job Stories</a></h3>
<p><img src="https://img.shields.io/badge/HCI-UX-orange" alt="HCI" /></p>
<p><strong>Definition</strong>: Format for capturing user needs based on context, motivation, and outcome. Structure: <strong>‚ÄúWhen [situation], I want [motivation], so I can [outcome], because [reasoning].‚Äù</strong></p>
<p><strong>Example</strong>: ‚ÄúWhen I‚Äôm reviewing my weekly tasks on Sunday evening, I want to see incomplete items highlighted, so I can prioritize tomorrow‚Äôs work, because I need to meet Friday‚Äôs deadline.‚Äù</p>
<p><strong>Why not user stories</strong>: User stories (‚ÄúAs a user, I want‚Ä¶‚Äù) focus on demographics. Job stories focus on context and causality.</p>
<p><strong>Used in COMP2850</strong>: Week 6 Lab 2.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#needs-finding">Needs-Finding</a></p>
<hr />
<h3 id="json"><a class="header" href="#json">JSON</a></h3>
<p><img src="https://img.shields.io/badge/Web_Tech-HTML%2FCSS%2FJS-yellow" alt="Web Tech" /></p>
<p><strong>Full name</strong>: JavaScript Object Notation</p>
<p><strong>Definition</strong>: Lightweight data format for exchanging data between server and client. Common in REST APIs.</p>
<p><strong>Used in COMP2850</strong>: We <strong>do not</strong> use JSON APIs. Server sends HTML fragments, not JSON.</p>
<p><strong>Why</strong>: Hypermedia approach. HTML is the data format.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#hypermedia">Hypermedia</a></p>
<hr />
<h3 id="kotlin"><a class="header" href="#kotlin">Kotlin</a></h3>
<p><img src="https://img.shields.io/badge/Tools-Tech-grey" alt="Tools" /></p>
<p><strong>Definition</strong>: Modern programming language for JVM (Java Virtual Machine). Statically typed, null-safe, concise syntax.</p>
<p><strong>Used in COMP2850</strong>: Server-side code (routes, data models, storage).</p>
<p><strong>See also</strong>: <a href="references/glossary.html#ktor">Ktor</a></p>
<hr />
<h3 id="ktor"><a class="header" href="#ktor">Ktor</a></h3>
<p><img src="https://img.shields.io/badge/Tools-Tech-grey" alt="Tools" /></p>
<p><strong>Definition</strong>: Kotlin web framework for building server applications. Lightweight, asynchronous, uses coroutines.</p>
<p><strong>Used in COMP2850</strong>: HTTP server, routing, template rendering (via Pebble plugin).</p>
<p><strong>Documentation</strong>: <a href="https://ktor.io/">ktor.io</a></p>
<p><strong>See also</strong>: <a href="references/glossary.html#kotlin">Kotlin</a>, <a href="references/glossary.html#pebble">Pebble</a></p>
<hr />
<h3 id="needs-finding"><a class="header" href="#needs-finding">Needs-Finding</a></h3>
<p><img src="https://img.shields.io/badge/HCI-UX-orange" alt="HCI" /></p>
<p><strong>Definition</strong>: Research method to understand what people actually need (not what they say they want). Uses observation, interviews, job stories, contextual inquiry.</p>
<p><strong>Why not ‚Äúrequirements gathering‚Äù</strong>: Implies people know what they need and can articulate it. Needs-finding acknowledges we must discover unstated needs.</p>
<p><strong>Used in COMP2850</strong>: Week 6 Lab 2 - conduct peer interviews, write job stories.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#job-stories">Job Stories</a>, <a href="references/glossary.html#people-centred-language">People-Centred Language</a></p>
<hr />
<h3 id="no-js-parity"><a class="header" href="#no-js-parity">No-JS Parity</a></h3>
<p><img src="https://img.shields.io/badge/Architecture-Design-blue" alt="Architecture" /></p>
<p><strong>Definition</strong>: Requirement that every feature must work identically with JavaScript disabled. The user experience may differ (page reload vs. instant swap), but functionality must be identical.</p>
<p><strong>Why it matters</strong>: Accessibility, resilience, progressive enhancement compliance.</p>
<p><strong>Example</strong>: Add task button works via form POST ‚Üí redirect (no-JS) OR HTMX AJAX ‚Üí fragment swap (JS-enabled).</p>
<p><strong>See also</strong>: <a href="references/glossary.html#progressive-enhancement">Progressive Enhancement</a></p>
<hr />
<h3 id="oob-swap"><a class="header" href="#oob-swap">OOB Swap (Out-of-Band Swap)</a></h3>
<p><img src="https://img.shields.io/badge/HTMX-Hypermedia-green" alt="HTMX" /></p>
<p><strong>Full name</strong>: Out-of-Band Swap</p>
<p><strong>Definition</strong>: HTMX feature that updates an element <strong>outside</strong> the main target. The server includes <code>hx-swap-oob="true"</code> on an element, and HTMX updates it based on its <code>id</code>, even if it‚Äôs not the primary target.</p>
<p><strong>Why it matters</strong>: Lets you update multiple parts of the page from one response (e.g., update task list + update status message).</p>
<p><strong>Example</strong>:</p>
<pre><code class="language-html">&lt;!-- Main target --&gt;
&lt;li id="task-3"&gt;Updated task&lt;/li&gt;

&lt;!-- OOB swap (updates #status even though target is #task-list) --&gt;
&lt;div id="status" hx-swap-oob="true"&gt;Task added!&lt;/div&gt;
</code></pre>
<p><strong>See also</strong>: <a href="references/glossary.html#htmx">HTMX</a>, <a href="references/glossary.html#aria-live-region">ARIA Live Region</a></p>
<hr />
<h3 id="partial"><a class="header" href="#partial">Partial</a></h3>
<p><img src="https://img.shields.io/badge/HTMX-Hypermedia-green" alt="HTMX" /></p>
<p><strong>Definition</strong>: A reusable template file (e.g., <code>_item.peb</code>, <code>_list.peb</code>, <code>_header.peb</code>) designed to be included in other templates or rendered independently as a fragment.</p>
<p><strong>Naming convention</strong>: Prefixed with underscore (<code>_</code>) to distinguish from full-page templates.</p>
<p><strong>Example</strong>:</p>
<ul>
<li><code>templates/tasks/_list.peb</code> - Partial template (source code)</li>
<li><code>templates/tasks/index.peb</code> - Full page template (includes partials)</li>
</ul>
<p><strong>How it works</strong>: The server renders a partial template to produce a <a href="references/glossary.html#fragment">fragment</a> of HTML that can be:</p>
<ul>
<li>Included in a full page via <code>{% include "tasks/_list.peb" %}</code></li>
<li>Returned directly for HTMX requests: <code>GET /tasks/fragment</code> renders <code>_list.peb</code> ‚Üí HTML fragment</li>
</ul>
<p><strong>Why it matters</strong>: Partials eliminate duplication‚Äîaccessibility fixes, ARIA attributes, and markup stay in one source file, ensuring consistency across full-page and HTMX-enhanced flows.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#fragment">Fragment</a>, <a href="references/glossary.html#template-factoring">Template Factoring</a></p>
<hr />
<h3 id="participant"><a class="header" href="#participant">Participant</a></h3>
<p><img src="https://img.shields.io/badge/Module-COMP2850-darkblue" alt="Module" /></p>
<p><strong>Definition</strong>: Person taking part in research (pilots, interviews, usability tests). Preferred term over ‚Äúuser‚Äù or ‚Äúsubject.‚Äù</p>
<p><strong>Why</strong>: More respectful, acknowledges agency, aligns with ethics protocols.</p>
<p><strong>Used in COMP2850</strong>: Module-wide standard term.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#people-centred-language">People-Centred Language</a></p>
<hr />
<h3 id="pebble"><a class="header" href="#pebble">Pebble</a></h3>
<p><img src="https://img.shields.io/badge/Tools-Tech-grey" alt="Tools" /></p>
<p><strong>Definition</strong>: Template engine for Java/Kotlin. Similar to Jinja2 (Python) or Twig (PHP). Renders HTML with dynamic data.</p>
<p><strong>Syntax</strong>:</p>
<ul>
<li><code>{{ variable }}</code> - Output</li>
<li><code>{% for item in list %}...{% endfor %}</code> - Logic</li>
<li><code>{% extends "base.peb" %}</code> - Inheritance</li>
</ul>
<p><strong>Used in COMP2850</strong>: Server-side HTML rendering.</p>
<p><strong>Documentation</strong>: <a href="https://pebbletemplates.io/">pebbletemplates.io</a></p>
<p><strong>See also</strong>: <a href="references/glossary.html#ktor">Ktor</a>, <a href="references/glossary.html#template-factoring">Template Factoring</a></p>
<hr />
<h3 id="people-centred-language"><a class="header" href="#people-centred-language">People-Centred Language</a></h3>
<p><img src="https://img.shields.io/badge/HCI-UX-orange" alt="HCI" /></p>
<p><strong>Definition</strong>: Putting the person first, not the disability or technology. Avoids deficit-based terms.</p>
<p><strong>Examples</strong>:</p>
<ul>
<li>‚úÖ ‚ÄúPerson using a screen reader‚Äù (not ‚Äúblind user‚Äù)</li>
<li>‚úÖ ‚ÄúKeyboard user‚Äù (not ‚Äúdisabled person‚Äù)</li>
<li>‚úÖ ‚ÄúPerson with low vision‚Äù (not ‚Äúvisually impaired user‚Äù)</li>
</ul>
<p><strong>Why it matters</strong>: Disability arises from environmental barriers (bad design), not individual impairment. Language shapes how we think about accessibility.</p>
<p><strong>Used in COMP2850</strong>: Module-wide terminology standard.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#accessibility">Accessibility</a></p>
<hr />
<h3 id="pii"><a class="header" href="#pii">PII (Personally Identifiable Information)</a></h3>
<p><img src="https://img.shields.io/badge/Module-COMP2850-darkblue" alt="Module" /></p>
<p><strong>Full name</strong>: Personally Identifiable Information</p>
<p><strong>Definition</strong>: Data that can identify a specific individual (name, email, photo, student ID, IP address).</p>
<p><strong>Used in COMP2850</strong>: We collect <strong>no PII</strong>. Only anonymous session IDs and timestamps. UK GDPR compliant.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#privacy-by-design">Privacy by Design</a></p>
<hr />
<h3 id="pico-css"><a class="header" href="#pico-css">Pico CSS</a></h3>
<p><img src="https://img.shields.io/badge/Tools-Tech-grey" alt="Tools" /></p>
<p><strong>Definition</strong>: Minimal CSS framework with semantic styling. Classless (styles semantic HTML tags) + optional utility classes.</p>
<p><strong>Why Pico</strong>: Accessibility-first, no-JS, works with semantic HTML, lightweight (~10KB).</p>
<p><strong>Used in COMP2850</strong>: Baseline styling for student web apps.</p>
<p><strong>Documentation</strong>: <a href="https://picocss.com/">picocss.com</a></p>
<p><strong>See also</strong>: <a href="references/glossary.html#css">CSS</a>, <a href="references/glossary.html#semantic-html">Semantic HTML</a></p>
<hr />
<h3 id="prg"><a class="header" href="#prg">PRG (Post-Redirect-Get)</a></h3>
<p><img src="https://img.shields.io/badge/Architecture-Design-blue" alt="Architecture" /></p>
<p><strong>Full name</strong>: Post-Redirect-Get pattern</p>
<p><strong>Definition</strong>: After processing a POST request (form submission), the server returns an HTTP 303 redirect to a GET URL instead of rendering a page directly. This prevents duplicate submissions if the user refreshes.</p>
<p><strong>How it works</strong>:</p>
<ol>
<li>User submits form ‚Üí POST <code>/tasks</code> (create task)</li>
<li>Server validates, saves to database</li>
<li>Server returns HTTP 303 redirect to GET <code>/tasks</code></li>
<li>Browser follows redirect ‚Üí GET <code>/tasks</code> (displays updated list)</li>
<li>User refreshes ‚Üí safe GET request (no duplicate)</li>
</ol>
<p><strong>Used in COMP2850</strong>: Every form POST must use PRG for the no-JS path.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#http-methods">HTTP Methods</a></p>
<hr />
<h3 id="privacy-by-design"><a class="header" href="#privacy-by-design">Privacy by Design</a></h3>
<p><img src="https://img.shields.io/badge/Module-COMP2850-darkblue" alt="Module" /></p>
<p><strong>Definition</strong>: Approach to system design where privacy protections are built in from the start, not added later.</p>
<p><strong>Principles</strong>:</p>
<ol>
<li>Proactive (prevent, don‚Äôt react)</li>
<li>Privacy as default setting</li>
<li>Privacy embedded in design</li>
<li>Full functionality (positive-sum, not zero-sum)</li>
<li>End-to-end security</li>
<li>Visibility and transparency</li>
<li>Respect for user privacy</li>
</ol>
<p><strong>Used in COMP2850</strong>: No PII collection, anonymous instrumentation, module-wide blanket consent.</p>
<p><strong>Reference</strong>: <code>references/privacy-by-design.md</code></p>
<p><strong>See also</strong>: <a href="references/glossary.html#pii">PII</a></p>
<hr />
<h3 id="progressive-enhancement"><a class="header" href="#progressive-enhancement">Progressive Enhancement</a></h3>
<p><img src="https://img.shields.io/badge/Architecture-Design-blue" alt="Architecture" /></p>
<p><strong>Definition</strong>: Design philosophy where you build a baseline experience that works for everyone (HTML), then add optional layers (CSS for styling, JavaScript for interactivity) that enhance the experience when available.</p>
<p><strong>Why it matters</strong>: If JavaScript fails to load (network error, corporate firewall, assistive tech incompatibility), users still get full functionality.</p>
<p><strong>Example</strong>: Form submits via POST/redirect (no-JS baseline) + HTMX intercepts and does AJAX swap (enhanced).</p>
<p><strong>See also</strong>: <a href="references/glossary.html#server-first">Server-First</a>, <a href="references/glossary.html#no-js-parity">No-JS Parity</a></p>
<hr />
<h3 id="request-headers"><a class="header" href="#request-headers">Request Headers</a></h3>
<p><img src="https://img.shields.io/badge/HTTP-Protocol-red" alt="HTTP" /></p>
<p><strong>Definition</strong>: Key-value pairs sent by the browser with each HTTP request, providing metadata about the request.</p>
<p><strong>Examples</strong>:</p>
<ul>
<li><code>User-Agent: Mozilla/5.0...</code> (browser identity)</li>
<li><code>Accept: text/html</code> (what content types browser accepts)</li>
<li><code>HX-Request: true</code> (HTMX adds this to identify AJAX requests)</li>
<li><code>Content-Type: application/x-www-form-urlencoded</code> (form data format)</li>
</ul>
<p><strong>Used in COMP2850</strong>: Server checks <code>HX-Request</code> header to decide whether to return full page or fragment.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#htmx">HTMX</a>, <a href="references/glossary.html#fragment">Fragment</a></p>
<hr />
<h3 id="rest"><a class="header" href="#rest">REST</a></h3>
<p><img src="https://img.shields.io/badge/Architecture-Design-blue" alt="Architecture" /></p>
<p><strong>Full name</strong>: Representational State Transfer</p>
<p><strong>Definition</strong>: Architectural style for web services that uses standard HTTP methods (GET, POST, PUT, DELETE) to operate on resources identified by URLs. Key principles include stateless communication, resource-based URLs, and hypermedia as the engine of application state.</p>
<p><strong>HTTP methods</strong>:</p>
<ul>
<li><strong>GET</strong> <code>/tasks</code> - Retrieve resources (safe, idempotent)</li>
<li><strong>POST</strong> <code>/tasks</code> - Create new resource</li>
<li><strong>PUT</strong> <code>/tasks/123</code> - Update entire resource</li>
<li><strong>DELETE</strong> <code>/tasks/123</code> - Remove resource</li>
</ul>
<p><strong>Why it matters</strong>: REST principles guide our route design. We use hypermedia (HTML) instead of JSON APIs, following the original REST vision.</p>
<p><strong>Used in COMP2850</strong>: All routes follow RESTful conventions. GET for reading, POST for creating, DELETE for removing.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#hateoas">HATEOAS</a>, <a href="references/glossary.html#http-methods">HTTP Methods</a>, <a href="references/glossary.html#hypermedia">Hypermedia</a></p>
<hr />
<h3 id="screen-reader"><a class="header" href="#screen-reader">Screen Reader</a></h3>
<p><img src="https://img.shields.io/badge/Accessibility-a11y-purple" alt="Accessibility" /></p>
<p><strong>Definition</strong>: Assistive technology that converts on-screen text and UI elements into synthesized speech or braille. Used by people who are blind or have low vision.</p>
<p><strong>Examples</strong>:</p>
<ul>
<li><strong>NVDA</strong> (Windows, free)</li>
<li><strong>JAWS</strong> (Windows, commercial)</li>
<li><strong>VoiceOver</strong> (macOS/iOS, built-in)</li>
<li><strong>Orca</strong> (Linux, built-in)</li>
</ul>
<p><strong>Used in COMP2850</strong>: All features must be tested with NVDA or VoiceOver to verify labels, announcements, and keyboard navigation.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#aria-live-region">ARIA Live Region</a>, <a href="references/glossary.html#accessibility">Accessibility</a></p>
<hr />
<h3 id="semantic-html"><a class="header" href="#semantic-html">Semantic HTML</a></h3>
<p><img src="https://img.shields.io/badge/Accessibility-a11y-purple" alt="Accessibility" /></p>
<p><strong>Definition</strong>: Using HTML elements that convey <strong>meaning</strong> (semantics), not just structure or appearance.</p>
<p><strong>Examples</strong>:</p>
<ul>
<li>‚úÖ Good: <code>&lt;button type="submit"&gt;Add&lt;/button&gt;</code></li>
<li>‚ùå Bad: <code>&lt;div onclick="submit()"&gt;Add&lt;/div&gt;</code></li>
<li>‚úÖ Good: <code>&lt;nav&gt;</code>, <code>&lt;main&gt;</code>, <code>&lt;article&gt;</code>, <code>&lt;section&gt;</code></li>
<li>‚ùå Bad: <code>&lt;div class="nav"&gt;</code>, <code>&lt;div class="main"&gt;</code></li>
</ul>
<p><strong>Why it matters</strong>: Assistive technologies (screen readers, voice control) rely on semantic elements to understand page structure and functionality.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#html">HTML</a>, <a href="references/glossary.html#accessibility">Accessibility</a></p>
<hr />
<h3 id="server-first"><a class="header" href="#server-first">Server-First Architecture</a></h3>
<p><img src="https://img.shields.io/badge/Architecture-Design-blue" alt="Architecture" /></p>
<p><strong>Definition</strong>: Architecture where the server generates complete HTML pages and sends them to the browser, rather than sending JavaScript that builds the page client-side.</p>
<p><strong>Why it matters</strong>: Pages load faster, work without JavaScript, and are accessible by default because the server controls the semantic HTML structure.</p>
<p><strong>Example</strong>: Ktor renders a Pebble template ‚Üí sends complete HTML ‚Üí browser displays immediately.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#progressive-enhancement">Progressive Enhancement</a>, <a href="references/glossary.html#ssr">SSR</a></p>
<hr />
<h3 id="skip-link"><a class="header" href="#skip-link">Skip Link</a></h3>
<p><img src="https://img.shields.io/badge/Accessibility-a11y-purple" alt="Accessibility" /></p>
<p><strong>Definition</strong>: Link at the top of a page that lets keyboard users jump directly to main content, bypassing repeated navigation.</p>
<p><strong>Why it matters</strong>: WCAG 2.4.1 (Bypass Blocks). Users shouldn‚Äôt have to tab through 50 nav links on every page.</p>
<p><strong>Implementation</strong>:</p>
<pre><code class="language-html">&lt;a href="#main" class="skip-link"&gt;Skip to main content&lt;/a&gt;
&lt;!-- ... nav ... --&gt;
&lt;main id="main" tabindex="-1"&gt;Content here&lt;/main&gt;
</code></pre>
<p><strong>Styling</strong>: Hidden visually until keyboard-focused (<code>:focus</code>).</p>
<p><strong>See also</strong>: <a href="references/glossary.html#accessibility">Accessibility</a>, <a href="references/glossary.html#wcag">WCAG</a></p>
<hr />
<h3 id="ssr"><a class="header" href="#ssr">SSR (Server-Side Rendering)</a></h3>
<p><img src="https://img.shields.io/badge/Architecture-Design-blue" alt="Architecture" /></p>
<p><strong>Full name</strong>: Server-Side Rendering</p>
<p><strong>Definition</strong>: The server generates the final HTML and sends it to the browser. The browser receives complete markup, not an empty shell that JavaScript fills in.</p>
<p><strong>Contrast with CSR</strong>: Client-side rendering (CSR) sends minimal HTML + JavaScript bundle ‚Üí browser runs JS ‚Üí JS fetches data ‚Üí JS builds DOM. Slower, accessibility-unfriendly.</p>
<p><strong>Used in COMP2850</strong>: Ktor + Pebble templates = SSR.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#server-first">Server-First</a></p>
<hr />
<h3 id="task-based-evaluation"><a class="header" href="#task-based-evaluation">Task-Based Evaluation</a></h3>
<p><img src="https://img.shields.io/badge/HCI-UX-orange" alt="HCI" /></p>
<p><strong>Definition</strong>: Usability testing where participants attempt realistic tasks while you measure performance (time, errors, completion rate) and gather qualitative observations.</p>
<p><strong>Example</strong>: ‚ÄúAdd a task called ‚ÄòBuy milk‚Äô, mark it complete, then delete it‚Äù (measures core CRUD functionality).</p>
<p><strong>Used in COMP2850</strong>: Week 9 Lab 2 - 4-person peer pilots with 4 tasks.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#evaluation">Evaluation</a></p>
<hr />
<h3 id="template-factoring"><a class="header" href="#template-factoring">Template Factoring</a></h3>
<p><img src="https://img.shields.io/badge/HTMX-Hypermedia-green" alt="HTMX" /></p>
<p><strong>Definition</strong>: Breaking templates into reusable partials so the server can render full pages OR just fragments for HTMX.</p>
<p><strong>Example</strong>:</p>
<ul>
<li><code>base.peb</code> - Full page layout</li>
<li><code>tasks/index.peb</code> - Full page (extends base)</li>
<li><code>tasks/_list.peb</code> - Partial (just the <code>&lt;ul&gt;</code>)</li>
<li><code>tasks/_item.peb</code> - Partial (just one <code>&lt;li&gt;</code>)</li>
</ul>
<p><strong>Why it matters</strong>: Server returns <code>_list.peb</code> for HTMX requests, <code>index.peb</code> for full page loads.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#partial">Partial</a>, <a href="references/glossary.html#fragment">Fragment</a>, <a href="references/glossary.html#htmx">HTMX</a></p>
<hr />
<h3 id="uk-gdpr"><a class="header" href="#uk-gdpr">UK GDPR</a></h3>
<p><img src="https://img.shields.io/badge/Module-COMP2850-darkblue" alt="Module" /></p>
<p><strong>Full name</strong>: UK General Data Protection Regulation (Data Protection Act 2018)</p>
<p><strong>Definition</strong>: UK law governing personal data collection, storage, and processing.</p>
<p><strong>Key principles</strong>: Lawfulness, fairness, transparency, purpose limitation, data minimization, accuracy, storage limitation, integrity/confidentiality, accountability.</p>
<p><strong>Used in COMP2850</strong>: All instrumentation must be GDPR-compliant (no PII, verbal consent, opt-out supported).</p>
<p><strong>See also</strong>: <a href="references/glossary.html#privacy-by-design">Privacy by Design</a>, <a href="references/glossary.html#pii">PII</a></p>
<hr />
<h3 id="wcag"><a class="header" href="#wcag">WCAG</a></h3>
<p><img src="https://img.shields.io/badge/Accessibility-a11y-purple" alt="Accessibility" /></p>
<p><strong>Full name</strong>: Web Content Accessibility Guidelines</p>
<p><strong>Definition</strong>: International standard for web accessibility published by W3C. Defines success criteria at 3 levels: A (minimum), AA (target), AAA (enhanced).</p>
<p><strong>Used in COMP2850</strong>: We target <strong>WCAG 2.2 Level AA</strong> compliance for all features.</p>
<p><strong>Reference</strong>: <a href="https://www.w3.org/WAI/WCAG22/quickref/">W3C WCAG 2.2 Quick Reference</a></p>
<p><strong>See also</strong>: <a href="references/glossary.html#accessibility">Accessibility</a></p>
<hr />
<h2 id="acronyms-quick-reference"><a class="header" href="#acronyms-quick-reference">Acronyms Quick Reference</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Acronym</th><th>Full Name</th><th>Link</th></tr></thead><tbody>
<tr><td><strong>a11y</strong></td><td>Accessibility (a + 11 letters + y)</td><td><a href="references/glossary.html#accessibility">‚Üë</a></td></tr>
<tr><td><strong>AJAX</strong></td><td>Asynchronous JavaScript and XML</td><td><a href="references/glossary.html#ajax">‚Üë</a></td></tr>
<tr><td><strong>ARIA</strong></td><td>Accessible Rich Internet Applications</td><td><a href="references/glossary.html#aria">‚Üë</a></td></tr>
<tr><td><strong>CSS</strong></td><td>Cascading Style Sheets</td><td><a href="references/glossary.html#css">‚Üë</a></td></tr>
<tr><td><strong>CSR</strong></td><td>Client-Side Rendering</td><td><a href="references/glossary.html#ssr">‚Üë</a></td></tr>
<tr><td><strong>GDPR</strong></td><td>General Data Protection Regulation</td><td><a href="references/glossary.html#uk-gdpr">‚Üë</a></td></tr>
<tr><td><strong>HATEOAS</strong></td><td>Hypermedia As The Engine Of Application State</td><td><a href="references/glossary.html#hateoas">‚Üë</a></td></tr>
<tr><td><strong>HTML</strong></td><td>HyperText Markup Language</td><td><a href="references/glossary.html#html">‚Üë</a></td></tr>
<tr><td><strong>HTTP</strong></td><td>HyperText Transfer Protocol</td><td><a href="references/glossary.html#http-methods">‚Üë</a></td></tr>
<tr><td><strong>JSON</strong></td><td>JavaScript Object Notation</td><td><a href="references/glossary.html#json">‚Üë</a></td></tr>
<tr><td><strong>OOB</strong></td><td>Out-of-Band (swap)</td><td><a href="references/glossary.html#oob-swap">‚Üë</a></td></tr>
<tr><td><strong>PII</strong></td><td>Personally Identifiable Information</td><td><a href="references/glossary.html#pii">‚Üë</a></td></tr>
<tr><td><strong>PRG</strong></td><td>Post-Redirect-Get</td><td><a href="references/glossary.html#prg">‚Üë</a></td></tr>
<tr><td><strong>SSR</strong></td><td>Server-Side Rendering</td><td><a href="references/glossary.html#ssr">‚Üë</a></td></tr>
<tr><td><strong>WCAG</strong></td><td>Web Content Accessibility Guidelines</td><td><a href="references/glossary.html#wcag">‚Üë</a></td></tr>
</tbody></table>
</div>
<hr />
<p><strong>Version</strong>: 0.2
<strong>Last updated</strong>: 2025-01-07
<strong>Module</strong>: COMP2850 HCI, University of Leeds</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="learning-outcomes-reference"><a class="header" href="#learning-outcomes-reference">Learning Outcomes Reference</a></h1>
<blockquote>
<p><strong>Purpose</strong> This document is the <strong>definitive reference</strong> for all Learning Outcomes in COMP2850 HCI. It clarifies terminology, maps outcomes to weeks/labs, and ensures consistency across all teaching materials.</p>
</blockquote>
<hr />
<h2 id="understanding-the-hierarchy"><a class="header" href="#understanding-the-hierarchy">Understanding the Hierarchy</a></h2>
<p>There are <strong>three levels</strong> of learning specifications in this module:</p>
<div class="table-wrapper"><table><thead><tr><th>Level</th><th>Scope</th><th>Purpose</th><th>Where Used</th></tr></thead><tbody>
<tr><td><strong>Module Aims</strong></td><td>Broad, aspirational statements about overall module goals</td><td>High-level intentions; what the module sets out to achieve</td><td>Homepage, module outline</td></tr>
<tr><td><strong>Learning Outcomes (LOs)</strong></td><td>Specific, measurable competencies students will demonstrate</td><td>Assessment criteria; aligned to accreditation standards (ACM CS2023)</td><td>Week/lab mappings, assessment rubrics, portfolio</td></tr>
<tr><td><strong>Lab Objectives</strong></td><td>Session-specific tasks and activities</td><td>What students will do in this lab to work toward LOs</td><td>Individual lab pages</td></tr>
</tbody></table>
</div>
<p><strong>Key distinction</strong>:</p>
<ul>
<li><strong>Aims</strong> are broad intentions (‚Äúenable students to‚Ä¶‚Äù)</li>
<li><strong>Outcomes</strong> are measurable achievements (‚Äústudents will be able to‚Ä¶‚Äù)</li>
<li><strong>Objectives</strong> are specific activities (‚Äúimplement a consent form‚Äù, ‚Äúrun 4 pilots‚Äù)</li>
</ul>
<hr />
<h2 id="module-wide-learning-outcomes-comp2850"><a class="header" href="#module-wide-learning-outcomes-comp2850">Module-Wide Learning Outcomes (COMP2850)</a></h2>
<p>These <strong>10 outcomes</strong> apply to the <strong>entire COMP2850 module</strong> (Weeks 1-11, covering OOP + HCI). The HCI component (Weeks 6-11) contributes to these outcomes alongside the OOP component (Weeks 1-5).</p>
<p>On successful completion of COMP2850, students will have demonstrated the ability to:</p>
<ol>
<li>
<p><strong>Apply subject specific knowledge and engineering design principles</strong> to design and implement software artefacts which satisfy complex real-world requirements, considering accessibility and inclusive design principles <em>(C1, M1, C2, M2, C5, M5, C6, M6, C11, M11)</em></p>
</li>
<li>
<p><strong>Select and interpret sources of information</strong> to solve complex real-world problems <em>(C4, M4)</em></p>
</li>
<li>
<p><strong>Use appropriately selected tools and processes</strong> to design, test, analyse and evaluate computer systems and identify limitations <em>(C12, M12, C13, M13)</em></p>
</li>
<li>
<p><strong>Identify and analyse ethical and sustainability concerns</strong> when designing and implementing software and make reasoned decisions informed by ethical frameworks and codes of conduct to minimise adverse impacts <em>(C7, M7, C8, M8)</em></p>
</li>
<li>
<p><strong>Identify and interpret risk</strong> assessing the potential impact and plan mitigation approaches <em>(C9, M9, C10, M10)</em></p>
</li>
<li>
<p><strong>Apply and discuss the principles of quality management</strong> in software engineering and systems design <em>(C14, M14)</em></p>
</li>
<li>
<p><strong>Operate effectively as a member of a team</strong> in various roles <em>(C16, M16)</em></p>
</li>
<li>
<p><strong>Apply and discuss engineering management principles</strong> demonstrating awareness of commercial context, project and change management, and relevant legal matters <em>(C15, M15)</em></p>
</li>
<li>
<p><strong>Communicate effectively complex topics</strong> related to programming and software engineering to technical and non-technical audiences <em>(C17, M17)</em></p>
</li>
<li>
<p><strong>Reflect on their level of mastery</strong> of subject knowledge and skills and plan for personal development <em>(C18, M18)</em></p>
</li>
</ol>
<p><strong>HCI contribution</strong>: Weeks 6-11 primarily contribute to outcomes <strong>1, 2, 3, 4, 7, 9, and 10</strong>.</p>
<hr />
<h2 id="hci-specific-learning-outcomes-weeks-6-11"><a class="header" href="#hci-specific-learning-outcomes-weeks-6-11">HCI-Specific Learning Outcomes (Weeks 6-11)</a></h2>
<p>These <strong>13 outcomes</strong> are specific to the <strong>HCI component</strong> (Weeks 6-11). They elaborate on how the module-wide outcomes are achieved through HCI activities. They are numbered <strong>LO1 through LO13</strong> and should be referenced consistently across all lab materials.</p>
<p><strong>Source</strong>: <code>learning-outcomes-condensed.md</code></p>
<h3 id="lo1-differentiate-people-centred-design-and-evaluation-methodologies"><a class="header" href="#lo1-differentiate-people-centred-design-and-evaluation-methodologies">LO1: Differentiate people-centred design and evaluation methodologies</a></h3>
<p><strong>Description</strong>: Distinguish between design methodologies (e.g., participatory design, user-centred design) and evaluation methods (e.g., heuristic evaluation, task-based testing, A/B testing).</p>
<p><strong>Evidenced in</strong>: Week 6 Lab 2 (needs-finding, job stories), Week 9 Lab 1 (evaluation planning, method selection)</p>
<p><strong>ACM strands</strong>: Understanding People (UP/1-3), HCI-Evaluation (HC/5)</p>
<hr />
<h3 id="lo2-design-and-conduct-needs-finding-activities"><a class="header" href="#lo2-design-and-conduct-needs-finding-activities">LO2: Design and conduct needs-finding activities</a></h3>
<p><strong>Description</strong>: Plan and run structured needs-finding sessions (interviews, observation, job story extraction) following ethical protocols including informed consent.</p>
<p><strong>Evidenced in</strong>: Week 6 Lab 2 (job stories, consent forms), Week 7 Lab 1 (user scenarios)</p>
<p><strong>ACM strands</strong>: Understanding People (UP/1-2), Requirements Engineering</p>
<hr />
<h3 id="lo3-analyse-ethical-implications-of-design-decisions"><a class="header" href="#lo3-analyse-ethical-implications-of-design-decisions">LO3: Analyse ethical implications of design decisions</a></h3>
<p><strong>Description</strong>: Identify ethical concerns (privacy, consent, data retention, bias) in interface designs and propose mitigation strategies informed by frameworks like UK GDPR, BCS Code of Conduct.</p>
<p><strong>Evidenced in</strong>: Week 7 Lab 1 (consent modal, privacy by design), Week 6 Lab 2 (data handling), Week 10 Lab 2 (inclusive redesign)</p>
<p><strong>ACM strands</strong>: Social and Professional Issues (SP/1-2), Privacy &amp; Security</p>
<hr />
<h3 id="lo4-evaluate-software-interfaces-for-accessibility-concerns"><a class="header" href="#lo4-evaluate-software-interfaces-for-accessibility-concerns">LO4: Evaluate software interfaces for accessibility concerns</a></h3>
<p><strong>Description</strong>: Conduct accessibility audits using automated tools (axe DevTools) and manual testing (keyboard navigation, screen readers) against WCAG 2.2 AA standards.</p>
<p><strong>Evidenced in</strong>: Week 7 Lab 2 (accessibility audit, WCAG mapping), Week 8 Lab 2 (no-JS verification), Week 10 Lab 2 (regression testing)</p>
<p><strong>ACM strands</strong>: Designing Interaction (HC/2), Accessibility (WCAG 2.2 AA)</p>
<hr />
<h3 id="lo5-create-interface-prototypes-using-appropriate-fidelity-levels"><a class="header" href="#lo5-create-interface-prototypes-using-appropriate-fidelity-levels">LO5: Create interface prototypes using appropriate fidelity levels</a></h3>
<p><strong>Description</strong>: Build prototypes ranging from paper sketches to functional HTML/HTMX implementations, selecting fidelity appropriate to the design question.</p>
<p><strong>Evidenced in</strong>: Week 8 Lab 1 (HTMX prototypes, partials), Week 10 Lab 2 (redesign implementation)</p>
<p><strong>ACM strands</strong>: Prototyping Techniques (HC/3)</p>
<hr />
<h3 id="lo6-apply-iterative-design-processes"><a class="header" href="#lo6-apply-iterative-design-processes">LO6: Apply iterative design processes</a></h3>
<p><strong>Description</strong>: Execute design-test-refine cycles, incorporating evaluation findings into redesigns and documenting rationale with evidence.</p>
<p><strong>Evidenced in</strong>: Week 9 Lab 2 (pilots, debrief), Week 10 Lab 1 (analysis, prioritisation), Week 10 Lab 2 (redesign, re-verification)</p>
<p><strong>ACM strands</strong>: Iterative Design (HC/4)</p>
<hr />
<h3 id="lo7-analyse-how-design-constraints-affect-interface-decisions"><a class="header" href="#lo7-analyse-how-design-constraints-affect-interface-decisions">LO7: Analyse how design constraints affect interface decisions</a></h3>
<p><strong>Description</strong>: Identify technical, accessibility, and no-JS constraints; explain trade-offs in design decisions (e.g., progressive enhancement vs SPA, server-first vs client-first).</p>
<p><strong>Evidenced in</strong>: Week 8 Lab 1 (pagination, filtering constraints), Week 8 Lab 2 (no-JS parity, routing trade-offs)</p>
<p><strong>ACM strands</strong>: Design Constraints (HC/4), Software Architecture</p>
<hr />
<h3 id="lo8-design-and-execute-appropriate-evaluation-methods"><a class="header" href="#lo8-design-and-execute-appropriate-evaluation-methods">LO8: Design and execute appropriate evaluation methods</a></h3>
<p><strong>Description</strong>: Develop task-based evaluation protocols, define metrics (time-on-task, errors, SUS), run pilots with n=4 participants, and analyse quantitative/qualitative data.</p>
<p><strong>Evidenced in</strong>: Week 9 Lab 1 (evaluation plan, metrics, instrumentation), Week 9 Lab 2 (pilots, observer notes), Week 10 Lab 1 (data analysis)</p>
<p><strong>ACM strands</strong>: HCI-Evaluation (HC/5), Empirical Methods</p>
<hr />
<h3 id="lo9-apply-universal-and-inclusive-design-principles"><a class="header" href="#lo9-apply-universal-and-inclusive-design-principles">LO9: Apply universal and inclusive design principles</a></h3>
<p><strong>Description</strong>: Design interfaces that work for diverse users (keyboard-only, screen reader, low vision, cognitive differences) using techniques like semantic HTML, ARIA, focus management.</p>
<p><strong>Evidenced in</strong>: Week 7 Lab 2 (inclusive fix), Week 8 Lab 2 (no-JS parity), Week 10 Lab 2 (inclusive redesign)</p>
<p><strong>ACM strands</strong>: Accessibility (HC/2), Universal Design (UP/3)</p>
<hr />
<h3 id="lo10-critique-potential-impacts-of-designs-on-society"><a class="header" href="#lo10-critique-potential-impacts-of-designs-on-society">LO10: Critique potential impacts of designs on society</a></h3>
<p><strong>Description</strong>: Analyse societal implications of design choices (surveillance, exclusion, environmental cost) and propose alternatives that reduce harm.</p>
<p><strong>Evidenced in</strong>: Week 7 Lab 1 (ethics analysis), Week 6 Lab 2 (privacy considerations)</p>
<p><strong>ACM strands</strong>: Social and Professional Issues (SP/1-2), Ethics</p>
<hr />
<h3 id="lo11-collaborate-effectively-in-multidisciplinary-teams"><a class="header" href="#lo11-collaborate-effectively-in-multidisciplinary-teams">LO11: Collaborate effectively in multidisciplinary teams</a></h3>
<p><strong>Description</strong>: Work in teams using version control (Git), code review, and shared documentation; communicate design rationale to technical and non-technical peers.</p>
<p><strong>Evidenced in</strong>: Week 9 Lab 2 (peer pilots, observer role), Week 11 Lab 1 (studio crit, peer feedback)</p>
<p><strong>ACM strands</strong>: Teamwork (Professional Skills)</p>
<hr />
<h3 id="lo12-demonstrate-professional-dispositions"><a class="header" href="#lo12-demonstrate-professional-dispositions">LO12: Demonstrate professional dispositions</a></h3>
<p><strong>Description</strong>: Show responsibility (meet deadlines, follow protocols), integrity (cite sources, report honestly), and respect (use people-centred language, honour consent).</p>
<p><strong>Evidenced in</strong>: All labs (consent adherence, evidence-based claims, inclusive language)</p>
<p><strong>ACM strands</strong>: Professional Skills, Ethics</p>
<hr />
<h3 id="lo13-integrate-people-centred-design-with-se-lifecycle"><a class="header" href="#lo13-integrate-people-centred-design-with-se-lifecycle">LO13: Integrate people-centred design with SE lifecycle</a></h3>
<p><strong>Description</strong>: Embed HCI practices (needs-finding, evaluation, iteration) within software engineering workflows (version control, testing, deployment).</p>
<p><strong>Evidenced in</strong>: Week 8 Lab 1 (server-first patterns), Week 9 Lab 1 (instrumentation in code), Week 10 Lab 2 (regression testing)</p>
<p><strong>ACM strands</strong>: Software Engineering Processes, Requirements Engineering</p>
<hr />
<h2 id="cross-reference-los-to-weeks--activities"><a class="header" href="#cross-reference-los-to-weeks--activities">Cross-Reference: LOs to Weeks &amp; Activities</a></h2>
<p>This table maps each HCI Learning Outcome to specific weeks, labs, and deliverables. Use this for curriculum planning, assessment design, and student progress tracking.</p>
<div class="table-wrapper"><table><thead><tr><th>LO</th><th>Outcome (condensed)</th><th>Primary Evidence</th><th>Secondary Evidence</th><th>Assessment Task</th><th>ACM Strands</th></tr></thead><tbody>
<tr><td><strong>LO1</strong></td><td>Differentiate people-centred methods</td><td>W6 L2 (needs-finding, job stories)</td><td>W9 L1 (evaluation methods)</td><td>Task 1: Evaluation plan</td><td>UP/1-3, HC/5</td></tr>
<tr><td><strong>LO2</strong></td><td>Design and conduct needs-finding</td><td>W6 L2 (job stories, consent)</td><td>W7 L1 (scenarios)</td><td>Backlog (user needs)</td><td>UP/1-2</td></tr>
<tr><td><strong>LO3</strong></td><td>Analyse ethical implications</td><td>W7 L1 (consent modal, GDPR)</td><td>W6 L2 (privacy), W10 L2 (bias)</td><td>Task 2: Privacy audit</td><td>SP/1-2</td></tr>
<tr><td><strong>LO4</strong></td><td>Evaluate for accessibility</td><td>W7 L2 (audit, WCAG map)</td><td>W8 L2 (no-JS), W10 L2 (regression)</td><td>Task 2: Accessibility fixes</td><td>HC/2, WCAG 2.2 AA</td></tr>
<tr><td><strong>LO5</strong></td><td>Create prototypes</td><td>W8 L1 (HTMX partials)</td><td>W10 L2 (redesign)</td><td>Code submissions</td><td>HC/3</td></tr>
<tr><td><strong>LO6</strong></td><td>Apply iterative design</td><td>W9 L2 (pilots), W10 (analysis + redesign)</td><td>W11 L1 (critique)</td><td>Tasks 1 &amp; 2: Full cycle</td><td>HC/4</td></tr>
<tr><td><strong>LO7</strong></td><td>Analyse design constraints</td><td>W8 L1 (pagination, filtering)</td><td>W8 L2 (no-JS trade-offs)</td><td>Task 2: Trade-offs doc</td><td>HC/4</td></tr>
<tr><td><strong>LO8</strong></td><td>Design and execute evaluation</td><td>W9 L1 (plan, metrics), W9 L2 (pilots)</td><td>W10 L1 (analysis)</td><td>Task 1: Pilots &amp; findings</td><td>HC/5</td></tr>
<tr><td><strong>LO9</strong></td><td>Apply inclusive design</td><td>W7 L2 (inclusive fix)</td><td>W8 L2 (no-JS), W10 L2 (redesign)</td><td>Task 2: WCAG compliance</td><td>HC/2, UP/3</td></tr>
<tr><td><strong>LO10</strong></td><td>Critique societal impacts</td><td>W7 L1 (ethics overlay)</td><td>W6 L2 (privacy)</td><td>Reflections</td><td>SP/1-2</td></tr>
<tr><td><strong>LO11</strong></td><td>Collaborate in teams</td><td>W9 L2 (peer pilots)</td><td>W11 L1 (studio crit)</td><td>Peer feedback forms</td><td>Professional Skills</td></tr>
<tr><td><strong>LO12</strong></td><td>Demonstrate professionalism</td><td>All labs (consent, citations)</td><td>Portfolio (integrity)</td><td>All submissions</td><td>Professional Skills</td></tr>
<tr><td><strong>LO13</strong></td><td>Integrate HCI with SE</td><td>W8 L1 (server patterns), W9 L1 (instrumentation)</td><td>W10 L2 (regression)</td><td>Codebase quality</td><td>SE Processes</td></tr>
</tbody></table>
</div>
<p><strong>How to use this table</strong>:</p>
<ul>
<li><strong>Curriculum planning</strong>: Ensure each LO has sufficient coverage across weeks</li>
<li><strong>Student progress</strong>: Track which LOs are being addressed in each lab</li>
<li><strong>Assessment design</strong>: Align rubrics to LOs</li>
<li><strong>Accreditation</strong>: Map LOs to ACM/BCS requirements</li>
</ul>
<hr />
<h2 id="module-aims-not-learning-outcomes"><a class="header" href="#module-aims-not-learning-outcomes">Module Aims (Not Learning Outcomes)</a></h2>
<p>These <strong>four aims</strong> appear on the homepage.<br />
They are <strong>broad aspirational statements</strong> about what the module
enables you to do. They are <strong>not</strong> the same as Learning Outcomes (which are specific and measurable).</p>
<ol>
<li>Apply HCI principles to design inclusive interfaces</li>
<li>Evaluate accessibility and ethics in interactive systems</li>
<li>Implement server-first architecture with progressive enhancement</li>
<li>Communicate design decisions with evidence</li>
</ol>
<hr />
<h2 id="terminology-clarification"><a class="header" href="#terminology-clarification">Terminology Clarification</a></h2>
<h3 id="module-aims-1"><a class="header" href="#module-aims-1">Module Aims</a></h3>
<p><strong>Definition</strong>: Broad, aspirational statements about what the module sets out to achieve.</p>
<p><strong>Characteristics</strong>:</p>
<ul>
<li>High-level, conceptual</li>
<li>Focus on ‚Äúenabling‚Äù or ‚Äúequipping‚Äù students</li>
<li>Not directly assessed (but outcomes derived from aims are assessed)</li>
</ul>
<p><strong>Example</strong>: ‚ÄúThis module aims to enable students to design accessible web interfaces.‚Äù</p>
<h3 id="learning-outcomes-los"><a class="header" href="#learning-outcomes-los">Learning Outcomes (LOs)</a></h3>
<p><strong>Definition</strong>: Specific, measurable competencies that students will demonstrate by the end of the module.</p>
<p><strong>Characteristics</strong>:</p>
<ul>
<li>Use action verbs (apply, analyse, design, evaluate)</li>
<li>Aligned to Bloom‚Äôs Taxonomy</li>
<li>Directly assessed</li>
<li>Mapped to accreditation standards (ACM, BCS)</li>
</ul>
<p><strong>Example</strong>: ‚ÄúLO4: Evaluate software interfaces for accessibility concerns using WCAG 2.2 AA standards.‚Äù</p>
<h3 id="lab-objectives-12"><a class="header" href="#lab-objectives-12">Lab Objectives</a></h3>
<p><strong>Definition</strong>: Session-specific tasks and activities that contribute to achieving Learning Outcomes.</p>
<p><strong>Characteristics</strong>:</p>
<ul>
<li>Concrete, actionable</li>
<li>Time-bound (this lab session)</li>
<li>Contribute to one or more LOs</li>
</ul>
<p><strong>Example</strong>: ‚ÄúRun an axe DevTools audit and document 5+ WCAG violations‚Äù (contributes to LO4).</p>
<hr />
<h2 id="acm-cs2023-mapping"><a class="header" href="#acm-cs2023-mapping">ACM CS2023 Mapping</a></h2>
<p>The 13 HCI Learning Outcomes map to the following ACM Computer Science 2023 curriculum standards:</p>
<h3 id="human-computer-interaction-hc"><a class="header" href="#human-computer-interaction-hc">Human-Computer Interaction (HC)</a></h3>
<ul>
<li><strong>HC/2</strong>: Designing Interaction (LO4, LO9)</li>
<li><strong>HC/3</strong>: Prototyping Techniques (LO5)</li>
<li><strong>HC/4</strong>: Iterative Design (LO6, LO7)</li>
<li><strong>HC/5</strong>: Evaluation (LO1, LO8)</li>
</ul>
<h3 id="understanding-people-up"><a class="header" href="#understanding-people-up">Understanding People (UP)</a></h3>
<ul>
<li><strong>UP/1</strong>: User Research (LO1, LO2)</li>
<li><strong>UP/2</strong>: Needs Finding (LO2)</li>
<li><strong>UP/3</strong>: Accessibility &amp; Universal Design (LO9)</li>
</ul>
<h3 id="social-and-professional-issues-sp"><a class="header" href="#social-and-professional-issues-sp">Social and Professional Issues (SP)</a></h3>
<ul>
<li><strong>SP/1</strong>: Ethics in Computing (LO3, LO10)</li>
<li><strong>SP/2</strong>: Privacy &amp; Security (LO3)</li>
<li><strong>SP/Professional Skills</strong>: Teamwork, Communication (LO11, LO12)</li>
</ul>
<h3 id="software-engineering-processes-sep"><a class="header" href="#software-engineering-processes-sep">Software Engineering Processes (SEP)</a></h3>
<ul>
<li><strong>SEP/2</strong>: Requirements Engineering (LO2, LO13)</li>
<li><strong>SEP/3</strong>: Design Patterns &amp; Architecture (LO7, LO13)</li>
</ul>
<h3 id="web--mobile-systems"><a class="header" href="#web--mobile-systems">Web &amp; Mobile Systems</a></h3>
<ul>
<li><strong>Server-first patterns</strong> (LO5, LO7, LO13)</li>
<li><strong>Progressive enhancement</strong> (LO7, LO9)</li>
</ul>
<hr />
<h2 id="wcag-22-mapping"><a class="header" href="#wcag-22-mapping">WCAG 2.2 Mapping</a></h2>
<p>Learning Outcomes with direct WCAG 2.2 AA compliance requirements:</p>
<div class="table-wrapper"><table><thead><tr><th>LO</th><th>WCAG Principles</th><th>Key Success Criteria</th></tr></thead><tbody>
<tr><td><strong>LO4</strong></td><td>All (Perceivable, Operable, Understandable, Robust)</td><td>1.3.1 Info &amp; Relationships, 1.4.3 Contrast, 2.1.1 Keyboard, 2.4.7 Focus Visible, 4.1.2 Name/Role/Value</td></tr>
<tr><td><strong>LO9</strong></td><td>Operable, Understandable</td><td>2.1.1 Keyboard, 2.4.1 Skip Links, 2.4.3 Focus Order, 3.3.2 Labels, 4.1.3 Status Messages</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="for-students-self-assessment"><a class="header" href="#for-students-self-assessment">For Students: Self-Assessment</a></h2>
<p>Use this checklist to track your progress across the 13 HCI Learning Outcomes:</p>
<div class="table-wrapper"><table><thead><tr><th>LO</th><th>Outcome</th><th>Confidence (1‚Äì5)</th><th>Evidence Location</th></tr></thead><tbody>
<tr><td>LO1</td><td>Differentiate people-centred methods</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W6 L2 job stories, W9 L1 eval plan</td></tr>
<tr><td>LO2</td><td>Design and conduct needs-finding</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W6 L2 consent protocol</td></tr>
<tr><td>LO3</td><td>Analyse ethical implications</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W7 L1 consent modal, privacy audit</td></tr>
<tr><td>LO4</td><td>Evaluate for accessibility</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W7 L2 axe audit, WCAG map</td></tr>
<tr><td>LO5</td><td>Create prototypes</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W8 L1 HTMX features</td></tr>
<tr><td>LO6</td><td>Apply iterative design</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W9 L2 pilots ‚Üí W10 L2 redesign</td></tr>
<tr><td>LO7</td><td>Analyse design constraints</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W8 L2 no-JS trade-offs doc</td></tr>
<tr><td>LO8</td><td>Design and execute evaluation</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W9 L1 metrics + W9 L2 pilots</td></tr>
<tr><td>LO9</td><td>Apply inclusive design</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W7 L2 fix, W10 L2 redesign</td></tr>
<tr><td>LO10</td><td>Critique societal impacts</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W7 L1 ethics reflection</td></tr>
<tr><td>LO11</td><td>Collaborate in teams</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W9 L2 peer pilots, W11 L1 crit</td></tr>
<tr><td>LO12</td><td>Demonstrate professionalism</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>All labs: consent, citations</td></tr>
<tr><td>LO13</td><td>Integrate HCI with SE</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W8 L1 Ktor patterns, W9 L1 instrumentation</td></tr>
</tbody></table>
</div>
<p><strong>Confidence scale</strong>: 1 = Not confident, 3 = Moderately confident, 5 = Very confident</p>
<hr />
<h2 id="for-teaching-staff-using-this-reference"><a class="header" href="#for-teaching-staff-using-this-reference">For Teaching Staff: Using This Reference</a></h2>
<h3 id="curriculum-design"><a class="header" href="#curriculum-design">Curriculum Design</a></h3>
<ul>
<li>Ensure each LO has ‚â•2 touchpoints across weeks</li>
<li>Balance formative (practice) and summative (assessed) evidence</li>
<li>Check ACM/WCAG coverage for accreditation</li>
</ul>
<h3 id="assessment-design"><a class="header" href="#assessment-design">Assessment Design</a></h3>
<ul>
<li>Tasks 1 &amp; 2 should collectively assess all 13 LOs</li>
<li>Use cross-reference table to verify coverage</li>
<li>Map rubric criteria to specific LOs</li>
</ul>
<h3 id="student-support"><a class="header" href="#student-support">Student Support</a></h3>
<ul>
<li>Link to this reference in feedback (‚Äúsee LO4 for accessibility criteria‚Äù)</li>
<li>Use self-assessment checklist in tutorials</li>
<li>Explain aims vs outcomes vs objectives in Week 6</li>
</ul>
<h3 id="quality-assurance"><a class="header" href="#quality-assurance">Quality Assurance</a></h3>
<ul>
<li>Annual review: verify LO mappings still accurate</li>
<li>External examiner reports: reference this document</li>
<li>Student feedback: check if LO structure is clear</li>
</ul>
<hr />
<h2 id="version-history"><a class="header" href="#version-history">Version History</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Version</th><th>Date</th><th>Changes</th></tr></thead><tbody>
<tr><td>0.2</td><td>2025-11-07</td><td>Initial definitive reference created; standardised terminology; mapped 13 HCI LOs + 10 module LOs</td></tr>
<tr><td>0.1</td><td>2025-10-29</td><td>Initial draft created; added learning outcomes, aims, and cross-reference table</td></tr>
</tbody></table>
</div>
<hr />
<p><strong>Questions?</strong> See <a href="references/glossary.html">Glossary</a> for term definitions or contact module teaching staff.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="serverfirst-a-practical-guide-for-comp2850-hci"><a class="header" href="#serverfirst-a-practical-guide-for-comp2850-hci">Server‚ÄëFirst: A Practical Guide for COMP2850 (HCI)</a></h1>
<blockquote>
<p><strong>TL;DR</strong>: Render HTML on the <strong>server</strong> by default. Add interactivity as <strong><a href="references/glossary.html#progressive-enhancement">progressive enhancement</a></strong> using <a href="references/glossary.html#htmx">HTMX</a>. If JavaScript is off, everything still works. Use <strong><a href="references/glossary.html#prg">PRG (Post/Redirect/Get)</a></strong> for forms, return <strong><a href="references/glossary.html#fragment">fragments</a></strong> to HTMX when it asks, and make <strong><a href="references/glossary.html#accessibility">accessibility</a></strong> non‚Äënegotiable.</p>
</blockquote>
<p><strong>New to these terms?</strong> See the <strong><a href="references/glossary.html">Glossary</a></strong> for full definitions.</p>
<hr />
<h2 id="why-serverfirst"><a class="header" href="#why-serverfirst">Why ‚Äúserver‚Äëfirst‚Äù?</a></h2>
<ul>
<li><strong>Reliability</strong>: No dependency on client frameworks to show a page or submit a form.</li>
<li><strong>Simplicity</strong>: Routing, validation, and business logic live on the server (<a href="references/glossary.html#ktor">Ktor</a>). You avoid duplicating logic in the browser.</li>
<li><strong>Performance</strong>: Initial loads are fast (HTML streams quickly); interactivity is layered as needed.</li>
<li><strong><a href="references/glossary.html#accessibility">Accessibility</a></strong>: <a href="references/glossary.html#semantic-html">Semantic HTML</a>, sensible focus order, and <a href="references/glossary.html#aria">ARIA</a> work from the start.</li>
</ul>
<hr />
<h2 id="core-principles"><a class="header" href="#core-principles">Core principles</a></h2>
<ol>
<li><strong>Server renders the UI</strong> (full pages + partials).</li>
<li><strong><a href="references/glossary.html#progressive-enhancement">Progressive enhancement</a></strong> with <a href="references/glossary.html#htmx">HTMX</a> (or plain forms and links).</li>
<li><strong><a href="references/glossary.html#no-js-parity">No‚ÄëJS parity</a></strong> is mandatory‚Äîevery action has a full-page path.</li>
<li><strong><a href="references/glossary.html#prg">PRG pattern</a></strong> for all forms (avoid resubmits; clean URLs).</li>
<li><strong>One source of truth</strong>: validation and business rules on the server.</li>
<li><strong><a href="references/glossary.html#accessibility">Accessibility</a> by default</strong>: structure, labels, keyboard paths, and <a href="references/glossary.html#aria-live-region">live updates</a>.</li>
</ol>
<hr />
<h2 id="quickstart-checklist"><a class="header" href="#quickstart-checklist">Quick‚Äëstart checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox"/>
<strong>Routes</strong> return full pages by default; fragments when <code>HX-Request: true</code> is present.</li>
<li><input disabled="" type="checkbox"/>
<strong>Forms</strong> use PRG: <code>POST /thing</code> ‚Üí validate ‚Üí save ‚Üí <code>redirect("/things")</code>.</li>
<li><input disabled="" type="checkbox"/>
<strong>HTMX</strong> requests hit the <em>same</em> routes; server returns only the fragment (no layout).</li>
<li><input disabled="" type="checkbox"/>
<strong>Validation</strong> errors re-render the form (full page or fragment) with error messages bound to fields.</li>
<li><input disabled="" type="checkbox"/>
<strong>Announcements</strong> use <code>aria-live="polite"</code> and/or <code>hx-swap-oob</code> for status banners.</li>
<li><input disabled="" type="checkbox"/>
<strong>No client-only state machines</strong>. Server owns state.</li>
<li><input disabled="" type="checkbox"/>
<strong>Links still work</strong> with normal navigation (use <code>hx-boost="true"</code> as a <a href="https://hypermedia.systems/htmx-patterns/">sprinkle</a> only).</li>
<li><input disabled="" type="checkbox"/>
<strong>Keyboard &amp; screen reader</strong> flows are tested (Tab order, headings, labels).</li>
<li><input disabled="" type="checkbox"/>
<strong>JS disabled</strong> tests pass (you can complete tasks end-to-end).</li>
</ul>
<hr />
<h2 id="minimal-reference-implementation"><a class="header" href="#minimal-reference-implementation">Minimal reference implementation</a></h2>
<h3 id="1-routing-in-ktor-kotlin"><a class="header" href="#1-routing-in-ktor-kotlin">1) Routing in Ktor (Kotlin)</a></h3>
<p>Use a helper to detect HTMX and return the right view.</p>
<pre><code class="language-kotlin">fun Application.module() {
    routing {
        // List
        get("/tasks") {
            val tasks = taskRepo.all()
            if (call.request.headers["HX-Request"] == "true") {
                call.respond(renderPartial("_tasks_table.peb", mapOf("tasks" to tasks)))
            } else {
                call.respond(renderPage("tasks.peb", mapOf("tasks" to tasks)))
            }
        }

        // Create (PRG)
        post("/tasks") {
            val params = call.receiveParameters()
            val title = params["title"]?.trim().orEmpty()

            val errors = mutableMapOf&lt;String, String&gt;()
            if (title.isBlank()) errors["title"] = "Title is required."

            if (errors.isNotEmpty()) {
                val model = mapOf("errors" to errors, "values" to params)
                if (call.request.headers["HX-Request"] == "true") {
                    // return just the form fragment with errors
                    call.respond(HttpStatusCode.UnprocessableEntity, renderPartial("_task_form.peb", model))
                } else {
                    call.respond(renderPage("task_new.peb", model))
                }
                return@post
            }

            taskRepo.add(title)
            // PRG: after success, redirect for full-page; or return fragment for HTMX
            if (call.request.headers["HX-Request"] == "true") {
                val tasks = taskRepo.all()
                call.respond(renderPartial("_tasks_table.peb", mapOf("tasks" to tasks, "flash" to "Task added")))
            } else {
                call.respondRedirect("/tasks?flash=Task+added")
            }
        }
    }
}
</code></pre>
<blockquote>
<p><strong>Notes</strong></p>
<ul>
<li><code>renderPage(template, model)</code> returns the <strong>full</strong> layout (header/footer + body).</li>
<li><code>renderPartial(template, model)</code> returns a <strong>fragment</strong> only (no Chrome).</li>
<li>HTMX sets <code>HX-Request: true</code> automatically‚Äîuse it to branch responses.</li>
<li>On error, send <strong>422 Unprocessable Entity</strong> for HTMX (helps debugging).</li>
</ul>
</blockquote>
<h3 id="2-templates-pebblefreemarkeretc"><a class="header" href="#2-templates-pebblefreemarkeretc">2) Templates (Pebble/FreeMarker/etc.)</a></h3>
<p><strong><code>tasks.peb</code></strong> (full page)</p>
<pre><code class="language-html">&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
  &lt;meta charset="utf-8" /&gt;
  &lt;title&gt;Tasks&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
  &lt;main&gt;
    &lt;h1&gt;Tasks&lt;/h1&gt;

    &lt;div id="alerts" aria-live="polite"&gt;
      {% if flash %}&lt;div class="alert"&gt;{{ flash }}&lt;/div&gt;{% endif %}
    &lt;/div&gt;

    &lt;section&gt;
      {% include "_task_form.peb" %}
    &lt;/section&gt;

    &lt;section id="tasks-table"&gt;
      {% include "_tasks_table.peb" %}
    &lt;/section&gt;
  &lt;/main&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<p><strong><code>_task_form.peb</code></strong> (fragment)</p>
<pre><code class="language-html">&lt;form action="/tasks" method="post"
      hx-post="/tasks" hx-target="#tasks-table" hx-swap="innerHTML"&gt;
  &lt;label for="title"&gt;Title&lt;/label&gt;
  &lt;input id="title" name="title" value="{{ values.title | default('') }}"
         aria-invalid="{{ errors.title ? 'true' : 'false' }}"
         aria-describedby="{{ errors.title ? 'title-error' : '' }}"&gt;

  {% if errors.title %}
    &lt;div id="title-error" class="error"&gt;{{ errors.title }}&lt;/div&gt;
  {% endif %}

  &lt;button type="submit"&gt;Add&lt;/button&gt;
&lt;/form&gt;
</code></pre>
<p><strong><code>_tasks_table.peb</code></strong> (fragment)</p>
<pre><code class="language-html">&lt;table role="table"&gt;
  &lt;thead&gt;
    &lt;tr&gt;&lt;th&gt;Title&lt;/th&gt;&lt;th&gt;Actions&lt;/th&gt;&lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
  {% for t in tasks %}
    &lt;tr&gt;
      &lt;td&gt;{{ t.title }}&lt;/td&gt;
      &lt;td&gt;
        &lt;button hx-delete="/tasks/{{ t.id }}"
                hx-target="#tasks-table"
                hx-swap="innerHTML"&gt;Delete&lt;/button&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  {% endfor %}
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;!-- Optional OOB flash update --&gt;
&lt;div id="alerts" hx-swap-oob="true" aria-live="polite"&gt;
  {% if flash %}&lt;div class="alert"&gt;{{ flash }}&lt;/div&gt;{% endif %}
&lt;/div&gt;
</code></pre>
<blockquote>
<p><strong>Why this works</strong></p>
<ul>
<li>Full page render for normal navigation.</li>
<li>HTMX swaps only <code>#tasks-table</code> (fast, minimal HTML over the wire).</li>
<li>Same URLs &amp; same controllers for both full and partial flows.</li>
<li><code>hx-swap-oob</code> lets us update the flash area <em>outside</em> the target region.</li>
</ul>
</blockquote>
<hr />
<h2 id="prg-postredirectget-done-right"><a class="header" href="#prg-postredirectget-done-right">PRG (Post/Redirect/Get) done right</a></h2>
<ul>
<li><strong>Full page</strong>: <code>POST /tasks</code> ‚Üí validate ‚Üí save ‚Üí <code>302 Location: /tasks</code> ‚Üí browser GETs ‚Üí shows ‚ÄúTask added‚Äù.</li>
<li><strong>HTMX</strong>: <code>POST /tasks</code> ‚Üí validate ‚Üí save ‚Üí return <strong>updated fragment</strong> (or send header <code>HX-Redirect: /tasks</code> if you want HTMX to follow a redirect).</li>
<li><strong>Avoid</strong> returning ‚Äúsuccess pages‚Äù to a POST. They break refresh/back and risk duplicate submissions.</li>
</ul>
<hr />
<h2 id="validation--errors"><a class="header" href="#validation--errors">Validation &amp; errors</a></h2>
<ul>
<li>Use server-side validators; <strong>never</strong> rely solely on client hints.</li>
<li>Return <strong>422</strong> with the form fragment and inline errors for HTMX.</li>
<li>For full pages, re-render the page with the form and errors bound.</li>
<li>Keep focus management in mind‚Äîon error, focus the first invalid field.</li>
</ul>
<hr />
<h2 id="accessibility-essentials-baked-in"><a class="header" href="#accessibility-essentials-baked-in">Accessibility essentials (baked in)</a></h2>
<ul>
<li>Semantic HTML: headings, lists, labels, landmark regions (<code>&lt;main&gt;</code>, <code>&lt;nav&gt;</code>).</li>
<li><strong>Labels</strong> bound to inputs; <strong>error text</strong> bound with <code>aria-describedby</code>.</li>
<li>Buttons are real <code>&lt;button&gt;</code> elements; links are <code>&lt;a&gt;</code> elements (not divs).</li>
<li><strong>Focus states</strong> visible; Tab order logical.</li>
<li>Live updates (<code>aria-live="polite"</code>) for flash/status messages.</li>
<li>Test with keyboard only and with a screen reader (e.g., Orca/NVDA/VoiceOver).</li>
</ul>
<hr />
<h2 id="progressive-enhancement-patterns"><a class="header" href="#progressive-enhancement-patterns">Progressive enhancement patterns</a></h2>
<h3 id="a-boost-links--forms-optional"><a class="header" href="#a-boost-links--forms-optional">A) Boost links &amp; forms (optional)</a></h3>
<pre><code class="language-html">&lt;body hx-boost="true"&gt;
  &lt;!-- Links and forms become HTMX requests automatically.
       Turn off if it confuses the flow for beginners. --&gt;
&lt;/body&gt;
</code></pre>
<h3 id="b-keep-urls-tidy-on-partial-swaps"><a class="header" href="#b-keep-urls-tidy-on-partial-swaps">B) Keep URLs tidy on partial swaps</a></h3>
<p>If a swap represents a ‚Äúreal‚Äù navigation, add <code>hx-push-url="true"</code> so the back button works as expected.</p>
<h3 id="c-small-composable-fragments"><a class="header" href="#c-small-composable-fragments">C) Small, composable fragments</a></h3>
<p>Prefer <code>_task_row.peb</code> included by <code>_tasks_table.peb</code> so you can swap a single row on update, e.g. <code>hx-target="#task-{{id}}"</code>.</p>
<hr />
<h2 id="debugging--testing"><a class="header" href="#debugging--testing">Debugging &amp; testing</a></h2>
<ul>
<li><strong>No‚ÄëJS test</strong>: Disable JS and complete every critical flow (create, list, delete).</li>
<li><strong>HTMX visibility</strong>: In the browser console, run <code>htmx.logAll()</code> to see events.</li>
<li><strong>Headers</strong>: Confirm <code>HX-Request: true</code> in devtools for HTMX requests.</li>
<li><strong>Status codes</strong>: Use 200/302 for success; 422 for validation errors.</li>
<li><strong>cURL</strong>: Simulate HTMX:
<pre><code class="language-bash">curl -H "HX-Request: true" http://localhost:8080/tasks
</code></pre>
</li>
</ul>
<hr />
<h2 id="security-notes"><a class="header" href="#security-notes">Security notes</a></h2>
<ul>
<li><strong>CSRF</strong>: Include a CSRF token in all forms (double-submit cookie or server session token). HTMX will submit it like any other field.</li>
<li><strong>Method safety</strong>: Use proper HTTP verbs (GET is read‚Äëonly; POST/PUT/PATCH/DELETE mutate).</li>
<li><strong>Validation &amp; encoding</strong>: Validate inputs; encode all dynamic output in templates.</li>
</ul>
<hr />
<h2 id="performance-tips"><a class="header" href="#performance-tips">Performance tips</a></h2>
<ul>
<li>Keep fragments <strong>small</strong> and <strong>cacheable</strong> where appropriate.</li>
<li>Avoid sending large JSON blobs. Send just the HTML you need.</li>
<li>Consider <strong>ETags/Last‚ÄëModified</strong> for GET endpoints with expensive renders.</li>
</ul>
<hr />
<h2 id="common-antipatterns-avoid"><a class="header" href="#common-antipatterns-avoid">Common anti‚Äëpatterns (avoid)</a></h2>
<ul>
<li>‚ùå Two separate apps (SPA + API) for simple CRUD‚Äîoverkill here.</li>
<li>‚ùå Client‚Äëside validation only‚Äîexcludes customers and risks bad data.</li>
<li>‚ùå Hidden, fragile UI state that the server doesn‚Äôt know about.</li>
<li>‚ùå POST responses that render success pages without redirects (breaks back/refresh).</li>
</ul>
<hr />
<h2 id="make-it-real-checklist-for-your-lab"><a class="header" href="#make-it-real-checklist-for-your-lab">‚ÄúMake it real‚Äù checklist for your lab</a></h2>
<ol>
<li>Build the <strong>list</strong> + <strong>create</strong> flows using the patterns above.</li>
<li>Add <strong>inline validation</strong> and a <strong>flash</strong> region.</li>
<li>Prove <strong>no‚ÄëJS parity</strong> by completing the flow with JS turned off.</li>
<li>Add one <strong>OOB update</strong> (e.g., flash, count badge).</li>
<li>Write a <strong>one‚Äëpage test plan</strong>: steps, expected results, and screenshots.</li>
</ol>
<hr />
<h2 id="appendix-tiny-helper-ktor"><a class="header" href="#appendix-tiny-helper-ktor">Appendix: tiny helper (Ktor)</a></h2>
<pre><code class="language-kotlin">fun ApplicationCall.isHtmx() = request.headers["HX-Request"] == "true"
</code></pre>
<p>Use <code>if (call.isHtmx()) renderPartial(...) else renderPage(...)</code> to keep controllers tidy.</p>
<hr />
<h3 id="final-thought"><a class="header" href="#final-thought">Final thought</a></h3>
<p><strong>Server‚Äëfirst ‚â† anti‚ÄëJavaScript.</strong> It‚Äôs about choosing HTML as the reliable baseline, then layering interaction where it genuinely improves the experience. You‚Äôll build features faster, with fewer bugs, and everyone‚Äîincluding people navigating with assistive tech‚Äîbenefits.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="serverfirst-in-github-codespaces-ktor--htmx"><a class="header" href="#serverfirst-in-github-codespaces-ktor--htmx">Server‚ÄëFirst in GitHub Codespaces (Ktor + HTMX)</a></h1>
<p>This guide shows how to run the <strong>server‚Äëfirst</strong> pattern in <strong>GitHub Codespaces</strong> with <strong>Ktor</strong> and <strong>HTMX</strong>. It includes a minimal devcontainer, project skeleton, and common fixes.</p>
<hr />
<h2 id="what-youll-get"><a class="header" href="#what-youll-get">What you‚Äôll get</a></h2>
<ul>
<li>One‚Äëclick Codespaces environment (JDK 21 + Gradle).</li>
<li>Ktor server bound to <code>0.0.0.0</code>, using <code>$PORT</code> or <code>8080</code>.</li>
<li>FreeMarker templating (official Ktor support) with HTMX for progressive enhancement.</li>
<li>Works with JavaScript <strong>off</strong> (no‚ÄëJS parity).</li>
</ul>
<hr />
<h2 id="1-devcontainerdevcontainerjson"><a class="header" href="#1-devcontainerdevcontainerjson">1) <code>.devcontainer/devcontainer.json</code></a></h2>
<pre><code class="language-json">{
  "name": "COMP2850 Ktor (server-first)",
  "build": { "dockerfile": "Dockerfile" },
  "forwardPorts": [8080],
  "portsAttributes": {
    "8080": { "label": "Ktor app", "onAutoForward": "openPreview" }
  },
  "postCreateCommand": "chmod +x ./gradlew || true",
  "customizations": {
    "vscode": {
      "extensions": [
        "vscjava.vscode-java-pack",
        "fwcd.kotlin",
        "redhat.vscode-yaml",
        "editorconfig.editorconfig"
      ]
    }
  }
}
</code></pre>
<h2 id="2-devcontainerdockerfile"><a class="header" href="#2-devcontainerdockerfile">2) <code>.devcontainer/Dockerfile</code></a></h2>
<pre><code class="language-dockerfile">FROM mcr.microsoft.com/devcontainers/java:1-21-bullseye

# Optional: Gradle cache to speed up builds
ENV GRADLE_USER_HOME=/workspace/.gradle
</code></pre>
<h2 id="3-buildgradlekts-essentials"><a class="header" href="#3-buildgradlekts-essentials">3) <code>build.gradle.kts</code> (essentials)</a></h2>
<p>Uses <strong>Ktor 2.x + Netty + FreeMarker</strong> for smooth Codespaces support.</p>
<pre><code class="language-kotlin">plugins {
    application
    kotlin("jvm") version "2.0.0"
    id("io.ktor.plugin") version "2.3.11"
}

repositories { mavenCentral() }

val ktorVersion = "2.3.11"

dependencies {
    implementation("io.ktor:ktor-server-core-jvm:$ktorVersion")
    implementation("io.ktor:ktor-server-netty-jvm:$ktorVersion")
    implementation("io.ktor:ktor-server-freemarker-jvm:$ktorVersion")
    implementation("ch.qos.logback:logback-classic:1.4.14")

    testImplementation(kotlin("test"))
    testImplementation("io.ktor:ktor-server-tests-jvm:$ktorVersion")
}

application {
    mainClass.set("MainKt")
}

tasks.withType&lt;JavaExec&gt; {
    systemProperty("io.ktor.development", "true")
}
</code></pre>
<h2 id="4-srcmainkotlinmainkt"><a class="header" href="#4-srcmainkotlinmainkt">4) <code>src/main/kotlin/Main.kt</code></a></h2>
<pre><code class="language-kotlin">import io.ktor.server.application.*
import io.ktor.server.engine.*
import io.ktor.server.netty.*
import io.ktor.server.response.*
import io.ktor.server.request.*
import io.ktor.server.routing.*
import io.ktor.server.freemarker.*
import io.ktor.server.plugins.contentnegotiation.*
import io.ktor.http.*
import freemarker.cache.ClassTemplateLoader

fun main() {
    val port = System.getenv("PORT")?.toIntOrNull() ?: 8080
    embeddedServer(Netty, port = port, host = "0.0.0.0") {
        module()
    }.start(wait = true)
}

fun Application.module() {
    install(FreeMarker) {
        templateLoader = ClassTemplateLoader(this::class.java.classLoader, "templates")
    }
    install(ContentNegotiation)

    routing {
        get("/") {
            // Full-page render (server-first)
            call.respond(FreeMarkerContent("tasks.ftl", mapOf("tasks" to listOf("Example task"))))
        }

        post("/tasks") {
            val params = call.receiveParameters()
            val title = params["title"]?.trim().orEmpty()
            if (title.isBlank()) {
                // 422 for HTMX validation errors; full page flow would re-render with errors
                call.respond(HttpStatusCode.UnprocessableEntity, "Title is required")
                return@post
            }
            // PRG for full-page; for HTMX you can return a fragment or tell HTMX to redirect
            call.response.headers.append("HX-Redirect", "/")
            call.respond(HttpStatusCode.OK)
        }
    }
}
</code></pre>
<h2 id="5-srcmainresourcestemplatestasksftl-full-page--htmx"><a class="header" href="#5-srcmainresourcestemplatestasksftl-full-page--htmx">5) <code>src/main/resources/templates/tasks.ftl</code> (full page + HTMX)</a></h2>
<pre><code class="language-html">&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
  &lt;meta charset="utf-8"&gt;
  &lt;title&gt;Tasks&lt;/title&gt;
  &lt;script src="https://unpkg.com/htmx.org@1.9.10"&gt;&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
  &lt;main&gt;
    &lt;h1&gt;Tasks&lt;/h1&gt;

    &lt;section aria-live="polite" id="alerts"&gt;&lt;/section&gt;

    &lt;form action="/tasks" method="post"
          hx-post="/tasks"
          hx-target="#alerts"
          hx-swap="innerHTML"&gt;
      &lt;label for="title"&gt;Title&lt;/label&gt;
      &lt;input id="title" name="title" required&gt;
      &lt;button type="submit"&gt;Add&lt;/button&gt;
    &lt;/form&gt;

    &lt;ul&gt;
      &lt;#list tasks as t&gt;
        &lt;li&gt;${t}&lt;/li&gt;
      &lt;/#list&gt;
    &lt;/ul&gt;
  &lt;/main&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<hr />
<h2 id="6-how-to-run-in-codespaces"><a class="header" href="#6-how-to-run-in-codespaces">6) How to run in Codespaces</a></h2>
<ol>
<li>Open the repo in Codespaces (with the <code>.devcontainer</code> files present).</li>
<li>In the terminal, run:
<pre><code class="language-bash">./gradlew run
</code></pre>
</li>
<li>Codespaces will auto‚Äëforward <strong>port 8080</strong> and open a preview. If not, open the <strong>Ports</strong> tab and make port 8080 <strong>Public</strong> or click the forwarded URL.</li>
</ol>
<hr />
<h2 id="7-common-gotchas-fix-quickly"><a class="header" href="#7-common-gotchas-fix-quickly">7) Common gotchas (fix quickly)</a></h2>
<ul>
<li><strong>Bind host</strong> to <code>0.0.0.0</code> (not <code>localhost</code>), or Codespaces can‚Äôt reach it.</li>
<li><strong>Use <code>$PORT</code></strong> if Codespaces provides one; default to 8080 otherwise.</li>
<li><strong>Official templates</strong>: stick to FreeMarker/Thymeleaf/Mustache/Velocity to reduce surprises.</li>
<li><strong>Fragments vs pages</strong>: HTMX sends <code>HX-Request: true</code>; branch accordingly if you add fragment routes.</li>
<li><strong>Live reload</strong>: <code>-Dio.ktor.development=true</code> is enabled via Gradle task config.</li>
</ul>
<hr />
<h2 id="8-optional-enhancements"><a class="header" href="#8-optional-enhancements">8) Optional enhancements</a></h2>
<ul>
<li><strong><code>hx-boost="true"</code></strong> to progressively enhance links/forms without changing routes.</li>
<li><strong>OOB updates</strong> (<code>hx-swap-oob</code>) for global banners like flash messages.</li>
<li><strong>Accessibility checks</strong>: keyboard‚Äëonly test, visible focus, labelled inputs, <code>aria-live</code> for status.</li>
<li><strong>cURL HTMX</strong>:
<pre><code class="language-bash">curl -H "HX-Request: true" http://localhost:8080/
</code></pre>
</li>
</ul>
<hr />
<h2 id="9-suggested-repo-structure"><a class="header" href="#9-suggested-repo-structure">9) Suggested repo structure</a></h2>
<pre><code>.
‚îú‚îÄ .devcontainer/
‚îÇ  ‚îú‚îÄ Dockerfile
‚îÇ  ‚îî‚îÄ devcontainer.json
‚îú‚îÄ src/
‚îÇ  ‚îú‚îÄ main/
‚îÇ  ‚îÇ  ‚îú‚îÄ kotlin/
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ Main.kt
‚îÇ  ‚îÇ  ‚îî‚îÄ resources/
‚îÇ  ‚îÇ     ‚îî‚îÄ templates/
‚îÇ  ‚îÇ        ‚îî‚îÄ tasks.ftl
‚îú‚îÄ build.gradle.kts
‚îî‚îÄ settings.gradle.kts
</code></pre>
<hr />
<div style="break-before: page; page-break-before: always;"></div><h1 id="pebble-templates-in-comp2850"><a class="header" href="#pebble-templates-in-comp2850">Pebble templates in COMP2850</a></h1>
<h2 id="what-is-pebble"><a class="header" href="#what-is-pebble">What is Pebble?</a></h2>
<p>Pebble is a lightweight HTML templating engine for the JVM. It takes plain text files (usually HTML) and replaces expressions, loops, and conditionals using the data you pass from Kotlin. Pebble renders on the server, so the browser receives fully formed HTML that works even when JavaScript is disabled.</p>
<h2 id="why-we-use-pebble"><a class="header" href="#why-we-use-pebble">Why we use Pebble</a></h2>
<ul>
<li>Server-first philosophy: we can build complete, accessible HTML before any enhancement.</li>
<li>Safe by default: output is escaped unless you explicitly mark it as safe, which reduces XSS risks.</li>
<li>Familiar syntax: Jinja- or Twig-style blocks (<code>{% %}</code>) and expressions (<code>{{ }}</code>) keep the learning curve gentle.</li>
<li>Layouts and partials: <code>extends</code>, <code>block</code>, and <code>include</code> let us reuse structure and enforce consistency.</li>
<li>No build tooling required: templates are plain files in <code>resources/templates/</code> so they work on RHEL lab machines and Codespaces without extra setup.</li>
</ul>
<h2 id="mental-model"><a class="header" href="#mental-model">Mental model</a></h2>
<ol>
<li>Ktor gathers or builds the data (for example <code>tasks: List&lt;Task&gt;</code>).</li>
<li>We call <code>PebbleRender.render("tasks/index.peb", model)</code> to render HTML as a string.</li>
<li>Ktor sends that HTML to the browser. HTMX can then request fragments of the same templates.</li>
</ol>
<p>Because rendering is server-side, keyboard-only usage, screen readers, and automated auditing tools get identical
content to the HTMX-enhanced version.</p>
<h2 id="syntax-common-examples"><a class="header" href="#syntax-common-examples">Syntax common examples</a></h2>
<pre><code class="language-pebble">{% extends "base.peb" %}
{% block content %}
  &lt;h1&gt;{{ title }}&lt;/h1&gt;
  &lt;ul&gt;
    {% for task in tasks %}
      &lt;li&gt;{{ task.title }}&lt;/li&gt;
    {% endfor %}
  &lt;/ul&gt;
{% endblock %}
</code></pre>
<ul>
<li><code>{% ... %}</code>: control structures (extends, block, if, for).</li>
<li><code>{{ ... }}</code>: output an expression; values are HTML-escaped automatically.</li>
<li><code>{# ... #}</code>: comments; they do not appear in the rendered output.</li>
</ul>
<h2 id="layouts-and-includes"><a class="header" href="#layouts-and-includes">Layouts and includes</a></h2>
<ul>
<li>Define shared chrome in <code>base.peb</code> and expose replaceable sections with <code>{% block %}</code>.</li>
<li>Pull reusable fragments into separate files and include them:
<pre><code class="language-pebble">{% include "tasks/item.peb" with task=task %}
</code></pre>
</li>
<li>Because includes are just files, we can create patterns like <code>_list.peb</code>, <code>_status.peb</code>, and <code>_pager.peb</code> once and reuse them across weeks.</li>
</ul>
<h2 id="passing-data-from-ktor"><a class="header" href="#passing-data-from-ktor">Passing data from Ktor</a></h2>
<pre><code class="language-kotlin">val model = mapOf(
    "title" to "Tasks",
    "tasks" to repo.all()
)
call.respondHtml(PebbleRender.render("tasks/index.peb", model))
</code></pre>
<p>Pebble sees the keys of the model map as variables in the template. Use descriptive names and prefer simple DTOs or immutable data to keep templates readable.</p>
<h2 id="friendliness-with-htmx-and-accessibility"><a class="header" href="#friendliness-with-htmx-and-accessibility">Friendliness with HTMX and accessibility</a></h2>
<ul>
<li>HTMX requests hit the same templates; we often render a partial (for example the <code>&lt;li&gt;</code> fragment) and return it.</li>
<li>Live regions (<code>role="status"</code>) live in <code>base.peb</code>, so every page automatically announces status updates.</li>
<li>Because Pebble renders semantic HTML, WCAG checks and screen readers work irrespective of JavaScript state.</li>
</ul>
<h2 id="debug-tips"><a class="header" href="#debug-tips">Debug tips</a></h2>
<ul>
<li>Pebble line numbers appear in stack traces. If you see <code>Line 24, Column 10</code>, open that template and check the expression.</li>
<li>When nothing renders, confirm the template path matches the file name and that you passed the expected keys in the model map.</li>
<li>To inspect the final HTML, view source in the browser or log the rendered string locally.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="pebble-template-engine-cheatsheet"><a class="header" href="#pebble-template-engine-cheatsheet">Pebble Template Engine Cheatsheet</a></h1>
<p><strong>Quick reference for COMP2850 HCI students</strong></p>
<hr />
<h2 id="1-basic-syntax"><a class="header" href="#1-basic-syntax">1. Basic Syntax</a></h2>
<h3 id="three-types-of-delimiters"><a class="header" href="#three-types-of-delimiters">Three Types of Delimiters</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Delimiter</th><th>Purpose</th><th>Example</th></tr></thead><tbody>
<tr><td><code>{{ }}</code></td><td><strong>Output</strong> - Print expressions</td><td><code>{{ task.title }}</code></td></tr>
<tr><td><code>{% %}</code></td><td><strong>Tags/Logic</strong> - Control flow</td><td><code>{% if completed %}...{% endif %}</code></td></tr>
<tr><td><code>{# #}</code></td><td><strong>Comments</strong> - Not rendered</td><td><code>{# TODO: Add pagination #}</code></td></tr>
</tbody></table>
</div>
<hr />
<h2 id="2-variables--output"><a class="header" href="#2-variables--output">2. Variables &amp; Output</a></h2>
<h3 id="simple-variables"><a class="header" href="#simple-variables">Simple Variables</a></h3>
<pre><code class="language-pebble">{{ taskTitle }}           {# Outputs: "Buy Groceries" #}
{{ taskCount }}           {# Outputs: 5 #}
{{ isCompleted }}         {# Outputs: true or false #}
</code></pre>
<h3 id="object-properties-dot-notation"><a class="header" href="#object-properties-dot-notation">Object Properties (Dot Notation)</a></h3>
<pre><code class="language-pebble">{{ task.id }}             {# Accesses task object's id property #}
{{ task.title }}          {# Accesses task object's title property #}
{{ task.createdAt }}      {# Accesses task object's createdAt property #}
</code></pre>
<h3 id="accessing-maps-from-kotlin"><a class="header" href="#accessing-maps-from-kotlin">Accessing Maps (from Kotlin)</a></h3>
<pre><code class="language-kotlin">// In Kotlin route:
mapOf("task" to task.toPebbleContext())

// In Pebble template:
{{ task.id }}             {# Accesses map key "id" #}
{{ task.completed }}      {# Accesses map key "completed" #}
</code></pre>
<hr />
<h2 id="3-filters-pipe-syntax"><a class="header" href="#3-filters-pipe-syntax">3. Filters (Pipe Syntax)</a></h2>
<p>Filters transform output values using the pipe <code>|</code> operator.</p>
<h3 id="common-filters"><a class="header" href="#common-filters">Common Filters</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Filter</th><th>Purpose</th><th>Example</th><th>Output</th></tr></thead><tbody>
<tr><td><code>length</code></td><td>Get collection size</td><td><code>{{ tasks | length }}</code></td><td><code>5</code></td></tr>
<tr><td><code>upper</code></td><td>Uppercase</td><td><code>{{ title | upper }}</code></td><td><code>"BUY GROCERIES"</code></td></tr>
<tr><td><code>lower</code></td><td>Lowercase</td><td><code>{{ title | lower }}</code></td><td><code>"buy groceries"</code></td></tr>
<tr><td><code>capitalise</code></td><td>Capitalise first letter</td><td><code>{{ status | capitalize }}</code></td><td><code>"Complete"</code></td></tr>
<tr><td><code>escape</code></td><td>HTML escape (auto in Pebble)</td><td><code>{{ userInput | escape }}</code></td><td><code>&amp;lt;script&amp;gt;</code></td></tr>
<tr><td><code>default</code></td><td>Fallback if null/empty</td><td><code>{{ title | default("Untitled") }}</code></td><td><code>"Untitled"</code> if title is null</td></tr>
<tr><td><code>date</code></td><td>Format date</td><td><code>{{ createdAt | date("yyyy-MM-dd") }}</code></td><td><code>"2025-10-14"</code></td></tr>
<tr><td><code>trim</code></td><td>Remove whitespace</td><td><code>{{ title | trim }}</code></td><td><code>"Buy groceries"</code> (no spaces)</td></tr>
</tbody></table>
</div>
<h3 id="chaining-filters"><a class="header" href="#chaining-filters">Chaining Filters</a></h3>
<pre><code class="language-pebble">{{ task.title | lower | capitalize }}
{# "buy groceries" ‚Üí "Buy groceries" #}

{{ tasks | length | default(0) }}
{# If tasks is null, output 0 #}
</code></pre>
<hr />
<h2 id="4-control-flow"><a class="header" href="#4-control-flow">4. Control Flow</a></h2>
<h3 id="if--else"><a class="header" href="#if--else">If / Else</a></h3>
<pre><code class="language-pebble">{% if task.completed %}
  &lt;span class="completed"&gt;‚úì Done&lt;/span&gt;
{% else %}
  &lt;span class="pending"&gt;Pending&lt;/span&gt;
{% endif %}
</code></pre>
<h3 id="if--elseif--else"><a class="header" href="#if--elseif--else">If / ElseIf / Else</a></h3>
<pre><code class="language-pebble">{% if taskCount == 0 %}
  &lt;p&gt;No tasks yet.&lt;/p&gt;
{% elseif taskCount == 1 %}
  &lt;p&gt;You have 1 task.&lt;/p&gt;
{% else %}
  &lt;p&gt;You have {{ taskCount }} tasks.&lt;/p&gt;
{% endif %}
</code></pre>
<h3 id="comparison-operators"><a class="header" href="#comparison-operators">Comparison Operators</a></h3>
<pre><code class="language-pebble">{% if count &gt; 5 %}          {# Greater than #}
{% if count &gt;= 5 %}         {# Greater than or equal #}
{% if count &lt; 5 %}          {# Less than #}
{% if count &lt;= 5 %}         {# Less than or equal #}
{% if count == 5 %}         {# Equal (use ==, not =) #}
{% if count != 5 %}         {# Not equal #}
</code></pre>
<h3 id="logical-operators"><a class="header" href="#logical-operators">Logical Operators</a></h3>
<pre><code class="language-pebble">{% if completed and visible %}           {# AND #}
{% if completed or visible %}            {# OR #}
{% if not completed %}                   {# NOT #}
{% if (a or b) and (c or d) %}          {# Grouping with () #}
</code></pre>
<h3 id="checking-for-nullempty"><a class="header" href="#checking-for-nullempty">Checking for Null/Empty</a></h3>
<pre><code class="language-pebble">{% if tasks is null %}                   {# Is null #}
{% if tasks is not null %}               {# Is not null #}
{% if tasks is empty %}                  {# Is null or empty collection #}
{% if title is defined %}                {# Variable exists #}
</code></pre>
<hr />
<h2 id="5-loops-for"><a class="header" href="#5-loops-for">5. Loops (For)</a></h2>
<h3 id="basic-for-loop"><a class="header" href="#basic-for-loop">Basic For Loop</a></h3>
<pre><code class="language-pebble">&lt;ul&gt;
  {% for task in tasks %}
    &lt;li&gt;{{ task.title }}&lt;/li&gt;
  {% endfor %}
&lt;/ul&gt;
</code></pre>
<h3 id="for-loop-with-empty-fallback"><a class="header" href="#for-loop-with-empty-fallback">For Loop with Empty Fallback</a></h3>
<pre><code class="language-pebble">&lt;ul&gt;
  {% for task in tasks %}
    &lt;li&gt;{{ task.title }}&lt;/li&gt;
  {% empty %}
    &lt;li&gt;No tasks to display.&lt;/li&gt;
  {% endfor %}
&lt;/ul&gt;
</code></pre>
<h3 id="loop-variables-special-properties"><a class="header" href="#loop-variables-special-properties">Loop Variables (Special Properties)</a></h3>
<p>Inside a <code>{% for %}</code> loop, you have access to special <code>loop</code> variables:</p>
<div class="table-wrapper"><table><thead><tr><th>Variable</th><th>Description</th><th>Example Value</th></tr></thead><tbody>
<tr><td><code>loop.index</code></td><td>Current iteration (1-based)</td><td><code>1, 2, 3, ...</code></td></tr>
<tr><td><code>loop.index0</code></td><td>Current iteration (0-based)</td><td><code>0, 1, 2, ...</code></td></tr>
<tr><td><code>loop.revindex</code></td><td>Iterations remaining (1-based)</td><td><code>5, 4, 3, ...</code></td></tr>
<tr><td><code>loop.revindex0</code></td><td>Iterations remaining (0-based)</td><td><code>4, 3, 2, ...</code></td></tr>
<tr><td><code>loop.first</code></td><td>True if first iteration</td><td><code>true</code> or <code>false</code></td></tr>
<tr><td><code>loop.last</code></td><td>True if last iteration</td><td><code>true</code> or <code>false</code></td></tr>
<tr><td><code>loop.length</code></td><td>Total number of items</td><td><code>5</code></td></tr>
</tbody></table>
</div>
<p><strong>Example</strong>:</p>
<pre><code class="language-pebble">{% for task in tasks %}
  &lt;li class="{% if loop.first %}first{% endif %} {% if loop.last %}last{% endif %}"&gt;
    {{ loop.index }}. {{ task.title }}
  &lt;/li&gt;
{% endfor %}
</code></pre>
<p>Output:</p>
<pre><code class="language-html">&lt;li class="first"&gt;1. Buy groceries&lt;/li&gt;
&lt;li&gt;2. Pay bills&lt;/li&gt;
&lt;li class="last"&gt;3. Call dentist&lt;/li&gt;
</code></pre>
<hr />
<h2 id="6-template-inheritance"><a class="header" href="#6-template-inheritance">6. Template Inheritance</a></h2>
<h3 id="base-template-_layoutbasepeb"><a class="header" href="#base-template-_layoutbasepeb">Base Template (<code>_layout/base.peb</code>)</a></h3>
<pre><code class="language-pebble">&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
  &lt;title&gt;{% block title %}Default Title{% endblock %}&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
  &lt;header&gt;
    &lt;h1&gt;Task Manager&lt;/h1&gt;
  &lt;/header&gt;

  &lt;main&gt;
    {% block content %}
      {# Default content if child doesn't override #}
    {% endblock %}
  &lt;/main&gt;

  &lt;footer&gt;
    {% block footer %}
      &lt;p&gt;&amp;copy; 2025 COMP2850&lt;/p&gt;
    {% endblock %}
  &lt;/footer&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<h3 id="child-template-tasksindexpeb"><a class="header" href="#child-template-tasksindexpeb">Child Template (<code>tasks/index.peb</code>)</a></h3>
<pre><code class="language-pebble">{% extends "_layout/base.peb" %}

{% block title %}Task List{% endblock %}

{% block content %}
  &lt;h2&gt;Your Tasks&lt;/h2&gt;
  &lt;ul&gt;
    {% for task in tasks %}
      &lt;li&gt;{{ task.title }}&lt;/li&gt;
    {% endfor %}
  &lt;/ul&gt;
{% endblock %}
</code></pre>
<p><strong>Result</strong>: Child template inherits base layout, overrides <code>title</code> and <code>content</code> blocks.</p>
<hr />
<h2 id="7-including-partials"><a class="header" href="#7-including-partials">7. Including Partials</a></h2>
<h3 id="include-without-parameters"><a class="header" href="#include-without-parameters">Include Without Parameters</a></h3>
<pre><code class="language-pebble">{% include "tasks/_item.peb" %}
</code></pre>
<h3 id="include-with-parameters"><a class="header" href="#include-with-parameters">Include With Parameters</a></h3>
<pre><code class="language-pebble">{% for task in tasks %}
  {% include "tasks/_item.peb" with {"task": task} %}
{% endfor %}
</code></pre>
<h3 id="include-with-override-pass-specific-variables"><a class="header" href="#include-with-override-pass-specific-variables">Include With Override (Pass Specific Variables)</a></h3>
<pre><code class="language-pebble">{% include "tasks/_list.peb" with {"tasks": completedTasks, "heading": "Completed Tasks"} %}
</code></pre>
<p><strong>Note</strong>: <code>with</code> creates a new scope. Only variables explicitly passed are available in the included template.</p>
<hr />
<h2 id="8-comp2850-specific-patterns"><a class="header" href="#8-comp2850-specific-patterns">8. COMP2850-Specific Patterns</a></h2>
<h3 id="dual-mode-htmx-pattern"><a class="header" href="#dual-mode-htmx-pattern">Dual-Mode HTMX Pattern</a></h3>
<pre><code class="language-pebble">{# Full page vs partial detection #}
{% if isHtmx %}
  {# Return fragment only (no layout) #}
  {% include "tasks/_list.peb" %}
{% else %}
  {# Return full page (extends base) #}
  {% extends "_layout/base.peb" %}
  {% block content %}
    {% include "tasks/_list.peb" %}
  {% endblock %}
{% endif %}
</code></pre>
<h3 id="aria-live-region-status-announcements"><a class="header" href="#aria-live-region-status-announcements">ARIA Live Region (Status Announcements)</a></h3>
<pre><code class="language-pebble">&lt;div id="status" role="status" aria-live="polite" aria-atomic="true"&gt;
  {% if statusMessage %}
    {{ statusMessage }}
  {% endif %}
&lt;/div&gt;
</code></pre>
<h3 id="out-of-band-oob-updates"><a class="header" href="#out-of-band-oob-updates">Out-of-Band (OOB) Updates</a></h3>
<pre><code class="language-pebble">{# Update status region separately from main content #}
&lt;div id="status" hx-swap-oob="true" role="alert"&gt;
  Task "{{ task.title }}" added successfully!
&lt;/div&gt;

{# Main content also returned in same response #}
&lt;li id="task-{{ task.id }}"&gt;
  {{ task.title }}
&lt;/li&gt;
</code></pre>
<h3 id="task-list-with-accessibility"><a class="header" href="#task-list-with-accessibility">Task List with Accessibility</a></h3>
<pre><code class="language-pebble">&lt;ul id="task-list" aria-describedby="task-count"&gt;
  {% for task in tasks %}
    &lt;li id="task-{{ task.id }}"&gt;
      &lt;span&gt;{{ task.title }}&lt;/span&gt;
      &lt;form action="/tasks/{{ task.id }}/delete" method="post" style="display:inline;"&gt;
        &lt;button type="submit" aria-label="Delete task: {{ task.title }}"&gt;Delete&lt;/button&gt;
      &lt;/form&gt;
    &lt;/li&gt;
  {% empty %}
    &lt;li&gt;No tasks yet. Add one above!&lt;/li&gt;
  {% endfor %}
&lt;/ul&gt;
&lt;p id="task-count" class="visually-hidden"&gt;
  Showing {{ tasks | length }} tasks.
&lt;/p&gt;
</code></pre>
<hr />
<h2 id="9-common-mistakes--solutions"><a class="header" href="#9-common-mistakes--solutions">9. Common Mistakes &amp; Solutions</a></h2>
<h3 id="-wrong-using--for-comparison"><a class="header" href="#-wrong-using--for-comparison">‚ùå Wrong: Using <code>=</code> for Comparison</a></h3>
<pre><code class="language-pebble">{% if count = 5 %}  {# WRONG: Use == #}
</code></pre>
<h3 id="-right-use-"><a class="header" href="#-right-use-">‚úÖ Right: Use <code>==</code></a></h3>
<pre><code class="language-pebble">{% if count == 5 %}  {# CORRECT #}
</code></pre>
<hr />
<h3 id="-wrong-missing-quotes-in-strings"><a class="header" href="#-wrong-missing-quotes-in-strings">‚ùå Wrong: Missing Quotes in Strings</a></h3>
<pre><code class="language-pebble">{% if status == completed %}  {# WRONG: 'completed' is a variable #}
</code></pre>
<h3 id="-right-quote-string-literals"><a class="header" href="#-right-quote-string-literals">‚úÖ Right: Quote String Literals</a></h3>
<pre><code class="language-pebble">{% if status == "completed" %}  {# CORRECT: String literal #}
</code></pre>
<hr />
<h3 id="-wrong-accessing-undefined-variables"><a class="header" href="#-wrong-accessing-undefined-variables">‚ùå Wrong: Accessing Undefined Variables</a></h3>
<pre><code class="language-pebble">{{ user.name }}  {# ERROR if user is null #}
</code></pre>
<h3 id="-right-use-default-filter"><a class="header" href="#-right-use-default-filter">‚úÖ Right: Use Default Filter</a></h3>
<pre><code class="language-pebble">{{ user.name | default("Guest") }}  {# Safe: Returns "Guest" if null #}
</code></pre>
<hr />
<h3 id="-wrong-forgetting-endfor--endif"><a class="header" href="#-wrong-forgetting-endfor--endif">‚ùå Wrong: Forgetting <code>endfor</code> / <code>endif</code></a></h3>
<pre><code class="language-pebble">{% for task in tasks %}
  &lt;li&gt;{{ task.title }}&lt;/li&gt;
{# WRONG: Missing {% endfor %} #}
</code></pre>
<h3 id="-right-always-close-tags"><a class="header" href="#-right-always-close-tags">‚úÖ Right: Always Close Tags</a></h3>
<pre><code class="language-pebble">{% for task in tasks %}
  &lt;li&gt;{{ task.title }}&lt;/li&gt;
{% endfor %}  {# CORRECT #}
</code></pre>
<hr />
<h3 id="-wrong-using---for-output"><a class="header" href="#-wrong-using---for-output">‚ùå Wrong: Using <code>{% %}</code> for Output</a></h3>
<pre><code class="language-pebble">{% task.title %}  {# WRONG: Use {{ }} for output #}
</code></pre>
<h3 id="-right-use--"><a class="header" href="#-right-use--">‚úÖ Right: Use <code>{{ }}</code></a></h3>
<pre><code class="language-pebble">{{ task.title }}  {# CORRECT #}
</code></pre>
<hr />
<h2 id="10-debugging-tips"><a class="header" href="#10-debugging-tips">10. Debugging Tips</a></h2>
<h3 id="check-variable-type"><a class="header" href="#check-variable-type">Check Variable Type</a></h3>
<pre><code class="language-pebble">{# Temporarily output variable to see what it contains #}
&lt;pre&gt;{{ task }}&lt;/pre&gt;
</code></pre>
<h3 id="check-if-variable-exists"><a class="header" href="#check-if-variable-exists">Check If Variable Exists</a></h3>
<pre><code class="language-pebble">{% if task is defined %}
  Task exists: {{ task.title }}
{% else %}
  Task is undefined!
{% endif %}
</code></pre>
<h3 id="view-loop-variables"><a class="header" href="#view-loop-variables">View Loop Variables</a></h3>
<pre><code class="language-pebble">{% for task in tasks %}
  &lt;p&gt;Index: {{ loop.index }}, First: {{ loop.first }}, Last: {{ loop.last }}&lt;/p&gt;
{% endfor %}
</code></pre>
<h3 id="escape-html-to-see-raw-output"><a class="header" href="#escape-html-to-see-raw-output">Escape HTML to See Raw Output</a></h3>
<pre><code class="language-pebble">&lt;pre&gt;{{ task.title | escape }}&lt;/pre&gt;
</code></pre>
<hr />
<h2 id="11-pebble-vs-other-template-engines"><a class="header" href="#11-pebble-vs-other-template-engines">11. Pebble vs Other Template Engines</a></h2>
<p>If you‚Äôve used other template engines, here‚Äôs a quick comparison:</p>
<div class="table-wrapper"><table><thead><tr><th>Feature</th><th>Pebble</th><th>Thymeleaf</th><th>FreeMarker</th></tr></thead><tbody>
<tr><td>Variables</td><td><code>{{ var }}</code></td><td><code>${var}</code></td><td><code>${var}</code></td></tr>
<tr><td>If statement</td><td><code>{% if %}</code></td><td><code>th:if</code></td><td><code>&lt;#if&gt;</code></td></tr>
<tr><td>For loop</td><td><code>{% for %}</code></td><td><code>th:each</code></td><td><code>&lt;#list&gt;</code></td></tr>
<tr><td>Comments</td><td><code>{# #}</code></td><td><code>&lt;!--/* */--&gt;</code></td><td><code>&lt;#-- --&gt;</code></td></tr>
<tr><td>Inheritance</td><td><code>{% extends %}</code></td><td><code>th:replace</code></td><td><code>&lt;#include&gt;</code></td></tr>
</tbody></table>
</div>
<hr />
<h2 id="12-resources"><a class="header" href="#12-resources">12. Resources</a></h2>
<h3 id="official-documentation"><a class="header" href="#official-documentation">Official Documentation</a></h3>
<ul>
<li><strong>Pebble Docs</strong>: https://pebbletemplates.io/</li>
<li><strong>Syntax Guide</strong>: https://pebbletemplates.io/wiki/guide/basic-usage/</li>
<li><strong>Filters Reference</strong>: https://pebbletemplates.io/wiki/filter/abs/</li>
</ul>
<h3 id="comp2850-specific"><a class="header" href="#comp2850-specific">COMP2850-Specific</a></h3>
<ul>
<li>Week 6 Lab 1: Pebble syntax primer (inline)</li>
<li><code>pebble-intro.md</code>: Longer introduction to Pebble</li>
</ul>
<h3 id="getting-help"><a class="header" href="#getting-help">Getting Help</a></h3>
<ul>
<li><strong>Syntax errors</strong>: Check matching tags (<code>{% if %}</code> needs <code>{% endif %}</code>)</li>
<li><strong>Variable undefined</strong>: Use <code>| default()</code> filter or check spelling</li>
<li><strong>Unexpected output</strong>: Use <code>&lt;pre&gt;{{ var }}&lt;/pre&gt;</code> to inspect variable</li>
</ul>
<hr />
<p><strong>Cheatsheet Version</strong>: 1.0
<strong>Last Updated</strong>: 2025-10-14
<strong>Module</strong>: COMP2850 HCI</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="htmx-patterns--progressive-enhancement"><a class="header" href="#htmx-patterns--progressive-enhancement">HTMX Patterns &amp; Progressive Enhancement</a></h1>
<h2 id="what-is-htmx"><a class="header" href="#what-is-htmx">What is HTMX?</a></h2>
<p><strong>HTMX</strong> is a JavaScript library that lets you build <strong>dynamic web interfaces</strong> using <strong>HTML attributes</strong> instead of writing JavaScript code. It extends HTML with attributes like <code>hx-get</code>, <code>hx-post</code>, <code>hx-target</code>, and <code>hx-swap</code> that trigger <a href="references/glossary.html#ajax">AJAX</a> requests and update parts of the page.</p>
<p><strong>Key idea</strong>: The server sends <strong><a href="references/glossary.html#fragment">HTML fragments</a></strong> (not <a href="references/glossary.html#json">JSON</a>), and HTMX swaps them into the page. You write normal HTML forms and links, add a few <code>hx-*</code> attributes, and suddenly they work dynamically without page reloads.</p>
<p><strong>Core text</strong>: <a href="https://hypermedia.systems/">Hypermedia Systems</a> by Carson Gross, Adam Stepinski, and Deniz Ak≈üim≈üek (2023) - read Chapters 1-6 for foundations.</p>
<h2 id="why-htmx-for-hci"><a class="header" href="#why-htmx-for-hci">Why HTMX for HCI?</a></h2>
<ol>
<li><strong><a href="references/glossary.html#accessibility">Accessibility</a> by default</strong> - Server controls HTML structure, ensuring <a href="references/glossary.html#semantic-html">semantic markup</a>, <a href="references/glossary.html#aria">ARIA</a> roles, and <a href="references/glossary.html#screen-reader">screen reader</a> compatibility</li>
<li><strong><a href="references/glossary.html#progressive-enhancement">Progressive enhancement</a></strong> - Everything works without JavaScript; HTMX enhances the experience when available</li>
<li><strong>Simplicity</strong> - No build tools, no client-side state management, no framework complexity</li>
<li><strong><a href="references/glossary.html#hypermedia">Hypermedia</a>-driven</strong> - Follows <a href="references/glossary.html#rest">REST</a>/<a href="references/glossary.html#hateoas">HATEOAS</a> principles - the server tells the client what to display (HTML) and what actions are available (links/forms)</li>
</ol>
<h2 id="how-it-works"><a class="header" href="#how-it-works">How it works</a></h2>
<ol>
<li><strong>Human interaction</strong> - Click a button, submit a form, type in a search box</li>
<li><strong>HTMX sends AJAX request</strong> - Adds <code>HX-Request: true</code> <a href="references/glossary.html#request-headers">header</a> so server knows it‚Äôs AJAX</li>
<li><strong>Server responds with HTML</strong> - Returns a <a href="references/glossary.html#fragment">fragment</a> (e.g., <code>&lt;li&gt;New item&lt;/li&gt;</code>) not a full page</li>
<li><strong>HTMX swaps the fragment</strong> - Updates the target element (append, replace, etc.)</li>
<li><strong>Screen readers announce</strong> - <a href="references/glossary.html#aria-live-region">ARIA live regions</a> announce changes automatically</li>
</ol>
<p><strong>Example</strong>:</p>
<pre><code class="language-html">&lt;button hx-get="/tasks/123" hx-target="#content"&gt;Load Task&lt;/button&gt;
</code></pre>
<ul>
<li>Click ‚Üí AJAX GET to <code>/tasks/123</code></li>
<li>Server returns HTML: <code>&lt;div&gt;Task details...&lt;/div&gt;</code></li>
<li>HTMX replaces <code>#content</code> with the response</li>
<li>No page reload, no JavaScript written by you</li>
</ul>
<h2 id="core-attributes"><a class="header" href="#core-attributes">Core Attributes</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Attribute</th><th>Purpose</th><th>Example</th></tr></thead><tbody>
<tr><td><code>hx-get</code></td><td>HTTP GET request</td><td><code>&lt;button hx-get="/tasks"&gt;</code></td></tr>
<tr><td><code>hx-post</code></td><td>HTTP POST request</td><td><code>&lt;form hx-post="/tasks"&gt;</code></td></tr>
<tr><td><code>hx-target</code></td><td>Where to insert response</td><td><code>hx-target="#task-list"</code></td></tr>
<tr><td><code>hx-swap</code></td><td>How to insert (replace/append/etc.)</td><td><code>hx-swap="beforeend"</code></td></tr>
<tr><td><code>hx-trigger</code></td><td>What event triggers request</td><td><code>hx-trigger="keyup changed delay:300ms"</code></td></tr>
<tr><td><code>hx-swap-oob</code></td><td>Update element outside target</td><td><code>&lt;div id="status" hx-swap-oob="true"&gt;</code></td></tr>
</tbody></table>
</div>
<h2 id="progressive-enhancement-pattern"><a class="header" href="#progressive-enhancement-pattern">Progressive Enhancement Pattern</a></h2>
<p>Every HTMX feature must have a <strong><a href="references/glossary.html#no-js-parity">no-JS fallback</a></strong>:</p>
<pre><code class="language-html">&lt;!-- Works WITHOUT JavaScript (full page POST-Redirect-GET) --&gt;
&lt;!-- Works WITH JavaScript (HTMX AJAX, fragment swap) --&gt;
&lt;form action="/tasks" method="post"
      hx-post="/tasks"
      hx-target="#task-list"
      hx-swap="beforeend"&gt;
  &lt;input name="title" required&gt;
  &lt;button type="submit"&gt;Add Task&lt;/button&gt;
&lt;/form&gt;
</code></pre>
<p><strong>Server detects HTMX</strong>:</p>
<pre><code class="language-kotlin">if (call.request.headers["HX-Request"] == "true") {
    // Return fragment for HTMX
    call.respondText("&lt;li&gt;New task&lt;/li&gt;", ContentType.Text.Html)
} else {
    // Return full page or redirect for no-JS
    call.respondRedirect("/tasks")
}
</code></pre>
<hr />
<h2 id="common-patterns"><a class="header" href="#common-patterns">Common Patterns</a></h2>
<p>Use these canonical patterns repeatedly across Weeks 6‚Äì10. Each snippet assumes the server exposes matching routes and keeps the no-JS fallback intact.</p>
<h2 id="1-active-search--filter"><a class="header" href="#1-active-search--filter">1. Active Search / Filter</a></h2>
<p><strong>üìñ Reference</strong>: <a href="https://hypermedia.systems/more-htmx-patterns/#_active_search">Hypermedia Systems, Ch. 6: More HTMX Patterns</a></p>
<p>Filter results as people type, with history support and a live status update.</p>
<pre><code class="language-html">&lt;form action="/tasks" method="get"
      hx-get="/tasks/fragment"
      hx-target="#task-area"
      hx-trigger="keyup changed delay:300ms, submit from:closest(form)"
      hx-push-url="true"&gt;
  &lt;label for="q"&gt;Filter tasks&lt;/label&gt;
  &lt;input id="q" name="q" type="search" aria-describedby="q-hint"&gt;
  &lt;small id="q-hint"&gt;Type to filter. Works without JavaScript.&lt;/small&gt;
  &lt;button type="submit"&gt;Apply&lt;/button&gt;
&lt;/form&gt;

&lt;div id="task-area" hx-indicator="#loading"&gt;
  &lt;progress id="loading" class="visually-hidden" aria-hidden="true"&gt;&lt;/progress&gt;
  {% include "tasks/_list.peb" %}
  {% include "tasks/_pager.peb" %}
&lt;/div&gt;
</code></pre>
<p>Server path (return list + pager + status when HX request):</p>
<pre><code class="language-kotlin">get("/tasks/fragment") {
    val q = call.request.queryParameters["q"].orEmpty()
    val page = call.request.queryParameters["page"]?.toIntOrNull() ?: 1
    val data = repo.search(q, page)
    val list = PebbleRender.render("tasks/_list.peb", mapOf("page" to data, "q" to q))
    val pager = PebbleRender.render("tasks/_pager.peb", mapOf("page" to data, "q" to q))
    val status = """&lt;div id="status" hx-swap-oob="true"&gt;Found ${data.total} tasks.&lt;/div&gt;"""
    call.respondText(list + pager + status, ContentType.Text.Html)
}
</code></pre>
<h2 id="2-oob-out-of-band-status-messages"><a class="header" href="#2-oob-out-of-band-status-messages">2. OOB (Out-of-Band) Status Messages</a></h2>
<p><strong>üìñ Reference</strong>: <a href="https://htmx.org/attributes/hx-swap-oob/">HTMX Docs: hx-swap-oob</a> | <a href="https://hypermedia.systems/hypermedia-on-the-web/#_practical_patterns">Hypermedia Systems, Ch. 9</a></p>
<p>Announce changes without touching focus.</p>
<pre><code class="language-html">&lt;p id="status" role="status" aria-live="polite" class="visually-hidden"&gt;&lt;/p&gt;
</code></pre>
<pre><code class="language-kotlin">val status = """&lt;div id="status" hx-swap-oob="true"&gt;Added "${task.title}".&lt;/div&gt;"""
call.respondText(fragment + status, ContentType.Text.Html)
</code></pre>
<h2 id="3-inline-edit-click-to-edit"><a class="header" href="#3-inline-edit-click-to-edit">3. Inline Edit (Click to Edit)</a></h2>
<p><strong>üìñ Reference</strong>: <a href="https://hypermedia.systems/htmx-patterns/#_click_to_edit">Hypermedia Systems, Ch. 5: HTMX Patterns</a></p>
<p>Swap a container after a PATCH-like request (inline editing).</p>
<pre><code class="language-html">&lt;form action="/tasks/{{ task.id }}/edit" method="post"
      hx-post="/tasks/{{ task.id }}/edit"
      hx-target="#task-{{ task.id }}"
      hx-swap="outerHTML"&gt;
  &lt;!-- label + input + button --&gt;
&lt;/form&gt;
</code></pre>
<h2 id="4-deferred-swap-after-swap-delay"><a class="header" href="#4-deferred-swap-after-swap-delay">4. Deferred Swap (after swap delay)</a></h2>
<p>Useful for optimistic UI (e.g. show success, then clear form).</p>
<pre><code class="language-html">&lt;div hx-target="this"
     hx-swap="outerHTML settle:1s"&gt;
  &lt;p class="success"&gt;Saved!&lt;/p&gt;
&lt;/div&gt;
</code></pre>
<h2 id="5-multi-target-updates"><a class="header" href="#5-multi-target-updates">5. Multi-target updates</a></h2>
<p>Use <code>hx-swap-oob</code> to update multiple DOM nodes from one response.</p>
<pre><code class="language-html">&lt;div id="summary" hx-swap-oob="true"&gt;‚Ä¶&lt;/div&gt;
&lt;li id="task-3"&gt;‚Ä¶&lt;/li&gt;
</code></pre>
<h2 id="6-indicators--disabled-states"><a class="header" href="#6-indicators--disabled-states">6. Indicators &amp; Disabled States</a></h2>
<pre><code class="language-html">&lt;form hx-post="/tasks" hx-target="#task-list" hx-disabled-elt="[data-disable]"&gt;
  &lt;button data-disable&gt;Save&lt;/button&gt;
  &lt;div class="spinner" hx-indicator&gt;&lt;/div&gt;
&lt;/form&gt;
</code></pre>
<h2 id="7-confirmcancel-actions"><a class="header" href="#7-confirmcancel-actions">7. Confirm/Cancel Actions</a></h2>
<pre><code class="language-html">&lt;button hx-delete="/tasks/{{ task.id }}"
        hx-target="#task-{{ task.id }}"
        hx-swap="outerHTML"
        hx-confirm="Delete this task?"&gt;
  Delete
&lt;/button&gt;
</code></pre>
<h2 id="8-lazy-loading"><a class="header" href="#8-lazy-loading">8. Lazy Loading</a></h2>
<p><strong>üìñ Reference</strong>: <a href="https://hypermedia.systems/more-htmx-patterns/#_lazy_loading">Hypermedia Systems, Ch. 6: More HTMX Patterns</a></p>
<p>Lazy load content</p>
<pre><code class="language-html">&lt;div hx-get="/tasks/details/{{ task.id }}"
     hx-trigger="revealed"&gt;
  Loading‚Ä¶
&lt;/div&gt;
</code></pre>
<p>Keep parity: every pattern must have a server-rendered fallback so the same request works without HTMX attributes present.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="worked-example--accessible-inline-edit-week-7-lab-2"><a class="header" href="#worked-example--accessible-inline-edit-week-7-lab-2">Worked Example ‚Äî Accessible Inline Edit (Week 7 Lab 2)</a></h1>
<h2 id="scenario"><a class="header" href="#scenario">Scenario</a></h2>
<p>Inline edit form for updating a task title.
Original implementation failed accessibility checks:</p>
<ul>
<li>No label tied to the input generated for editing</li>
<li>Error message appended visually but not announced</li>
<li>Focus jumped unexpectedly after save</li>
</ul>
<h2 id="before-problematic-code"><a class="header" href="#before-problematic-code">Before (problematic code)</a></h2>
<pre><code class="language-pebble">&lt;li id="task-{{ task.id }}"&gt;
  &lt;span&gt;{{ task.title }}&lt;/span&gt;
  &lt;form action="/tasks/{{ task.id }}/edit" method="post"
        hx-post="/tasks/{{ task.id }}/edit"
        hx-target="#task-{{ task.id }}"&gt;
    &lt;input name="title" value="{{ task.title }}"&gt;
    &lt;button type="submit"&gt;Save&lt;/button&gt;
  &lt;/form&gt;
&lt;/li&gt;
</code></pre>
<p>Issues found in audit:</p>
<ul>
<li>Missing <code>&lt;label&gt;</code> and <code>id</code> ‚Üí fails WCAG 1.3.1 (A)</li>
<li>No error summary or field-level association</li>
<li>Screen readers received no confirmation message</li>
</ul>
<h2 id="after-fixed-version"><a class="header" href="#after-fixed-version">After (fixed version)</a></h2>
<pre><code class="language-pebble">&lt;li id="task-{{ task.id }}"&gt;
  &lt;form action="/tasks/{{ task.id }}/edit" method="post"
        hx-post="/tasks/{{ task.id }}/edit"
        hx-target="#task-{{ task.id }}"
        hx-swap="outerHTML"&gt;
    &lt;label class="visually-hidden" for="title-{{ task.id }}"&gt;
      Edit title for {{ task.title }}
    &lt;/label&gt;
    &lt;input id="title-{{ task.id }}" name="title" value="{{ task.title }}"
           aria-describedby="hint-{{ task.id }}"&gt;
    &lt;small id="hint-{{ task.id }}" class="visually-hidden"&gt;
      Keep titles concise; changes announce in status area.
    &lt;/small&gt;
    &lt;button type="submit"&gt;Save&lt;/button&gt;
  &lt;/form&gt;
&lt;/li&gt;
</code></pre>
<p>Server route (Ktor) now logs validation errors and returns OOB status updates:</p>
<pre><code class="language-kotlin">post("/tasks/{id}/edit") {
    val id = call.parameters["id"]?.toIntOrNull() ?: return@post call.respond(HttpStatusCode.BadRequest)
    val title = call.receiveParameters()["title"].orEmpty().trim()
    if (title.isBlank()) {
        val fragment = PebbleRender.render("tasks/edit-error.peb", mapOf("task" to repo.get(id)))
        val status = """&lt;div id="status" hx-swap-oob="true"&gt;Title is required.&lt;/div&gt;"""
        // Logger implementation covered in Week 9; shown here for completeness
        Logger.write(session = sid(call), req = reqId(call), task = "T2_edit", step = "validation_error", outcome = "blank_title", ms = 0, status = 400, js = jsMode(call))
        return@post call.respondText(fragment + status, ContentType.Text.Html)
    }

    repo.update(id, title)
    val fragment = PebbleRender.render("tasks/item.peb", mapOf("task" to repo.get(id)))
    val status = """&lt;div id="status" hx-swap-oob="true"&gt;Updated "$title".&lt;/div&gt;"""
    call.respondText(fragment + status, ContentType.Text.Html)
}
</code></pre>
<p>Checklist we ticked off:</p>
<ul>
<li>‚úÖ Field has a label (visually hidden) and <code>aria-describedby</code></li>
<li>‚úÖ Error path returns fragment with inline message + status update</li>
<li>‚úÖ Success path announces change via live region (<code>status</code> element in base template)</li>
<li>‚úÖ Focus management: HTMX attempts to restore focus to the matching <code>id="title-{{ task.id }}"</code> after swap; test with keyboard navigation to verify behaviour</li>
<li>‚úÖ Logger records validation errors for metrics analysis (Week 9 addition)</li>
</ul>
<h2 id="evidence-to-capture-for-task-1"><a class="header" href="#evidence-to-capture-for-task-1">Evidence to capture (for Task 1)</a></h2>
<ul>
<li>Screenshot of before/after (with annotations on label / status)</li>
<li>Screen reader transcript (NVDA) confirming: ‚ÄúUpdated ‚ÄúSubmit report‚Äù.‚Äù</li>
<li>Backlog entry referencing WCAG 1.3.1 and 4.1.3</li>
</ul>
<p>Use this pattern as a blueprint: the key is tying markup + server response + evidence together.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="assistive-technology-testing-checklist-week-6--week-11"><a class="header" href="#assistive-technology-testing-checklist-week-6--week-11">Assistive Technology Testing Checklist (Week 6 ‚Üí Week 11)</a></h1>
<h2 id="what-is-accessibility-first-design"><a class="header" href="#what-is-accessibility-first-design">What is Accessibility-First Design?</a></h2>
<p><strong>Accessibility-first design</strong> means building interfaces that work for everyone from the start‚Äînot retrofitting accessible features after the fact. In this module, we prioritise:</p>
<ul>
<li><strong><a href="references/glossary.html#wcag">WCAG</a> 2.2 AA compliance</strong> as the minimum standard for all features</li>
<li><strong><a href="references/glossary.html#screen-reader">Screen reader</a> compatibility</strong> verified through NVDA/Orca testing in every lab</li>
<li><strong>Keyboard navigation</strong> ensuring all interactions work without a mouse</li>
<li><strong><a href="references/glossary.html#no-js-parity">No-JS parity</a></strong> so core functionality remains available when JavaScript fails or is unavailable</li>
<li><strong>Inclusive design</strong> informed by people-centred language and real customer needs</li>
</ul>
<p>Unlike ‚Äúaccessibility as an audit‚Äù (checking compliance at the end), accessibility-first means every design decision‚Äîfrom route structure to <a href="references/glossary.html#aria">ARIA</a> attributes to colour contrast‚Äîis evaluated for inclusion before implementation. This approach reduces technical debt, improves usability for all users, and ensures legal compliance with the Equality Act 2010 and UK GDPR.</p>
<h2 id="testing-checklist"><a class="header" href="#testing-checklist">Testing Checklist</a></h2>
<p>Use this mini-check at the end of every lab to capture evidence quickly. Print it or keep it in your repo (<code>testing/checklist.md</code>).</p>
<div class="table-wrapper"><table><thead><tr><th>Area</th><th>Steps</th><th>Evidence to capture</th></tr></thead><tbody>
<tr><td>Keyboard-only</td><td>Tab through the entire flow: skip link ‚Üí forms ‚Üí buttons. Ensure visible focus.</td><td>Screenshot or short note confirming order + any issues.</td></tr>
<tr><td>No-JS parity</td><td>Disable JS (DevTools) and repeat the task. Watch network panel to confirm only full-page requests.</td><td>Browser screenshot + note. If broken, log backlog item.</td></tr>
<tr><td>Screen reader (SR)</td><td>NVDA (Windows) or Orca (RHEL): navigate headings (<code>H</code>), forms (<code>F</code>), run the interaction, listen for live status.</td><td>Transcript snippet or notes of announcements.</td></tr>
<tr><td>Zoom &amp; reflow</td><td>Zoom to 200%; ensure layout doesn‚Äôt break and no horizontal scroll on desktop widths.</td><td>Screenshot at 200% zoom.</td></tr>
<tr><td>Colour/contrast</td><td>Use built-in contrast checker or extension (e.g. Chrome DevTools ‚Üí CSS overview).</td><td>Contrast report or note with values.</td></tr>
<tr><td>Error messaging</td><td>Trigger validation errors; confirm focus stays in context and SR announces the message.</td><td>Screenshot of error + note on announcement.</td></tr>
<tr><td>Metrics logging (when added)</td><td>Confirm <code>data/metrics.csv</code> records success + validation_error rows.</td><td>Copy of latest rows or summary in notes.</td></tr>
</tbody></table>
</div>
<h2 id="tips"><a class="header" href="#tips">Tips</a></h2>
<ul>
<li>Pair up: one person drives, another logs issues in <code>backlog/backlog.csv</code>.</li>
<li>If a check fails, capture it immediately‚Äîauditors and Week 7-10 labs rely on real evidence.</li>
<li>Create an <code>evidence/</code> directory in your repo and store artefacts per week (e.g., <code>evidence/wk6/</code>, <code>evidence/wk7/</code>) to keep things tidy.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="assistive-technology-testing-checklist-week-6--week-11-1"><a class="header" href="#assistive-technology-testing-checklist-week-6--week-11-1">Assistive Technology Testing Checklist (Week 6 ‚Üí Week 11)</a></h1>
<p>Use this mini-check at the end of every lab to capture evidence quickly. Print it or keep it in your repo (<code>testing/checklist.md</code>).</p>
<div class="table-wrapper"><table><thead><tr><th>Area</th><th>Steps</th><th>Evidence to capture</th></tr></thead><tbody>
<tr><td>Keyboard-only</td><td>Tab through the entire flow: skip link ‚Üí forms ‚Üí buttons. Ensure visible focus.</td><td>Screenshot or short note confirming order + any issues.</td></tr>
<tr><td>No-JS parity</td><td>Disable JS (DevTools) and repeat the task. Watch network panel to confirm only full-page requests.</td><td>Browser screenshot + note. If broken, log backlog item.</td></tr>
<tr><td>Screen reader (SR)</td><td><strong>NVDA</strong> (Windows, free), <strong>VoiceOver</strong> (macOS, built-in), or <strong>Orca</strong> (Linux/RHEL, built-in but can be clunky‚Äîsee <a href="references/assistive-testing-checklist.html#orca-linux">setup notes</a>). Navigate headings (<code>H</code>), forms (<code>F</code>), run the interaction, listen for live status.</td><td>Transcript snippet or notes of announcements.</td></tr>
<tr><td>Zoom &amp; reflow</td><td>Zoom to 200%; ensure layout doesn‚Äôt break and no horizontal scroll on desktop widths.</td><td>Screenshot at 200% zoom.</td></tr>
<tr><td>Colour/contrast</td><td>Use built-in contrast checker or extension (e.g. Chrome DevTools ‚Üí CSS overview).</td><td>Contrast report or note with values.</td></tr>
<tr><td>Error messaging</td><td>Trigger validation errors; confirm focus stays in context and SR announces the message.</td><td>Screenshot of error + note on announcement.</td></tr>
<tr><td>Metrics logging (when added)</td><td>Confirm <code>data/metrics.csv</code> records success + validation_error rows.</td><td>Copy of latest rows or summary in notes.</td></tr>
</tbody></table>
</div>
<h2 id="tips-1"><a class="header" href="#tips-1">Tips</a></h2>
<ul>
<li>Pair up: one person drives, another logs issues in <code>backlog/backlog.csv</code>.</li>
<li>If a check fails, capture it immediately‚Äîauditors and Week 7-10 labs rely on real evidence.</li>
<li>Create an <code>evidence/</code> directory in your repo and store artefacts per week (e.g., <code>evidence/wk6/</code>, <code>evidence/wk7/</code>) to keep things tidy.</li>
</ul>
<h2 id="orca-linux"><a class="header" href="#orca-linux">Orca (Linux)</a></h2>
<p><strong>Orca</strong> is the built-in screen reader for GNOME (RHEL/Fedora/Ubuntu). It‚Äôs functional but can be clunky compared to NVDA (Windows) or VoiceOver (macOS).</p>
<h3 id="starting-orca"><a class="header" href="#starting-orca">Starting Orca</a></h3>
<ul>
<li><strong>Terminal</strong>: <code>orca</code> (use this if keyboard shortcuts don‚Äôt work)</li>
<li><strong>Shortcut</strong>: <code>Super + Alt + S</code> (Super = Windows key on laptops)</li>
<li><strong>Stop Orca</strong>: Press <code>Super + Alt + S</code> again, or <code>Insert + Q</code></li>
</ul>
<p><strong>Note</strong>: You may see warnings when starting from terminal. Orca should still work, but if speech doesn‚Äôt activate,
check your system‚Äôs accessibility settings.</p>
<h3 id="resources-1"><a class="header" href="#resources-1">Resources</a></h3>
<ul>
<li><strong>Official guide</strong>: <a href="https://help.gnome.org/users/orca/stable/">GNOME Orca Help</a></li>
</ul>
<h3 id="basic-navigation"><a class="header" href="#basic-navigation">Basic Navigation</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Action</th></tr></thead><tbody>
<tr><td><code>Insert + Space</code></td><td>Toggle browse/focus mode</td></tr>
<tr><td><code>H</code></td><td>Next heading (in browse mode)</td></tr>
<tr><td><code>F</code></td><td>Next form field</td></tr>
<tr><td><code>Insert + Down Arrow</code></td><td>Read current line</td></tr>
<tr><td><code>Insert + ;</code></td><td>Read entire page</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="privacy-by-design"><a class="header" href="#privacy-by-design">Privacy by Design</a></h1>
<h2 id="what-is-privacy-by-design"><a class="header" href="#what-is-privacy-by-design">What is Privacy by Design?</a></h2>
<p><strong>Privacy by Design</strong> is an approach to system development that embeds privacy and data protection into the entire lifecycle of technologies, from the earliest design stages through to deployment and beyond. Rather than treating privacy as an afterthought or compliance checkbox, it becomes a core design principle that shapes every decision.</p>
<p>The concept was developed by <a href="https://iapp.org/media/pdf/resource_center/pbd_implement_7found_principles.pdf">Dr Ann Cavoukian</a> in the 1990s and has since become a foundational principle in data protection legislation, including GDPR (General Data Protection Regulation).</p>
<h2 id="core-principles-1"><a class="header" href="#core-principles-1">Core Principles</a></h2>
<h3 id="1-proactive-not-reactive-preventative-not-remedial"><a class="header" href="#1-proactive-not-reactive-preventative-not-remedial">1. Proactive not Reactive; Preventative not Remedial</a></h3>
<ul>
<li>Anticipate and prevent privacy risks before they occur</li>
<li>Don‚Äôt wait for privacy breaches to happen before taking action</li>
<li>Design systems that cannot easily leak or misuse personal data</li>
</ul>
<h3 id="2-privacy-as-the-default-setting"><a class="header" href="#2-privacy-as-the-default-setting">2. Privacy as the Default Setting</a></h3>
<ul>
<li>Participants‚Äô privacy should be protected automatically</li>
<li>No action required from the participant to protect their privacy</li>
<li>Systems should work with minimal data collection by default</li>
</ul>
<h3 id="3-privacy-embedded-into-design"><a class="header" href="#3-privacy-embedded-into-design">3. Privacy Embedded into Design</a></h3>
<ul>
<li>Privacy is integral to the system, not a bolt-on feature</li>
<li>Not an add-on, not an afterthought</li>
<li>Becomes a core functional requirement</li>
</ul>
<h3 id="4-full-functionality--positive-sum-not-zero-sum"><a class="header" href="#4-full-functionality--positive-sum-not-zero-sum">4. Full Functionality ‚Äì Positive-Sum, not Zero-Sum</a></h3>
<ul>
<li>Privacy doesn‚Äôt require trade-offs with functionality</li>
<li>Both privacy and functionality can be achieved</li>
<li>False dichotomy between ‚Äúusable‚Äù and ‚Äúprivate‚Äù</li>
</ul>
<h3 id="5-end-to-end-security--full-lifecycle-protection"><a class="header" href="#5-end-to-end-security--full-lifecycle-protection">5. End-to-End Security ‚Äì Full Lifecycle Protection</a></h3>
<ul>
<li>Strong security measures from data collection to destruction</li>
<li>Data minimisation at every stage</li>
<li>Secure deletion when data is no longer needed</li>
</ul>
<h3 id="6-visibility-and-transparency"><a class="header" href="#6-visibility-and-transparency">6. Visibility and Transparency</a></h3>
<ul>
<li>Keep systems open and accountable</li>
<li>Operations remain visible to participants and stakeholders</li>
<li>Trust but verify approach</li>
</ul>
<h3 id="7-respect-for-participant-privacy"><a class="header" href="#7-respect-for-participant-privacy">7. Respect for Participant Privacy</a></h3>
<ul>
<li>Keep person-centred focus</li>
<li>Give participants control over their data</li>
<li>Make privacy the default, but allow informed choices</li>
</ul>
<h2 id="why-privacy-by-design-matters"><a class="header" href="#why-privacy-by-design-matters">Why Privacy by Design Matters</a></h2>
<h3 id="1-legal-compliance"><a class="header" href="#1-legal-compliance">1. <strong>Legal Compliance</strong></a></h3>
<ul>
<li>GDPR requires Privacy by Design (Article 25)</li>
<li>UK Data Protection Act 2018 codifies these principles</li>
<li>Non-compliance can result in significant fines (up to 4% of global turnover or ‚Ç¨20 million)</li>
<li>Better to build it in than retrofit later</li>
</ul>
<h3 id="2-ethical-responsibility"><a class="header" href="#2-ethical-responsibility">2. <strong>Ethical Responsibility</strong></a></h3>
<ul>
<li>As software engineers, we have power over people‚Äôs data</li>
<li>With that power comes responsibility to protect it</li>
<li>People have a right to privacy, autonomy, and dignity</li>
<li>Our systems should respect those rights by default</li>
</ul>
<h3 id="3-trust-and-reputation"><a class="header" href="#3-trust-and-reputation">3. <strong>Trust and Reputation</strong></a></h3>
<ul>
<li>Privacy breaches destroy trust</li>
<li>Trust takes years to build, seconds to lose</li>
<li>Privacy-respecting systems build confidence</li>
<li>Competitive advantage in privacy-conscious markets</li>
</ul>
<h3 id="4-security-benefits"><a class="header" href="#4-security-benefits">4. <strong>Security Benefits</strong></a></h3>
<ul>
<li>Less data collected = smaller attack surface</li>
<li>Fewer high-value targets for attackers</li>
<li>Reduced impact if a breach does occur</li>
<li>Minimises risk exposure for both participants and organisation</li>
</ul>
<h3 id="5-cost-efficiency"><a class="header" href="#5-cost-efficiency">5. <strong>Cost Efficiency</strong></a></h3>
<ul>
<li>Cheaper to build privacy in from the start</li>
<li>Retrofitting privacy is expensive and often incomplete</li>
<li>Reduces storage and processing costs (less data to manage)</li>
<li>Avoids costly breach responses and legal fees</li>
</ul>
<h3 id="6-participant-empowerment"><a class="header" href="#6-participant-empowerment">6. <strong>Participant Empowerment</strong></a></h3>
<ul>
<li>People should control their own data</li>
<li>Informed consent requires clear, simple choices</li>
<li>Privacy by Design enables genuine agency</li>
<li>Respects human autonomy and dignity</li>
</ul>
<h2 id="privacy-by-design-in-comp2850-hci"><a class="header" href="#privacy-by-design-in-comp2850-hci">Privacy by Design in COMP2850 HCI</a></h2>
<p>In this module, we practise Privacy by Design through several concrete patterns:</p>
<h3 id="data-minimisation"><a class="header" href="#data-minimisation">Data Minimisation</a></h3>
<p><strong>What we do:</strong></p>
<ul>
<li>Collect only anonymous session IDs (6-8 characters)</li>
<li>Use random request IDs instead of personally identifiable information</li>
<li>No names, emails, IP addresses, or other PII (Personally Identifiable Information) in logs</li>
<li>No accounts, authentication, or persistent profiles</li>
</ul>
<p><strong>Why:</strong></p>
<pre><code class="language-csv"># Our logs look like this:
ts_iso,session_id,request_id,task_code,step,outcome,ms,http_status,js_mode
2024-10-13T14:23:01Z,abc123xy,req-8f7g,T1_filter,start,success,234,200,true

# NOT like this (bad example):
ts_iso,user_email,user_name,ip_address,task_code,outcome,ms
2024-10-13T14:23:01Z,alice@email.com,Alice Smith,192.168.1.42,T1_filter,success,234
</code></pre>
<p>We can still measure usability metrics (completion time, error rates) without knowing <em>who</em> the person is.</p>
<h3 id="local-storage-only"><a class="header" href="#local-storage-only">Local Storage Only</a></h3>
<p><strong>What we do:</strong></p>
<ul>
<li>All metrics stored in local CSV files on University of Leeds OneDrive (covered by institutional ethical consent)</li>
<li>No cloud services, no external analytics</li>
<li>No third-party tracking scripts</li>
<li>Data stays within UoL-controlled infrastructure</li>
</ul>
<p><strong>Why:</strong></p>
<ul>
<li>Reduces risk of data exposure through third parties</li>
<li>No terms-of-service surprises from external vendors</li>
<li>Clear data lifecycle (we control retention and deletion)</li>
<li>Compliance is simpler when data doesn‚Äôt leave our infrastructure</li>
<li>UoL OneDrive provides secure, GDPR-compliant storage with appropriate access controls</li>
</ul>
<h3 id="peer-only-testing-protocol"><a class="header" href="#peer-only-testing-protocol">Peer-Only Testing Protocol</a></h3>
<p><strong>What we do:</strong></p>
<ul>
<li>Usability testing only with course peers</li>
<li>Module-wide blanket consent (everyone knows they may be observed)</li>
<li>No external participants who might not understand context</li>
<li>No recordings (video/audio)</li>
</ul>
<p><strong>Why:</strong></p>
<ul>
<li>Creates safe learning environment</li>
<li>Everyone understands the educational purpose</li>
<li>Reduces power imbalance (peers, not vulnerable populations)</li>
<li>Minimal risk because everyone is consenting participant</li>
</ul>
<h3 id="evidence-without-pii"><a class="header" href="#evidence-without-pii">Evidence Without PII</a></h3>
<p><strong>What we do:</strong></p>
<ul>
<li>Screenshots must be cropped to show only interface</li>
<li>Personal information scrubbed from any evidence</li>
<li>No images of people</li>
<li>Alt text required for accessibility, but no identifying details</li>
<li>Use pseudoanonymisation (e.g., ‚ÄúParticipant A‚Äù, ‚ÄúSession 1‚Äù) when reporting qualitative data from interviews, recordings, or transcription</li>
</ul>
<p><strong>Why:</strong></p>
<ul>
<li>Evidence is about interface design, not people</li>
<li>Respects dignity and consent of participants</li>
<li>Prevents accidental identification years later</li>
<li>Forces focus on the system, not the person using it</li>
<li><strong>Note</strong>: Full anonymisation is often impossible for qualitative research; pseudoanonymisation (removing direct identifiers while retaining links for analysis) is typically the best achievable practice for interviews, recordings, transcription, and quantitative analysis</li>
</ul>
<h3 id="transparent-research-protocol"><a class="header" href="#transparent-research-protocol">Transparent Research Protocol</a></h3>
<p><strong>What we do:</strong></p>
<ul>
<li>Clear written protocol explaining what data is collected</li>
<li>Explicit task descriptions and measures</li>
<li>Right to withdraw at any time</li>
<li>Minimal task time caps (3 minutes max to avoid frustration)</li>
</ul>
<p><strong>Why:</strong></p>
<ul>
<li>Informed consent requires transparency</li>
<li>People can only consent to what they understand</li>
<li>Respects participant autonomy</li>
<li>Builds trust in research process</li>
</ul>
<h3 id="no-feature-creep"><a class="header" href="#no-feature-creep">No Feature Creep</a></h3>
<p><strong>What we do:</strong></p>
<ul>
<li>Don‚Äôt add ‚Äúhelpful‚Äù tracking features</li>
<li>Resist temptation to add ‚Äújust one more field‚Äù</li>
<li>Question every data point: is this necessary?</li>
<li>Start with minimal data, expand only if justified</li>
</ul>
<p><strong>Why:</strong></p>
<ul>
<li>Scope creep applies to data collection too</li>
<li>Each new field is a new privacy risk</li>
<li>‚ÄúWe might need it someday‚Äù is not justification</li>
<li>Constraints breed creativity (work within limits)</li>
</ul>
<h2 id="practical-examples-from-our-labs"><a class="header" href="#practical-examples-from-our-labs">Practical Examples from Our Labs</a></h2>
<h3 id="week-9-server-side-instrumentation"><a class="header" href="#week-9-server-side-instrumentation">Week 9: Server-Side Instrumentation</a></h3>
<p><strong>Privacy-Respecting Approach:</strong></p>
<pre><code class="language-kotlin">// Log only what's needed for metrics
Logger.log(
    sessionId = "abc123xy",      // Anonymous cookie
    requestId = "req-8f7g",       // Random per-task
    taskCode = "T1_filter",       // Which task
    step = "start",               // What happened
    outcome = "success",          // Result
    ms = 234L,                    // Duration
    httpStatus = 200,             // HTTP response
    jsMode = "true"               // JS enabled/disabled
)
</code></pre>
<p><strong>What we DON‚ÄôT log:</strong></p>
<ul>
<li>Browser user agent strings (can fingerprint devices)</li>
<li>Full URLs (might contain personal data in query params)</li>
<li>Form input values (might be personal information)</li>
<li>Mouse movements or keystroke timings (surveillance-like)</li>
<li>IP addresses (can identify individuals)</li>
</ul>
<h3 id="week-10-analysis--evidence"><a class="header" href="#week-10-analysis--evidence">Week 10: Analysis &amp; Evidence</a></h3>
<p><strong>Privacy-Respecting Analysis:</strong></p>
<pre><code class="language-kotlin">// Aggregate data, analyse patterns, no individuals
data class TaskStats(
    val taskCode: String,
    val medianMs: Double,
    val completionRate: Double,
    val errorRate: Double
)
</code></pre>
<p>We report: ‚ÄúTask T1 had a median completion time of 8.2 seconds with a 90% completion rate.‚Äù</p>
<p>We DON‚ÄôT report: ‚ÄúSession abc123xy took 15 seconds and made 3 errors.‚Äù</p>
<p><strong>Why:</strong> The goal is to improve the interface, not judge individuals.</p>
<h3 id="week-11-portfolio--submission"><a class="header" href="#week-11-portfolio--submission">Week 11: Portfolio &amp; Submission</a></h3>
<p><strong>Privacy-Respecting Evidence:</strong></p>
<ul>
<li>Screenshots cropped to show only UI elements</li>
<li>No usernames visible in interface</li>
<li>No timestamps that could identify sessions</li>
<li>Generic task data (‚Äúrename task A to task B‚Äù)</li>
</ul>
<p><strong>Privacy-Violating Evidence (Don‚Äôt do this):</strong></p>
<ul>
<li>Full-screen screenshots showing participant‚Äôs desktop</li>
<li>Visible personal calendar events or email notifications</li>
<li>Identifiable profiles in test data</li>
<li>Timestamped evidence linking to specific people</li>
</ul>
<h2 id="common-myths-about-privacy"><a class="header" href="#common-myths-about-privacy">Common Myths About Privacy</a></h2>
<h3 id="myth-1-were-not-collecting-sensitive-data-so-privacy-doesnt-matter"><a class="header" href="#myth-1-were-not-collecting-sensitive-data-so-privacy-doesnt-matter">Myth 1: ‚ÄúWe‚Äôre not collecting sensitive data, so privacy doesn‚Äôt matter‚Äù</a></h3>
<p><strong>Reality:</strong> What seems innocuous can become sensitive in aggregate or context. Session patterns, timing data, and behavioural metrics can reveal sensitive information. Privacy by Design applies to all data.</p>
<h3 id="myth-2-privacy-and-usability-are-in-conflict"><a class="header" href="#myth-2-privacy-and-usability-are-in-conflict">Myth 2: ‚ÄúPrivacy and usability are in conflict‚Äù</a></h3>
<p><strong>Reality:</strong> Privacy by Design is about smart design choices, not removing features. Anonymous session IDs work just as well as personal accounts for our use case. Good UX respects participants‚Äô privacy.</p>
<h3 id="myth-3-we-can-just-anonymise-data-later"><a class="header" href="#myth-3-we-can-just-anonymise-data-later">Myth 3: ‚ÄúWe can just anonymise data later‚Äù</a></h3>
<p><strong>Reality:</strong> Anonymisation is hard and often fails. Re-identification attacks are common. Better to never collect identifying data in the first place. True anonymity requires design from the start.</p>
<h3 id="myth-4-people-dont-care-about-privacy-anyway"><a class="header" href="#myth-4-people-dont-care-about-privacy-anyway">Myth 4: ‚ÄúPeople don‚Äôt care about privacy anyway‚Äù</a></h3>
<p><strong>Reality:</strong> People care deeply when they understand the implications. Surveys show privacy is a top concern. More importantly, privacy is a right, not a popularity contest.</p>
<h3 id="myth-5-we-need-data-to-improve-the-product"><a class="header" href="#myth-5-we-need-data-to-improve-the-product">Myth 5: ‚ÄúWe need data to improve the product‚Äù</a></h3>
<p><strong>Reality:</strong> We need <em>insights</em>, not personal data. Aggregate metrics, task success rates, and usability findings don‚Äôt require knowing who anyone is. Data minimisation often leads to better focus.</p>
<h2 id="questions-to-ask"><a class="header" href="#questions-to-ask">Questions to Ask</a></h2>
<p>When designing any system that collects data, ask:</p>
<ol>
<li>
<p><strong>Do we need this data at all?</strong></p>
<ul>
<li>What decision does it inform?</li>
<li>What happens if we don‚Äôt collect it?</li>
<li>Is there a less invasive alternative?</li>
</ul>
</li>
<li>
<p><strong>Can we use anonymous or pseudonymous data?</strong></p>
<ul>
<li>Random session IDs instead of accounts?</li>
<li>Request IDs instead of tracking individuals?</li>
<li>Aggregate statistics instead of individual records?</li>
</ul>
</li>
<li>
<p><strong>How long do we need to keep it?</strong></p>
<ul>
<li>Set retention policies upfront</li>
<li>Delete data when no longer needed</li>
<li>Question perpetual storage defaults</li>
</ul>
</li>
<li>
<p><strong>Who has access?</strong></p>
<ul>
<li>Minimise access to those who need it</li>
<li>Log access to sensitive data</li>
<li>Audit regularly</li>
</ul>
</li>
<li>
<p><strong>What could go wrong?</strong></p>
<ul>
<li>Threat model: what attacks are possible?</li>
<li>Data breach: what‚Äôs the impact?</li>
<li>Misuse: could this data harm people?</li>
</ul>
</li>
<li>
<p><strong>Can people control their data?</strong></p>
<ul>
<li>Export their data?</li>
<li>Delete their data?</li>
<li>Correct inaccuracies?</li>
</ul>
</li>
<li>
<p><strong>Is collection transparent?</strong></p>
<ul>
<li>Do people know what‚Äôs collected?</li>
<li>Do they understand why?</li>
<li>Can they make informed choices?</li>
</ul>
</li>
</ol>
<h2 id="resources--further-reading"><a class="header" href="#resources--further-reading">Resources &amp; Further Reading</a></h2>
<h3 id="foundational-documents"><a class="header" href="#foundational-documents">Foundational Documents</a></h3>
<ul>
<li><a href="https://iapp.org/media/pdf/resource_center/pbd_implement_7found_principles.pdf">Privacy by Design: The 7 Foundational Principles</a> (Ann Cavoukian)</li>
<li><a href="https://gdpr-info.eu/art-25-gdpr/">GDPR Article 25: Data Protection by Design and by Default</a></li>
</ul>
<h3 id="uk-context"><a class="header" href="#uk-context">UK Context</a></h3>
<ul>
<li><a href="https://ico.org.uk/for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gdpr/accountability-and-governance/data-protection-by-design-and-default/">ICO Guide to Privacy by Design</a></li>
<li><a href="https://www.legislation.gov.uk/ukpga/2018/12/contents/enacted">UK Data Protection Act 2018</a></li>
</ul>
<h3 id="practical-guides"><a class="header" href="#practical-guides">Practical Guides</a></h3>
<ul>
<li><a href="https://cheatsheetseries.owasp.org/cheatsheets/Privacy_Cheat_Sheet.html">OWASP Privacy Cheat Sheet</a></li>
<li><a href="https://privacypatterns.org/">Privacy Patterns (design patterns for privacy)</a></li>
<li></li>
</ul>
<h2 id="summary-why-this-matters-for-hci--ux"><a class="header" href="#summary-why-this-matters-for-hci--ux">Summary: Why This Matters for HCI &amp; UX</a></h2>
<p>As HCI practitioners, we design the interfaces, systems and UX that mediate people‚Äôs digital lives.<br />
Every interaction we design, every feature we implement, has privacy implications.</p>
<p><strong>Privacy by Design is good HCI &amp; UX because:</strong></p>
<ol>
<li><strong>Respects human dignity</strong> - People are not data points</li>
<li><strong>Builds trust</strong> - Essential for meaningful human-computer interaction</li>
<li><strong>Reduces cognitive burden</strong> - People shouldn‚Äôt need law degrees to protect themselves</li>
<li><strong>Enables inclusion</strong> - Privacy concerns disproportionately affect marginalised groups</li>
<li><strong>Future-proofs systems</strong> - Privacy-respecting design ages better</li>
<li><strong>Aligns with ethics</strong> - Core ACM Code of Ethics principle (1.6: Respect privacy)</li>
</ol>
<p>In COMP2850, we practise Privacy by Design not because it‚Äôs required for coursework, but because it‚Äôs required for <strong>responsible software engineering</strong>. The habits you form now shape the systems you‚Äôll build throughout your career.</p>
<p><strong>The question is not ‚ÄúHow much data can we collect?‚Äù</strong></p>
<p><strong>The question is ‚ÄúHow little data do we need to achieve our goals?‚Äù</strong></p>
<p>Privacy by Design starts with that question.</p>
<h3 id="academic-perspectives"><a class="header" href="#academic-perspectives">Academic Perspectives</a></h3>
<ul>
<li>
<p>Shirlei Aparecida de Chaves and Fabiane Benitti. 2025. User-Centred Privacy and Data Protection: An Overview of Current Research Trends and Challenges for the Human‚ÄìComputer Interaction Field. ACM Comput. Surv. 57, 7, Article 176 (February 2025), 36 pages. https://doi.org/10.1145/3715903</p>
</li>
<li>
<p>Giovanni Iachello and Jason Hong. 2007. End-User Privacy in Human-Computer Interaction. Found. Trends Hum.‚ÄìComput. Interact. 1, 1 (January 2007), 1‚Äì137. https://www.cs.cmu.edu/~jasonh/publications/fnt-end-user-privacy-in-human-computer-interaction-final.pdf</p>
</li>
<li>
<p>Jaap-Henk Hoepman. 2014. Privacy Design Strategies. In ICT Systems Security and Privacy Protection, Nora Cuppens-Boulahia, Fr√©d√©ric Cuppens, Sushil Jajodia, Anas Abou El Kalam, and Thierry Sans (Eds.). Springer, Berlin, Heidelberg, 446‚Äì459. https://doi.org/10.1007/978-3-642-55415-5_38</p>
</li>
<li>
<p>George Danezis, Josep Domingo-Ferrer, Marit Hansen, Jaap-Henk Hoepman, Daniel Le M√©tayer, Rodica Tirtea, and Stefan Schiffner. 2014. Privacy and Data Protection by Design ‚Äì from policy to engineering. ENISA, European Union Agency for Network and Information Security. https://arxiv.org/abs/1501.03726</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="consent-pii-and-low-risk-research-faq-weeks-67"><a class="header" href="#consent-pii-and-low-risk-research-faq-weeks-67">Consent, PII, and Low-Risk Research FAQ (Weeks 6‚Äì7)</a></h1>
<h2 id="why-this-matters-6"><a class="header" href="#why-this-matters-6">Why this matters</a></h2>
<p>Even with peer-to-peer studies in lab, we must follow university guidance and treat peers‚Äô data respectfully. This FAQ clarifies what‚Äôs in scope for our blanket low-risk consent protocol.</p>
<hr />
<h2 id="quick-definitions"><a class="header" href="#quick-definitions">Quick definitions</a></h2>
<ul>
<li><strong>PII (Personally Identifiable Information)</strong>: Anything that can identify a person. In our labs it includes full names, student IDs, email addresses, recorded voices, facial images, device IDs.</li>
<li><strong>De-identified notes</strong>: Observations or timings that cannot point to a specific person (e.g., ‚ÄúParticipant A took 48s to complete T2, mis-clicked once‚Äù).</li>
<li><strong>Low-risk study</strong>: Peer pairs, no external participants, no vulnerable groups, no sensitive topics, no recordings.</li>
</ul>
<hr />
<h2 id="whats-allowed-in-week-67-labs"><a class="header" href="#whats-allowed-in-week-67-labs">What‚Äôs allowed in Week 6‚Äì7 labs?</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Activity</th><th>Allowed?</th><th>Notes</th></tr></thead><tbody>
<tr><td>Peer needs-finding interviews (with consent script)</td><td>‚úÖ</td><td>Keep to lab partners, no recording. Use initials or pseudonyms in notes.</td></tr>
<tr><td>Timing tasks during pilots (Stopwatch / server logs)</td><td>‚úÖ</td><td>Store in <code>data/metrics.csv</code> without names.</td></tr>
<tr><td>Collecting demographic data</td><td>‚ùå</td><td>Out of scope; introduces unnecessary sensitivity.</td></tr>
<tr><td>Screenshots of peers</td><td>‚ùå</td><td>Do not capture faces. Crop to interface only.</td></tr>
<tr><td>Recording audio/video</td><td>‚ùå</td><td>Not covered by low-risk blanket approval.</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="consent-protocol-essentials"><a class="header" href="#consent-protocol-essentials">Consent protocol essentials</a></h2>
<ol>
<li><strong>Introduce</strong> the activity and remind peers participation is voluntary.</li>
<li><strong>Clarify</strong> data collected (timings, errors, notes) and how it will be stored (local repo, private).</li>
<li><strong>Offer opt-out</strong>: they can stop at any time, no penalty.</li>
<li><strong>Confirm no PII</strong> is stored; use pseudonyms or IDs like <code>P1</code>, <code>P2</code>.</li>
<li><strong>Record consent</strong> in <code>research/consent_protocol.md</code> (date, activity, initials if needed).</li>
</ol>
<p>Sample script (use in Week 6 Lab 2):</p>
<blockquote>
<p>‚ÄúWe‚Äôre running a quick needs-finding chat about the task list app. I‚Äôll take notes under <code>P1</code>, no names, and we won‚Äôt record. You can stop whenever you like. Okay to proceed?‚Äù</p>
</blockquote>
<hr />
<h2 id="storing-notes-safely"><a class="header" href="#storing-notes-safely">Storing notes safely</a></h2>
<ul>
<li>Keep notes in the repo under <code>research/</code> with pseudonyms.</li>
<li>Do not sync to public forks. Push only to private module repos or upload via Minerva if required.</li>
<li>If you accidentally capture PII, remove it immediately and note the correction in your reflection.</li>
</ul>
<hr />
<h2 id="handling-data-after-the-lab"><a class="header" href="#handling-data-after-the-lab">Handling data after the lab</a></h2>
<ul>
<li>Delete raw notes/screenshots containing identifying details once you‚Äôve transcribed anonymised versions.</li>
<li>For Gradescope submissions, ensure evidence folders contain cropped UI screenshots, no participant info.</li>
</ul>
<hr />
<h2 id="common-mistakes-to-avoid"><a class="header" href="#common-mistakes-to-avoid">Common mistakes to avoid</a></h2>
<ul>
<li>Writing ‚ÄúSpoke to Sam, she struggled with focus order‚Äù ‚Üí instead use ‚ÄúParticipant A‚Ä¶‚Äù</li>
<li>Storing Google Form responses with email addresses ‚Üí don‚Äôt collect emails (use plain Markdown tables).</li>
<li>Sharing repo publicly before removing <code>research/</code> folder ‚Üí keep private until evidence is sanitised.</li>
</ul>
<hr />
<h2 id="who-to-ask-if-unsure"><a class="header" href="#who-to-ask-if-unsure">Who to ask if unsure?</a></h2>
<ul>
<li>Lab teaching staff during sessions.</li>
<li>Lecturers for edge cases (e.g., wanting to test with someone outside the cohort).</li>
</ul>
<p>Document any unusual situations in your self-reflection so we can show due diligence.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="evaluation-metrics-quick-reference-week-910"><a class="header" href="#evaluation-metrics-quick-reference-week-910">Evaluation Metrics Quick Reference (Week 9‚Äì10)</a></h1>
<h2 id="what-are-evaluation-metrics"><a class="header" href="#what-are-evaluation-metrics">What are Evaluation Metrics?</a></h2>
<p><strong>Evaluation metrics</strong> are quantitative measures that help us assess the usability and effectiveness of interactive systems. Rather than relying on assumptions or opinions about whether an interface works well, metrics provide <strong>evidence-based data</strong> to identify problems, track improvements, and justify design decisions.</p>
<p>In HCI, we distinguish between:</p>
<ul>
<li><strong>Objective metrics</strong> - Measurable performance data (time, error rates, completion rates) captured through instrumentation</li>
<li><strong>Subjective metrics</strong> - Self-reported experiences (confidence, satisfaction, perceived difficulty) captured through questionnaires</li>
</ul>
<p>For COMP2850, we focus on <strong>task-based evaluation</strong>: participants attempt specific tasks (e.g., ‚Äúfilter tasks by status‚Äù) while we measure completion time, success rates, and errors. This approach reveals usability issues that might not surface through inspection methods alone.</p>
<p><strong>Why metrics matter:</strong></p>
<ul>
<li><strong>Data-driven redesign</strong> - Identify which tasks cause the most friction</li>
<li><strong>Accessibility verification</strong> - Compare JS-on vs JS-off performance to ensure <a href="references/glossary.html#no-js-parity">no-JS parity</a></li>
<li><strong>Prioritisation</strong> - Use error rates and completion times to rank backlog fixes by impact</li>
<li><strong>Evidence chains</strong> - Support claims in Task 1 and Task 2 submissions with concrete data, not guesswork</li>
</ul>
<p>All metrics must respect <a href="references/privacy-by-design.html">privacy by design</a> principles: we log anonymous session IDs and task codes, never personal identifiers.</p>
<hr />
<h2 id="why-task-based-evaluation"><a class="header" href="#why-task-based-evaluation">Why Task-Based Evaluation?</a></h2>
<h3 id="theoretical-foundation"><a class="header" href="#theoretical-foundation">Theoretical Foundation</a></h3>
<p><strong>Task-based usability evaluation</strong> has its roots in cognitive psychology and human factors research from the 1980s-90s. Rather than measuring abstract performance (e.g., reaction time, motor precision), task-based methods assess how well people can accomplish <strong>realistic goals</strong> with a system.</p>
<p><strong>Key foundations:</strong></p>
<ul>
<li><strong>ISO 9241-11 (2018)</strong>: Defines usability as ‚Äúthe extent to which a system can be used by specified users to achieve specified goals with effectiveness, efficiency and satisfaction in a specified context of use‚Äù</li>
<li><strong>Nielsen &amp; Landauer (1993)</strong>: Established the ‚Äú5-user rule‚Äù - testing with 5 participants identifies ~85% of usability issues</li>
<li><strong>Dumas &amp; Redish (1993)</strong>: <em>A Practical Guide to Usability Testing</em> - formalized task-based protocols for industry</li>
<li><strong>Lewis (1982, 2014)</strong>: Developed task-based metrics (completion rate, time-on-task, subjective ratings) still used today</li>
</ul>
<p><strong>Why task-based over alternatives?</strong></p>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>What it measures</th><th>When to use</th><th>Why we don‚Äôt use it here</th></tr></thead><tbody>
<tr><td><strong>Fitts‚Äô Law / ISO 9241-9</strong></td><td>Motor performance (pointing, clicking speed)</td><td>Low-level widget design (button size, target distance)</td><td>Too low-level; doesn‚Äôt capture real workflow issues</td></tr>
<tr><td><strong>GOMS / KLM</strong></td><td>Expert performance (keystroke-level model)</td><td>Predict expert task time for routine operations</td><td>Assumes error-free performance; misses novice struggles</td></tr>
<tr><td><strong>Reaction time tests</strong></td><td>Perceptual-motor speed (stimulus ‚Üí response)</td><td>Attention research, cognitive load studies</td><td>Doesn‚Äôt reflect real task complexity</td></tr>
<tr><td><strong>Task-based evaluation</strong></td><td>Effectiveness, efficiency, satisfaction on realistic tasks</td><td>Formative evaluation, iterative design, accessibility testing</td><td>‚úÖ Matches our goal: find usability + accessibility issues in real workflows</td></tr>
</tbody></table>
</div>
<h3 id="ecological-validity"><a class="header" href="#ecological-validity">Ecological Validity</a></h3>
<p>Task-based evaluation prioritizes <strong>ecological validity</strong> - the extent to which findings generalize to real-world use. By asking participants to complete realistic scenarios (‚Äúadd a task with a deadline‚Äù), we uncover issues that matter in practice:</p>
<ul>
<li>Form validation errors that block task completion</li>
<li>Missing labels that confuse screen reader navigation</li>
<li>Keyboard traps that prevent no-mouse workflows</li>
<li>Performance differences between JS-on and JS-off conditions</li>
</ul>
<p>These issues don‚Äôt surface in abstract performance tests but critically affect real users.</p>
<h3 id="our-approach-in-comp2850"><a class="header" href="#our-approach-in-comp2850">Our Approach in COMP2850</a></h3>
<p>We use <strong>lightweight task-based testing</strong> inspired by:</p>
<ul>
<li><strong>Nielsen‚Äôs discount usability engineering</strong>: Small samples (n=4-5), qualitative + quantitative data, rapid iteration</li>
<li><strong>Lewis‚Äôs task-based metrics</strong>: Completion rate, time-on-task, error rate, confidence ratings</li>
<li><strong>WCAG evaluation methodology</strong>: Test with assistive technology variants (keyboard, screen reader, no-JS)</li>
</ul>
<p><strong>What we test:</strong></p>
<ul>
<li>Representative tasks from Week 6 needs-finding (job stories ‚Üí evaluation tasks)</li>
<li>Multiple interaction modes: mouse + keyboard, JS-on + JS-off, visual + screen reader</li>
<li>Both <strong>effectiveness</strong> (Can people complete the task?) and <strong>efficiency</strong> (How quickly?)</li>
</ul>
<p><strong>What makes our approach academically rigorous:</strong></p>
<ul>
<li><strong>Privacy-safe instrumentation</strong>: Server-side logging (not surveillance)</li>
<li><strong>Mixed methods</strong>: Quantitative metrics + qualitative observations</li>
<li><strong>Evidence chains</strong>: Every claim traceable to data</li>
<li><strong>Ethical protocols</strong>: Informed consent, right to withdraw, no PII</li>
</ul>
<p>For detailed task descriptions and assessment criteria, see <a href="references/../assessment/task1.html">Task 1: Evaluation &amp; Findings</a>.</p>
<hr />
<h2 id="core-metrics"><a class="header" href="#core-metrics">Core Metrics</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>How to calculate</th><th>Why we use it</th><th>Notes</th></tr></thead><tbody>
<tr><td>Median time (<code>median_ms</code>)</td><td>Sort successful task durations; pick middle value (or average middle two)</td><td>Resistant to outliers; tells us typical completion time</td><td>Use Kotlin helper in <code>Analyse.kt</code> or spreadsheet <code>MEDIAN</code>.</td></tr>
<tr><td>Median absolute deviation (<code>mad_ms</code>)</td><td>Median of `</td><td>value - median</td><td>` for each duration</td></tr>
<tr><td>Completion rate</td><td><code>success / (success + fail)</code></td><td>Shows task feasibility; &lt;1 means people are stuck</td><td>Track separately for JS-on vs JS-off.</td></tr>
<tr><td>Validation error count</td><td>Number of <code>validation_error</code> rows per task</td><td>Flags form issues (copy errors, missing labels)</td><td>Relates directly to accessibility backlog items.</td></tr>
<tr><td>Error rate</td><td><code>validation_error / (success + validation_error)</code></td><td>Highlights forms that confuse or block people</td><td>Pair with qualitative notes to prioritise fixes.</td></tr>
<tr><td>Confidence score</td><td>Average of 1‚Äì5 scale reported post-task</td><td>Taps into affective feedback (HCI evaluation requirement)</td><td>Capture in <code>metrics.csv</code> or a parallel sheet.</td></tr>
</tbody></table>
</div>
<h2 id="workflow-reminder"><a class="header" href="#workflow-reminder">Workflow reminder</a></h2>
<ol>
<li>Append raw pilot data to <code>data/metrics.csv</code> (server logs + manual entries).</li>
<li>Run <code>./gradlew runAnalyse</code> (or <code>Analyse.kt</code>) to regenerate <code>analysis/analysis.csv</code>.</li>
<li>Copy summary rows into <code>analysis/summary.md</code> with narrative interpretation.</li>
<li>Use the numbers to populate <code>analysis/prioritisation.csv</code> (impact/inclusion/effort scores).</li>
</ol>
<p>Keep this reference handy during Weeks 9‚Äì10 labs so you don‚Äôt have to re-derive the formulas under time pressure.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="screenshot-guide-for-evidence-collection"><a class="header" href="#screenshot-guide-for-evidence-collection">Screenshot Guide for Evidence Collection</a></h1>
<p><strong>COMP2850 HCI - Privacy-Safe Screenshot Practices</strong></p>
<hr />
<h2 id="why-screenshots-matter"><a class="header" href="#why-screenshots-matter">Why Screenshots Matter</a></h2>
<p>For Task 1 (Week 9) and Task 2 (Week 10-11) submissions, you‚Äôll include <strong>screenshot evidence</strong> showing:</p>
<ul>
<li>Interface states (before/after redesign)</li>
<li>Accessibility features (ARIA live regions, focus indicators)</li>
<li>Browser DevTools inspections (HTML structure, network timing)</li>
<li>Screen reader output (NVDA/VoiceOver speech viewer)</li>
</ul>
<p>Screenshots must be <strong>privacy-safe</strong> (no PII) and <strong>readable</strong> (clear, well-cropped).</p>
<hr />
<h2 id="1-recommended-tools"><a class="header" href="#1-recommended-tools">1. Recommended Tools</a></h2>
<h3 id="windows"><a class="header" href="#windows">Windows</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Tool</th><th>Use Case</th><th>How to Access</th></tr></thead><tbody>
<tr><td><strong>Snipping Tool</strong></td><td>Quick screenshots, built-in</td><td><code>Win + Shift + S</code></td></tr>
<tr><td><strong>Windows Snip &amp; Sketch</strong></td><td>Annotate after capture</td><td>Windows Search ‚Üí ‚ÄúSnip &amp; Sketch‚Äù</td></tr>
<tr><td><strong>ShareX</strong> (free)</td><td>Advanced (regions, scrolling pages)</td><td>Download: https://getsharex.com/</td></tr>
<tr><td><strong>Greenshot</strong> (free)</td><td>Annotate, auto-save to folders</td><td>Download: https://getgreenshot.org/</td></tr>
</tbody></table>
</div>
<h3 id="macos"><a class="header" href="#macos">macOS</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Tool</th><th>Use Case</th><th>How to Access</th></tr></thead><tbody>
<tr><td><strong>Screenshot</strong> (built-in)</td><td>Full screen, window, region</td><td><code>Cmd + Shift + 3/4/5</code></td></tr>
<tr><td><strong>CleanShot X</strong> (paid)</td><td>Professional annotations</td><td>App Store</td></tr>
<tr><td><strong>Skitch</strong> (free)</td><td>Annotate after capture</td><td>App Store</td></tr>
</tbody></table>
</div>
<h3 id="linux"><a class="header" href="#linux">Linux</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Tool</th><th>Use Case</th><th>How to Access</th></tr></thead><tbody>
<tr><td><strong>Spectacle</strong> (KDE)</td><td>Full screen, window, region</td><td>Install via package manager</td></tr>
<tr><td><strong>GNOME Screenshot</strong></td><td>Built-in for GNOME desktop</td><td><code>PrtScn</code> key</td></tr>
<tr><td><strong>Flameshot</strong> (free)</td><td>Annotate, draw arrows</td><td>Install: <code>sudo apt install flameshot</code></td></tr>
</tbody></table>
</div>
<h3 id="browser-extensions-cross-platform"><a class="header" href="#browser-extensions-cross-platform">Browser Extensions (Cross-Platform)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Extension</th><th>Use Case</th><th>Install</th></tr></thead><tbody>
<tr><td><strong>Awesome Screenshot</strong></td><td>Full page, scrolling captures</td><td>Chrome/Firefox Web Store</td></tr>
<tr><td><strong>Nimbus Screenshot</strong></td><td>Annotate, blur sensitive areas</td><td>Chrome/Firefox Web Store</td></tr>
<tr><td><strong>Full Page Screen Capture</strong></td><td>Long pages (useful for task lists)</td><td>Chrome Web Store</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="2-what-to-crop-out-privacy-scrubbing"><a class="header" href="#2-what-to-crop-out-privacy-scrubbing">2. What to Crop Out (Privacy Scrubbing)</a></h2>
<h3 id="-remove-these-piisensitive-data"><a class="header" href="#-remove-these-piisensitive-data">‚ùå Remove These (PII/Sensitive Data)</a></h3>
<ul>
<li><strong>Usernames/Real Names</strong>: In browser tabs, bookmarks, login forms</li>
<li><strong>Email Addresses</strong>: In bookmarks, open Gmail tabs, login screens</li>
<li><strong>Profile Pictures</strong>: In browser toolbar, Google account icons</li>
<li><strong>Bookmark Bar Content</strong>: May reveal personal sites, work projects</li>
<li><strong>Browser History</strong>: If visible in search suggestions</li>
<li><strong>File Paths with Usernames</strong>: <code>C:\Users\JohnSmith\...</code> ‚Üí <code>C:\Users\[redacted]\...</code></li>
<li><strong>IP Addresses</strong>: In DevTools Network tab (if showing server IPs)</li>
<li><strong>Session Tokens</strong>: In DevTools Application ‚Üí Cookies</li>
<li><strong>Real Task Data</strong>: If using personal tasks instead of test data</li>
</ul>
<h3 id="-keep-these-useful-evidence"><a class="header" href="#-keep-these-useful-evidence">‚úÖ Keep These (Useful Evidence)</a></h3>
<ul>
<li><strong>Browser Name/Version</strong>: ‚ÄúChrome 120.0‚Äù (shows compatibility)</li>
<li><strong>Window Title</strong>: ‚ÄúTask Manager - localhost:8080‚Äù (shows page context)</li>
<li><strong>DevTools Panel</strong>: HTML inspector, Console, Network tab</li>
<li><strong>Code Line Numbers</strong>: In DevTools Elements panel</li>
<li><strong>ARIA Attributes</strong>: <code>role="status"</code>, <code>aria-label="..."</code></li>
<li><strong>Network Request Timing</strong>: Duration, status codes (200, 400)</li>
<li><strong>Screen Reader Output</strong>: NVDA/VoiceOver speech viewer text</li>
</ul>
<hr />
<h2 id="3-screenshot-checklist-before-saving"><a class="header" href="#3-screenshot-checklist-before-saving">3. Screenshot Checklist (Before Saving)</a></h2>
<p>Before saving each screenshot, check:</p>
<ul>
<li><input disabled="" type="checkbox"/>
<strong>No real names</strong> in browser tabs, bookmarks, or login forms</li>
<li><input disabled="" type="checkbox"/>
<strong>No email addresses</strong> visible</li>
<li><input disabled="" type="checkbox"/>
<strong>No personal task titles</strong> (use test data: ‚ÄúBuy milk‚Äù, ‚ÄúPay bills‚Äù)</li>
<li><input disabled="" type="checkbox"/>
<strong>No usernames in file paths</strong> (crop or blur <code>C:\Users\YourName\</code>)</li>
<li><input disabled="" type="checkbox"/>
<strong>Bookmark bar hidden or cropped</strong></li>
<li><input disabled="" type="checkbox"/>
<strong>Screenshot is readable</strong> (text legible, not too small)</li>
<li><input disabled="" type="checkbox"/>
<strong>Relevant content in focus</strong> (crop to show only what‚Äôs needed)</li>
<li><input disabled="" type="checkbox"/>
<strong>Annotations added</strong> (if needed: arrows, boxes, labels)</li>
</ul>
<hr />
<h2 id="4-optimal-dimensions--file-formats"><a class="header" href="#4-optimal-dimensions--file-formats">4. Optimal Dimensions &amp; File Formats</a></h2>
<h3 id="dimensions"><a class="header" href="#dimensions">Dimensions</a></h3>
<p><strong>For web interfaces</strong>:</p>
<ul>
<li><strong>Full screenshot</strong>: 1920√ó1080 (or your screen resolution)</li>
<li><strong>Cropped to browser content</strong>: 1280√ó720 (readable in PDFs)</li>
<li><strong>Close-up (DevTools, code)</strong>: 800√ó600 minimum (text must be legible)</li>
</ul>
<p><strong>General rule</strong>: Text should be <strong>14pt or larger</strong> when viewed at 100% zoom in PDF.</p>
<h3 id="file-formats"><a class="header" href="#file-formats">File Formats</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Format</th><th>When to Use</th><th>Pros</th><th>Cons</th></tr></thead><tbody>
<tr><td><strong>PNG</strong></td><td>Screenshots with text, UI elements</td><td>Lossless, sharp text</td><td>Larger file size</td></tr>
<tr><td><strong>JPG</strong></td><td>Photos, complex images (not UI)</td><td>Smaller file size</td><td>Lossy compression, blurry text</td></tr>
<tr><td><strong>WebP</strong></td><td>Modern alternative to PNG/JPG</td><td>Smaller + lossless</td><td>Not all viewers support it</td></tr>
</tbody></table>
</div>
<p><strong>Recommendation</strong>: Use <strong>PNG</strong> for all UI/code screenshots. Use <strong>JPG</strong> only for photos (if applicable).</p>
<hr />
<h2 id="5-how-to-crop-effectively"><a class="header" href="#5-how-to-crop-effectively">5. How to Crop Effectively</a></h2>
<h3 id="tool-specific-instructions"><a class="header" href="#tool-specific-instructions">Tool-Specific Instructions</a></h3>
<h4 id="windows-snipping-tool"><a class="header" href="#windows-snipping-tool">Windows Snipping Tool</a></h4>
<ol>
<li>Press <code>Win + Shift + S</code></li>
<li>Drag rectangle around <strong>relevant area only</strong> (not entire screen)</li>
<li>Click notification ‚Üí Opens Snip &amp; Sketch</li>
<li><strong>Before saving</strong>: Use pen tool to blur usernames/emails</li>
<li>Save as PNG to <code>wk09/evidence/screenshots/</code></li>
</ol>
<h4 id="macos-screenshot"><a class="header" href="#macos-screenshot">macOS Screenshot</a></h4>
<ol>
<li>Press <code>Cmd + Shift + 4</code></li>
<li>Drag crosshair around relevant area</li>
<li>Screenshot saves to Desktop (default)</li>
<li>Open in Preview ‚Üí Tools ‚Üí Annotate ‚Üí Blur sensitive areas</li>
<li>Export as PNG to <code>wk09/evidence/screenshots/</code></li>
</ol>
<h4 id="linux-flameshot"><a class="header" href="#linux-flameshot">Linux (Flameshot)</a></h4>
<ol>
<li>Run <code>flameshot gui</code></li>
<li>Drag rectangle around relevant area</li>
<li>Use blur tool (icon) to redact sensitive info</li>
<li>Click Save icon ‚Üí Save as PNG</li>
</ol>
<hr />
<h2 id="6-common-screenshot-types--best-practices"><a class="header" href="#6-common-screenshot-types--best-practices">6. Common Screenshot Types &amp; Best Practices</a></h2>
<h3 id="a-interface-screenshots-full-page"><a class="header" href="#a-interface-screenshots-full-page">A. Interface Screenshots (Full Page)</a></h3>
<p><strong>Purpose</strong>: Show complete UI state (e.g., task list before/after redesign)</p>
<p><strong>Best Practices</strong>:</p>
<ul>
<li>Hide bookmark bar (<code>Ctrl + Shift + B</code> in most browsers)</li>
<li>Close unnecessary tabs (only keep relevant tab open)</li>
<li>Zoom browser to 100% (not 125% or 67%)</li>
<li>Ensure URL bar shows <code>localhost:8080</code> or Codespaces URL</li>
<li>Crop to show browser content area + minimal chrome</li>
</ul>
<p><strong>Example Filename</strong>: <code>task-list-before-redesign.png</code></p>
<hr />
<h3 id="b-devtools-screenshots-html-structure"><a class="header" href="#b-devtools-screenshots-html-structure">B. DevTools Screenshots (HTML Structure)</a></h3>
<p><strong>Purpose</strong>: Show ARIA attributes, semantic HTML, live regions</p>
<p><strong>Best Practices</strong>:</p>
<ul>
<li>Open DevTools (<code>F12</code>)</li>
<li>Navigate to Elements tab</li>
<li>Expand relevant HTML section (e.g., <code>&lt;div id="status"&gt;</code>)</li>
<li>Highlight element to show in right panel:
<ul>
<li>Attributes (ARIA roles, labels)</li>
<li>Styles</li>
<li>Accessibility tree (if available)</li>
</ul>
</li>
<li><strong>Crop tightly</strong> to code + right panel (no need for full browser window)</li>
<li>Increase DevTools font size if text is small (DevTools Settings ‚Üí Appearance)</li>
</ul>
<p><strong>Example Filename</strong>: <code>aria-live-region-devtools.png</code></p>
<hr />
<h3 id="c-screen-reader-screenshots-speech-viewer"><a class="header" href="#c-screen-reader-screenshots-speech-viewer">C. Screen Reader Screenshots (Speech Viewer)</a></h3>
<p><strong>Purpose</strong>: Show what screen reader announces</p>
<p><strong>NVDA (Windows)</strong>:</p>
<ol>
<li>Enable Speech Viewer: <code>NVDA menu ‚Üí Tools ‚Üí Speech Viewer</code></li>
<li>Navigate through interface with <code>Tab</code> or <code>Down Arrow</code></li>
<li>Speech Viewer window shows announced text</li>
<li>Screenshot Speech Viewer window (crop to just that window)</li>
<li><strong>Blur any personal info</strong> in background windows</li>
</ol>
<p><strong>VoiceOver (macOS)</strong>:</p>
<ol>
<li>Enable Caption Panel: VoiceOver Utility ‚Üí Visuals ‚Üí Show Caption Panel</li>
<li>Navigate with <code>VO + Right Arrow</code> (where VO = <code>Ctrl + Option</code>)</li>
<li>Caption Panel shows announced text</li>
<li>Screenshot Caption Panel</li>
<li><strong>Blur any personal info</strong> in background</li>
</ol>
<p><strong>Example Filename</strong>: <code>nvda-task-added-announcement.png</code></p>
<hr />
<h3 id="d-network-timing-screenshots-performance-evidence"><a class="header" href="#d-network-timing-screenshots-performance-evidence">D. Network Timing Screenshots (Performance Evidence)</a></h3>
<p><strong>Purpose</strong>: Show request duration (for Task 1 metrics analysis)</p>
<p><strong>Best Practices</strong>:</p>
<ul>
<li>Open DevTools (<code>F12</code>) ‚Üí Network tab</li>
<li>Perform action (e.g., add task)</li>
<li>Look for POST request to <code>/tasks</code></li>
<li>Click request ‚Üí Timing tab shows duration</li>
<li><strong>Crop to show</strong>:
<ul>
<li>Request URL (<code>/tasks</code>)</li>
<li>Status code (200, 400, etc.)</li>
<li><strong>Duration</strong> (e.g., <code>234ms</code>)</li>
<li>Request headers showing <code>HX-Request: true</code> (if HTMX mode)</li>
</ul>
</li>
<li><strong>Crop out</strong>:
<ul>
<li>Session cookies (in Cookies tab)</li>
<li>Other unrelated requests</li>
</ul>
</li>
</ul>
<p><strong>Example Filename</strong>: <code>add-task-timing-234ms.png</code></p>
<hr />
<h2 id="7-organizing-screenshots-for-submission"><a class="header" href="#7-organizing-screenshots-for-submission">7. Organizing Screenshots for Submission</a></h2>
<h3 id="directory-structure"><a class="header" href="#directory-structure">Directory Structure</a></h3>
<pre><code>wk09/evidence/screenshots/
‚îú‚îÄ‚îÄ 01-baseline/
‚îÇ   ‚îú‚îÄ‚îÄ task-list-full-page.png
‚îÇ   ‚îú‚îÄ‚îÄ add-form-validation-error.png
‚îÇ   ‚îî‚îÄ‚îÄ aria-live-region-devtools.png
‚îú‚îÄ‚îÄ 02-screen-reader/
‚îÇ   ‚îú‚îÄ‚îÄ nvda-task-added.png
‚îÇ   ‚îú‚îÄ‚îÄ nvda-validation-error.png
‚îÇ   ‚îî‚îÄ‚îÄ voiceover-delete-confirmation.png
‚îú‚îÄ‚îÄ 03-network-timing/
‚îÇ   ‚îú‚îÄ‚îÄ add-task-timing.png
‚îÇ   ‚îú‚îÄ‚îÄ delete-task-timing.png
‚îÇ   ‚îî‚îÄ‚îÄ filter-task-timing.png
‚îî‚îÄ‚îÄ 04-after-redesign/
    ‚îú‚îÄ‚îÄ improved-error-message.png
    ‚îú‚îÄ‚îÄ aria-alert-devtools.png
    ‚îî‚îÄ‚îÄ nvda-improved-announcement.png
</code></pre>
<h3 id="naming-convention"><a class="header" href="#naming-convention">Naming Convention</a></h3>
<p>Use <strong>descriptive, searchable filenames</strong>:</p>
<p><strong>Good</strong> ‚úÖ:</p>
<ul>
<li><code>task-list-before-redesign.png</code></li>
<li><code>nvda-announcement-validation-error.png</code></li>
<li><code>devtools-aria-live-region-status.png</code></li>
<li><code>network-timing-add-task-567ms.png</code></li>
</ul>
<p><strong>Bad</strong> ‚ùå:</p>
<ul>
<li><code>Screenshot1.png</code></li>
<li><code>IMG_2024_10_14.png</code></li>
<li><code>Capture.png</code></li>
<li><code>untitled.png</code></li>
</ul>
<hr />
<h2 id="8-privacy-scrubbing-tools"><a class="header" href="#8-privacy-scrubbing-tools">8. Privacy Scrubbing Tools</a></h2>
<h3 id="built-in-most-tools"><a class="header" href="#built-in-most-tools">Built-In (Most Tools)</a></h3>
<ul>
<li><strong>Blur Tool</strong>: Flameshot, Greenshot, Snip &amp; Sketch</li>
<li><strong>Rectangle/Box</strong>: Draw solid box over sensitive area (use same color as background)</li>
<li><strong>Crop</strong>: Remove edges with sensitive info</li>
</ul>
<h3 id="external-if-needed"><a class="header" href="#external-if-needed">External (If Needed)</a></h3>
<ul>
<li>
<p><strong>ImageMagick</strong> (command-line):</p>
<pre><code class="language-bash"># Blur region (x, y, width, height)
convert input.png -region 100x50+10+10 -blur 0x8 output.png
</code></pre>
</li>
<li>
<p><strong>GIMP</strong> (free GUI editor):</p>
<ol>
<li>Open image</li>
<li>Select region (Rectangle Select tool)</li>
<li>Filters ‚Üí Blur ‚Üí Pixelize (or Gaussian Blur)</li>
<li>Export as PNG</li>
</ol>
</li>
</ul>
<h3 id="quick-check-metadata-removal"><a class="header" href="#quick-check-metadata-removal">Quick Check: Metadata Removal</a></h3>
<p>Some screenshot tools embed metadata (creation date, device name). Remove with:</p>
<p><strong>ExifTool</strong> (all platforms):</p>
<pre><code class="language-bash">exiftool -all= screenshot.png
</code></pre>
<p><strong>Or</strong>: Most screenshot tools don‚Äôt embed EXIF data by default (unlike phone cameras), but verify if submitting to external sites.</p>
<hr />
<h2 id="9-annotation-best-practices"><a class="header" href="#9-annotation-best-practices">9. Annotation Best Practices</a></h2>
<p>When adding <strong>arrows, boxes, or text</strong> to explain screenshots:</p>
<h3 id="good-annotations-"><a class="header" href="#good-annotations-">Good Annotations ‚úÖ</a></h3>
<ul>
<li><strong>Red boxes/arrows</strong>: Highlight relevant code/UI element</li>
<li><strong>Text labels</strong>: Short (1-3 words), clear font (Arial 14pt+)</li>
<li><strong>Contrast</strong>: Red/yellow on light backgrounds, white/yellow on dark</li>
<li><strong>Purpose</strong>: Point to specific ARIA attribute, error message, focus indicator</li>
</ul>
<p><strong>Example</strong>: Red arrow pointing to <code>role="status"</code> in DevTools with label ‚ÄúLive region‚Äù</p>
<h3 id="bad-annotations-"><a class="header" href="#bad-annotations-">Bad Annotations ‚ùå</a></h3>
<ul>
<li><strong>Too many arrows</strong>: Cluttered, confusing</li>
<li><strong>Tiny text</strong>: Labels must be 14pt+ to read in PDF</li>
<li><strong>Vague labels</strong>: ‚ÄúThis part‚Äù instead of ‚ÄúARIA live region‚Äù</li>
<li><strong>Covering content</strong>: Arrow/box blocks the code you‚Äôre highlighting</li>
</ul>
<hr />
<h2 id="10-testing-screenshot-readability"><a class="header" href="#10-testing-screenshot-readability">10. Testing Screenshot Readability</a></h2>
<p>Before submitting, test if screenshots are readable:</p>
<ol>
<li><strong>Export to PDF</strong> (as you will for submission)</li>
<li><strong>View at 100% zoom</strong> (not zoomed in)</li>
<li><strong>Check text is legible</strong>:
<ul>
<li>Code in DevTools should be readable without squinting</li>
<li>ARIA attributes should be clear</li>
<li>Error messages should be sharp (not blurry JPG artifacts)</li>
</ul>
</li>
<li><strong>If too small</strong>: Retake at higher resolution or crop tighter</li>
</ol>
<p><strong>Rule of thumb</strong>: If you need to zoom to 150%+ to read text, screenshot is too small/blurry.</p>
<hr />
<h2 id="11-common-mistakes--fixes"><a class="header" href="#11-common-mistakes--fixes">11. Common Mistakes &amp; Fixes</a></h2>
<h3 id="mistake-1-full-desktop-screenshot-too-much-context"><a class="header" href="#mistake-1-full-desktop-screenshot-too-much-context">Mistake 1: Full Desktop Screenshot (Too Much Context)</a></h3>
<p><strong>Problem</strong>: Screenshot shows taskbar, desktop icons, unrelated windows
<strong>Fix</strong>: Crop to <strong>browser window only</strong> or <strong>DevTools panel only</strong></p>
<hr />
<h3 id="mistake-2-text-too-small-low-resolution"><a class="header" href="#mistake-2-text-too-small-low-resolution">Mistake 2: Text Too Small (Low Resolution)</a></h3>
<p><strong>Problem</strong>: Took screenshot on 4K monitor but text is tiny in PDF
<strong>Fix</strong>: Increase browser zoom to 125-150% before screenshot, OR use higher DPI export</p>
<hr />
<h3 id="mistake-3-personal-bookmarks-visible"><a class="header" href="#mistake-3-personal-bookmarks-visible">Mistake 3: Personal Bookmarks Visible</a></h3>
<p><strong>Problem</strong>: Bookmark bar shows ‚ÄúPersonal Email‚Äù, ‚ÄúWork Project‚Äù, ‚ÄúBank Login‚Äù
<strong>Fix</strong>: Hide bookmark bar (<code>Ctrl + Shift + B</code>) OR crop it out OR blur it</p>
<hr />
<h3 id="mistake-4-username-in-file-path"><a class="header" href="#mistake-4-username-in-file-path">Mistake 4: Username in File Path</a></h3>
<p><strong>Problem</strong>: Screenshot shows <code>C:\Users\JohnSmith\IdeaProjects\comp2850\...</code>
<strong>Fix</strong>:</p>
<ul>
<li>Option A: Crop file path out</li>
<li>Option B: Blur username portion</li>
<li>Option C: Use environment variable in terminal: <code>~/IdeaProjects/...</code> instead of full path</li>
</ul>
<hr />
<h3 id="mistake-5-dark-mode-code-unreadable"><a class="header" href="#mistake-5-dark-mode-code-unreadable">Mistake 5: Dark Mode Code Unreadable</a></h3>
<p><strong>Problem</strong>: White text on black background exports as low-contrast gray in PDF
<strong>Fix</strong>:</p>
<ul>
<li>Use <strong>light theme</strong> in DevTools (Settings ‚Üí Appearance ‚Üí Light)</li>
<li>OR export as PNG (not JPG which loses contrast)</li>
</ul>
<hr />
<h2 id="12-accessibility-of-screenshots-for-your-portfolio"><a class="header" href="#12-accessibility-of-screenshots-for-your-portfolio">12. Accessibility of Screenshots (For Your Portfolio)</a></h2>
<p>When preparing your <strong>final portfolio</strong>, ensure screenshots are accessible:</p>
<h3 id="add-alt-text-if-embedding-in-web-portfolio"><a class="header" href="#add-alt-text-if-embedding-in-web-portfolio">Add Alt Text (If Embedding in Web Portfolio)</a></h3>
<pre><code class="language-html">&lt;img src="aria-live-region.png"
     alt="Chrome DevTools showing div element with id='status', role='status', and aria-live='polite' attributes"&gt;
</code></pre>
<h3 id="provide-captions-in-pdf-submission"><a class="header" href="#provide-captions-in-pdf-submission">Provide Captions (In PDF Submission)</a></h3>
<p><strong>Example</strong>:</p>
<pre><code>Figure 1: ARIA live region in DevTools
The status div has role="status" and aria-live="polite", ensuring screen readers announce task additions without interrupting the user.
</code></pre>
<h3 id="use-high-contrast"><a class="header" href="#use-high-contrast">Use High Contrast</a></h3>
<ul>
<li>Avoid light gray text on white backgrounds</li>
<li>Annotations should be <strong>red</strong> (high contrast) not light pink</li>
<li>Ensure focus indicators are visible (3:1 contrast minimum)</li>
</ul>
<hr />
<h2 id="13-quick-reference-screenshot-workflow"><a class="header" href="#13-quick-reference-screenshot-workflow">13. Quick Reference: Screenshot Workflow</a></h2>
<ol>
<li><strong>Before</strong>: Hide bookmark bar, close extra tabs, use test data</li>
<li><strong>Capture</strong>: Use tool‚Äôs region select (not full screen)</li>
<li><strong>Inspect</strong>: Check for PII (usernames, emails, file paths)</li>
<li><strong>Scrub</strong>: Blur or crop sensitive areas</li>
<li><strong>Annotate</strong> (if needed): Add red arrows/boxes to highlight</li>
<li><strong>Save</strong>: PNG format, descriptive filename</li>
<li><strong>Organise</strong>: Move to appropriate evidence subfolder</li>
<li><strong>Verify</strong>: Open in PDF viewer at 100% zoom, check readability</li>
</ol>
<hr />
<h2 id="14-example-evidence-package"><a class="header" href="#14-example-evidence-package">14. Example Evidence Package</a></h2>
<p>Here‚Äôs what a complete screenshot evidence folder might look like for <strong>Task 1 (Week 9)</strong>:</p>
<pre><code>wk09/evidence/screenshots/
‚îú‚îÄ‚îÄ 01-baseline-interface/
‚îÇ   ‚îú‚îÄ‚îÄ task-list-full-view.png              (1280x720, 156KB)
‚îÇ   ‚îú‚îÄ‚îÄ add-task-form-validation-error.png   (800x600, 89KB)
‚îÇ   ‚îî‚îÄ‚îÄ filter-results-no-announcement.png   (1280x720, 142KB)
‚îÇ
‚îú‚îÄ‚îÄ 02-html-structure/
‚îÇ   ‚îú‚îÄ‚îÄ aria-live-region-status-devtools.png (1024x768, 203KB)
‚îÇ   ‚îú‚îÄ‚îÄ form-labels-aria-describedby.png     (800x600, 134KB)
‚îÇ   ‚îî‚îÄ‚îÄ skip-link-html-structure.png         (800x600, 98KB)
‚îÇ
‚îú‚îÄ‚îÄ 03-screen-reader-testing/
‚îÇ   ‚îú‚îÄ‚îÄ nvda-task-added-success.png          (600x400, 45KB)
‚îÇ   ‚îú‚îÄ‚îÄ nvda-validation-error-not-announced.png (600x400, 52KB)
‚îÇ   ‚îî‚îÄ‚îÄ voiceover-delete-button-label.png    (700x300, 67KB)
‚îÇ
‚îú‚îÄ‚îÄ 04-network-performance/
‚îÇ   ‚îú‚îÄ‚îÄ add-task-post-timing-234ms.png       (900x700, 178KB)
‚îÇ   ‚îú‚îÄ‚îÄ delete-task-post-timing-187ms.png    (900x700, 165KB)
‚îÇ   ‚îî‚îÄ‚îÄ filter-get-timing-1847ms.png         (900x700, 189KB)
‚îÇ
‚îî‚îÄ‚îÄ 05-after-redesign/
    ‚îú‚îÄ‚îÄ improved-error-aria-alert.png        (1280x720, 156KB)
    ‚îú‚îÄ‚îÄ nvda-now-announces-error.png         (600x400, 48KB)
    ‚îî‚îÄ‚îÄ devtools-role-alert-added.png        (800x600, 145KB)
</code></pre>
<p><strong>Total</strong>: ~20 screenshots, ~2MB compressed (well within Gradescope limits)</p>
<hr />
<h2 id="resources-2"><a class="header" href="#resources-2">Resources</a></h2>
<ul>
<li><strong>WCAG 2.2 Images of Text</strong>: https://www.w3.org/WAI/WCAG22/Understanding/images-of-text</li>
<li><strong>UK GDPR Compliance</strong>: https://ico.org.uk/for-organisations/guide-to-data-protection/</li>
<li><strong>Screenshot Tools Comparison</strong>: https://alternativeto.net/software/snipping-tool/</li>
</ul>
<hr />
<p><strong>Guide Version</strong>: 1.0
<strong>Last Updated</strong>: 2025-10-14
<strong>Module</strong>: COMP2850 HCI
<strong>Contact</strong>: See module Minerva page for help with evidence submission</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="process-visuals"><a class="header" href="#process-visuals">Process Visuals</a></h1>
<p>High-level diagrams that map the Week 6-11 journey, evidence pipelines, component structure, and critique loop. Each figure renders via Mermaid; follow the anchor links from labs or the index to revisit them.</p>
<h2 id="semester-flow"><a class="header" href="#semester-flow">Semester Flow</a></h2>
<pre class="mermaid">graph LR
  W6[Week 6&lt;br/&gt;Server-first&lt;br/&gt;Needs-finding]
  W7[Week 7&lt;br/&gt;Ethics&lt;br/&gt;Accessibility]
  W8[Week 8&lt;br/&gt;Prototyping&lt;br/&gt;Constraints]
  W9[Week 9&lt;br/&gt;Evaluation&lt;br/&gt;Pilots]
  W10[Week 10&lt;br/&gt;Analysis&lt;br/&gt;Redesign]
  W11[Week 11&lt;br/&gt;Studio Crit&lt;br/&gt;Portfolio]

  W6 --&gt; W7
  W7 --&gt; W8
  W8 --&gt; W9
  W9 --&gt; W10
  W10 --&gt; W11
</pre>
<p><strong>What it shows:</strong> the six-week arc from observation to wrap-up, one swimlane per theme.</p>
<h2 id="evidence-map"><a class="header" href="#evidence-map">Evidence Map</a></h2>
<pre class="mermaid">graph TD
  A[Needs-finding stories] --&gt; B[Inclusive backlog]
  B --&gt; C[WCAG &amp; heuristic audit]
  C --&gt; D[Pilots &amp; metrics]
  D --&gt; E[Analysis &amp; prioritisation]
  E --&gt; F[Inclusive redesign]
  F --&gt; G[Task 2 evidence pack]
  G --&gt; H[Studio crit &amp; wrap-up]
  H --&gt;|Carry forward| B
</pre>
<p><strong>What it shows:</strong> how artefacts produced in each lab feed Task 1 and Task 2, ensuring evidence chains stay intact.</p>
<h2 id="template-hierarchy"><a class="header" href="#template-hierarchy">Template Hierarchy</a></h2>
<pre class="mermaid">graph TD
  Base[_layout/base.peb&lt;br/&gt;skip link, live region, Pico.css]
  Base --&gt; Index[tasks/index.peb]
  Index --&gt; List[tasks/_list.peb]
  List --&gt; Item[tasks/_item.peb]
  Index --&gt; Pager[tasks/_pager.peb]
  Item --&gt;|Forms| Routes[(Ktor routes)]
  Pager --&gt;|Links| Routes
  Routes --&gt; HTMX[HTMX fragment responses]
  Routes --&gt; PRG[Full-page PRG responses]
</pre>
<p><strong>What it shows:</strong> relationships between the Pebble layout, task partials, and Ktor routes used in Week 8‚Äôs partial refactor.</p>
<h2 id="crit-loop"><a class="header" href="#crit-loop">Crit Loop</a></h2>
<pre class="mermaid">graph TD
  Present[Evidence-led demo]
  Present --&gt; Feedback[Peer &amp; staff critique]
  Feedback --&gt; Notes[Crit notes &amp; backlog updates]
  Notes --&gt; Portfolio[Portfolio &amp; wrap-up]
  Portfolio --&gt; Plan[Semester 2 planning]
  Plan --&gt; Present
</pre>
<p><strong>What it shows:</strong> the continuous feedback cycle students should follow during the Week 11 studio critique and portfolio wrap-up.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="starter-code-repository"><a class="header" href="#starter-code-repository">Starter Code Repository</a></h1>
<blockquote>
<p>Starter repository URL: https://github.com/julianbrooks/comp2850-hci-starter</p>
</blockquote>
<p>Use this reference to navigate between the mdBook documentation and the runnable starter repository. All paths are relative to the repo root (<code>starter-repo/</code>).</p>
<h2 id="week-6"><a class="header" href="#week-6">Week 6</a></h2>
<ul>
<li>Starter baseline: <code>starter-repo/</code>
<ul>
<li>Lab pack: <code>starter-repo/wk06/</code></li>
<li>Server code scaffold: <code>starter-repo/src/main/</code></li>
</ul>
</li>
</ul>
<h2 id="week-7"><a class="header" href="#week-7">Week 7</a></h2>
<ul>
<li>Lab pack: <code>starter-repo/wk07/</code></li>
<li>Note: Inline edit implementation is built during this week‚Äôs labs</li>
</ul>
<h2 id="week-8"><a class="header" href="#week-8">Week 8</a></h2>
<ul>
<li>Lab pack: <code>starter-repo/wk08/</code></li>
<li>Note: Pagination and filtering utilities are built during this week‚Äôs labs</li>
</ul>
<h2 id="week-9"><a class="header" href="#week-9">Week 9</a></h2>
<ul>
<li>Lab pack: <code>starter-repo/wk09/</code></li>
<li>Note: Instrumentation utilities (<code>utils/Logger.kt</code>, <code>utils/Timing.kt</code>) are built during this week‚Äôs labs</li>
</ul>
<h2 id="week-10"><a class="header" href="#week-10">Week 10</a></h2>
<ul>
<li>Lab pack: <code>starter-repo/wk10/</code></li>
<li>Analysis scaffolds and templates provided</li>
</ul>
<h2 id="week-11"><a class="header" href="#week-11">Week 11</a></h2>
<ul>
<li>Lab pack: <code>starter-repo/wk11/</code></li>
<li>Wrap-up templates and critique materials provided</li>
</ul>
<h2 id="quick-tips"><a class="header" href="#quick-tips">Quick Tips</a></h2>
<ul>
<li>Use <code>git status</code> inside <code>starter-repo/</code> to check your progress</li>
<li>Check the README inside each <code>wk0X/</code> directory for specific instructions</li>
<li>Each week‚Äôs lab pack includes templates, scaffolds, and deliverable checklists</li>
</ul>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->
        <script src="mermaid.min.js"></script>
        <script src="mermaid-init.js"></script>

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>


    </div>
    </body>
</html>
