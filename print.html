<!DOCTYPE HTML>
<html lang="en" class="navy sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>COMP2850 ‚Ä¢ Human-Computer Interaction</title>
        <meta name="robots" content="noindex">


        <!-- Custom HTML head -->

        <meta name="description" content="HCI module covering server-first architecture, accessibility, privacy by design, and evaluation (Weeks 6-11)">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="css/admonish.css">
        <link rel="stylesheet" href="css/custom.css">
        <link rel="stylesheet" href="css/retro-theme.css">
        <link rel="stylesheet" href="./mdbook-admonish.css">


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "";
            const default_light_theme = "navy";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>‚Üê</kbd> or <kbd>‚Üí</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('navy')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">COMP2850 ‚Ä¢ Human-Computer Interaction</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="comp2850--human-computer-interaction"><a class="header" href="#comp2850--human-computer-interaction">COMP2850 ‚Ä¢ Human-Computer Interaction</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/University-Leeds-green" alt="University of Leeds" />
<img src="https://img.shields.io/badge/Year-2025%2F26-orange" alt="Academic Year" /></p>
<hr />
<h2 id="welcome"><a class="header" href="#welcome">Welcome</a></h2>
<p>This is the <strong>HCI (Human-Computer Interaction)</strong> component of <strong>COMP2850</strong>, running from <strong>Week 6 to Week 11</strong>. You'll build <strong>inclusive web interfaces</strong> using <strong>HTML as your UI layer</strong> (no React/Vue/Angular). We follow the <strong><a href="https://hypermedia.systems/">hypermedia systems</a></strong> approach‚Äîdynamic, accessible UIs built with server-rendered HTML and progressive enhancement.</p>
<p><strong>Core approaches</strong>:</p>
<ul>
<li><strong><a href="references/htmx-patterns.html">Hypermedia-driven interfaces (HTMX)</a></strong> - Dynamic HTML UIs without JavaScript frameworks</li>
<li><strong><a href="references/accessibility-testing.html">Accessibility-first design</a></strong> - WCAG 2.2 AA compliance, screen reader testing, keyboard navigation</li>
<li><strong><a href="references/htmx-patterns.html">Progressive enhancement</a></strong> - No-JS baseline, HTMX enhancements layered on top</li>
<li><strong><a href="references/server-first.html">Server-rendered HTML</a></strong> - Kotlin/Ktor + Pebble templates generate complete pages</li>
<li><strong><a href="references/privacy-by-design.html">Privacy by design</a></strong> - UK GDPR compliance, anonymous instrumentation</li>
<li><strong><a href="references/evaluation-guide.html">Evidence-based iteration</a></strong> - Task-based evaluation, metrics analysis, data-driven redesign</li>
</ul>
<p><strong>New to these terms?</strong> See the <strong><a href="references/glossary.html">Glossary</a></strong> for definitions of HTMX, AJAX, ARIA, WCAG, and 80+ other terms.</p>
<hr />
<h2 id="module-structure-for-semester-1"><a class="header" href="#module-structure-for-semester-1">Module Structure for Semester 1</a></h2>
<h3 id="weeks-1-5-object-oriented-programming-oop"><a class="header" href="#weeks-1-5-object-oriented-programming-oop">Weeks 1-5: Object-Oriented Programming (OOP)</a></h3>
<p>Foundation in Kotlin, classes, inheritance, interfaces. See <a href="https://python33r.github.io/comp2850-kotlin/index.html">OOP mdBook</a>.</p>
<h3 id="weeks-6-11-human-computer-interaction-hci"><a class="header" href="#weeks-6-11-human-computer-interaction-hci">Weeks 6-11: Human-Computer Interaction (HCI)</a></h3>
<p><strong><a href="wk06/wk6-lab1-html-css-htmx.html">Week 6</a></strong> ‚Äî Intro: Server-first foundations + needs-finding</p>
<p><strong><a href="wk07/wk7-lab1-ethics-inline-edit.html">Week 7</a></strong> ‚Äî Ethics in practice + accessibility audit</p>
<p><strong><a href="wk08/wk8-lab1-prototyping-constraints.html">Week 8</a></strong> ‚Äî Prototyping, constraints, no-JS parity</p>
<p><strong><a href="wk09/wk9-lab1-eval-plan-instrumentation.html">Week 9</a></strong> ‚Äî Evaluation planning + instrumentation</p>
<p><strong><a href="wk10/wk10-lab1-analysis-prioritisation.html">Week 10</a></strong> ‚Äî Analysis, prioritisation, redesign</p>
<p><strong><a href="wk11/wk11-lab1-studio-crit.html">Week 11</a></strong> ‚Äî Studio critique + portfolio wrap-up</p>
<h3 id="semester-flow-weeks-6-11"><a class="header" href="#semester-flow-weeks-6-11">Semester Flow (Weeks 6-11)</a></h3>
<pre class="mermaid">graph LR
  W6[Week 6&lt;br/&gt;Server-first&lt;br/&gt;Needs-finding]
  W7[Week 7&lt;br/&gt;Ethics&lt;br/&gt;Accessibility]
  W8[Week 8&lt;br/&gt;Prototyping&lt;br/&gt;Constraints]
  W9[Week 9&lt;br/&gt;Evaluation&lt;br/&gt;Pilots]
  W10[Week 10&lt;br/&gt;Analysis&lt;br/&gt;Redesign]
  W11[Week 11&lt;br/&gt;Studio Crit&lt;br/&gt;Portfolio]

  W6 --&gt; W7
  W7 --&gt; W8
  W8 --&gt; W9
  W9 --&gt; W10
  W10 --&gt; W11
</pre>
<p><small>See <a href="references/process-visuals.html#semester-flow">Process Visuals</a> for captions and alternative formats.</small></p>
<hr />
<h2 id="assessment"><a class="header" href="#assessment">Assessment</a></h2>
<p>Two evidence-based tasks assess all 13 HCI Learning Outcomes:</p>
<h3 id="task-1-evaluation--findings"><a class="header" href="#task-1-evaluation--findings">Task 1: Evaluation &amp; Findings</a></h3>
<ul>
<li><strong>Launch</strong>: Week 8 Lab 2</li>
<li><strong>Submit</strong>: Week 9 Lab 2 (Gradescope)</li>
<li>Design and execute task-based peer pilots (n=4+), collect quantitative and qualitative data, synthesise findings with evidence chains</li>
<li><strong>Learning Outcomes</strong>: LO1, LO2, LO6, LO8, LO11, LO12, LO13</li>
</ul>
<h3 id="task-2-redesign--verification"><a class="header" href="#task-2-redesign--verification">Task 2: Redesign &amp; Verification</a></h3>
<ul>
<li><strong>Launch</strong>: Week 10 Lab 1</li>
<li><strong>Submit</strong>: Week 11 Lab 2 (Gradescope)</li>
<li>Implement inclusive redesign based on Task 1 findings, verify via regression testing (30+ checks) and re-pilots (n=2+), analyse societal impacts</li>
<li><strong>Learning Outcomes</strong>: LO3, LO4, LO5, LO6, LO7, LO9, LO10, LO12, LO13</li>
</ul>
<p><strong>See <a href="assessment/overview.html">Assessment Overview</a> for full details</strong>, timelines, templates, marking criteria, and FAQs.</p>
<p><strong>Weighting</strong>: See Minerva for grade breakdown.</p>
<hr />
<h2 id="key-principles"><a class="header" href="#key-principles">Key Principles</a></h2>
<h3 id="1-people-centred-language"><a class="header" href="#1-people-centred-language">1. People-Centred Language</a></h3>
<p>We use "<strong>person navigating with a screen reader</strong>" (not "blind user"), "<strong>person navigating by keyboard</strong>" (not
"disabled user"), or "participant" in evaluation contexts.<br />
<strong>Why this matters:</strong><br />
Disability arises from barriers in the environment‚Äîinaccessible design, missing features,
exclusionary assumptions‚Äînot from individual impairment.<br />
People-first language centres the person, not a diagnostic label.</p>
<h3 id="2-privacy-by-design"><a class="header" href="#2-privacy-by-design">2. Privacy by Design</a></h3>
<p>No personal data collected. Anonymous session IDs only. UK GDPR compliant (Data Protection Act 2018).</p>
<h3 id="3-progressive-enhancement"><a class="header" href="#3-progressive-enhancement">3. Progressive Enhancement</a></h3>
<p>Start with semantic HTML. Add JavaScript sparingly. Ensure all features work without JS.</p>
<h3 id="4-evidence-led-design"><a class="header" href="#4-evidence-led-design">4. Evidence-Led Design</a></h3>
<p>Every claim must be backed by data (pilot metrics, quotes, WCAG audits). No assumptions.</p>
<hr />
<h2 id="tools--technologies"><a class="header" href="#tools--technologies">Tools &amp; Technologies</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Tool</th><th>Purpose</th></tr></thead><tbody>
<tr><td><strong>HTMX</strong></td><td>Dynamic updates without full page reload</td></tr>
<tr><td><strong>Kotlin/Ktor</strong></td><td>Server-side routing, template rendering</td></tr>
<tr><td><strong>Pebble</strong></td><td>HTML templating (server-rendered)</td></tr>
<tr><td><strong>axe DevTools</strong></td><td>Accessibility auditing (WCAG 2.2)</td></tr>
<tr><td><strong>NVDA / VoiceOver</strong></td><td>Screen reader testing</td></tr>
<tr><td><strong>Colour Contrast Analyser</strong></td><td>WCAG 1.4.3 compliance</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="module-aims"><a class="header" href="#module-aims">Module Aims</a></h2>
<p>This module aims to enable you to:</p>
<ol>
<li>Apply HCI principles to design inclusive interfaces</li>
<li>Evaluate accessibility and ethics in interactive systems</li>
<li>Implement server-first architecture with progressive enhancement</li>
<li>Communicate design decisions with evidence</li>
</ol>
<p>These aims are achieved through <strong>13 specific Learning Outcomes</strong> detailed across Weeks 6-11. See the <strong><a href="references/learning-outcomes.html">Learning Outcomes Reference</a></strong> for mappings to weeks, labs, and assessment tasks.</p>
<hr />
<h2 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h2>
<ol>
<li><strong>Read Week 6 Lab 1</strong>: <a href="wk06/wk6-lab1-html-css-htmx.html">Server-first foundations with HTMX</a></li>
<li><strong>Clone starter pack</strong>: <code>git clone [repo URL]</code> (see Minerva for link)</li>
<li><strong>Install/setup tools</strong>: JDK 21+, Gradle 8+, axe DevTools, IntelliJ IDEA (or) VSCode (or) Codespaces - choose one</li>
<li><strong>Attend lab sessions</strong>: Bragg 2.05 Main Lab (check your timetable for days/times)</li>
<li><strong>Independent Study</strong>: We expect you to manage your time and complete all module requirements</li>
</ol>
<hr />
<h2 id="support"><a class="header" href="#support">Support</a></h2>
<ul>
<li><strong>Lab sessions</strong>: Staff on hand for questions (2-hour taught labs &amp; open lab sessions with TA's available)</li>
<li><strong>Office hours</strong>: Contact teaching team for availability</li>
<li><strong>Discussion board</strong>: MS Teams COMP2850 forum for all module peer/staff questions</li>
<li><strong>Personal issues</strong>: Contact via Teams DM or email module staff directly</li>
<li><strong>Bugs in course materials</strong>: If you spot errors, typos, or mismatches in the mdBook content, contact Julian Brooks (author of the HCI materials) at <a href="mailto:j.brooks2@leeds.ac.uk">j.brooks2@leeds.ac.uk</a></li>
</ul>
<hr />
<h2 id="references"><a class="header" href="#references">References</a></h2>
<ul>
<li><strong>HTMX</strong>: <a href="https://hypermedia.systems/">hypermedia.systems</a> (Carson Gross et al., 2023)</li>
<li><strong>WCAG 2.2</strong>: <a href="https://www.w3.org/WAI/WCAG22/quickref/">W3C Quick Reference</a></li>
<li><strong>GOV.UK Design System</strong>: <a href="https://design-system.service.gov.uk/">Patterns &amp; Components</a></li>
<li><strong>Privacy by Design</strong>: <a href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/">ICO Guidance</a></li>
</ul>
<hr />
<p><strong>Module Lead</strong>: [Amy Brereton]
<strong>Teaching Team</strong>: [Ban Adil Naji Al-Jassani, Amy Brereton, Julian Brooks, Nick Efford, Will Kingdon, Ping Lu, David
Ofili, Jonathan Pickering, Xiao Wang]
<strong>Academic Year</strong>: 25/26
<strong>Department</strong>: School of Computer Science, University of Leeds</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-6--lab-1-server-first-foundations-with-htmx"><a class="header" href="#week-6--lab-1-server-first-foundations-with-htmx">Week 6 ‚Ä¢ Lab 1: Server-First Foundations with HTMX</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-6-orange" alt="Week 6" />
<img src="https://img.shields.io/badge/Lab-1-green" alt="Lab 1" />
<img src="https://img.shields.io/badge/Status-Draft-yellow" alt="Status" /></p>
<hr />
<h2 id="terminology-note"><a class="header" href="#terminology-note">Terminology Note</a></h2>
<p>Throughout COMP2850 we use <strong>people-centred language</strong> (e.g., "person using a screen reader") rather than deficit-based terms (e.g., "blind user"). This reflects contemporary inclusive-design practice and acknowledges that disability arises from environmental barriers, not individual impairment.</p>
<hr />
<h2 id="pre-reading"><a class="header" href="#pre-reading">Pre-reading</a></h2>
<p><strong>Essential</strong></p>
<ul>
<li><a href="https://hypermedia.systems/">Gross, Stepinski &amp; Ak≈üim≈üek (2023). <em>Hypermedia Systems</em>, Ch. 1-3</a></li>
<li><a href="https://htmx.org/docs/">HTMX Documentation: Core Concepts</a></li>
<li><a href="https://www.gov.uk/service-manual/technology/using-progressive-enhancement">GOV.UK Service Manual: Progressive Enhancement</a></li>
</ul>
<p><strong>Recommended</strong></p>
<ul>
<li><a href="https://www.w3.org/WAI/WCAG22/quickref/">W3C (2024). WCAG 2.2 Quick Reference</a></li>
<li><a href="https://developer.mozilla.org/en-US/docs/Glossary/Semantics#semantic_elements">MDN: Semantic HTML</a></li>
<li><a href="wk06/../references/privacy-by-design.html">Privacy by Design</a> (module-specific ethics guidance)</li>
</ul>
<blockquote>
<p><strong>Starter code</strong>: Clone the <a href="wk06/../../resources/code-resources.html#week-6">starter repository</a> or download the zip before the lab.</p>
</blockquote>
<h2 id="introduction"><a class="header" href="#introduction">Introduction</a></h2>
<h3 id="context"><a class="header" href="#context">Context</a></h3>
<p>This lab marks the beginning of the <strong>HCI component</strong> of COMP2850 (Weeks 6-11). For the first five weeks you built foundational Kotlin/OOP skills. Now you'll apply those skills to a real-world HCI challenge: building inclusive, accessible web applications using <strong>server-first architecture</strong> with <strong>progressive enhancement</strong>.</p>
<p>Modern web development often defaults to client-heavy JavaScript frameworks (React, Vue, Angular). While powerful, these approaches can create accessibility barriers:</p>
<ul>
<li>Screen readers struggle with dynamically-rendered content</li>
<li>Keyboard navigation breaks when focus management is incorrect</li>
<li>Customers with JavaScript disabled (corporate firewalls, data-saving modes) lose functionality</li>
<li>Development complexity increases, making accessibility fixes expensive to retrofit</li>
</ul>
<p><strong>Server-first architecture</strong> inverts this model: the server renders complete, semantic HTML that works <em>without</em> JavaScript. We then add HTMX as a <strong>progressive enhancement layer</strong> to improve interactivity without sacrificing the baseline experience.</p>
<h3 id="why-this-matters"><a class="header" href="#why-this-matters">Why This Matters</a></h3>
<p><strong>Professionally</strong>, server-first patterns are gaining traction in industry:</p>
<ul>
<li><strong>GOV.UK</strong> (UK government digital services) mandates progressive enhancement</li>
<li><strong>Basecamp</strong> (project management, 3M+ customers) uses server-rendered HTML + Turbo (similar to HTMX)</li>
<li><strong>GitHub</strong> serves primarily server-rendered HTML with JavaScript enhancements</li>
<li><strong>Stack Overflow</strong> is 90% server-rendered for performance and accessibility</li>
</ul>
<p><strong>Academically</strong>, this lab introduces core HCI concepts:</p>
<ul>
<li><strong>Inclusion by design</strong>: building accessibility into the foundation, not retrofitting it</li>
<li><strong>Progressive enhancement</strong>: layering capabilities so everyone gets a baseline experience</li>
<li><strong>Server-side rendering (SSR)</strong>: generating HTML on the server vs. client-side rendering (CSR)</li>
<li><strong>Hypermedia-driven architecture</strong>: using HTML as the engine of application state (HATEOAS)</li>
</ul>
<h2 id="learning-focus"><a class="header" href="#learning-focus">Learning Focus</a></h2>
<h3 id="lab-objectives"><a class="header" href="#lab-objectives">Lab Objectives</a></h3>
<p>By the end of this session, you will have:</p>
<ul>
<li>Implemented server-first routes using Ktor and Pebble templates</li>
<li>Enhanced a form with HTMX while maintaining no-JS functionality</li>
<li>Created accessible HTML with semantic structure, ARIA live regions, and skip links</li>
<li>Verified keyboard navigation, screen reader announcements, and no-JS parity</li>
</ul>
<h3 id="learning-outcomes-addressed"><a class="header" href="#learning-outcomes-addressed">Learning Outcomes Addressed</a></h3>
<p>This lab contributes to the following module Learning Outcomes (<a href="wk06/../references/learning-outcomes.html">full definitions</a>):</p>
<ul>
<li><strong>LO5</strong>: Create interface prototypes ‚Äî evidenced by functional HTMX task list</li>
<li><strong>LO7</strong>: Analyse design constraints ‚Äî evidenced by no-JS parity verification</li>
<li><strong>LO9</strong>: Apply inclusive design ‚Äî evidenced by semantic HTML + ARIA implementation</li>
<li><strong>LO13</strong>: Integrate HCI with SE ‚Äî evidenced by server-first architecture patterns</li>
</ul>
<hr />
<h2 id="key-concepts"><a class="header" href="#key-concepts">Key Concepts</a></h2>
<h3 id="1-server-first-architecture"><a class="header" href="#1-server-first-architecture">1. Server-First Architecture</a></h3>
<p><strong>Server-first</strong> (also called "server-side rendering" or SSR) means the server generates complete HTML pages and sends them to the browser. The browser displays them immediately without waiting for JavaScript to run.</p>
<p><strong>Example</strong>:</p>
<pre><code>Customer requests /tasks
‚Üí Server queries database
‚Üí Server renders tasks/index.peb template with data
‚Üí Server sends complete HTML to browser
‚Üí Browser displays page (works even if JS is disabled)
</code></pre>
<p><strong>Contrast with client-side rendering (CSR)</strong>:</p>
<pre><code>Customer requests /tasks
‚Üí Server sends empty HTML + JavaScript bundle
‚Üí Browser downloads and executes JS
‚Üí JS makes API call to /api/tasks
‚Üí JS renders HTML and inserts into DOM
‚ùå If JS fails to load, page is blank
</code></pre>
<p><strong>Benefits</strong>:</p>
<ul>
<li>‚úÖ Faster initial page load (no JS parsing delay)</li>
<li>‚úÖ Works without JavaScript (resilience)</li>
<li>‚úÖ Search engines can index content (SEO)</li>
<li>‚úÖ Screen readers receive semantic HTML immediately</li>
</ul>
<h3 id="2-progressive-enhancement"><a class="header" href="#2-progressive-enhancement">2. Progressive Enhancement</a></h3>
<p><strong>Progressive enhancement</strong> is a design philosophy: start with a baseline experience that works for everyone, then add enhancements for browsers that support them.</p>
<p><strong>Layers</strong>:</p>
<ol>
<li><strong>HTML</strong> (content layer): semantic markup, accessible by default</li>
<li><strong>CSS</strong> (presentation layer): styling, gracefully degrades if not supported</li>
<li><strong>JavaScript</strong> (behaviour layer): dynamic interactions, optional</li>
</ol>
<p><strong>Example (COMP2850 task manager)</strong>:</p>
<ul>
<li><strong>Baseline</strong>: Form POSTs to <code>/tasks</code>, server validates, redirects (PRG pattern)</li>
<li><strong>Enhancement</strong>: HTMX intercepts POST, swaps HTML fragment, no page reload</li>
</ul>
<p><strong>Key principle</strong>: JavaScript failure (network error, blocked script, unsupported browser) should not break core functionality.</p>
<h3 id="3-htmx-fundamentals"><a class="header" href="#3-htmx-fundamentals">3. HTMX Fundamentals</a></h3>
<p><strong>HTMX</strong> extends HTML with attributes that trigger AJAX requests and update the DOM. Instead of writing JavaScript, you declare behaviour in HTML.</p>
<p><strong>Core attributes</strong>:</p>
<div class="table-wrapper"><table><thead><tr><th>Attribute</th><th>Purpose</th><th>Example</th></tr></thead><tbody>
<tr><td><code>hx-get</code></td><td>HTTP GET request</td><td><code>&lt;button hx-get="/tasks/1"&gt;Load&lt;/button&gt;</code></td></tr>
<tr><td><code>hx-post</code></td><td>HTTP POST request</td><td><code>&lt;form hx-post="/tasks"&gt;</code></td></tr>
<tr><td><code>hx-target</code></td><td>Where to insert response</td><td><code>hx-target="#task-list"</code></td></tr>
<tr><td><code>hx-swap</code></td><td>How to insert response</td><td><code>hx-swap="beforeend"</code> (append), <code>hx-swap="outerHTML"</code> (replace)</td></tr>
<tr><td><code>hx-swap-oob</code></td><td>Out-of-band swap (update element not in target)</td><td><code>&lt;div id="status" hx-swap-oob="true"&gt;</code></td></tr>
</tbody></table>
</div>
<p><strong>How HTMX works</strong>:</p>
<ol>
<li>Customer triggers event (click, submit)</li>
<li>HTMX makes AJAX request to server</li>
<li>Server returns HTML fragment (not JSON)</li>
<li>HTMX swaps fragment into target element</li>
<li>Screen reader live regions announce changes</li>
</ol>
<p><strong>Why this helps accessibility</strong>:</p>
<ul>
<li>Server controls HTML structure (consistent semantics)</li>
<li>No manual DOM manipulation (reduces ARIA errors)</li>
<li>Live regions work automatically (if server includes them)</li>
</ul>
<h3 id="4-post-redirect-get-prg-pattern"><a class="header" href="#4-post-redirect-get-prg-pattern">4. Post-Redirect-Get (PRG) Pattern</a></h3>
<p><strong>Problem</strong>: If a person submits a form with POST and then refreshes the page, the browser re-submits the form
(duplicate submission).</p>
<p><strong>Solution</strong>: After processing a POST, return a redirect (HTTP 303) to a GET URL.</p>
<p><strong>Flow</strong>:</p>
<pre><code>1. Customer submits form ‚Üí POST /tasks (title="Buy milk")
2. Server validates, saves to database
3. Server returns: HTTP 303 See Other, Location: /tasks
4. Browser follows redirect ‚Üí GET /tasks
5. Server renders updated task list
6. Customer sees new task; refresh = safe GET (no duplicate)
</code></pre>
<p><strong>In Ktor</strong>:</p>
<pre><code class="language-kotlin">post("/tasks") {
    val title = call.receiveParameters()["title"].orEmpty().trim()
    if (title.isNotBlank()) {
        repo.add(title)
    }
    call.respondRedirect("/tasks") // PRG redirect
}
</code></pre>
<h3 id="5-aria-live-regions"><a class="header" href="#5-aria-live-regions">5. ARIA Live Regions</a></h3>
<p><strong>ARIA</strong> (Accessible Rich Internet Applications) provides attributes that help screen readers understand dynamic content.</p>
<p><strong>Live regions</strong> announce changes without moving focus. Essential for AJAX-updated content.</p>
<p><strong>Key attributes</strong>:</p>
<div class="table-wrapper"><table><thead><tr><th>Attribute</th><th>Purpose</th><th>Example</th></tr></thead><tbody>
<tr><td><code>role="status"</code></td><td>Announces non-critical updates</td><td><code>&lt;div role="status" aria-live="polite"&gt;Task added&lt;/div&gt;</code></td></tr>
<tr><td><code>role="alert"</code></td><td>Announces critical errors</td><td><code>&lt;div role="alert"&gt;Title is required&lt;/div&gt;</code></td></tr>
<tr><td><code>aria-live="polite"</code></td><td>Waits for customer to finish before announcing</td><td>Status messages</td></tr>
<tr><td><code>aria-live="assertive"</code></td><td>Interrupts to announce immediately</td><td>Error messages</td></tr>
</tbody></table>
</div>
<p><strong>Example (COMP2850 pattern)</strong>:</p>
<pre><code class="language-html">&lt;!-- In base.peb --&gt;
&lt;div id="status" role="status" aria-live="polite" class="visually-hidden"&gt;&lt;/div&gt;

&lt;!-- Server response (HTMX OOB swap) --&gt;
&lt;div id="status" hx-swap-oob="true"&gt;Task "Buy milk" added&lt;/div&gt;
</code></pre>
<p><strong>How it works</strong>:</p>
<ol>
<li>HTMX request completes</li>
<li>Server returns fragment + status div with <code>hx-swap-oob="true"</code></li>
<li>HTMX swaps main content <em>and</em> status div (out-of-band)</li>
<li>Screen reader detects status div change, announces "Task 'Buy milk' added"</li>
</ol>
<hr />
<h2 id="activity-1-project-setup--scaffold-inspection"><a class="header" href="#activity-1-project-setup--scaffold-inspection">Activity 1: Project Setup &amp; Scaffold Inspection</a></h2>
<p><strong>Time</strong>: 15 minutes
<strong>Materials</strong>: Starter pack (Gradle project with Ktor + Pebble)</p>
<blockquote>
<p>Keep the <a href="wk06/../references/pebble-cheatsheet.html">Pebble Cheatsheet</a> handy for syntax reminders.</p>
</blockquote>
<h3 id="step-1-clone-starter-pack"><a class="header" href="#step-1-clone-starter-pack">Step 1: Clone Starter Pack</a></h3>
<pre><code class="language-bash"># Clone starter repository (URL provided on Minerva)
git clone [REPO_URL]/comp2850-hci-starter.git
cd comp2850-hci-starter

# Or open in Codespaces: Click "Code" ‚Üí "Create codespace on main"
</code></pre>
<h3 id="step-2-verify-dependencies"><a class="header" href="#step-2-verify-dependencies">Step 2: Verify Dependencies</a></h3>
<p>Open <code>build.gradle.kts</code> and confirm these dependencies:</p>
<pre><code class="language-kotlin">dependencies {
    implementation("io.ktor:ktor-server-core:2.3.12")
    implementation("io.ktor:ktor-server-netty:2.3.12")
    implementation("io.pebbletemplates:pebble:3.2.2")
    implementation("ch.qos.logback:logback-classic:1.5.6")
}
</code></pre>
<p><strong>What these do</strong>:</p>
<ul>
<li><strong>Ktor</strong>: Kotlin web framework (routes, HTTP handling)</li>
<li><strong>Pebble</strong>: Template engine (renders HTML with data)</li>
<li><strong>Logback</strong>: Logging (debug server behaviour)</li>
</ul>
<h3 id="step-3-run-the-server"><a class="header" href="#step-3-run-the-server">Step 3: Run the Server</a></h3>
<pre><code class="language-bash">./gradlew run

# Windows
gradlew.bat run
</code></pre>
<p><strong>Expected output</strong>:</p>
<pre><code>Application started in 0.5s
Listening on http://0.0.0.0:8080
</code></pre>
<p><strong>Visit</strong>: http://localhost:8080/tasks</p>
<p>You should see placeholder text: "Task manager coming soon..." This confirms the server works.</p>
<h3 id="step-4-inspect-directory-structure"><a class="header" href="#step-4-inspect-directory-structure">Step 4: Inspect Directory Structure</a></h3>
<pre><code>comp2850-hci-starter/
‚îú‚îÄ‚îÄ src/main/kotlin/
‚îÇ   ‚îú‚îÄ‚îÄ Main.kt               # Server entry point
‚îÇ   ‚îú‚îÄ‚îÄ model/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ Task.kt           # Data model
‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ TaskRoutes.kt     # CRUD operations
‚îÇ   ‚îú‚îÄ‚îÄ storage/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ TaskStore.kt      # CSV persistence
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îî‚îÄ‚îÄ SessionUtils.kt   # Anonymous sessions
‚îú‚îÄ‚îÄ src/main/resources/
‚îÇ   ‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ _layout/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ base.peb      # Accessible base layout
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tasks/
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ index.peb     # Full page view
‚îÇ   ‚îÇ       ‚îú‚îÄ‚îÄ _list.peb     # Task list partial
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ _item.peb     # Single task partial
‚îÇ   ‚îî‚îÄ‚îÄ static/
‚îÇ       ‚îú‚îÄ‚îÄ css/custom.css    # WCAG styles
‚îÇ       ‚îî‚îÄ‚îÄ js/htmx-1.9.12.min.js
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ tasks.csv             # File-based storage
‚îú‚îÄ‚îÄ build.gradle.kts          # Dependencies
‚îî‚îÄ‚îÄ README.md                 # Comprehensive guide
</code></pre>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ Server runs without errors</li>
<li>‚úÖ http://localhost:8080/tasks loads (even if placeholder)</li>
<li>‚úÖ You can see <code>base.peb</code> and <code>tasks/index.peb</code> in your IDE</li>
</ul>
<hr />
<h2 id="activity-2-build-accessible-base-layout"><a class="header" href="#activity-2-build-accessible-base-layout">Activity 2: Build Accessible Base Layout</a></h2>
<p><strong>Time</strong>: 30 minutes
<strong>Materials</strong>: <code>src/main/resources/templates/base.peb</code></p>
<h3 id="step-1-create-semantic-html-structure"><a class="header" href="#step-1-create-semantic-html-structure">Step 1: Create Semantic HTML Structure</a></h3>
<p>Replace the contents of <code>base.peb</code> with:</p>
<pre><code class="language-html">&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
  &lt;meta charset="UTF-8"&gt;
  &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt;
  &lt;title&gt;{{ title | default("COMP2850 Task Manager") }}&lt;/title&gt;
  &lt;link rel="stylesheet" href="https://unpkg.com/@picocss/pico@2/css/pico.min.css"&gt;
  &lt;style&gt;
    /* Visually hidden but accessible to screen readers */
    .visually-hidden {
      position: absolute !important;
      clip: rect(1px, 1px, 1px, 1px);
      padding: 0 !important;
      border: 0 !important;
      height: 1px !important;
      width: 1px !important;
      overflow: hidden;
      white-space: nowrap;
    }

    /* Skip link (keyboard only) */
    .skip-link {
      position: absolute;
      left: -10000px;
      width: 1px;
      height: 1px;
      overflow: hidden;
    }
    .skip-link:focus {
      position: static;
      width: auto;
      height: auto;
      background: #1976d2;
      color: white;
      padding: 0.5rem 1rem;
      text-decoration: none;
      font-weight: bold;
    }

    /* ARIA live region styling */
    #status:not(:empty) {
      background: #e3f2fd;
      border-left: 4px solid #1976d2;
      padding: 1rem;
      margin: 1rem 0;
    }
  &lt;/style&gt;
  &lt;script src="https://unpkg.com/htmx.org@2.0.0"&gt;&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
  &lt;a href="#main" class="skip-link"&gt;Skip to main content&lt;/a&gt;

  &lt;main class="container" id="main"&gt;
    &lt;div id="status" role="status" aria-live="polite" class="visually-hidden"&gt;&lt;/div&gt;
    {% block content %}{% endblock %}
  &lt;/main&gt;

  &lt;footer class="container"&gt;
    &lt;p&gt;&lt;small&gt;COMP2850 HCI ‚Ä¢ University of Leeds ‚Ä¢ 2024/25&lt;/small&gt;&lt;/p&gt;
  &lt;/footer&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<h3 id="step-2-understanding-the-accessibility-features"><a class="header" href="#step-2-understanding-the-accessibility-features">Step 2: Understanding the Accessibility Features</a></h3>
<p><strong>Skip link</strong> (line 35-36):</p>
<ul>
<li>Allows keyboard/SR to jump past repeated navigation</li>
<li>Hidden until focused (keyboard Tab reveals it)</li>
<li><strong>WCAG 2.4.1 (Bypass Blocks, A)</strong>: Mechanism to bypass repeated content</li>
</ul>
<p><strong>Live region</strong> (line 39):</p>
<ul>
<li><code>role="status"</code>: Announces updates without stealing focus</li>
<li><code>aria-live="polite"</code>: Waits for customer to pause before announcing</li>
<li><code>.visually-hidden</code>: Hidden visually but announced by SR</li>
<li><strong>WCAG 4.1.3 (Status Messages, AA)</strong>: Status messages programmatically announced</li>
</ul>
<p><strong>Semantic HTML</strong>:</p>
<ul>
<li><code>&lt;main&gt;</code>: Primary content landmark</li>
<li><code>&lt;footer&gt;</code>: Site information landmark</li>
<li><code>lang="en"</code>: Tells SR which language to use</li>
<li><strong>WCAG 1.3.1 (Info and Relationships, A)</strong>: Structure conveyed programmatically</li>
</ul>
<h3 id="step-3-test-the-base-layout"><a class="header" href="#step-3-test-the-base-layout">Step 3: Test the Base Layout</a></h3>
<p>Reload http://localhost:8080/tasks. You should still see placeholder text, but now:</p>
<ol>
<li><strong>Tab once</strong>: Skip link appears with blue background</li>
<li><strong>Press Enter on skip link</strong>: Focus jumps to <code>#main</code> (no effect yet, but will matter when we add navigation)</li>
<li><strong>Inspect with DevTools</strong>:
<ul>
<li>Open Elements panel</li>
<li>Find <code>&lt;div id="status"&gt;</code> with <code>role="status"</code> and <code>aria-live="polite"</code></li>
<li>Confirm <code>.visually-hidden</code> class applied</li>
</ul>
</li>
</ol>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ Skip link appears on keyboard focus</li>
<li>‚úÖ Live region exists in DOM (empty for now)</li>
<li>‚úÖ Pico.css loaded (page has default styling)</li>
</ul>
<hr />
<h2 id="activity-3-implement-server-side-routes--repository"><a class="header" href="#activity-3-implement-server-side-routes--repository">Activity 3: Implement Server-Side Routes &amp; Repository</a></h2>
<p><strong>Time</strong>: 35 minutes
<strong>Materials</strong>: <code>src/main/kotlin/routes/TaskRoutes.kt</code>, <code>data/tasks.csv</code></p>
<h3 id="step-1-create-a-simple-repository"><a class="header" href="#step-1-create-a-simple-repository">Step 1: Create a Simple Repository</a></h3>
<p>Create <code>src/main/kotlin/data/TaskRepository.kt</code>:</p>
<pre><code class="language-kotlin">package data

import java.io.File
import java.util.concurrent.atomic.AtomicInteger

data class Task(val id: Int, var title: String)

object TaskRepository {
    private val file = File("data/tasks.csv")
    private val tasks = mutableListOf&lt;Task&gt;()
    private val idCounter = AtomicInteger(1)

    init {
        file.parentFile?.mkdirs()
        if (!file.exists()) {
            file.writeText("id,title\n")
        } else {
            file.readLines().drop(1).forEach { line -&gt;
                val parts = line.split(",", limit = 2)
                if (parts.size == 2) {
                    val id = parts[0].toIntOrNull() ?: return@forEach
                    tasks.add(Task(id, parts[1]))
                    idCounter.set(maxOf(idCounter.get(), id + 1))
                }
            }
        }
    }

    fun all(): List&lt;Task&gt; = tasks.toList()

    fun add(title: String): Task {
        val task = Task(idCounter.getAndIncrement(), title)
        tasks.add(task)
        persist()
        return task
    }

    fun delete(id: Int): Boolean {
        val removed = tasks.removeIf { it.id == id }
        if (removed) persist()
        return removed
    }

    private fun persist() {
        file.writeText("id,title\n" + tasks.joinToString("\n") { "${it.id},${it.title}" })
    }
}
</code></pre>
<p><strong>Why CSV?</strong></p>
<ul>
<li>Simple, inspectable, no database setup required</li>
<li>Good for learning (focus on HCI, not DB configuration)</li>
<li>Production apps would use PostgreSQL/MongoDB</li>
</ul>
<h3 id="step-2-create-baseline-routes-no-htmx-yet"><a class="header" href="#step-2-create-baseline-routes-no-htmx-yet">Step 2: Create Baseline Routes (No HTMX Yet)</a></h3>
<p>Edit <code>src/main/kotlin/routes/TaskRoutes.kt</code>:</p>
<pre><code class="language-kotlin">package routes

import data.TaskRepository
import io.ktor.http.*
import io.ktor.server.application.*
import io.ktor.server.request.*
import io.ktor.server.response.*
import io.ktor.server.routing.*
import io.pebbletemplates.pebble.PebbleEngine
import java.io.StringWriter

fun Route.taskRoutes() {
    val pebble = PebbleEngine.Builder().build()

    get("/tasks") {
        val model = mapOf(
            "title" to "Tasks",
            "tasks" to TaskRepository.all()
        )
        val template = pebble.getTemplate("templates/tasks/index.peb")
        val writer = StringWriter()
        template.evaluate(writer, model)
        call.respondText(writer.toString(), ContentType.Text.Html)
    }

    post("/tasks") {
        val title = call.receiveParameters()["title"].orEmpty().trim()
        if (title.isNotBlank()) {
            TaskRepository.add(title)
        }
        call.respondRedirect("/tasks") // PRG pattern
    }

    post("/tasks/{id}/delete") {
        val id = call.parameters["id"]?.toIntOrNull()
        id?.let { TaskRepository.delete(it) }
        call.respondRedirect("/tasks") // PRG pattern
    }
}
</code></pre>
<p><strong>Update <code>Application.kt</code></strong> (or wherever routing is configured):</p>
<pre><code class="language-kotlin">import io.ktor.server.application.*
import io.ktor.server.routing.*
import routes.taskRoutes

fun Application.configureRouting() {
    routing {
        taskRoutes()
    }
}
</code></pre>
<h3 id="step-3-create-task-list-template"><a class="header" href="#step-3-create-task-list-template">Step 3: Create Task List Template</a></h3>
<blockquote>
<p><strong>üí° Pebble Template Syntax Primer</strong></p>
<p>Pebble uses three types of delimiters:</p>
<div class="table-wrapper"><table><thead><tr><th>Syntax</th><th>Purpose</th><th>Example</th></tr></thead><tbody>
<tr><td><code>{{ variable }}</code></td><td><strong>Output</strong> - Print variable values</td><td><code>{{ task.title }}</code> outputs "Buy milk"</td></tr>
<tr><td><code>{% statement %}</code></td><td><strong>Logic</strong> - Control structures (if, for, extends)</td><td><code>{% for task in tasks %}...{% endfor %}</code></td></tr>
<tr><td><code>{# comment #}</code></td><td><strong>Comments</strong> - Not rendered in HTML</td><td><code>{# TODO: Add pagination #}</code></td></tr>
</tbody></table>
</div>
<p><strong>Common statements</strong>:</p>
<ul>
<li><code>{% extends "base.peb" %}</code> - Inherit from parent template</li>
<li><code>{% block content %}...{% endblock %}</code> - Define/override content sections</li>
<li><code>{% for item in list %}...{% endfor %}</code> - Loop over collections</li>
<li><code>{% if condition %}...{% endif %}</code> - Conditional rendering</li>
<li><code>{% else %}</code> - Inside <code>{% for %}</code>, shown if list is empty</li>
</ul>
<p><strong>Filters</strong> (pipe syntax):</p>
<ul>
<li><code>{{ tasks | length }}</code> - Get list size (outputs: <code>3</code>)</li>
<li><code>{{ title | escape }}</code> - HTML-escape (auto-enabled in Pebble)</li>
<li><code>{{ price | default(0) }}</code> - Fallback value if null</li>
</ul>
<p><strong>Reference</strong>: <a href="https://pebbletemplates.io/">Pebble Documentation</a> ‚Ä¢ <a href="wk06/../references/pebble-intro.html">Pebble Intro</a></p>
</blockquote>
<p>Edit <code>src/main/resources/templates/tasks/index.peb</code>:</p>
<pre><code class="language-html">{% extends "base.peb" %}

{% block content %}
&lt;h1&gt;Tasks&lt;/h1&gt;

&lt;section aria-labelledby="add-heading"&gt;
  &lt;h2 id="add-heading"&gt;Add a new task&lt;/h2&gt;
  &lt;form action="/tasks" method="post"&gt;
    &lt;label for="title"&gt;Title&lt;/label&gt;
    &lt;input type="text" id="title" name="title" required
           placeholder="e.g., Buy milk" aria-describedby="title-hint"&gt;
    &lt;small id="title-hint"&gt;Keep it short and specific.&lt;/small&gt;
    &lt;button type="submit"&gt;Add Task&lt;/button&gt;
  &lt;/form&gt;
&lt;/section&gt;

&lt;section aria-labelledby="list-heading"&gt;
  &lt;h2 id="list-heading"&gt;Current tasks ({{ tasks | length }})&lt;/h2&gt;
  &lt;ul id="task-list"&gt;
    {% for task in tasks %}
      &lt;li id="task-{{ task.id }}"&gt;
        &lt;span&gt;{{ task.title }}&lt;/span&gt;
        &lt;form action="/tasks/{{ task.id }}/delete" method="post" style="display: inline;"&gt;
          &lt;button type="submit" aria-label="Delete task: {{ task.title }}"&gt;Delete&lt;/button&gt;
        &lt;/form&gt;
      &lt;/li&gt;
    {% else %}
      &lt;li&gt;No tasks yet. Add one above!&lt;/li&gt;
    {% endfor %}
  &lt;/ul&gt;
&lt;/section&gt;
{% endblock %}
</code></pre>
<p><strong>Accessibility features</strong>:</p>
<ul>
<li><code>aria-labelledby</code>: Links sections to headings (SR announces "Add a new task, region")</li>
<li><code>aria-describedby</code>: Links input to hint (SR announces "Title, edit text, Keep it short and specific")</li>
<li><code>aria-label</code> on Delete button: SR announces "Delete task: Buy milk" (context-specific)</li>
<li>Semantic <code>&lt;section&gt;</code>, <code>&lt;h2&gt;</code>, <code>&lt;ul&gt;</code> structure</li>
</ul>
<h3 id="step-4-test-no-js-baseline"><a class="header" href="#step-4-test-no-js-baseline">Step 4: Test No-JS Baseline</a></h3>
<ol>
<li>
<p><strong>Disable JavaScript</strong> in browser:</p>
<ul>
<li>Chrome: DevTools (F12) ‚Üí Settings (‚öôÔ∏è) ‚Üí Debugger ‚Üí "Disable JavaScript"</li>
<li>Firefox: about:config ‚Üí javascript.enabled ‚Üí false</li>
</ul>
</li>
<li>
<p><strong>Reload http://localhost:8080/tasks</strong></p>
</li>
<li>
<p><strong>Add a task</strong>:</p>
<ul>
<li>Type "Buy milk" in Title field</li>
<li>Click "Add Task"</li>
<li><strong>Expected</strong>: Page reloads, "Buy milk" appears in list</li>
</ul>
</li>
<li>
<p><strong>Delete a task</strong>:</p>
<ul>
<li>Click "Delete" next to "Buy milk"</li>
<li><strong>Expected</strong>: Page reloads, task removed</li>
</ul>
</li>
</ol>
<p><strong>If this works, you have a fully functional, accessible baseline without any JavaScript.</strong></p>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ Adding tasks works (no-JS)</li>
<li>‚úÖ Deleting tasks works (no-JS)</li>
<li>‚úÖ Page reloads on each action (PRG pattern)</li>
<li>‚úÖ Screen reader announces labels correctly (test with NVDA/VoiceOver if available)</li>
</ul>
<hr />
<h2 id="activity-4-add-htmx-progressive-enhancement"><a class="header" href="#activity-4-add-htmx-progressive-enhancement">Activity 4: Add HTMX Progressive Enhancement</a></h2>
<p><strong>Time</strong>: 40 minutes
<strong>Materials</strong>: Updated routes and templates</p>
<h3 id="step-1-detect-htmx-requests"><a class="header" href="#step-1-detect-htmx-requests">Step 1: Detect HTMX Requests</a></h3>
<p>Add helper function to <code>TaskRoutes.kt</code>:</p>
<pre><code class="language-kotlin">fun ApplicationCall.isHtmx(): Boolean =
    request.headers["HX-Request"]?.equals("true", ignoreCase = true) == true
</code></pre>
<p><strong>How it works</strong>: HTMX adds <code>HX-Request: true</code> header to all AJAX requests. Server checks this to decide whether to return full page or fragment.</p>
<h3 id="step-2-update-post-tasks-route"><a class="header" href="#step-2-update-post-tasks-route">Step 2: Update POST /tasks Route</a></h3>
<p>Replace <code>post("/tasks")</code> route with:</p>
<pre><code class="language-kotlin">post("/tasks") {
    val title = call.receiveParameters()["title"].orEmpty().trim()

    // Validation
    if (title.isBlank()) {
        if (call.isHtmx()) {
            val error = """&lt;div id="status" hx-swap-oob="true" role="alert" aria-live="assertive"&gt;
                Title is required. Please enter at least one character.
            &lt;/div&gt;"""
            return@post call.respondText(error, ContentType.Text.Html, HttpStatusCode.BadRequest)
        } else {
            // No-JS path: redirect with error flag (handle in GET if needed)
            return@post call.respondRedirect("/tasks?error=required")
        }
    }

    val task = TaskRepository.add(title)

    if (call.isHtmx()) {
        // Return HTML fragment for new task
        val fragment = """&lt;li id="task-${task.id}"&gt;
            &lt;span&gt;${task.title}&lt;/span&gt;
            &lt;form action="/tasks/${task.id}/delete" method="post" style="display: inline;"
                  hx-post="/tasks/${task.id}/delete"
                  hx-target="#task-${task.id}"
                  hx-swap="outerHTML"&gt;
              &lt;button type="submit" aria-label="Delete task: ${task.title}"&gt;Delete&lt;/button&gt;
            &lt;/form&gt;
        &lt;/li&gt;"""

        val status = """&lt;div id="status" hx-swap-oob="true"&gt;Task "${task.title}" added successfully.&lt;/div&gt;"""

        return@post call.respondText(fragment + status, ContentType.Text.Html, HttpStatusCode.Created)
    }

    call.respondRedirect("/tasks") // No-JS fallback
}
</code></pre>
<p><strong>Key pattern</strong>:</p>
<ul>
<li><strong>HTMX path</strong>: Returns <code>&lt;li&gt;</code> fragment + OOB status message</li>
<li><strong>No-JS path</strong>: Redirects to <code>/tasks</code> (page reload)</li>
<li>Both paths end up in the same state (DRY principle)</li>
</ul>
<h3 id="step-3-update-post-tasksiddelete-route"><a class="header" href="#step-3-update-post-tasksiddelete-route">Step 3: Update POST /tasks/{id}/delete Route</a></h3>
<pre><code class="language-kotlin">post("/tasks/{id}/delete") {
    val id = call.parameters["id"]?.toIntOrNull()
    val removed = id?.let { TaskRepository.delete(it) } ?: false

    if (call.isHtmx()) {
        val message = if (removed) "Task deleted." else "Could not delete task."
        val status = """&lt;div id="status" hx-swap-oob="true"&gt;$message&lt;/div&gt;"""
        // Return empty content to trigger outerHTML swap (removes the &lt;li&gt;)
        return@post call.respondText(status, ContentType.Text.Html)
    }

    call.respondRedirect("/tasks")
}
</code></pre>
<h3 id="step-4-add-htmx-attributes-to-template"><a class="header" href="#step-4-add-htmx-attributes-to-template">Step 4: Add HTMX Attributes to Template</a></h3>
<p>Update <code>tasks/index.peb</code>:</p>
<pre><code class="language-html">{% extends "base.peb" %}

{% block content %}
&lt;h1&gt;Tasks&lt;/h1&gt;

&lt;section aria-labelledby="add-heading"&gt;
  &lt;h2 id="add-heading"&gt;Add a new task&lt;/h2&gt;
  &lt;form action="/tasks" method="post"
        hx-post="/tasks"
        hx-target="#task-list"
        hx-swap="beforeend"&gt;
    &lt;label for="title"&gt;Title&lt;/label&gt;
    &lt;input type="text" id="title" name="title" required
           placeholder="e.g., Buy milk" aria-describedby="title-hint"&gt;
    &lt;small id="title-hint"&gt;Keep it short and specific.&lt;/small&gt;
    &lt;button type="submit"&gt;Add Task&lt;/button&gt;
  &lt;/form&gt;
&lt;/section&gt;

&lt;section aria-labelledby="list-heading"&gt;
  &lt;h2 id="list-heading"&gt;Current tasks ({{ tasks | length }})&lt;/h2&gt;
  &lt;ul id="task-list"&gt;
    {% for task in tasks %}
      &lt;li id="task-{{ task.id }}"&gt;
        &lt;span&gt;{{ task.title }}&lt;/span&gt;
        &lt;form action="/tasks/{{ task.id }}/delete" method="post" style="display: inline;"
              hx-post="/tasks/{{ task.id }}/delete"
              hx-target="#task-{{ task.id }}"
              hx-swap="outerHTML"&gt;
          &lt;button type="submit" aria-label="Delete task: {{ task.title }}"&gt;Delete&lt;/button&gt;
        &lt;/form&gt;
      &lt;/li&gt;
    {% else %}
      &lt;li&gt;No tasks yet. Add one above!&lt;/li&gt;
    {% endfor %}
  &lt;/ul&gt;
&lt;/section&gt;
{% endblock %}
</code></pre>
<p><strong>HTMX attributes explained</strong>:</p>
<ul>
<li>
<p><strong>Add form</strong>:</p>
<ul>
<li><code>hx-post="/tasks"</code>: AJAX POST on submit</li>
<li><code>hx-target="#task-list"</code>: Insert response into task list</li>
<li><code>hx-swap="beforeend"</code>: Append (not replace)</li>
</ul>
</li>
<li>
<p><strong>Delete form</strong>:</p>
<ul>
<li><code>hx-post="/tasks/{id}/delete"</code>: AJAX POST</li>
<li><code>hx-target="#task-{{ task.id }}"</code>: Target the specific <code>&lt;li&gt;</code></li>
<li><code>hx-swap="outerHTML"</code>: Replace entire <code>&lt;li&gt;</code> (removes it if response is empty)</li>
</ul>
</li>
</ul>
<h3 id="step-5-test-htmx-enhancement"><a class="header" href="#step-5-test-htmx-enhancement">Step 5: Test HTMX Enhancement</a></h3>
<ol>
<li>
<p><strong>Re-enable JavaScript</strong> in browser</p>
</li>
<li>
<p><strong>Reload http://localhost:8080/tasks</strong></p>
</li>
<li>
<p><strong>Add a task</strong>:</p>
<ul>
<li>Type "Buy oat milk"</li>
<li>Click "Add Task"</li>
<li><strong>Expected</strong>: Task appears instantly, NO page reload</li>
<li><strong>Check DevTools Network tab</strong>: See AJAX POST to <code>/tasks</code></li>
</ul>
</li>
<li>
<p><strong>Check live region announcement</strong>:</p>
<ul>
<li>Open browser console</li>
<li>Type: <code>document.getElementById('status').textContent</code></li>
<li><strong>Expected</strong>: "Task 'Buy oat milk' added successfully."</li>
<li><strong>With screen reader</strong>: Should announce this message</li>
</ul>
</li>
<li>
<p><strong>Delete a task</strong>:</p>
<ul>
<li>Click "Delete" next to "Buy oat milk"</li>
<li><strong>Expected</strong>: Task removed instantly, NO page reload</li>
</ul>
</li>
<li>
<p><strong>Verify no-JS still works</strong>:</p>
<ul>
<li>Disable JavaScript again</li>
<li>Repeat add/delete tests</li>
<li><strong>Expected</strong>: Both still work (page reloads)</li>
</ul>
</li>
</ol>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ HTMX path: instant updates, no reload</li>
<li>‚úÖ No-JS path: still works with redirects</li>
<li>‚úÖ Live region updates (inspect with DevTools)</li>
<li>‚úÖ Network tab shows AJAX requests (JS enabled) vs. full page loads (JS disabled)</li>
</ul>
<hr />
<h2 id="activity-5-accessibility-verification"><a class="header" href="#activity-5-accessibility-verification">Activity 5: Accessibility Verification</a></h2>
<p><strong>Time</strong>: 25 minutes
<strong>Materials</strong>: Keyboard, screen reader (NVDA/VoiceOver), browser DevTools</p>
<h3 id="test-1-keyboard-navigation"><a class="header" href="#test-1-keyboard-navigation">Test 1: Keyboard Navigation</a></h3>
<p><strong>Enable JavaScript</strong>, reload page, then:</p>
<ol>
<li>
<p><strong>Tab through page</strong>:</p>
<ul>
<li>Tab 1: Skip link appears ‚Üí Press Enter ‚Üí Focus jumps to main</li>
<li>Tab 2: Title input</li>
<li>Tab 3: Add Task button</li>
<li>Tab 4: First Delete button</li>
<li>Continue tabbing through all Delete buttons</li>
</ul>
</li>
<li>
<p><strong>Check focus indicators</strong>:</p>
<ul>
<li>Pico.css provides default focus outlines</li>
<li>Ensure you can always see which element has focus</li>
</ul>
</li>
<li>
<p><strong>Submit form with keyboard</strong>:</p>
<ul>
<li>Focus Title input, type "Test task"</li>
<li>Press Enter (submits form)</li>
<li><strong>Expected</strong>: Task added via HTMX (no reload)</li>
</ul>
</li>
</ol>
<p><strong>Result</strong>: ‚úÖ All interactive elements keyboard-accessible</p>
<h3 id="test-2-screen-reader-testing"><a class="header" href="#test-2-screen-reader-testing">Test 2: Screen Reader Testing</a></h3>
<p><strong>Tools</strong>:</p>
<ul>
<li><strong>Windows</strong>: NVDA (free, https://www.nvaccess.org/)</li>
<li><strong>macOS</strong>: VoiceOver (built-in, Cmd+F5)</li>
<li><strong>Linux</strong>: Orca (pre-installed on RHEL labs)</li>
</ul>
<p><strong>Test with NVDA</strong> (Windows):</p>
<ol>
<li>Start NVDA (Ctrl+Alt+N)</li>
<li>Navigate to http://localhost:8080/tasks</li>
<li><strong>Listen for</strong>:
<ul>
<li>"Tasks, heading level 1"</li>
<li>"Add a new task, heading level 2"</li>
<li>"Title, edit, Keep it short and specific" (input + hint)</li>
</ul>
</li>
<li><strong>Type</strong> "NVDA test task" and press Enter</li>
<li><strong>Listen for</strong>: "Task 'NVDA test task' added successfully" (from live region)</li>
<li><strong>Tab to Delete button</strong>:
<ul>
<li><strong>Expected</strong>: "Delete task: NVDA test task, button"</li>
</ul>
</li>
<li><strong>Press Space</strong> (activates Delete)</li>
<li><strong>Listen for</strong>: "Task deleted" (from live region)</li>
</ol>
<p><strong>Result</strong>: ‚úÖ Screen reader announces labels, hints, and status messages</p>
<h3 id="test-3-no-js-parity"><a class="header" href="#test-3-no-js-parity">Test 3: No-JS Parity</a></h3>
<ol>
<li><strong>Disable JavaScript</strong> (DevTools ‚Üí Settings ‚Üí Disable JavaScript)</li>
<li><strong>Reload page</strong></li>
<li><strong>Add task</strong>: "No-JS test"
<ul>
<li><strong>Expected</strong>: Page reloads, task appears</li>
</ul>
</li>
<li><strong>Delete task</strong>:
<ul>
<li><strong>Expected</strong>: Page reloads, task removed</li>
</ul>
</li>
<li><strong>Compare with JS-enabled</strong>:
<ul>
<li>Functionality identical (only UX differs: reload vs. instant)</li>
</ul>
</li>
</ol>
<p><strong>Result</strong>: ‚úÖ No-JS parity achieved</p>
<h3 id="test-4-wcag-quick-check"><a class="header" href="#test-4-wcag-quick-check">Test 4: WCAG Quick Check</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Criterion</th><th>Test</th><th>Result</th></tr></thead><tbody>
<tr><td><strong>1.3.1 Info and Relationships (A)</strong></td><td>Inspect HTML: <code>&lt;label for="title"&gt;</code> links to <code>&lt;input id="title"&gt;</code></td><td>‚òê Pass</td></tr>
<tr><td><strong>2.1.1 Keyboard (A)</strong></td><td>All features accessible via Tab, Enter, Space</td><td>‚òê Pass</td></tr>
<tr><td><strong>2.4.1 Bypass Blocks (A)</strong></td><td>Skip link appears on focus, jumps to main</td><td>‚òê Pass</td></tr>
<tr><td><strong>3.2.2 On Input (A)</strong></td><td>Changing input doesn't auto-submit (only explicit button press)</td><td>‚òê Pass</td></tr>
<tr><td><strong>3.3.2 Labels or Instructions (A)</strong></td><td>All inputs have <code>&lt;label&gt;</code> and hint text</td><td>‚òê Pass</td></tr>
<tr><td><strong>4.1.3 Status Messages (AA)</strong></td><td>Live region announces add/delete confirmations</td><td>‚òê Pass</td></tr>
</tbody></table>
</div>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ All WCAG tests pass</li>
<li>‚úÖ Keyboard and SR can complete all tasks</li>
<li>‚úÖ No-JS path works identically</li>
</ul>
<hr />
<h2 id="reflection-questions"><a class="header" href="#reflection-questions">Reflection Questions</a></h2>
<ol>
<li>
<p><strong>Server-first vs. client-first</strong>: How would this lab differ if we used React instead of server-rendered HTML + HTMX? What would be harder? What would be easier?</p>
</li>
<li>
<p><strong>Progressive enhancement</strong>: Imagine a person on a slow 3G connection where HTMX fails to load. How does our
implementation handle this gracefully?</p>
</li>
<li>
<p><strong>Live regions</strong>: Why do we use <code>aria-live="polite"</code> for success messages but <code>aria-live="assertive"</code> for errors? When would you choose one over the other?</p>
</li>
<li>
<p><strong>HTMX trade-offs</strong>: What are the limitations of HTMX compared to a full JavaScript framework? When might HTMX <em>not</em> be appropriate?</p>
</li>
</ol>
<hr />
<h2 id="further-reading"><a class="header" href="#further-reading">Further Reading</a></h2>
<p><strong>Server-first architecture</strong></p>
<ul>
<li>Gross, C., Stepinski, A., &amp; Ak≈üim≈üek, D. (2023). <em>Hypermedia Systems</em>. <a href="https://hypermedia.systems/">https://hypermedia.systems/</a></li>
</ul>
<p><strong>Progressive enhancement</strong></p>
<ul>
<li>GOV.UK Service Manual. "Using Progressive Enhancement." <a href="https://www.gov.uk/service-manual/technology/using-progressive-enhancement">https://www.gov.uk/service-manual/technology/using-progressive-enhancement</a></li>
<li>Champeon, S. (2003). "Progressive Enhancement and the Future of Web Design." SXSW presentation.</li>
</ul>
<p><strong>HTMX &amp; hypermedia</strong></p>
<ul>
<li>HTMX Documentation. <a href="https://htmx.org/docs/">https://htmx.org/docs/</a></li>
</ul>
<p><strong>WCAG &amp; accessibility</strong></p>
<ul>
<li>W3C (2024). <em>Web Content Accessibility Guidelines (WCAG) 2.2</em>. <a href="https://www.w3.org/WAI/WCAG22/quickref/">https://www.w3.org/WAI/WCAG22/quickref/</a></li>
<li>Pickering, H. (2016). <em>Inclusive Design Patterns</em>. Smashing Magazine.</li>
</ul>
<hr />
<h2 id="glossary-summary"><a class="header" href="#glossary-summary">Glossary Summary</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Term</th><th>Definition</th><th>Example/Context</th></tr></thead><tbody>
<tr><td><strong>Server-first</strong></td><td>Architecture where server generates complete HTML pages</td><td>Ktor renders <code>tasks/index.peb</code> ‚Üí sends full HTML to browser</td></tr>
<tr><td><strong>Progressive enhancement</strong></td><td>Building baseline (HTML) first, adding optional layers (CSS, JS)</td><td>Form works with POST/redirect; HTMX adds instant updates</td></tr>
<tr><td><strong>HTMX</strong></td><td>Library that adds AJAX capabilities via HTML attributes</td><td><code>&lt;form hx-post="/tasks" hx-target="#list"&gt;</code></td></tr>
<tr><td><strong>PRG (Post-Redirect-Get)</strong></td><td>Pattern to prevent duplicate form submissions</td><td>POST /tasks ‚Üí 303 Redirect ‚Üí GET /tasks</td></tr>
<tr><td><strong>ARIA live region</strong></td><td>Element that announces dynamic changes to screen readers</td><td><code>&lt;div role="status" aria-live="polite"&gt;</code></td></tr>
<tr><td><strong>Out-of-band (OOB) swap</strong></td><td>HTMX updating an element outside the main target</td><td><code>&lt;div id="status" hx-swap-oob="true"&gt;</code></td></tr>
<tr><td><strong>Semantic HTML</strong></td><td>Using tags that convey meaning (not just structure)</td><td><code>&lt;main&gt;</code>, <code>&lt;section&gt;</code>, <code>&lt;label&gt;</code>, <code>&lt;button&gt;</code> (not <code>&lt;div onclick&gt;</code>)</td></tr>
<tr><td><strong>Skip link</strong></td><td>Link to jump past repeated content (navigation)</td><td><code>&lt;a href="#main"&gt;Skip to content&lt;/a&gt;</code></td></tr>
<tr><td><strong>WCAG 2.2 AA</strong></td><td>Web accessibility standard (Level AA = target for most orgs)</td><td>GOV.UK, universities, large companies must comply</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="git-commit-best-practices"><a class="header" href="#git-commit-best-practices">Git Commit Best Practices</a></h2>
<p>Good commit messages are essential for your <strong>portfolio assessment</strong> and <strong>professional practice</strong>. Your commits tell the story of your development process.</p>
<h3 id="conventional-commit-format"><a class="header" href="#conventional-commit-format">Conventional Commit Format</a></h3>
<p>Use this structure for clear, searchable commits:</p>
<pre><code>&lt;type&gt;(&lt;scope&gt;): &lt;short description&gt;

[Optional longer explanation]
</code></pre>
<p><strong>Examples</strong>:</p>
<pre><code class="language-bash"># Good ‚úÖ
git commit -m "feat(tasks): add HTMX progressive enhancement to delete button"
git commit -m "fix(a11y): add aria-label to delete buttons for screen readers"
git commit -m "docs(readme): add setup instructions for Codespaces"
git commit -m "refactor(templates): extract task item to partial template"

# Bad ‚ùå
git commit -m "stuff"
git commit -m "fixed it"
git commit -m "update"
git commit -m "changes"
</code></pre>
<h3 id="common-types"><a class="header" href="#common-types">Common Types</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Type</th><th>When to Use</th><th>Example</th></tr></thead><tbody>
<tr><td><code>feat</code></td><td>New feature or capability</td><td><code>feat(tasks): add search by title</code></td></tr>
<tr><td><code>fix</code></td><td>Bug fix</td><td><code>fix(validation): prevent blank task titles</code></td></tr>
<tr><td><code>refactor</code></td><td>Code restructure (no behaviour change)</td><td><code>refactor(store): move CSV logic to TaskStore class</code></td></tr>
<tr><td><code>docs</code></td><td>Documentation only</td><td><code>docs(readme): add IntelliJ setup guide</code></td></tr>
<tr><td><code>style</code></td><td>Formatting, CSS, no code change</td><td><code>style(tasks): improve focus indicator contrast</code></td></tr>
<tr><td><code>test</code></td><td>Adding or fixing tests</td><td><code>test(store): add TaskStore CRUD tests</code></td></tr>
<tr><td><code>chore</code></td><td>Build, dependencies, tooling</td><td><code>chore(deps): update Ktor to 2.3.11</code></td></tr>
</tbody></table>
</div>
<h3 id="scope-optional-but-helpful"><a class="header" href="#scope-optional-but-helpful">Scope (Optional but Helpful)</a></h3>
<p>Scope = which part of the codebase changed:</p>
<ul>
<li><code>(tasks)</code> = Task management feature</li>
<li><code>(a11y)</code> = Accessibility improvements</li>
<li><code>(htmx)</code> = HTMX enhancements</li>
<li><code>(templates)</code> = Pebble template changes</li>
<li><code>(docs)</code> = Documentation</li>
<li><code>(store)</code> = Data storage/persistence</li>
</ul>
<h3 id="why-this-matters-1"><a class="header" href="#why-this-matters-1">Why This Matters</a></h3>
<p><strong>For portfolio assessment</strong>:</p>
<ul>
<li>Demonstrates professional development practices</li>
<li>Shows your understanding of changes (not just "what" but "why")</li>
<li>Makes it easy to find specific features when preparing evidence</li>
</ul>
<p><strong>For collaboration</strong>:</p>
<ul>
<li>Team members understand changes at a glance</li>
<li>Easy to search git history (<code>git log --grep="feat(a11y)"</code>)</li>
<li>Tools can auto-generate changelogs from commit messages</li>
</ul>
<h3 id="week-6-lab-1-example-commit"><a class="header" href="#week-6-lab-1-example-commit">Week 6 Lab 1 Example Commit</a></h3>
<p>For this lab, a good commit message would be:</p>
<pre><code class="language-bash">git add src/main/kotlin/ src/main/resources/templates/ build.gradle.kts
git commit -m "feat(scaffold): implement server-first task manager with HTMX

- Add Ktor server with Pebble templating
- Implement TaskStore with CSV persistence
- Add dual-mode CRUD routes (HTMX + no-JS)
- Include WCAG 2.2 AA accessibility baseline (skip link, ARIA live region)
- Add progressive enhancement with HTMX for add/delete
- Tested with keyboard navigation and NVDA screen reader

Addresses Week 6 Lab 1 requirements.
WCAG: 2.4.1 (skip link), 4.1.3 (status messages)"
</code></pre>
<p><strong>Quick version</strong> (for smaller changes):</p>
<pre><code class="language-bash">git commit -m "feat(wk6-lab1): server-first scaffold with HTMX and WCAG 2.2 AA"
</code></pre>
<hr />
<h2 id="lab-checklist"><a class="header" href="#lab-checklist">Lab Checklist</a></h2>
<p>Before leaving lab, confirm:</p>
<ul>
<li><input disabled="" type="checkbox"/>
<strong>Server runs</strong>: <code>./gradlew run</code> ‚Üí http://localhost:8080/tasks loads</li>
<li><input disabled="" type="checkbox"/>
<strong>No-JS works</strong>: Add/delete tasks with JS disabled (page reloads)</li>
<li><input disabled="" type="checkbox"/>
<strong>HTMX works</strong>: Add/delete tasks with JS enabled (no reloads)</li>
<li><input disabled="" type="checkbox"/>
<strong>Keyboard accessible</strong>: Tab through all controls, submit with Enter</li>
<li><input disabled="" type="checkbox"/>
<strong>Screen reader tested</strong>: Labels, hints, and status messages announced (NVDA/VoiceOver)</li>
<li><input disabled="" type="checkbox"/>
<strong>Live region updates</strong>: Inspect DevTools ‚Üí <code>#status</code> text changes after add/delete</li>
<li><input disabled="" type="checkbox"/>
<strong>Code committed</strong>: <code>git add .</code>, <code>git commit -m "wk6-lab1: server-first scaffold with HTMX"</code></li>
</ul>
<hr />
<h2 id="next-steps"><a class="header" href="#next-steps">Next Steps</a></h2>
<p>In <strong>Week 6 Lab 2</strong> you will:</p>
<ol>
<li>Conduct peer interviews (needs-finding)</li>
<li>Document consent protocol (ethics)</li>
<li>Build an inclusive backlog from research insights</li>
<li>Plan instrumentation for Week 9 evaluation</li>
</ol>
<p><strong>Preparation</strong>:</p>
<ul>
<li>Read <a href="wk06/../references/consent-pii-faq.html">Consent &amp; PII FAQ</a> and <a href="wk06/../references/privacy-by-design.html">Privacy by Design</a></li>
<li>Bring laptop with working scaffold (Lab 1 code)</li>
<li>Be ready to pair with a classmate for interviews</li>
</ul>
<hr />
<p><strong>Lab authored by</strong>: COMP2850 Teaching Team, University of Leeds
<strong>Last updated</strong>: 2025-01-14
<strong>Licence</strong>: Academic use only (not for redistribution)</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-6--lab-2-needs-finding-consent--inclusive-backlog"><a class="header" href="#week-6--lab-2-needs-finding-consent--inclusive-backlog">Week 6 ‚Ä¢ Lab 2: Needs-Finding, Consent &amp; Inclusive Backlog</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-6-orange" alt="Week 6" />
<img src="https://img.shields.io/badge/Lab-2-green" alt="Lab 2" />
<img src="https://img.shields.io/badge/Status-Draft-yellow" alt="Status" /></p>
<hr />
<h2 id="terminology-note-1"><a class="header" href="#terminology-note-1">Terminology Note</a></h2>
<p>Throughout COMP2850 we use <strong>people-centred language</strong> (e.g., "person using a screen reader") rather than deficit-based terms (e.g., "blind user"). This reflects contemporary inclusive-design practice and acknowledges that disability arises from environmental barriers, not individual impairment.</p>
<hr />
<h2 id="pre-reading-1"><a class="header" href="#pre-reading-1">Pre-reading</a></h2>
<p><strong>Essential</strong></p>
<ul>
<li>Clone/update your Week 6 starter repo (same baseline code) to ensure tasks work before research session</li>
<li><a href="https://hbr.org/2016/09/know-your-customers-jobs-to-be-done">Christensen, C. M., Hall, T., Dillon, K., &amp; Duncan, D. S. (2016). "Know Your Customers' Jobs to Be Done"</a></li>
<li><a href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/">ICO (2024). "Guide to Data Protection by Design and Default"</a></li>
<li><a href="wk06/../references/consent-pii-faq.html">Consent &amp; PII FAQ</a> (module ethics guidance)</li>
<li><a href="wk06/../references/privacy-by-design.html">Privacy by Design</a> (UK GDPR compliance framework)</li>
<li><a href="wk06/../references/assistive-testing-checklist.html">Assistive Testing Checklist</a> (module testing guide for Weeks 6-11)</li>
</ul>
<p><strong>Recommended</strong></p>
<ul>
<li><a href="https://inclusive.microsoft.design/">Microsoft Inclusive Design Toolkit</a></li>
<li><a href="https://www.jpattonassociates.com/user-story-mapping/">Patton, J. (2014). <em>User Story Mapping</em>, Ch. 1-3</a></li>
<li><a href="https://www.nngroup.com/articles/interviewing-users/">Nielsen, J. (1993). "Usability Engineering", Ch. 5: User Interviews</a></li>
</ul>
<hr />
<h2 id="introduction-1"><a class="header" href="#introduction-1">Introduction</a></h2>
<h3 id="context-1"><a class="header" href="#context-1">Context</a></h3>
<p>In <strong>Week 6 Lab 1</strong> you built a server-first task manager with progressive enhancement (HTMX). The scaffold is technically sound: it works without JavaScript, keyboard navigation is accessible, and ARIA live regions announce status messages.</p>
<p><strong>But we don't yet know if it meets real people's needs.</strong></p>
<p>This lab introduces <strong>needs-finding</strong>: a lightweight research activity to understand how people work with task managers, what frustrates them, and what inclusive features would help. You'll capture insights using <strong>job stories</strong> (a people-centred alternative to user stories), document an <strong>ethical consent protocol</strong> for peer interviews, and build an <strong>inclusive backlog</strong> that will drive your accessibility work in Weeks 7-10.</p>
<h3 id="why-this-matters-2"><a class="header" href="#why-this-matters-2">Why This Matters</a></h3>
<p><strong>Professionally</strong>, needs-finding prevents "solution looking for a problem":</p>
<ul>
<li><strong>Basecamp</strong> (project management) conducts customer interviews every sprint</li>
<li><strong>GOV.UK</strong> runs user research sessions before building new services</li>
<li><strong>GitHub</strong> uses job stories to prioritise accessibility features</li>
</ul>
<p>Research shows that teams who ground design decisions in <strong>evidence</strong> (pilot data, interviews, observations) build more inclusive products than teams who rely on assumptions (Norman, 2013).</p>
<p><strong>Academically</strong>, this lab teaches:</p>
<ul>
<li><strong>Qualitative research methods</strong>: interviewing, note-taking, thematic coding</li>
<li><strong>Ethics in practice</strong>: informed consent, anonymisation, right to withdraw (UK GDPR)</li>
<li><strong>Jobs-to-Be-Done framework</strong>: understanding needs vs. specifying solutions</li>
<li><strong>Inclusive backlog management</strong>: prioritising features by severity √ó inclusion risk</li>
</ul>
<h2 id="learning-focus-1"><a class="header" href="#learning-focus-1">Learning Focus</a></h2>
<h3 id="lab-objectives-1"><a class="header" href="#lab-objectives-1">Lab Objectives</a></h3>
<p>By the end of this session, you will have:</p>
<ul>
<li>Conducted peer interviews using structured prompts and consent protocols</li>
<li>Written 5+ job stories from needs-finding activities that represent diverse needs</li>
<li>Designed and implemented a GDPR-compliant consent form</li>
<li>Created a prioritised backlog linking features to user needs with severity and inclusion-risk tagging</li>
</ul>
<h3 id="learning-outcomes-addressed-1"><a class="header" href="#learning-outcomes-addressed-1">Learning Outcomes Addressed</a></h3>
<p>This lab contributes to the following module Learning Outcomes (<a href="wk06/../references/learning-outcomes.html">full definitions</a>):</p>
<ul>
<li><strong>LO1</strong>: Differentiate people-centred methods ‚Äî evidenced by job story methodology</li>
<li><strong>LO2</strong>: Design and conduct needs-finding ‚Äî evidenced by structured interview + synthesis</li>
<li><strong>LO3</strong>: Analyse ethical implications ‚Äî evidenced by consent protocol and privacy audit</li>
<li><strong>LO13</strong>: Integrate HCI with SE ‚Äî evidenced by backlog with evidence chains</li>
</ul>
<hr />
<h2 id="key-concepts-1"><a class="header" href="#key-concepts-1">Key Concepts</a></h2>
<h3 id="1-needs-finding-vs-requirements-gathering"><a class="header" href="#1-needs-finding-vs-requirements-gathering">1. Needs-Finding vs. Requirements Gathering</a></h3>
<p><strong>Traditional requirements gathering</strong>:</p>
<blockquote>
<p>"The system shall allow users to filter tasks by status (complete/incomplete)."</p>
</blockquote>
<p><strong>Needs-finding</strong>:</p>
<blockquote>
<p>"When I'm preparing for a crit, I want to focus only on deliverable tasks so I can check I haven't missed anything, because I get anxious about deadlines."</p>
</blockquote>
<p><strong>Difference</strong>:</p>
<ul>
<li><strong>Requirements</strong> specify <em>solutions</em> ("filter by status")</li>
<li><strong>Needs</strong> uncover <em>motivations</em> ("reduce anxiety about missed deadlines")</li>
</ul>
<p><strong>Why this matters</strong>: Solutions can change (filter, search, tags, AI assistant), but needs stay constant. Understanding needs lets you pivot to better solutions as technology evolves.</p>
<h3 id="2-jobs-to-be-done-jtbd-framework"><a class="header" href="#2-jobs-to-be-done-jtbd-framework">2. Jobs-to-Be-Done (JTBD) Framework</a></h3>
<p><strong>Job story template</strong>:</p>
<pre><code>When [situation/context],
I want to [motivation/goal],
so I can [desired outcome],
because [underlying need/constraint].
</code></pre>
<p><strong>Example (COMP2850 context)</strong>:</p>
<pre><code>When I'm using a screen reader to check my task list,
I want confirmation messages announced immediately after I delete a task,
so I can know the action succeeded without navigating back to the list,
because re-scanning 20 items to confirm deletion is time-consuming and error-prone.
</code></pre>
<p><strong>Contrast with persona-based user story</strong>:</p>
<blockquote>
<p>"As a blind user, I want screen reader support so I can use the app."</p>
</blockquote>
<p><strong>Problems with persona stories</strong>:</p>
<ul>
<li>Assumes all "blind users" have same needs (heterogeneity ignored)</li>
<li>Focuses on disability label, not situational context</li>
<li>Doesn't explain <em>why</em> the need exists</li>
</ul>
<p><strong>JTBD advantages</strong>:</p>
<ul>
<li>Situation-specific (works for temporary impairments: broken mouse, bright sunlight)</li>
<li>Explains motivation (builds empathy)</li>
<li>Actionable (clear what success looks like)</li>
</ul>
<h3 id="3-informed-consent-uk-gdpr"><a class="header" href="#3-informed-consent-uk-gdpr">3. Informed Consent (UK GDPR)</a></h3>
<p><strong>UK GDPR principles</strong> (Data Protection Act 2018):</p>
<ol>
<li><strong>Lawfulness, fairness, transparency</strong>: People must know what data you collect and why</li>
<li><strong>Purpose limitation</strong>: Only collect data needed for stated purpose</li>
<li><strong>Data minimisation</strong>: Collect as little as possible</li>
<li><strong>Accuracy</strong>: Keep data correct and up-to-date</li>
<li><strong>Storage limitation</strong>: Delete when no longer needed</li>
<li><strong>Integrity &amp; confidentiality</strong>: Protect from unauthorised access</li>
</ol>
<p><strong>Low-risk peer research</strong> (COMP2850 context):</p>
<ul>
<li><strong>No PII</strong>: Use pseudonyms ("Participant A"), not names</li>
<li><strong>Local storage</strong>: CSV files on your machine, not cloud services</li>
<li><strong>Opt-out</strong>: Participant can withdraw at any time</li>
<li><strong>No recordings</strong>: Text notes only (unless explicit consent for audio)</li>
<li><strong>Deletion plan</strong>: Delete at end of Semester 1 (or anonymise for portfolio)</li>
</ul>
<p><strong>Consent script elements</strong>:</p>
<ol>
<li>Purpose ("We're researching task manager usability")</li>
<li>What you'll do ("5-minute interview, taking notes")</li>
<li>Data stored ("Pseudonymised notes in local Git repo")</li>
<li>Rights ("You can stop at any time, request deletion")</li>
<li>Contact ("Email <module> to opt out")</li>
</ol>
<h3 id="4-inclusive-backlog-structure"><a class="header" href="#4-inclusive-backlog-structure">4. Inclusive Backlog Structure</a></h3>
<p><strong>Standard backlog</strong>:</p>
<pre><code>ID | Title | Priority | Effort
1  | Add filter | P1 | 3
</code></pre>
<p><strong>Inclusive backlog</strong> (COMP2850 format):</p>
<pre><code>ID | Title | Story Ref | Need | Type | Severity | Inclusion Risk | Evidence | Notes
1  | Filter remembers query | stories.md#S2 | Reduce cognitive load | Accessibility | High | Cognitive, SR | P2 notes L15 | Filter resets on reload; SR users lose context
</code></pre>
<p><strong>Why additional columns</strong>:</p>
<ul>
<li><strong>Story Ref</strong>: Traceable to research evidence</li>
<li><strong>Inclusion Risk</strong>: Tags who's affected (SR, keyboard, low-vision, cognitive, motor)</li>
<li><strong>Evidence</strong>: Links to pilot notes, WCAG audits, screenshots</li>
<li><strong>Severity</strong>: Impact on task completion (High = blocks, Medium = hinders, Low = cosmetic)</li>
</ul>
<p><strong>Benefits</strong>:</p>
<ul>
<li>Transparent prioritisation (not just "gut feel")</li>
<li>Ensures diverse needs considered (not just mouse + sighted users)</li>
<li>Creates evidence chain for assessments (Task 1, Task 2, studio crit)</li>
</ul>
<h3 id="5-thematic-coding-light-touch"><a class="header" href="#5-thematic-coding-light-touch">5. Thematic Coding (Light Touch)</a></h3>
<p><strong>Thematic coding</strong> = systematically identifying patterns in qualitative data.</p>
<p><strong>Example process</strong>:</p>
<ol>
<li><strong>Read notes</strong>: Highlight key phrases</li>
<li><strong>Code observations</strong>: Tag with themes (e.g., <code>status_feedback</code>, <code>keyboard_nav</code>, <code>cognitive_load</code>)</li>
<li><strong>Group codes</strong>: Cluster similar tags</li>
<li><strong>Synthesise themes</strong>: "Participants struggle to confirm actions succeeded" ‚Üí backlog item: "Add persistent confirmation messages"</li>
</ol>
<p><strong>Tools</strong> (COMP2850 level):</p>
<ul>
<li>Markdown with inline tags: <code>[status_feedback] P2 said "I didn't know if it saved"</code></li>
<li>Spreadsheet with code column</li>
<li>Simple frequency count (how many times each theme appears)</li>
</ul>
<hr />
<h2 id="activity-1-setup--consent-protocol"><a class="header" href="#activity-1-setup--consent-protocol">Activity 1: Setup &amp; Consent Protocol</a></h2>
<p><strong>Time</strong>: 20 minutes
<strong>Materials</strong>: Git repo from Lab 1, consent script template</p>
<h3 id="step-1-create-research-directories"><a class="header" href="#step-1-create-research-directories">Step 1: Create Research Directories</a></h3>
<pre><code class="language-bash">cd comp2850-hci-starter  # Your project from Lab 1
mkdir -p research
mkdir -p backlog
mkdir -p wk06/instrumentation

# Create placeholder files
touch wk06/research/consent-protocol.md
touch wk06/research/stories.md
touch wk06/research/notes.md
touch backlog/backlog.csv
touch wk06/instrumentation/plan.md
</code></pre>
<h3 id="step-2-document-consent-protocol"><a class="header" href="#step-2-document-consent-protocol">Step 2: Document Consent Protocol</a></h3>
<p>Edit <code>wk06/research/consent-protocol.md</code>:</p>
<pre><code class="language-markdown"># Informed Consent Protocol ‚Äî Week 6 Peer Interviews

**Module**: COMP2850 Human-Computer Interaction
**Activity**: Low-risk needs-finding (peer interviews)
**Date**: [YYYY-MM-DD]
**Researcher**: [Your Name/Student ID]

---

## Purpose

We are conducting short peer interviews (5-10 minutes) to understand how people use task managers and identify accessibility improvements. This is part of our HCI coursework for Weeks 6-11.

## What You'll Do

I will ask you 3-5 questions about your experience with task management tools (e.g., "Tell me about a time you struggled to find a specific task"). I'll take brief notes. **No recordings** will be made unless you explicitly agree (and I'll ask again before starting).

## Data Collected

- **What I will collect**:
  - Pseudonymised notes (e.g., "Participant A said...")
  - Timestamps of interview
  - Contextual tags (e.g., "Uses keyboard only", "Prefers dark mode")

- **What I will NOT collect**:
  - Your name (unless you want credit in acknowledgements)
  - Student ID number
  - Email address
  - Any other personally identifiable information (PII)

## Data Storage

- **Where**: Local Git repository on my laptop (private repo, not shared publicly)
- **Who can access**: Me, my lab partner, module teaching staff (if requested for marking)
- **How long**: Until end of Semester 1 (January 2025), then deleted OR anonymised for portfolio

## Your Rights (UK GDPR / Data Protection Act 2018)

- **Right to withdraw**: You can stop at any time, no explanation needed
- **Right to access**: You can ask to see your data (I'll show you my notes)
- **Right to erasure**: You can request I delete your data (email me with interview date/pseudonym)
- **Right to complain**: Contact University Data Protection Officer if concerned: dpo@leeds.ac.uk

## Consent Confirmation

Before starting, I will ask:
- [ ] Have I explained the purpose clearly?
- [ ] Do you understand what data I'll collect?
- [ ] Do you know you can stop at any time?
- [ ] Do you consent to participate?

**Verbal consent is sufficient** for this low-risk activity. If you say "yes", I'll note:
- Date/time: [YYYY-MM-DD HH:MM]
- Pseudonym assigned: [e.g., "Participant A"]
- Consent confirmed: [Initials]

---

## Opt-Out Process

If you change your mind after the interview:
1. Email me at [your-university-email]
2. Include: interview date and pseudonym (if you remember it)
3. I will delete all notes related to your session within 48 hours
4. I will confirm deletion via email

---

## Contact

**Researcher**: [Your Name], [your-email@leeds.ac.uk]
**Module Lead**: Dr. [Name], [module-email]
**University Ethics**: Research Ethics, ethics@leeds.ac.uk

---

**Template source**: COMP2850 HCI, University of Leeds
**Reference**: ICO (2024). Guide to GDPR, &lt;https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/&gt;
</code></pre>
<h3 id="step-3-review-with-lab-partner"><a class="header" href="#step-3-review-with-lab-partner">Step 3: Review with Lab Partner</a></h3>
<p>Pair up with a classmate and:</p>
<ol>
<li>Read each other's consent protocols</li>
<li>Check for <strong>missing elements</strong>:
<ul>
<li>‚úÖ Purpose clearly stated?</li>
<li>‚úÖ Data storage location specified?</li>
<li>‚úÖ Participant rights listed (withdraw, access, delete)?</li>
<li>‚úÖ Opt-out process described?</li>
</ul>
</li>
<li>Suggest improvements (clearer language, missing details)</li>
</ol>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ Consent protocol saved in <code>wk06/research/consent-protocol.md</code></li>
<li>‚úÖ Reviewed by peer (get their initials/signature in notes)</li>
<li>‚úÖ Ready to use for interviews</li>
</ul>
<hr />
<h2 id="activity-2-conduct-peer-interviews"><a class="header" href="#activity-2-conduct-peer-interviews">Activity 2: Conduct Peer Interviews</a></h2>
<p><strong>Time</strong>: 40 minutes (20 min each direction)
<strong>Materials</strong>: Interview prompts, note-taking template</p>
<h3 id="step-1-interview-prompts"><a class="header" href="#step-1-interview-prompts">Step 1: Interview Prompts</a></h3>
<p>Use these open-ended prompts (adapt as needed):</p>
<p><strong>General task management</strong>:</p>
<ol>
<li>"Tell me about the last time you used a to-do list or task manager. What were you trying to accomplish?"</li>
<li>"What frustrates you most about managing tasks? Can you give me a specific example?"</li>
<li>"Have you ever lost track of an important task? What happened?"</li>
</ol>
<p><strong>Accessibility &amp; interaction</strong>:
4. "Do you ever work without a mouse (e.g., trackpad broken, using laptop on train)? How does that change how you interact with apps?"
5. "Have you used a task manager with your eyes closed or in bright sunlight? What was hard?"
6. "If you could add one feature to make task management less stressful, what would it be?"</p>
<p><strong>Follow-up probes</strong>:</p>
<ul>
<li>"Can you tell me more about that?"</li>
<li>"How did that make you feel?"</li>
<li>"What did you do to work around it?"</li>
</ul>
<h3 id="step-2-note-taking-template"><a class="header" href="#step-2-note-taking-template">Step 2: Note-Taking Template</a></h3>
<p>Create <code>wk06/research/notes.md</code>:</p>
<pre><code class="language-markdown"># Interview Notes ‚Äî Week 6

## Participant A
**Date**: [YYYY-MM-DD HH:MM]
**Context**: [e.g., Uses keyboard only, prefers dark mode, has ADHD]
**Consent**: ‚úÖ Confirmed verbally
**Duration**: [~10 minutes]

### Q1: Last time you used a task manager
**Response**: "I use Notion for uni work. Last week I had to find all tasks tagged 'COMP2850' to prepare for a deadline. It took ages because the filter kept resetting."

**Observations**:
- Mentioned filter UX issue (cognitive load)
- Time pressure context (deadline stress)
- Tag-based workflow (not just chronological)

**Themes**: `filter_persistence`, `cognitive_load`, `deadline_anxiety`

---

### Q2: What frustrates you?
**Response**: "When I submit a form and nothing happens‚Äîlike, did it save? I have to refresh the whole page to check."

**Observations**:
- Lack of confirmation feedback
- Low trust in interface
- Workaround = page reload (inefficient)

**Themes**: `status_feedback`, `confirmation`, `trust`

---

### Q3: Lost track of important task?
**Response**: "Yeah, I once forgot to submit coursework because it was buried in my list. I wish there was a way to pin urgent things."

**Observations**:
- List length issue (visibility)
- Prioritisation need
- Consequence = missed deadline (high impact)

**Themes**: `prioritisation`, `visibility`, `urgent_tasks`

---

### Q4: Work without a mouse?
**Response**: "My trackpad broke last month. I tried using Tab to navigate, but some buttons were impossible to reach. Had to borrow a friend's mouse."

**Observations**:
- Keyboard-only experience = friction
- Temporary impairment (broken hardware)
- Exclusion from features

**Themes**: `keyboard_nav`, `temporary_impairment`, `button_accessibility`

---

### Q5: Eyes closed / bright sunlight?
**Response**: "Haven't tried eyes closed, but in sunlight I can't read low-contrast text. I increase zoom but then the layout breaks."

**Observations**:
- Contrast issue (situational disability)
- Zoom breaks responsive design
- Environmental factor (sunlight)

**Themes**: `contrast`, `zoom`, `responsive_design`

---

### Q6: One feature to add?
**Response**: "A way to see progress‚Äîlike, 'You've completed 8 out of 12 tasks this week.' That would motivate me."

**Observations**:
- Motivation through feedback
- Progress visualisation
- Weekly scope (not just daily)

**Themes**: `progress_tracking`, `motivation`, `feedback`

---

## Summary (Participant A)
**Top pain points**:
1. Filter resets ‚Üí cognitive overload
2. No confirmation feedback ‚Üí uncertainty
3. Keyboard navigation gaps ‚Üí temporary exclusion
4. Contrast issues in bright light ‚Üí situational disability

**Job story ideas**:
- "When I'm filtering tasks, I want the selection to persist across page reloads so I don't lose my place."
- "When I submit a form, I want immediate confirmation so I know it worked without refreshing."
- "When my mouse breaks, I want full keyboard access so I can still complete tasks."
</code></pre>
<p><strong>Repeat for Participant B, C, etc.</strong></p>
<h3 id="step-3-swap-roles"><a class="header" href="#step-3-swap-roles">Step 3: Swap Roles</a></h3>
<ol>
<li><strong>Researcher ‚Üí Participant</strong>: Your partner interviews you (10 minutes)</li>
<li><strong>Participant ‚Üí Researcher</strong>: You interview your partner (10 minutes)</li>
</ol>
<p><strong>After both interviews</strong>:</p>
<ul>
<li>Compare notes</li>
<li>Identify overlapping themes (both mentioned confirmation feedback?)</li>
<li>Flag unique insights (only one person mentioned colour-blindness?)</li>
</ul>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ At least 2 interviews completed (ideally 3-4)</li>
<li>‚úÖ Notes saved in <code>wk06/research/notes.md</code></li>
<li>‚úÖ Themes tagged consistently (use same terms across interviews)</li>
</ul>
<hr />
<h2 id="activity-3-synthesise-job-stories"><a class="header" href="#activity-3-synthesise-job-stories">Activity 3: Synthesise Job Stories</a></h2>
<p><strong>Time</strong>: 25 minutes
<strong>Materials</strong>: Interview notes, job story template</p>
<h3 id="step-1-extract-situations--needs"><a class="header" href="#step-1-extract-situations--needs">Step 1: Extract Situations &amp; Needs</a></h3>
<p>Review <code>notes.md</code> and list <strong>situations</strong> where people struggled:</p>
<div class="table-wrapper"><table><thead><tr><th>Situation</th><th>Need</th><th>Evidence</th></tr></thead><tbody>
<tr><td>Filtering tasks for specific project</td><td>Filter persists across reloads</td><td>P-A notes L5</td></tr>
<tr><td>Submitting a form</td><td>Confirmation feedback</td><td>P-A notes L12, P-B notes L8</td></tr>
<tr><td>Using keyboard only (broken mouse)</td><td>Full keyboard access to all buttons</td><td>P-A notes L20</td></tr>
<tr><td>Bright sunlight</td><td>High-contrast text</td><td>P-A notes L28</td></tr>
<tr><td>Managing 20+ tasks</td><td>Visual progress indicator</td><td>P-A notes L35, P-B notes L15</td></tr>
</tbody></table>
</div>
<h3 id="step-2-write-job-stories"><a class="header" href="#step-2-write-job-stories">Step 2: Write Job Stories</a></h3>
<p>Create <code>wk06/research/stories.md</code>:</p>
<pre><code class="language-markdown"># Job Stories ‚Äî Week 6 Needs-Finding

## Story S1: Filter Persistence
**Situation**: When I'm filtering tasks by project tag (e.g., "COMP2850")
**Motivation**: I want the filter selection to persist across page reloads
**Outcome**: So I can pick up where I left off without re-selecting the filter
**Underlying need**: Because re-filtering 10+ times per session creates cognitive overload and wastes time

**Evidence**: Participant A (notes L5), Participant B (notes L3)
**Inclusion risk**: Cognitive, memory impairment, ADHD
**Type**: Job story (situation-specific)

---

## Story S2: Confirmation Feedback
**Situation**: When I submit a form (add task, edit task, delete task)
**Motivation**: I want immediate, explicit confirmation that the action succeeded
**Outcome**: So I can trust the interface without refreshing to verify
**Underlying need**: Because uncertainty about save status causes anxiety and inefficient workarounds (page reload)

**Evidence**: Participant A (notes L12), Participant B (notes L8)
**Inclusion risk**: Cognitive, screen reader (if confirmation not announced), low digital literacy
**Type**: Job story

---

## Story S3: Full Keyboard Access
**Situation**: When my mouse/trackpad is unavailable (broken hardware, RSI flare-up, preference)
**Motivation**: I want to access all features using only Tab, Enter, Space, and arrow keys
**Outcome**: So I can complete tasks without being excluded
**Underlying need**: Because reliance on pointing device excludes people with motor impairments or temporary injuries

**Evidence**: Participant A (notes L20)
**Inclusion risk**: Motor impairment, RSI, temporary disability, keyboard-only preference
**Type**: Job story
**WCAG**: 2.1.1 Keyboard (A), 2.1.3 Keyboard (No Exception, AAA)

---

## Story S4: High Contrast
**Situation**: When I'm working in bright sunlight or have low vision
**Motivation**: I want text to have sufficient contrast against background
**Outcome**: So I can read task titles and buttons without straining
**Underlying need**: Because low contrast creates situational disability (sunlight) or permanent exclusion (low vision)

**Evidence**: Participant A (notes L28)
**Inclusion risk**: Low vision, colour-blindness, situational (bright light)
**Type**: Job story
**WCAG**: 1.4.3 Contrast (Minimum, AA) ‚Äî 4.5:1 for normal text

---

## Story S5: Progress Visualisation
**Situation**: When I'm managing a long task list (15+ items)
**Motivation**: I want to see completion progress (e.g., "8/12 done this week")
**Outcome**: So I can feel motivated and track productivity
**Underlying need**: Because invisible progress reduces motivation and makes it hard to assess workload

**Evidence**: Participant A (notes L35), Participant B (notes L15)
**Inclusion risk**: Cognitive, ADHD (executive function support)
**Type**: Job story

---

## Story S6: Persistent Error Messages (No-JS)
**Situation**: When JavaScript is disabled (corporate firewall, data-saving mode) and I submit invalid data
**Motivation**: I want error messages to persist after page reload
**Outcome**: So I can understand what went wrong and correct it
**Underlying need**: Because ephemeral error messages (lost on redirect) require perfect memory or multiple submission attempts

**Evidence**: Inferred from Lab 1 no-JS testing; no explicit interview mention (add if time)
**Inclusion risk**: Cognitive, screen reader (needs page-level error summary)
**Type**: Pain point (internally identified)
**WCAG**: 3.3.1 Error Identification (A), 3.3.3 Error Suggestion (AA)
</code></pre>
<h3 id="step-3-map-stories-to-wcag"><a class="header" href="#step-3-map-stories-to-wcag">Step 3: Map Stories to WCAG</a></h3>
<p>For each story, check if it relates to a WCAG criterion:</p>
<div class="table-wrapper"><table><thead><tr><th>Story</th><th>WCAG Criterion</th><th>Level</th></tr></thead><tbody>
<tr><td>S3 (Keyboard access)</td><td>2.1.1 Keyboard</td><td>A</td></tr>
<tr><td>S4 (Contrast)</td><td>1.4.3 Contrast (Minimum)</td><td>AA</td></tr>
<tr><td>S6 (Error messages)</td><td>3.3.1 Error Identification</td><td>A</td></tr>
</tbody></table>
</div>
<p><strong>Why this matters</strong>: When you build the backlog, you can justify priority with "This is a WCAG Level A failure" vs. "This is a nice-to-have."</p>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ 5-6 job stories written</li>
<li>‚úÖ Each story cites evidence (participant + line number)</li>
<li>‚úÖ Inclusion risk tags added (SR, keyboard, cognitive, etc.)</li>
<li>‚úÖ At least 2 stories map to WCAG criteria</li>
</ul>
<hr />
<h2 id="activity-4-build-inclusive-backlog"><a class="header" href="#activity-4-build-inclusive-backlog">Activity 4: Build Inclusive Backlog</a></h2>
<p><strong>Time</strong>: 30 minutes
<strong>Materials</strong>: Job stories, <code>backlog.csv</code> template</p>
<h3 id="step-1-create-csv-headers"><a class="header" href="#step-1-create-csv-headers">Step 1: Create CSV Headers</a></h3>
<p>Edit <code>backlog/backlog.csv</code>:</p>
<pre><code class="language-csv">id,title,story_ref,story_type,need,type,severity,inclusion_risk,evidence,notes,candidate_fix
</code></pre>
<p><strong>Column definitions</strong>:</p>
<ul>
<li><strong>id</strong>: Unique number (1, 2, 3...)</li>
<li><strong>title</strong>: Short summary (&lt; 10 words)</li>
<li><strong>story_ref</strong>: Link to <code>stories.md#S1</code> or <code>notes.md#L15</code></li>
<li><strong>story_type</strong>: "Job story", "Pain point", "WCAG violation", "Research insight"</li>
<li><strong>need</strong>: High-level category ("Confirmation feedback", "Keyboard access")</li>
<li><strong>type</strong>: "Accessibility", "Usability", "Performance", "Tech debt"</li>
<li><strong>severity</strong>: High (blocks task), Medium (hinders), Low (cosmetic)</li>
<li><strong>inclusion_risk</strong>: Comma-separated tags (SR, Keyboard, Cognitive, Motor, Low vision)</li>
<li><strong>evidence</strong>: Path to notes, screenshot, WCAG reference</li>
<li><strong>notes</strong>: Free-form (root cause, affected flows)</li>
<li><strong>candidate_fix</strong>: <code>true</code> if planning to fix in Week 7 (pick 1-2)</li>
</ul>
<h3 id="step-2-populate-backlog-rows"><a class="header" href="#step-2-populate-backlog-rows">Step 2: Populate Backlog Rows</a></h3>
<p>Example entries:</p>
<pre><code class="language-csv">id,title,story_ref,story_type,need,type,severity,inclusion_risk,evidence,notes,candidate_fix
1,Filter selection resets on page reload,stories.md#S1,Job story,Reduce cognitive load,Usability,Medium,"Cognitive,Memory","P-A notes L5",Current implementation doesn't persist filter state in session or URL,false
2,No confirmation after form submission,stories.md#S2,Job story,Trust &amp; feedback,Accessibility,High,"Cognitive,SR,Low digital literacy","P-A notes L12; P-B notes L8",HTMX shows status in live region (good) but no-JS path gives no feedback (PRG redirect with no message),true
3,Delete button not keyboard-accessible,stories.md#S3,Job story,Full keyboard access,Accessibility,High,"Keyboard,Motor","P-A notes L20; WCAG 2.1.1","Inline form works but focus order unclear; test with Tab-only navigation",true
4,Text contrast below 4.5:1 in default theme,stories.md#S4,Job story,Visibility,Accessibility,Medium,"Low vision,Colour-blind,Situational","P-A notes L28; WCAG 1.4.3",Pico.css default gray (#6c757d) on white = 4.2:1 (fails AA); needs adjustment,false
5,No progress indicator for completed tasks,stories.md#S5,Job story,Motivation &amp; feedback,Usability,Low,Cognitive,"P-A notes L35; P-B notes L15",Nice-to-have; defer to Semester 2 backlog,false
6,Error messages not persistent in no-JS path,stories.md#S6,Pain point,Error recovery,Accessibility,High,"Cognitive,SR","Internal testing; WCAG 3.3.1",PRG redirect loses error context; need error summary on target page,true
7,Skip link not tested with screen reader,Internal audit,WCAG check,Bypass blocks,Accessibility,Medium,SR,"WCAG 2.4.1",Lab 1 tested keyboard focus but not SR announcement; verify with NVDA,false
8,Live region uses polite (should be assertive for errors),Internal audit,WCAG check,Error announcement,Accessibility,High,SR,"WCAG 4.1.3",Errors need aria-live=assertive so SR interrupts to announce; success messages stay polite,false
</code></pre>
<h3 id="step-3-prioritise-with-severity--inclusion"><a class="header" href="#step-3-prioritise-with-severity--inclusion">Step 3: Prioritise with Severity √ó Inclusion</a></h3>
<p><strong>Severity scoring</strong>:</p>
<ul>
<li><strong>High (3 points)</strong>: Blocks task completion or excludes a group</li>
<li><strong>Medium (2 points)</strong>: Makes task harder but workaround exists</li>
<li><strong>Low (1 point)</strong>: Cosmetic or enhancement</li>
</ul>
<p><strong>Inclusion weight</strong>:</p>
<ul>
<li><strong>Multiple groups affected</strong>: +1 point (e.g., SR + Keyboard + Cognitive = +1)</li>
<li><strong>WCAG Level A failure</strong>: +2 points</li>
<li><strong>WCAG Level AA failure</strong>: +1 point</li>
</ul>
<p><strong>Example calculation</strong> (Item #2):</p>
<ul>
<li>Severity: High (3)</li>
<li>Inclusion: SR + Cognitive + Low digital literacy (3 groups) = +1</li>
<li>WCAG: 4.1.3 (AA) = +1</li>
<li><strong>Total priority</strong>: 3 + 1 + 1 = 5 ‚Üí <strong>Fix in Week 7</strong></li>
</ul>
<p><strong>Example calculation</strong> (Item #5):</p>
<ul>
<li>Severity: Low (1)</li>
<li>Inclusion: Cognitive only (1 group) = 0</li>
<li>WCAG: N/A = 0</li>
<li><strong>Total priority</strong>: 1 ‚Üí <strong>Defer to Semester 2</strong></li>
</ul>
<h3 id="step-4-select-candidate-fixes"><a class="header" href="#step-4-select-candidate-fixes">Step 4: Select Candidate Fixes</a></h3>
<p>Mark 1-2 items with <code>candidate_fix=true</code>. These are the issues you'll fix in <strong>Week 7 Lab 2</strong>. Criteria:</p>
<ul>
<li>High severity + high inclusion risk</li>
<li>Fixable in 1-2 hours (scoped for lab time)</li>
<li>Clear WCAG criterion to verify against</li>
</ul>
<p><strong>Recommended first fixes</strong>:</p>
<ol>
<li>Item #2 (No confirmation in no-JS) ‚Üí Add error summary</li>
<li>Item #3 (Keyboard access) ‚Üí Verify Tab order, add aria-labels</li>
<li>Item #8 (Live region assertive for errors) ‚Üí Change <code>aria-live</code> attribute</li>
</ol>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ At least 8 backlog items (mix of research + WCAG audit)</li>
<li>‚úÖ Severity and inclusion risk assigned to each</li>
<li>‚úÖ 1-2 items marked as candidate fixes</li>
<li>‚úÖ Evidence column links to notes or WCAG reference</li>
</ul>
<hr />
<h2 id="activity-5-instrumentation-planning-teaser"><a class="header" href="#activity-5-instrumentation-planning-teaser">Activity 5: Instrumentation Planning (Teaser)</a></h2>
<p><strong>Time</strong>: 15 minutes
<strong>Materials</strong>: <code>wk06/instrumentation/plan.md</code></p>
<p>In <strong>Week 9</strong> you'll run task-based pilots and collect metrics (time-on-task, error rate, completion rate). Today you'll sketch what data to capture.</p>
<h3 id="step-1-identify-events-to-log"><a class="header" href="#step-1-identify-events-to-log">Step 1: Identify Events to Log</a></h3>
<p>Based on your backlog, list key events:</p>
<div class="table-wrapper"><table><thead><tr><th>Event</th><th>Why Log It</th><th>Fields to Capture</th></tr></thead><tbody>
<tr><td><code>task_created</code></td><td>Measure add task completion time</td><td><code>ts_iso</code>, <code>session_id</code>, <code>title_length</code>, <code>js_mode</code></td></tr>
<tr><td><code>task_deleted</code></td><td>Measure delete task completion time</td><td><code>ts_iso</code>, <code>session_id</code>, <code>task_id</code>, <code>js_mode</code></td></tr>
<tr><td><code>validation_error</code></td><td>Count errors (usability metric)</td><td><code>ts_iso</code>, <code>session_id</code>, <code>field</code>, <code>error_type</code>, <code>js_mode</code></td></tr>
<tr><td><code>filter_applied</code></td><td>Track filter usage (S1 story)</td><td><code>ts_iso</code>, <code>session_id</code>, <code>filter_value</code>, <code>result_count</code></td></tr>
</tbody></table>
</div>
<h3 id="step-2-draft-instrumentation-plan"><a class="header" href="#step-2-draft-instrumentation-plan">Step 2: Draft Instrumentation Plan</a></h3>
<p>Edit <code>wk06/instrumentation/plan.md</code>:</p>
<pre><code class="language-markdown"># Instrumentation Plan ‚Äî Week 6

**Purpose**: Capture objective metrics for Week 9 task-based pilots and Week 10 analysis.

---

## Events to Log

### 1. Task Created
**Trigger**: POST /tasks (success)
**Fields**:
- `ts_iso`: ISO 8601 timestamp (e.g., 2025-01-15T14:23:45Z)
- `session_id`: Anonymous 6-char hex (e.g., `P1_a3f7`)
- `request_id`: Unique per request (for tracing)
- `task_code`: `T3_add` (pilot task identifier)
- `step`: `submit`
- `outcome`: `success` | `validation_error`
- `ms`: Time from request start to response (server-side)
- `http_status`: 200 (success) | 400 (validation error)
- `js_mode`: `js-on` | `js-off`

**Why**: Measure task completion time, compare HTMX vs. no-JS.

---

### 2. Validation Error
**Trigger**: POST /tasks (blank title)
**Fields**: Same as Task Created, but `outcome=validation_error`, `http_status=400`

**Why**: Count errors as usability metric; high error rate = poor UX.

---

### 3. Task Deleted
**Trigger**: POST /tasks/{id}/delete (success)
**Fields**: Same structure as Task Created, but `task_code=T4_delete`

**Why**: Measure delete task time; verify live region announcement.

---

## Data Storage

- **Format**: CSV (human-readable, easy to analyse in Excel/Google Sheets)
- **Location**: `data/metrics.csv` (local file, not cloud)
- **Schema**:
  ```csv
  ts_iso,session_id,request_id,task_code,step,outcome,ms,http_status,js_mode
</code></pre>
<p><strong>Example rows</strong>:</p>
<pre><code class="language-csv">2025-01-15T14:23:45Z,P1_a3f7,req_001,T3_add,submit,success,120,200,js-on
2025-01-15T14:24:10Z,P1_a3f7,req_002,T4_delete,submit,success,85,200,js-on
2025-01-15T14:25:00Z,P2_b8c4,req_003,T3_add,submit,validation_error,0,400,js-off
</code></pre>
<hr />
<h2 id="ethics--privacy"><a class="header" href="#ethics--privacy">Ethics &amp; Privacy</a></h2>
<ul>
<li><strong>No PII</strong>: Session IDs are random hex (not linked to names/emails)</li>
<li><strong>Anonymisation</strong>: Use <code>P1</code>, <code>P2</code> pseudonyms (consistent with interview notes)</li>
<li><strong>Consent</strong>: Covered by Week 6 consent protocol (low-risk research)</li>
<li><strong>Retention</strong>: Delete after Semester 1 or anonymise for portfolio</li>
</ul>
<hr />
<h2 id="implementation-week-9"><a class="header" href="#implementation-week-9">Implementation (Week 9)</a></h2>
<p>Create <code>src/main/kotlin/utils/Logger.kt</code>:</p>
<pre><code class="language-kotlin">object Logger {
    private val file = File("data/metrics.csv").apply {
        parentFile?.mkdirs()
        if (!exists()) writeText("ts_iso,session_id,request_id,task_code,step,outcome,ms,http_status,js_mode\n")
    }

    @Synchronized
    fun write(session: String, req: String, task: String, step: String, outcome: String, ms: Long, status: Int, js: String) {
        val ts = DateTimeFormatter.ISO_INSTANT.format(Instant.now())
        file.appendText("$ts,$session,$req,$task,$step,$outcome,$ms,$status,$js\n")
    }
}
</code></pre>
<hr />
<p><strong>Next steps</strong>: In Week 9 Lab 1, integrate Logger into routes and test with manual pilots.</p>
<pre><code>
**Stop and check**:
- ‚úÖ Instrumentation plan saved
- ‚úÖ Events identified (at least 3)
- ‚úÖ CSV schema defined
- ‚úÖ Ethics considerations documented

---

## Reflection Questions

1. **Job stories vs. requirements**: Look at your backlog. How would the items differ if you'd written traditional requirements ("The system shall...") instead of job stories?

2. **Consent trade-offs**: Our protocol uses pseudonyms and no recordings. What insights might we *miss* by not recording audio? When would recordings be justified?

3. **Inclusion risk tagging**: Review your backlog. Did you find issues that affect *only* screen reader users, or do most issues affect multiple groups? What does this tell you about inclusive design?

4. **Evidence chains**: Pick one backlog item. Can you trace it from interview notes ‚Üí job story ‚Üí backlog ‚Üí (future) fix ‚Üí verification? What's missing in your chain?

---

## Further Reading

**Jobs-to-Be-Done**
- Christensen, C. M., Hall, T., Dillon, K., &amp; Duncan, D. S. (2016). "Know Your Customers' Jobs to Be Done." *Harvard Business Review*. &lt;https://hbr.org/2016/09/know-your-customers-jobs-to-be-done&gt;
- Christensen, C. M., Hall, T., Dillon, K., &amp; Duncan, D. S. (2016). *Competing Against Luck*. HarperCollins.

**Qualitative research methods**
- Lazar, J., Feng, J. H., &amp; Hochheiser, H. (2017). *Research Methods in Human-Computer Interaction* (2nd ed.). Morgan Kaufmann. (Ch. 9: Interviews &amp; Focus Groups)
- Braun, V., &amp; Clarke, V. (2006). "Using thematic analysis in psychology." *Qualitative Research in Psychology*, 3(2), 77-101.

**Ethics &amp; GDPR**
- ICO (2024). *Guide to the UK GDPR*. &lt;https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/&gt;
- BCS (2022). *Code of Conduct*. &lt;https://www.bcs.org/membership-and-registrations/become-a-member/bcs-code-of-conduct/&gt;

**Inclusive design**
- Microsoft (2024). *Inclusive Design Toolkit*. &lt;https://inclusive.microsoft.design/&gt;
- Holmes, K. (2018). *Mismatch: How Inclusion Shapes Design*. MIT Press.

---

## Glossary Summary

| Term | Definition | Example/Context |
|------|------------|-----------------|
| **Needs-finding** | Research to understand people's motivations, not just feature requests | Interviews reveal "I want confirmation" (need) vs. "Add a popup" (solution) |
| **Job story** | Situation-specific story format: When/I want/So I can/Because | "When filtering, I want persistence so I don't lose context because re-filtering is tedious" |
| **Informed consent** | Explaining research purpose, data use, and participant rights before collecting data | Consent script explains what you'll note, where it's stored, how to opt out |
| **Pseudonym** | Fake name to protect identity | "Participant A" instead of "Alice Smith" |
| **PII (Personally Identifiable Information)** | Data that can identify an individual (name, email, student ID) | Names = PII; random session IDs ‚â† PII |
| **UK GDPR** | Data protection law (Data Protection Act 2018) | Right to access, delete, withdraw consent |
| **Inclusive backlog** | Backlog with severity + inclusion risk tags | "High severity, affects SR + Keyboard users" |
| **Thematic coding** | Identifying patterns in qualitative data | Tag interview notes with `confirmation`, `keyboard_nav` themes |
| **Severity** | Impact on task completion (High/Medium/Low) | High = blocks completion; Low = cosmetic |
| **Inclusion risk** | Who's affected (SR, Keyboard, Cognitive, Motor, Low vision) | SR + Cognitive = multiple groups at risk |

---

## Lab Checklist

Before leaving lab, confirm:

- [ ] **Consent protocol written**: `wk06/research/consent-protocol.md` complete with opt-out process
- [ ] **Interviews completed**: At least 2 peer interviews (ideally 3-4)
- [ ] **Notes saved**: `wk06/research/notes.md` with themes tagged
- [ ] **Job stories written**: 5-6 stories in `wk06/research/stories.md` with evidence links
- [ ] **Backlog populated**: 8+ items in `backlog/backlog.csv` with severity + inclusion risk
- [ ] **Candidate fixes selected**: 1-2 items marked `candidate_fix=true`
- [ ] **Instrumentation plan drafted**: `wk06/instrumentation/plan.md` outlines metrics for Week 9
- [ ] **Code committed**: `git add wk06/`, `git commit -m "wk6-lab2: needs-finding + consent + backlog"`

---

## Next Steps

In **Week 7 Lab 1** you will:
1. Review ethics guidance from guest speaker
2. Implement accessible inline edit (dual-path HTMX + no-JS)
3. Add validation with `aria-describedby` and `role="alert"`
4. Test with screen reader (NVDA/VoiceOver)

**Preparation**:
- Ensure scaffold from Lab 1 still runs (`./gradlew run`)
- Review backlog items marked `candidate_fix=true`
- Install NVDA (Windows) or enable VoiceOver (macOS) for testing

---

**Lab authored by**: COMP2850 Teaching Team, University of Leeds
**Last updated**: 2025-01-14
**Licence**: Academic use only (not for redistribution)</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="code-resources"><a class="header" href="#code-resources">Code Resources</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-7--lab-1-ethics-in-practice--accessible-inline-edit"><a class="header" href="#week-7--lab-1-ethics-in-practice--accessible-inline-edit">Week 7 ‚Ä¢ Lab 1: Ethics in Practice &amp; Accessible Inline Edit</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-7-orange" alt="Week 7" />
<img src="https://img.shields.io/badge/Lab-1-green" alt="Lab 1" />
<img src="https://img.shields.io/badge/Status-Draft-yellow" alt="Status" /></p>
<hr />
<h2 id="terminology-note-2"><a class="header" href="#terminology-note-2">Terminology Note</a></h2>
<p>Throughout COMP2850 we use <strong>people-centred language</strong> (e.g., "person using a screen reader") rather than deficit-based terms (e.g., "blind user"). This reflects contemporary inclusive-design practice and acknowledges that disability arises from environmental barriers, not individual impairment.</p>
<hr />
<h2 id="pre-reading-2"><a class="header" href="#pre-reading-2">Pre-reading</a></h2>
<p><strong>Essential</strong></p>
<ul>
<li>Pull latest changes in your starter repository (Week 7 branch)</li>
<li><a href="https://www.w3.org/WAI/WCAG22/Understanding/error-identification.html">W3C (2024). WCAG 2.2: 3.3.1 Error Identification</a></li>
<li><a href="https://www.w3.org/WAI/WCAG22/Understanding/status-messages.html">W3C (2024). WCAG 2.2: 4.1.3 Status Messages</a></li>
<li><a href="https://htmx.org/examples/click-to-edit/">HTMX: Click to Edit Pattern</a></li>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/Accessibility/ARIA/ARIA_Live_Regions">MDN: ARIA Live Regions</a></li>
</ul>
<p><strong>Recommended</strong></p>
<ul>
<li><a href="https://design-system.service.gov.uk/components/error-message/">GOV.UK: Error Message Pattern</a></li>
<li><a href="wk07/../references/example-accessible-inline-edit.html">Example: Accessible Inline Edit</a> (worked example with code)</li>
<li><a href="wk07/../references/privacy-by-design.html">Privacy by Design</a> (ethics framework)</li>
</ul>
<hr />
<h2 id="introduction-2"><a class="header" href="#introduction-2">Introduction</a></h2>
<h3 id="context-2"><a class="header" href="#context-2">Context</a></h3>
<p>In <strong>Week 6</strong> you built a server-first task manager with add/delete functionality. The scaffold works without JavaScript, uses ARIA live regions for status announcements, and follows the PRG (Post-Redirect-Get) pattern.</p>
<p><strong>This week you'll add inline editing</strong>‚Äîone of the most challenging patterns to make accessible. Done poorly, inline edit breaks screen reader navigation, loses keyboard focus, and excludes people using assistive technology. Done well, it provides a seamless experience across HTMX, no-JS, keyboard, and screen reader interaction modes.</p>
<p>You'll also review <strong>ethics in practice</strong>: how consent, data minimisation, and privacy-by-design shape implementation decisions (not just policy documents).</p>
<h3 id="why-this-matters-3"><a class="header" href="#why-this-matters-3">Why This Matters</a></h3>
<p><strong>Professionally</strong>, inline edit is everywhere:</p>
<ul>
<li><strong>Trello</strong> (task management): click card title to edit</li>
<li><strong>Notion</strong> (knowledge base): click any block to edit</li>
<li><strong>GitHub</strong> (issue tracking): click issue title to edit</li>
</ul>
<p>All these examples face the same accessibility challenge: how do you swap view mode ‚Üî edit mode without losing context for screen reader users?</p>
<p><strong>Academically</strong>, this lab demonstrates:</p>
<ul>
<li><strong>Dual-path architecture</strong>: Same feature, different implementation (HTMX vs. no-JS)</li>
<li><strong>Progressive disclosure</strong>: Edit form only appears when needed (not cluttering UI)</li>
<li><strong>ARIA best practices</strong>: <code>aria-describedby</code>, <code>role="alert"</code>, focus management</li>
</ul>
<h2 id="learning-focus-2"><a class="header" href="#learning-focus-2">Learning Focus</a></h2>
<h3 id="lab-objectives-2"><a class="header" href="#lab-objectives-2">Lab Objectives</a></h3>
<p>By the end of this session, you will have:</p>
<ul>
<li>Implemented a consent modal with GDPR-compliant controls</li>
<li>Built an inline-edit feature with accessible focus management and dual-path support (HTMX + no-JS)</li>
<li>Created accessible validation with ARIA error identification</li>
<li>Tested with keyboard and screen reader (NVDA/VoiceOver)</li>
<li>Documented ethical trade-offs in design decisions</li>
</ul>
<h3 id="learning-outcomes-addressed-2"><a class="header" href="#learning-outcomes-addressed-2">Learning Outcomes Addressed</a></h3>
<p>This lab contributes to the following module Learning Outcomes (<a href="wk07/../references/learning-outcomes.html">full definitions</a>):</p>
<ul>
<li><strong>LO3</strong>: Analyse ethical implications ‚Äî evidenced by consent modal implementation</li>
<li><strong>LO5</strong>: Create interface prototypes ‚Äî evidenced by inline-edit feature</li>
<li><strong>LO9</strong>: Apply inclusive design ‚Äî evidenced by keyboard navigation + ARIA patterns</li>
<li><strong>LO10</strong>: Critique societal impacts ‚Äî evidenced by ethics reflection</li>
</ul>
<hr />
<h2 id="key-concepts-2"><a class="header" href="#key-concepts-2">Key Concepts</a></h2>
<h3 id="1-inline-edit-pattern"><a class="header" href="#1-inline-edit-pattern">1. Inline Edit Pattern</a></h3>
<p><strong>Inline edit</strong> = editing content in place (not navigating to a separate edit page).</p>
<p><strong>View mode</strong> ‚Üí <strong>Edit mode</strong> ‚Üí <strong>View mode</strong></p>
<p><strong>Traditional approach</strong> (separate edit page):</p>
<pre><code>View: GET /tasks/1 ‚Üí shows task details
Edit: GET /tasks/1/edit ‚Üí shows edit form
Save: POST /tasks/1 ‚Üí validates, redirects to /tasks/1
</code></pre>
<p><strong>Inline edit approach</strong>:</p>
<pre><code>View: Renders view template (title as text)
Edit: Swaps view ‚Üí edit template (title as input)
Save: Swaps edit ‚Üí view template (updated title)
</code></pre>
<p><strong>Why inline edit is harder for accessibility</strong>:</p>
<ul>
<li>Focus moves between elements (button ‚Üí input ‚Üí button)</li>
<li>Screen reader must announce mode change</li>
<li>Cancel action must restore original state</li>
<li>Keyboard shortcuts conflict (Enter = submit vs. newline)</li>
</ul>
<h3 id="2-dual-path-implementation"><a class="header" href="#2-dual-path-implementation">2. Dual-Path Implementation</a></h3>
<p><strong>HTMX path</strong> (JavaScript enabled):</p>
<ol>
<li>Customer clicks "Edit" button</li>
<li><code>hx-get="/tasks/1/edit"</code> ‚Üí server returns edit form HTML fragment</li>
<li><code>hx-target="#task-1" hx-swap="outerHTML"</code> ‚Üí replaces <code>&lt;li&gt;</code> with form</li>
<li>Customer edits, clicks "Save"</li>
<li><code>hx-post="/tasks/1/edit"</code> ‚Üí server validates, returns updated view fragment</li>
<li>HTMX swaps form ‚Üí view mode</li>
<li>OOB status update announces "Task updated"</li>
</ol>
<p><strong>No-JS path</strong> (JavaScript disabled):</p>
<ol>
<li>Customer clicks "Edit" button</li>
<li>GET <code>/tasks/1/edit</code> ‚Üí full-page reload with edit form shown</li>
<li>Customer edits, clicks "Save"</li>
<li>POST <code>/tasks/1/edit</code> ‚Üí validates, redirects to <code>/tasks</code> (PRG)</li>
<li>Page reloads showing updated task</li>
</ol>
<p><strong>Key invariant</strong>: Both paths end in same state (task updated), just different UX (instant swap vs. page reload).</p>
<h3 id="3-aria-error-identification-wcag-331"><a class="header" href="#3-aria-error-identification-wcag-331">3. ARIA Error Identification (WCAG 3.3.1)</a></h3>
<p><strong>WCAG 3.3.1 (Level A)</strong>: If an input error is detected, the item in error is identified and described to the user in text.</p>
<p><strong>Requirements</strong>:</p>
<ol>
<li>Error must be <strong>identified</strong>: Label or instruction shows which field has error</li>
<li>Error must be <strong>described</strong>: Specific message (not just "Invalid")</li>
<li>Error must be <strong>programmatically associated</strong>: Screen reader announces error with field</li>
</ol>
<p><strong>Implementation</strong>:</p>
<pre><code class="language-html">&lt;label for="title-1"&gt;Title&lt;/label&gt;
&lt;input id="title-1" name="title"
       aria-describedby="hint-1 error-1"&gt;
&lt;small id="hint-1"&gt;Keep it short and specific.&lt;/small&gt;
&lt;p id="error-1" role="alert"&gt;Title is required. Please enter at least one character.&lt;/p&gt;
</code></pre>
<p><strong>How it works</strong>:</p>
<ol>
<li>Input links to error via <code>aria-describedby="error-1"</code></li>
<li>Screen reader announces: "Title, edit, Keep it short and specific, Title is required. Please enter at least one character."</li>
<li><code>role="alert"</code> makes screen reader interrupt to announce error</li>
</ol>
<h3 id="4-focus-management"><a class="header" href="#4-focus-management">4. Focus Management</a></h3>
<p><strong>Problem</strong>: When HTMX swaps DOM elements, focus can be lost.</p>
<p><strong>Example</strong>:</p>
<pre><code>1. Customer focuses "Edit" button
2. Clicks Enter (activates button)
3. HTMX swaps &lt;li&gt; ‚Üí &lt;form&gt;
4. Focus lost (button no longer exists)
</code></pre>
<p><strong>Solutions</strong>:</p>
<ul>
<li><strong>HTMX attempts restoration</strong>: If swapped element has same <code>id</code>, HTMX tries to restore focus</li>
<li><strong>Manual focus</strong>: Use <code>hx-on::after-swap="document.getElementById('title-1').focus()"</code></li>
<li><strong>Tab order preserved</strong>: Ensure new elements appear in logical position</li>
</ul>
<p><strong>WCAG 2.4.3 (Focus Order, A)</strong>: If a web page can be navigated sequentially, focusable components receive focus in an order that preserves meaning and operability.</p>
<h3 id="5-status-messages-wcag-413"><a class="header" href="#5-status-messages-wcag-413">5. Status Messages (WCAG 4.1.3)</a></h3>
<p><strong>WCAG 4.1.3 (Level AA)</strong>: Status messages can be programmatically determined through role or properties such that they can be presented to the user by assistive technologies without receiving focus.</p>
<p><strong>Status message</strong> = information about the outcome of an action (success, error, progress).</p>
<p><strong>Implementation</strong>:</p>
<pre><code class="language-html">&lt;!-- In base.peb --&gt;
&lt;div id="status" role="status" aria-live="polite"&gt;&lt;/div&gt;

&lt;!-- Server response (HTMX OOB) --&gt;
&lt;div id="status" hx-swap-oob="true"&gt;Task "Buy milk" updated successfully.&lt;/div&gt;
</code></pre>
<p><strong>Why this matters</strong>: Screen reader users need confirmation that save succeeded, but moving focus to a status message disrupts workflow. Live regions solve this by announcing without focus change.</p>
<hr />
<h2 id="activity-1-ethics-refresher--data-boundaries"><a class="header" href="#activity-1-ethics-refresher--data-boundaries">Activity 1: Ethics Refresher &amp; Data Boundaries</a></h2>
<p><strong>Time</strong>: 20 minutes
<strong>Materials</strong>: Week 6 consent protocol, privacy-by-design guidance</p>
<h3 id="step-1-review-consent-protocol"><a class="header" href="#step-1-review-consent-protocol">Step 1: Review Consent Protocol</a></h3>
<p>Open <code>wk06/research/consent-protocol.md</code> from Week 6 Lab 2.</p>
<p><strong>Check</strong>:</p>
<ul>
<li>‚úÖ Purpose clearly stated?</li>
<li>‚úÖ Data storage location specified (local Git repo)?</li>
<li>‚úÖ Participant rights listed (withdraw, access, delete)?</li>
<li>‚úÖ Opt-out process described?</li>
</ul>
<p><strong>If missing any</strong>, update now before Week 7 interviews/testing.</p>
<h3 id="step-2-identify-data-boundaries"><a class="header" href="#step-2-identify-data-boundaries">Step 2: Identify Data Boundaries</a></h3>
<p>Create <code>wk07/ethics/data-boundaries.md</code>:</p>
<pre><code class="language-markdown"># Data Boundaries ‚Äî Week 7

## What We Collect (Allowed)
- **Pseudonymised session IDs**: Random 6-char hex (e.g., `P1_a3f7`)
- **Task metadata**: Title, completion status, timestamps
- **Interaction logs**: HTTP requests, response times, error codes
- **Accessibility testing notes**: "NVDA announced X", "Focus moved to Y"

## What We DO NOT Collect (Prohibited)
- ‚ùå Real names (use pseudonyms: Participant A, P1, etc.)
- ‚ùå Student ID numbers
- ‚ùå Email addresses
- ‚ùå IP addresses (Ktor logs disabled in production)
- ‚ùå Content of tasks beyond module examples (e.g., no personal to-do items)

## Storage &amp; Retention
- **Location**: Local CSV files (`data/tasks.csv`, `data/metrics.csv`)
- **Access**: Researcher, lab partner, module staff (on request)
- **Encryption**: Standard filesystem permissions (chmod 600)
- **Deletion**: End of Semester 1 (January 2025) OR anonymised for portfolio

## Privacy by Design Principles Applied
1. **Data minimisation**: Only collect session ID (not name)
2. **Purpose limitation**: Metrics used only for HCI evaluation (not sold/shared)
3. **Storage limitation**: Delete after assessment complete
4. **Integrity &amp; confidentiality**: Local storage (not cloud), Git repo private

## Ethics Risks Identified
| Risk | Mitigation |
|------|-----------|
| Task titles contain sensitive info | Provide example tasks ("Buy milk"); warn against personal content |
| Session IDs linked to participants | Use randomised IDs; don't store mapping |
| Git repo accidentally public | Verify `.git/config` remote is private; add `.gitignore` for `/data` |
| Screenshots include PII | Crop to relevant UI; blur names if visible |

---

**Reference**: ICO (2024). Guide to GDPR, &lt;https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/&gt;
</code></pre>
<h3 id="step-3-update-gitignore"><a class="header" href="#step-3-update-gitignore">Step 3: Update <code>.gitignore</code></a></h3>
<p>Ensure sensitive data isn't committed:</p>
<pre><code class="language-bash"># Add to .gitignore
/data/tasks.csv
/data/metrics.csv
/wk*/research/*notes.md  # Interview notes with pseudonyms
*.log
</code></pre>
<p><strong>Rationale</strong>: Even with pseudonyms, raw interview notes could be re-identified in small cohorts. Keep them local, don't push to remote.</p>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ Data boundaries documented</li>
<li>‚úÖ <code>.gitignore</code> updated to exclude sensitive files</li>
<li>‚úÖ Consent protocol from Week 6 still valid</li>
</ul>
<hr />
<h2 id="activity-2-implement-viewedit-templates"><a class="header" href="#activity-2-implement-viewedit-templates">Activity 2: Implement View/Edit Templates</a></h2>
<p><strong>Time</strong>: 30 minutes
<strong>Materials</strong>: <code>templates/tasks/</code>, Pebble template engine</p>
<blockquote>
<p><strong>üîÑ Refactoring Note: From Monolithic to Partials</strong></p>
<p>In <strong>Week 6</strong>, your <code>tasks/index.peb</code> rendered each task as a simple <code>&lt;li&gt;</code> with title + delete button:</p>
<pre><code class="language-html">{% for task in tasks %}
  &lt;li id="task-{{ task.id }}"&gt;
    &lt;span&gt;{{ task.title }}&lt;/span&gt;
    &lt;form action="/tasks/{{ task.id }}/delete" method="post"&gt;
      &lt;button type="submit"&gt;Delete&lt;/button&gt;
    &lt;/form&gt;
  &lt;/li&gt;
{% endfor %}
</code></pre>
<p>In <strong>Week 7</strong>, we introduce <strong>inline editing</strong>, which requires two states:</p>
<ul>
<li><strong>View mode</strong>: Display title with Edit/Delete buttons</li>
<li><strong>Edit mode</strong>: Show input field with Save/Cancel buttons</li>
</ul>
<p><strong>Refactoring strategy</strong>:</p>
<ol>
<li>Extract <code>&lt;li&gt;</code> markup into <strong>two partial templates</strong>:
<ul>
<li><code>_item.peb</code> - Read-only display (view mode)</li>
<li><code>_edit.peb</code> - Editable input (edit mode)</li>
</ul>
</li>
<li>Update <code>tasks/index.peb</code> to <code>{% include %}</code> the appropriate partial</li>
<li>HTMX will swap partials in-place (view ‚Üî edit) without full page reload</li>
</ol>
<p><strong>Before</strong> (Week 6):</p>
<pre><code>tasks/index.peb (full page)
  ‚îî‚îÄ‚îÄ &lt;li&gt; hardcoded for each task
</code></pre>
<p><strong>After</strong> (Week 7):</p>
<pre><code>tasks/index.peb (full page)
  ‚îî‚îÄ‚îÄ {% include "tasks/_item.peb" %}  ‚Üê Reusable view partial
  ‚îî‚îÄ‚îÄ {% include "tasks/_edit.peb" %}  ‚Üê Reusable edit partial
</code></pre>
<p><strong>Note</strong>: The underscore prefix (<code>_</code>) indicates these are <strong>partials</strong> (fragments included in other templates), not standalone pages. This is a widely-used convention (Rails, Jekyll, Sass) that Week 8 explains in detail.</p>
<pre><code>
This **separation of concerns** makes it easier to:
- Swap between states (HTMX swaps just the `&lt;li&gt;`, not the whole page)
- Test each mode independently
- Add more modes later (e.g., "completed" view with strikethrough)
</code></pre>
</blockquote>
<h3 id="step-1-understanding-the-existing-structure"><a class="header" href="#step-1-understanding-the-existing-structure">Step 1: Understanding the Existing Structure</a></h3>
<p>From Week 6, you already have <code>templates/tasks/_item.peb</code> which displays a task in <strong>view mode</strong>. In Week 7, we'll add an Edit button to <code>_item.peb</code> and create a new <code>_edit.peb</code> template for <strong>edit mode</strong>.</p>
<p>We'll create <strong>two modes</strong>: view (display title) and edit (input field).</p>
<h3 id="step-2-update-view-mode-partial"><a class="header" href="#step-2-update-view-mode-partial">Step 2: Update View Mode Partial</a></h3>
<p>The <code>_item.peb</code> template already exists from Week 6. We need to <strong>add an Edit button</strong> to it.</p>
<p>Update <code>templates/tasks/_item.peb</code> to add an Edit button before the Toggle button:</p>
<pre><code class="language-html">&lt;li id="task-{{ task.id }}" class="task-view"&gt;
  &lt;span class="task-title"&gt;{{ task.title }}&lt;/span&gt;

  &lt;form action="/tasks/{{ task.id }}/edit" method="get" style="display: inline;"
        hx-get="/tasks/{{ task.id }}/edit"
        hx-target="#task-{{ task.id }}"
        hx-swap="outerHTML"&gt;
    &lt;button type="submit" aria-label="Edit task: {{ task.title }}"&gt;Edit&lt;/button&gt;
  &lt;/form&gt;

  &lt;form action="/tasks/{{ task.id }}/delete" method="post" style="display: inline;"
        hx-post="/tasks/{{ task.id }}/delete"
        hx-target="#task-{{ task.id }}"
        hx-swap="outerHTML"&gt;
    &lt;button type="submit" aria-label="Delete task: {{ task.title }}"&gt;Delete&lt;/button&gt;
  &lt;/form&gt;
&lt;/li&gt;
</code></pre>
<p><strong>Accessibility features</strong>:</p>
<ul>
<li>Unique <code>id="task-{{ task.id }}"</code> for HTMX targeting</li>
<li><code>aria-label</code> on buttons provides context ("Edit task: Buy milk")</li>
<li>Semantic <code>&lt;li&gt;</code> structure (screen readers announce "List item 1 of 5")</li>
</ul>
<h3 id="step-3-create-edit-mode-partial"><a class="header" href="#step-3-create-edit-mode-partial">Step 3: Create Edit Mode Partial</a></h3>
<p>Create a new file <code>templates/tasks/_edit.peb</code>:</p>
<pre><code class="language-html">&lt;li id="task-{{ task.id }}" class="task-edit"&gt;
  &lt;form action="/tasks/{{ task.id }}/edit" method="post"
        hx-post="/tasks/{{ task.id }}/edit"
        hx-target="#task-{{ task.id }}"
        hx-swap="outerHTML"&gt;

    &lt;label for="title-{{ task.id }}"&gt;Title&lt;/label&gt;
    &lt;input type="text"
           id="title-{{ task.id }}"
           name="title"
           value="{{ task.title }}"
           required
           autofocus
           aria-describedby="hint-{{ task.id }}{% if error %} error-{{ task.id }}{% endif %}"&gt;

    &lt;small id="hint-{{ task.id }}"&gt;Keep it short and specific.&lt;/small&gt;

    {% if error %}
      &lt;p id="error-{{ task.id }}" class="error" role="alert" aria-live="assertive"&gt;
        {{ error }}
      &lt;/p&gt;
    {% else %}
      &lt;p id="error-{{ task.id }}" class="visually-hidden" aria-live="assertive"&gt;&lt;/p&gt;
    {% endif %}

    &lt;button type="submit"&gt;Save&lt;/button&gt;
    &lt;a href="/tasks"
       hx-get="/tasks/{{ task.id }}/view"
       hx-target="#task-{{ task.id }}"
       hx-swap="outerHTML"
       role="button"&gt;Cancel&lt;/a&gt;
  &lt;/form&gt;
&lt;/li&gt;
</code></pre>
<p><strong>Accessibility features</strong>:</p>
<ul>
<li><code>autofocus</code>: Input receives focus when form appears (keyboard users can start typing immediately)</li>
<li><code>aria-describedby</code>: Links input to hint and error (screen reader announces both)</li>
<li><code>role="alert" aria-live="assertive"</code>: Error interrupts screen reader to announce immediately</li>
<li>Error element always exists (even when hidden) so <code>aria-describedby</code> always points to valid ID</li>
<li>Cancel link has <code>role="button"</code> for semantic consistency</li>
</ul>
<h3 id="step-4-update-main-task-list-template"><a class="header" href="#step-4-update-main-task-list-template">Step 4: Update Main Task List Template</a></h3>
<p>Edit <code>templates/tasks/index.peb</code>:</p>
<pre><code class="language-html">{% extends "base.peb" %}

{% block content %}
&lt;h1&gt;Tasks&lt;/h1&gt;

&lt;section aria-labelledby="add-heading"&gt;
  &lt;h2 id="add-heading"&gt;Add a new task&lt;/h2&gt;
  &lt;form action="/tasks" method="post"
        hx-post="/tasks"
        hx-target="#task-list"
        hx-swap="beforeend"&gt;
    &lt;label for="title"&gt;Title&lt;/label&gt;
    &lt;input type="text" id="title" name="title" required
           placeholder="e.g., Buy milk" aria-describedby="title-hint"&gt;
    &lt;small id="title-hint"&gt;Keep it short and specific.&lt;/small&gt;
    &lt;button type="submit"&gt;Add Task&lt;/button&gt;
  &lt;/form&gt;
&lt;/section&gt;

&lt;section aria-labelledby="list-heading"&gt;
  &lt;h2 id="list-heading"&gt;Current tasks ({{ tasks | length }})&lt;/h2&gt;
  &lt;ul id="task-list"&gt;
    {% for task in tasks %}
      {% if editingId and editingId == task.id %}
        {% include "tasks/_edit.peb" with {"task": task, "error": errorMessage} %}
      {% else %}
        {% include "tasks/_item.peb" with {"task": task} %}
      {% endif %}
    {% empty %}
      &lt;li&gt;No tasks yet. Add one above!&lt;/li&gt;
    {% endfor %}
  &lt;/ul&gt;
&lt;/section&gt;
{% endblock %}
</code></pre>
<p><strong>Logic</strong>:</p>
<ul>
<li>If <code>editingId</code> matches current task, render edit mode</li>
<li>Otherwise, render view mode</li>
<li>This enables no-JS path (full-page render with one task in edit mode)</li>
</ul>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ <code>view.peb</code> created with Edit/Delete buttons</li>
<li>‚úÖ <code>edit.peb</code> created with input + Save/Cancel</li>
<li>‚úÖ <code>index.peb</code> uses conditional includes</li>
</ul>
<hr />
<h2 id="activity-3-implement-routes-dual-path"><a class="header" href="#activity-3-implement-routes-dual-path">Activity 3: Implement Routes (Dual-Path)</a></h2>
<p><strong>Time</strong>: 35 minutes
<strong>Materials</strong>: <code>src/main/kotlin/routes/Tasks.kt</code></p>
<h3 id="step-1-add-helper-to-detect-htmx"><a class="header" href="#step-1-add-helper-to-detect-htmx">Step 1: Add Helper to Detect HTMX</a></h3>
<p>Already exists from Week 6, but verify:</p>
<pre><code class="language-kotlin">fun ApplicationCall.isHtmx(): Boolean =
    request.headers["HX-Request"]?.equals("true", ignoreCase = true) == true
</code></pre>
<h3 id="step-2-add-get-tasksidedit-route"><a class="header" href="#step-2-add-get-tasksidedit-route">Step 2: Add GET /tasks/{id}/edit Route</a></h3>
<pre><code class="language-kotlin">get("/tasks/{id}/edit") {
    val id = call.parameters["id"]?.toIntOrNull() ?: return@get call.respond(HttpStatusCode.NotFound)
    val task = TaskRepository.find(id) ?: return@get call.respond(HttpStatusCode.NotFound)

    if (call.isHtmx()) {
        // HTMX path: return edit fragment
        val template = pebble.getTemplate("templates/tasks/_edit.peb")
        val model = mapOf("task" to task, "error" to null)
        val writer = StringWriter()
        template.evaluate(writer, model)
        call.respondText(writer.toString(), ContentType.Text.Html)
    } else {
        // No-JS path: full-page render with editingId
        val model = mapOf(
            "title" to "Tasks",
            "tasks" to TaskRepository.all(),
            "editingId" to id,
            "errorMessage" to null
        )
        val template = pebble.getTemplate("templates/tasks/index.peb")
        val writer = StringWriter()
        template.evaluate(writer, model)
        call.respondText(writer.toString(), ContentType.Text.Html)
    }
}
</code></pre>
<p><strong>Logic</strong>:</p>
<ul>
<li>HTMX: Returns <code>&lt;li&gt;</code> edit fragment (swaps in place)</li>
<li>No-JS: Returns full page with <code>editingId=1</code> (conditional rendering in template)</li>
</ul>
<h3 id="step-3-add-post-tasksidedit-route"><a class="header" href="#step-3-add-post-tasksidedit-route">Step 3: Add POST /tasks/{id}/edit Route</a></h3>
<pre><code class="language-kotlin">post("/tasks/{id}/edit") {
    val id = call.parameters["id"]?.toIntOrNull() ?: return@post call.respond(HttpStatusCode.NotFound)
    val task = TaskRepository.find(id) ?: return@post call.respond(HttpStatusCode.NotFound)

    val newTitle = call.receiveParameters()["title"].orEmpty().trim()

    // Validation
    if (newTitle.isBlank()) {
        if (call.isHtmx()) {
            // HTMX path: return edit fragment with error
            val template = pebble.getTemplate("templates/tasks/_edit.peb")
            val model = mapOf(
                "task" to task,
                "error" to "Title is required. Please enter at least one character."
            )
            val writer = StringWriter()
            template.evaluate(writer, model)
            return@post call.respondText(writer.toString(), ContentType.Text.Html, HttpStatusCode.BadRequest)
        } else {
            // No-JS path: redirect with error flag
            return@post call.respondRedirect("/tasks/${id}/edit?error=blank")
        }
    }

    // Update task
    task.title = newTitle
    TaskRepository.update(task)

    if (call.isHtmx()) {
        // HTMX path: return view fragment + OOB status
        val viewTemplate = pebble.getTemplate("templates/tasks/_item.peb")
        val viewWriter = StringWriter()
        viewTemplate.evaluate(viewWriter, mapOf("task" to task))

        val status = """&lt;div id="status" hx-swap-oob="true"&gt;Task "${task.title}" updated successfully.&lt;/div&gt;"""

        return@post call.respondText(viewWriter.toString() + status, ContentType.Text.Html)
    }

    // No-JS path: PRG redirect
    call.respondRedirect("/tasks")
}
</code></pre>
<p><strong>Validation paths</strong>:</p>
<ul>
<li><strong>HTMX + error</strong>: Returns edit fragment with error message, status 400</li>
<li><strong>No-JS + error</strong>: Redirects to <code>/tasks/{id}/edit?error=blank</code></li>
<li><strong>HTMX + success</strong>: Returns view fragment + OOB status</li>
<li><strong>No-JS + success</strong>: PRG redirect to <code>/tasks</code></li>
</ul>
<h3 id="step-4-handle-error-query-parameter-no-js"><a class="header" href="#step-4-handle-error-query-parameter-no-js">Step 4: Handle Error Query Parameter (No-JS)</a></h3>
<p>Update GET <code>/tasks/{id}/edit</code> to handle <code>?error=blank</code>:</p>
<pre><code class="language-kotlin">get("/tasks/{id}/edit") {
    val id = call.parameters["id"]?.toIntOrNull() ?: return@get call.respond(HttpStatusCode.NotFound)
    val task = TaskRepository.find(id) ?: return@get call.respond(HttpStatusCode.NotFound)
    val errorParam = call.request.queryParameters["error"]

    val errorMessage = when (errorParam) {
        "blank" -&gt; "Title is required. Please enter at least one character."
        else -&gt; null
    }

    if (call.isHtmx()) {
        val template = pebble.getTemplate("templates/tasks/_edit.peb")
        val model = mapOf("task" to task, "error" to errorMessage)
        val writer = StringWriter()
        template.evaluate(writer, model)
        call.respondText(writer.toString(), ContentType.Text.Html)
    } else {
        val model = mapOf(
            "title" to "Tasks",
            "tasks" to TaskRepository.all(),
            "editingId" to id,
            "errorMessage" to errorMessage
        )
        val template = pebble.getTemplate("templates/tasks/index.peb")
        val writer = StringWriter()
        template.evaluate(writer, model)
        call.respondText(writer.toString(), ContentType.Text.Html)
    }
}
</code></pre>
<h3 id="step-5-add-get-tasksidview-cancel-handler"><a class="header" href="#step-5-add-get-tasksidview-cancel-handler">Step 5: Add GET /tasks/{id}/view (Cancel Handler)</a></h3>
<pre><code class="language-kotlin">get("/tasks/{id}/view") {
    val id = call.parameters["id"]?.toIntOrNull() ?: return@get call.respond(HttpStatusCode.NotFound)
    val task = TaskRepository.find(id) ?: return@get call.respond(HttpStatusCode.NotFound)

    // HTMX path only (cancel is just a link to /tasks in no-JS)
    val template = pebble.getTemplate("templates/tasks/_item.peb")
    val model = mapOf("task" to task)
    val writer = StringWriter()
    template.evaluate(writer, model)
    call.respondText(writer.toString(), ContentType.Text.Html)
}
</code></pre>
<h3 id="step-6-add-taskrepository-methods"><a class="header" href="#step-6-add-taskrepository-methods">Step 6: Add TaskRepository Methods</a></h3>
<p>If not already present:</p>
<pre><code class="language-kotlin">object TaskRepository {
    // ... existing methods ...

    fun find(id: Int): Task? = tasks.find { it.id == id }

    fun update(task: Task) {
        tasks.find { it.id == task.id }?.let { it.title = task.title }
        persist()
    }
}
</code></pre>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ GET <code>/tasks/{id}/edit</code> returns edit fragment (HTMX) or full page (no-JS)</li>
<li>‚úÖ POST <code>/tasks/{id}/edit</code> validates, returns fragment/redirect</li>
<li>‚úÖ GET <code>/tasks/{id}/view</code> returns view fragment (cancel handler)</li>
<li>‚úÖ Error messages passed to templates</li>
</ul>
<hr />
<h2 id="activity-4-test-dual-path-functionality"><a class="header" href="#activity-4-test-dual-path-functionality">Activity 4: Test Dual-Path Functionality</a></h2>
<p><strong>Time</strong>: 25 minutes
<strong>Materials</strong>: Browser, keyboard, screen reader</p>
<h3 id="test-1-htmx-path-javascript-enabled"><a class="header" href="#test-1-htmx-path-javascript-enabled">Test 1: HTMX Path (JavaScript Enabled)</a></h3>
<ol>
<li><strong>Load http://localhost:8080/tasks</strong></li>
<li><strong>Add a task</strong>: "Test inline edit"</li>
<li><strong>Click "Edit"</strong>:
<ul>
<li><strong>Expected</strong>: Form appears in place (no page reload)</li>
<li><strong>Check Network tab</strong>: See GET <code>/tasks/1/edit</code> (AJAX)</li>
</ul>
</li>
<li><strong>Type new title</strong>: "Updated title"</li>
<li><strong>Click "Save"</strong>:
<ul>
<li><strong>Expected</strong>: View mode appears (no page reload)</li>
<li><strong>Check DevTools</strong>: <code>#status</code> text = "Task 'Updated title' updated successfully."</li>
</ul>
</li>
<li><strong>Click "Cancel"</strong> (after editing again):
<ul>
<li><strong>Expected</strong>: Returns to view mode, original title preserved</li>
</ul>
</li>
</ol>
<p><strong>Result</strong>: ‚úÖ Inline edit works with HTMX</p>
<h3 id="test-2-validation-htmx"><a class="header" href="#test-2-validation-htmx">Test 2: Validation (HTMX)</a></h3>
<ol>
<li><strong>Click "Edit"</strong> on a task</li>
<li><strong>Delete all text</strong>, click "Save"</li>
<li><strong>Expected</strong>: Error message appears: "Title is required..."</li>
<li><strong>Check error element</strong>:
<ul>
<li>Inspect <code>&lt;p id="error-1" role="alert"&gt;</code></li>
<li>Confirm <code>aria-live="assertive"</code></li>
</ul>
</li>
<li><strong>Type valid title</strong>, click "Save"</li>
<li><strong>Expected</strong>: Error disappears, save succeeds</li>
</ol>
<p><strong>Result</strong>: ‚úÖ Validation works (HTMX)</p>
<h3 id="test-3-no-js-path-javascript-disabled"><a class="header" href="#test-3-no-js-path-javascript-disabled">Test 3: No-JS Path (JavaScript Disabled)</a></h3>
<ol>
<li><strong>Disable JavaScript</strong> (DevTools ‚Üí Settings ‚Üí Disable JavaScript)</li>
<li><strong>Reload page</strong></li>
<li><strong>Click "Edit"</strong>:
<ul>
<li><strong>Expected</strong>: Full page reload, edit form shown</li>
</ul>
</li>
<li><strong>Type new title</strong>: "No-JS test"</li>
<li><strong>Click "Save"</strong>:
<ul>
<li><strong>Expected</strong>: Page reloads, task updated</li>
</ul>
</li>
<li><strong>Click "Edit"</strong>, delete title, click "Save"**:
<ul>
<li><strong>Expected</strong>: Page reloads, error message shown</li>
</ul>
</li>
</ol>
<p><strong>Result</strong>: ‚úÖ No-JS path works</p>
<h3 id="test-4-keyboard-navigation"><a class="header" href="#test-4-keyboard-navigation">Test 4: Keyboard Navigation</a></h3>
<p><strong>Re-enable JavaScript</strong>, reload page:</p>
<ol>
<li><strong>Tab to "Edit" button</strong></li>
<li><strong>Press Enter</strong>:
<ul>
<li><strong>Expected</strong>: Form appears, focus in input field (autofocus)</li>
</ul>
</li>
<li><strong>Type new title</strong></li>
<li><strong>Tab to "Save" button</strong>, press Enter:
<ul>
<li><strong>Expected</strong>: Saves, returns to view mode</li>
</ul>
</li>
<li><strong>Tab to "Edit"</strong>, Enter, Tab to "Cancel"**, Enter:
<ul>
<li><strong>Expected</strong>: Returns to view mode without saving</li>
</ul>
</li>
</ol>
<p><strong>Check focus indicators</strong>:</p>
<ul>
<li>‚úÖ All buttons have visible outline on focus</li>
<li>‚úÖ Input has visible outline</li>
<li>‚úÖ Focus order logical (Edit ‚Üí Title input ‚Üí Save ‚Üí Cancel)</li>
</ul>
<p><strong>Result</strong>: ‚úÖ Keyboard accessible</p>
<h3 id="test-5-screen-reader-nvdavoiceover"><a class="header" href="#test-5-screen-reader-nvdavoiceover">Test 5: Screen Reader (NVDA/VoiceOver)</a></h3>
<p><strong>Windows (NVDA)</strong>:</p>
<ol>
<li>Start NVDA (Ctrl+Alt+N)</li>
<li>Navigate to task list</li>
<li><strong>Tab to "Edit" button</strong>:
<ul>
<li><strong>Listen for</strong>: "Edit task: Test inline edit, button"</li>
</ul>
</li>
<li><strong>Press Enter</strong> (activates Edit)</li>
<li><strong>Listen for</strong>: "Title, edit, Keep it short and specific, [current value]"</li>
<li><strong>Delete text, Tab to Save, Enter</strong></li>
<li><strong>Listen for</strong>: "Title is required. Please enter at least one character, alert"</li>
<li><strong>Type valid title, Save</strong></li>
<li><strong>Listen for</strong>: "Task 'Valid title' updated successfully"</li>
</ol>
<p><strong>macOS (VoiceOver)</strong>:</p>
<ol>
<li>Enable VoiceOver (Cmd+F5)</li>
<li>Navigate with VoiceOver cursor (VO+Right Arrow)</li>
<li>Repeat NVDA steps, listen for equivalent announcements</li>
</ol>
<p><strong>Result</strong>: ‚úÖ Screen reader announces labels, errors, status</p>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ HTMX path: instant swaps</li>
<li>‚úÖ No-JS path: page reloads</li>
<li>‚úÖ Validation works both paths</li>
<li>‚úÖ Keyboard accessible</li>
<li>‚úÖ Screen reader announces correctly</li>
</ul>
<hr />
<h2 id="activity-5-evidence-collection"><a class="header" href="#activity-5-evidence-collection">Activity 5: Evidence Collection</a></h2>
<p><strong>Time</strong>: 15 minutes
<strong>Materials</strong>: Screenshots, testing notes</p>
<h3 id="step-1-capture-evidence"><a class="header" href="#step-1-capture-evidence">Step 1: Capture Evidence</a></h3>
<p>Create <code>wk07/evidence/</code> directory:</p>
<pre><code class="language-bash">mkdir -p wk07/evidence
</code></pre>
<p><strong>Screenshots to capture</strong>:</p>
<ol>
<li><strong>View mode</strong> (HTMX): Before clicking Edit</li>
<li><strong>Edit mode</strong> (HTMX): Form in place</li>
<li><strong>Validation error</strong> (HTMX): Error message with <code>role="alert"</code></li>
<li><strong>Status message</strong> (HTMX): DevTools showing <code>#status</code> content</li>
<li><strong>No-JS edit mode</strong>: Full page with form</li>
<li><strong>NVDA speech viewer</strong>: Showing error announcement</li>
</ol>
<p><strong>Example naming</strong>:</p>
<ul>
<li><code>01-view-mode-htmx.png</code></li>
<li><code>02-edit-mode-htmx.png</code></li>
<li><code>03-validation-error-htmx.png</code></li>
<li><code>04-status-oob-devtools.png</code></li>
<li><code>05-edit-mode-nojs.png</code></li>
<li><code>06-nvda-error-announcement.png</code></li>
</ul>
<h3 id="step-2-document-testing-notes"><a class="header" href="#step-2-document-testing-notes">Step 2: Document Testing Notes</a></h3>
<p>Create <code>wk07/evidence/testing-notes.md</code>:</p>
<pre><code class="language-markdown"># Testing Notes ‚Äî Week 7 Lab 1

## HTMX Path
**Date**: [YYYY-MM-DD]
**Browser**: Chrome 120.0
**JavaScript**: Enabled

### Test: Inline edit activation
- **Action**: Clicked "Edit" button
- **Result**: ‚úÖ Form appeared instantly (no page reload)
- **Network**: GET /tasks/1/edit (AJAX, 45ms)
- **Screenshot**: `01-view-mode-htmx.png`, `02-edit-mode-htmx.png`

### Test: Validation error
- **Action**: Deleted title, clicked "Save"
- **Result**: ‚úÖ Error shown: "Title is required..."
- **ARIA**: `&lt;p id="error-1" role="alert" aria-live="assertive"&gt;` confirmed in DevTools
- **Screenshot**: `03-validation-error-htmx.png`

### Test: Successful save
- **Action**: Entered valid title, clicked "Save"
- **Result**: ‚úÖ View mode restored, status = "Task 'New title' updated successfully."
- **Screenshot**: `04-status-oob-devtools.png`

---

## No-JS Path
**Date**: [YYYY-MM-DD]
**Browser**: Chrome 120.0
**JavaScript**: Disabled

### Test: Edit activation
- **Action**: Clicked "Edit" button
- **Result**: ‚úÖ Full page reload, form shown
- **URL**: http://localhost:8080/tasks/1/edit

### Test: Validation error
- **Action**: Deleted title, clicked "Save"
- **Result**: ‚úÖ Redirect to /tasks/1/edit?error=blank, error shown
- **Screenshot**: `05-edit-mode-nojs-error.png`

---

## Keyboard Testing
**Date**: [YYYY-MM-DD]
**Input**: Keyboard only (no mouse)

### Test: Tab navigation
- **Path**: Tab ‚Üí "Edit" ‚Üí Enter ‚Üí Title input (autofocus) ‚Üí Tab ‚Üí "Save" ‚Üí Enter
- **Result**: ‚úÖ Focus order logical, all buttons reachable
- **Focus indicators**: ‚úÖ Visible outline on all elements

---

## Screen Reader Testing
**Date**: [YYYY-MM-DD]
**Tool**: NVDA 2024.1 (Windows 11)

### Test: Edit button announcement
- **Navigated to**: "Edit" button
- **NVDA said**: "Edit task: Buy milk, button"
- **Result**: ‚úÖ Contextual label announced

### Test: Input field announcement
- **Activated**: Edit button (Enter)
- **NVDA said**: "Title, edit, Keep it short and specific, Buy milk"
- **Result**: ‚úÖ Label + hint + value announced

### Test: Error announcement
- **Action**: Deleted title, pressed Save
- **NVDA said**: "Title is required. Please enter at least one character, alert"
- **Result**: ‚úÖ Error announced immediately (assertive)

### Test: Status message announcement
- **Action**: Saved valid title
- **NVDA said**: "Task 'New title' updated successfully"
- **Result**: ‚úÖ Status announced (polite, didn't interrupt)

---

## Issues Found
None. All tests passed.

## WCAG Compliance Check
| Criterion | Status | Evidence |
|-----------|--------|----------|
| 2.1.1 Keyboard (A) | ‚úÖ Pass | All features accessible via Tab/Enter |
| 3.3.1 Error Identification (A) | ‚úÖ Pass | Error message explicit, aria-describedby links input |
| 4.1.3 Status Messages (AA) | ‚úÖ Pass | Live region announces success without focus change |
</code></pre>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ Screenshots saved in <code>wk07/evidence/</code></li>
<li>‚úÖ Testing notes documented</li>
<li>‚úÖ WCAG criteria mapped to evidence</li>
</ul>
<hr />
<h2 id="reflection-questions-1"><a class="header" href="#reflection-questions-1">Reflection Questions</a></h2>
<ol>
<li>
<p><strong>Dual-path trade-offs</strong>: The HTMX path returns HTML fragments; the no-JS path returns full pages. Which is easier to maintain? Which is easier to test?</p>
</li>
<li>
<p><strong>Focus management</strong>: HTMX tries to restore focus after swaps. Did you notice focus moving unexpectedly? How would you improve this?</p>
</li>
<li>
<p><strong>Error persistence</strong>: In the no-JS path, errors survive redirects via query parameters. Could you use session storage instead? What are the trade-offs?</p>
</li>
<li>
<p><strong>Screen reader experience</strong>: Compare the HTMX path (instant swap) vs. no-JS path (page reload). Which is better for screen reader users? Why?</p>
</li>
</ol>
<hr />
<h2 id="further-reading-1"><a class="header" href="#further-reading-1">Further Reading</a></h2>
<p><strong>Inline edit patterns</strong></p>
<ul>
<li>HTMX Examples: Click to Edit. <a href="https://htmx.org/examples/click-to-edit/">https://htmx.org/examples/click-to-edit/</a></li>
<li>Nielsen Norman Group (2015). "In-Place Editing". <a href="https://www.nngroup.com/articles/in-place-editing/">https://www.nngroup.com/articles/in-place-editing/</a></li>
</ul>
<p><strong>WCAG Error Identification</strong></p>
<ul>
<li>W3C (2024). Understanding 3.3.1 Error Identification. <a href="https://www.w3.org/WAI/WCAG22/Understanding/error-identification.html">https://www.w3.org/WAI/WCAG22/Understanding/error-identification.html</a></li>
<li>GOV.UK Design System: Error Message Component. <a href="https://design-system.service.gov.uk/components/error-message/">https://design-system.service.gov.uk/components/error-message/</a></li>
</ul>
<p><strong>Focus management</strong></p>
<ul>
<li>Deque (2023). "Focus Management in ARIA". <a href="https://www.deque.com/blog/give-focus-power/">https://www.deque.com/blog/give-focus-power/</a></li>
<li>WebAIM: Keyboard Accessibility. <a href="https://webaim.org/techniques/keyboard/">https://webaim.org/techniques/keyboard/</a></li>
</ul>
<hr />
<h2 id="glossary-summary-1"><a class="header" href="#glossary-summary-1">Glossary Summary</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Term</th><th>Definition</th><th>Example/Context</th></tr></thead><tbody>
<tr><td><strong>Inline edit</strong></td><td>Editing content in place (not separate page)</td><td>Click task title ‚Üí form appears ‚Üí save ‚Üí title updates</td></tr>
<tr><td><strong>Dual-path</strong></td><td>Same feature, different implementation (HTMX vs. no-JS)</td><td>HTMX = fragment swap; no-JS = full page reload</td></tr>
<tr><td><strong>aria-describedby</strong></td><td>Links input to descriptive text (hint/error)</td><td><code>&lt;input aria-describedby="hint-1 error-1"&gt;</code></td></tr>
<tr><td><strong>role="alert"</strong></td><td>Announces content immediately to screen readers</td><td><code>&lt;p role="alert"&gt;Error message&lt;/p&gt;</code></td></tr>
<tr><td><strong>OOB swap</strong></td><td>HTMX updating element outside main target</td><td><code>&lt;div id="status" hx-swap-oob="true"&gt;</code></td></tr>
<tr><td><strong>Autofocus</strong></td><td>Input receives focus when rendered</td><td><code>&lt;input autofocus&gt;</code> (use sparingly, can disorient SR users)</td></tr>
<tr><td><strong>Focus order</strong></td><td>Sequence of Tab navigation (WCAG 2.4.3)</td><td>Edit button ‚Üí Title input ‚Üí Save ‚Üí Cancel</td></tr>
<tr><td><strong>WCAG 3.3.1</strong></td><td>Error Identification (Level A)</td><td>Error must be identified + described + programmatically associated</td></tr>
<tr><td><strong>WCAG 4.1.3</strong></td><td>Status Messages (Level AA)</td><td>Status announced without focus change (live regions)</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="lab-checklist-1"><a class="header" href="#lab-checklist-1">Lab Checklist</a></h2>
<p>Before leaving lab, confirm:</p>
<ul>
<li><input disabled="" type="checkbox"/>
<strong>View/edit partials created</strong>: <code>templates/tasks/_item.peb</code> (updated with Edit button), <code>templates/tasks/_edit.peb</code> (new)</li>
<li><input disabled="" type="checkbox"/>
<strong>Routes implemented</strong>: GET/POST <code>/tasks/{id}/edit</code>, GET <code>/tasks/{id}/view</code></li>
<li><input disabled="" type="checkbox"/>
<strong>HTMX path works</strong>: Inline edit, validation, save (no page reload)</li>
<li><input disabled="" type="checkbox"/>
<strong>No-JS path works</strong>: Edit, validation, save (page reloads)</li>
<li><input disabled="" type="checkbox"/>
<strong>Keyboard accessible</strong>: Tab through all controls, submit with Enter</li>
<li><input disabled="" type="checkbox"/>
<strong>Screen reader tested</strong>: NVDA/VoiceOver announces labels, hints, errors, status</li>
<li><input disabled="" type="checkbox"/>
<strong>Evidence collected</strong>: Screenshots + testing notes in <code>wk07/evidence/</code></li>
<li><input disabled="" type="checkbox"/>
<strong>Code committed</strong>: <code>git add .</code>, <code>git commit -m "wk7-lab1: inline edit with dual-path + ARIA"</code></li>
</ul>
<hr />
<h2 id="next-steps-1"><a class="header" href="#next-steps-1">Next Steps</a></h2>
<p>In <strong>Week 7 Lab 2</strong> you will:</p>
<ol>
<li>Run structured accessibility audit (WCAG checklist, heuristics)</li>
<li>Log findings in inclusive backlog</li>
<li>Implement <strong>one priority fix</strong> from backlog (error summary, focus indicator, etc.)</li>
<li>Package evidence for Task 1 (Gradescope submission)</li>
</ol>
<p><strong>Preparation</strong>:</p>
<ul>
<li>Review backlog from Week 6 (<code>backlog/backlog.csv</code>)</li>
<li>Install axe DevTools browser extension</li>
<li>Bring inline edit code from Lab 1 (working state)</li>
</ul>
<hr />
<p><strong>Lab authored by</strong>: COMP2850 Teaching Team, University of Leeds
<strong>Last updated</strong>: 2025-01-14
<strong>Licence</strong>: Academic use only (not for redistribution)</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-7--lab-2-accessibility-audit-backlog--inclusive-fix"><a class="header" href="#week-7--lab-2-accessibility-audit-backlog--inclusive-fix">Week 7 ‚Ä¢ Lab 2: Accessibility Audit, Backlog &amp; Inclusive Fix</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-7-orange" alt="Week 7" />
<img src="https://img.shields.io/badge/Lab-2-green" alt="Lab 2" />
<img src="https://img.shields.io/badge/Status-Draft-yellow" alt="Status" /></p>
<hr />
<h2 id="terminology-note-3"><a class="header" href="#terminology-note-3">Terminology Note</a></h2>
<p>Throughout COMP2850 we use <strong>people-centred language</strong> (e.g., "person using a screen reader") rather than deficit-based terms (e.g., "blind user"). This reflects contemporary inclusive-design practice and acknowledges that disability arises from environmental barriers, not individual impairment.</p>
<hr />
<h2 id="pre-reading-3"><a class="header" href="#pre-reading-3">Pre-reading</a></h2>
<p><strong>Essential</strong></p>
<ul>
<li>Ensure your Week 7 starter repo clone is up to date (inline edit changes committed)</li>
<li><a href="https://www.w3.org/WAI/WCAG22/quickref/">W3C (2024). WCAG 2.2 Quick Reference</a></li>
<li><a href="https://www.deque.com/axe/devtools/">axe DevTools Documentation</a></li>
<li><a href="https://www.gov.uk/service-manual/helping-people-to-use-your-service/making-your-service-accessible-an-introduction">GOV.UK: Making Your Service Accessible</a></li>
</ul>
<p><strong>Recommended</strong></p>
<ul>
<li><a href="https://webaim.org/standards/wcag/checklist">WebAIM: WCAG 2 Checklist</a></li>
<li><a href="https://www.nngroup.com/articles/how-to-conduct-a-heuristic-evaluation/">Nielsen, J. (1994). "Heuristic Evaluation"</a></li>
<li><a href="https://www.cs.umd.edu/~ben/">Shneiderman et al. (2016). <em>Designing the User Interface</em>, Ch. 3: Guidelines</a></li>
</ul>
<hr />
<h2 id="introduction-3"><a class="header" href="#introduction-3">Introduction</a></h2>
<h3 id="context-3"><a class="header" href="#context-3">Context</a></h3>
<p>In <strong>Week 7 Lab 1</strong> you implemented accessible inline edit with dual-path support (HTMX + no-JS), ARIA error identification, and status message announcements. You tested with keyboard and screen reader (NVDA/VoiceOver) and collected evidence.</p>
<p><strong>Now you'll audit the entire application systematically</strong> using:</p>
<ol>
<li><strong>WCAG 2.2 AA checklist</strong> (technical compliance)</li>
<li><strong>Heuristics</strong> (Nielsen's 10 Usability Heuristics + Shneiderman's Golden Rules)</li>
<li><strong>Assistive technology testing</strong> (keyboard, screen reader, no-JS, zoom)</li>
</ol>
<p>You'll log findings in your inclusive backlog (from Week 6), prioritise using <em>severity √ó inclusion risk</em>, and
<strong>implement one high-priority fix end-to-end</strong> (code ‚Üí verification ‚Üí evidence).</p>
<p>This lab directly feeds <strong>Gradescope Task 1</strong> (evaluation &amp; findings) and sets up <strong>Task 2</strong> (redesign &amp; verification).</p>
<h3 id="why-this-matters-4"><a class="header" href="#why-this-matters-4">Why This Matters</a></h3>
<p><strong>Professionally</strong>, accessibility audits are standard practice:</p>
<ul>
<li><strong>GOV.UK</strong> mandates WCAG 2.2 AA compliance before launch</li>
<li><strong>BBC</strong> runs quarterly audits with assistive tech users</li>
<li><strong>Microsoft</strong> uses automated (axe) + manual (SR) testing in CI/CD pipeline</li>
</ul>
<p><strong>Academically</strong>, this lab teaches:</p>
<ul>
<li><strong>Systematic evaluation</strong>: Structured checklists reduce bias (vs. ad-hoc testing)</li>
<li><strong>Triangulation</strong>: Automated tools + manual testing + user feedback</li>
<li><strong>Evidence-based prioritisation</strong>: Data (backlog scores) beats intuition</li>
</ul>
<h2 id="learning-focus-3"><a class="header" href="#learning-focus-3">Learning Focus</a></h2>
<h3 id="lab-objectives-3"><a class="header" href="#lab-objectives-3">Lab Objectives</a></h3>
<p>By the end of this session, you will have:</p>
<ul>
<li>Conducted a structured accessibility audit using WCAG 2.2 AA criteria</li>
<li>Run axe DevTools audit and documented 5+ WCAG violations</li>
<li>Mapped violations to WCAG 2.2 success criteria</li>
<li>Populated inclusive backlog with severity + inclusion risk scores</li>
<li>Implemented one priority accessibility fix with regression testing</li>
</ul>
<h3 id="learning-outcomes-addressed-3"><a class="header" href="#learning-outcomes-addressed-3">Learning Outcomes Addressed</a></h3>
<p>This lab contributes to the following module Learning Outcomes (<a href="wk07/../references/learning-outcomes.html">full definitions</a>):</p>
<ul>
<li><strong>LO4</strong>: Evaluate for accessibility ‚Äî evidenced by axe audit + WCAG mapping</li>
<li><strong>LO6</strong>: Apply iterative design ‚Äî evidenced by fix implementation</li>
<li><strong>LO9</strong>: Apply inclusive design ‚Äî evidenced by WCAG 2.2 AA compliance</li>
<li><strong>LO12</strong>: Demonstrate professionalism ‚Äî evidenced by documentation + testing</li>
</ul>
<hr />
<h2 id="key-concepts-3"><a class="header" href="#key-concepts-3">Key Concepts</a></h2>
<h3 id="1-accessibility-audit-levels"><a class="header" href="#1-accessibility-audit-levels">1. Accessibility Audit Levels</a></h3>
<p><strong>Level 1: Automated testing</strong> (20-30% of WCAG issues)</p>
<ul>
<li>Tools: axe DevTools, WAVE, Lighthouse</li>
<li>Fast, repeatable, catches low-hanging fruit</li>
<li><strong>Limitations</strong>: Can't detect non-semantic HTML, focus order issues, SR announcements</li>
</ul>
<p><strong>Level 2: Manual testing</strong> (keyboard, screen reader)</p>
<ul>
<li>Catches 50-60% of issues</li>
<li>Time-consuming, requires expertise</li>
<li><strong>Essential for</strong>: Focus management, ARIA announcements, keyboard traps</li>
</ul>
<p><strong>Level 3: User testing</strong> (people with disabilities)</p>
<ul>
<li>Catches 90%+ of issues</li>
<li>Gold standard, but expensive and slow</li>
<li><strong>Week 9</strong>: You'll run task-based pilots (mini user tests)</li>
</ul>
<p><strong>COMP2850 approach</strong>: Levels 1 + 2 in Labs 7-8; Level 3 in Week 9.</p>
<h3 id="2-wcag-22-conformance-levels"><a class="header" href="#2-wcag-22-conformance-levels">2. WCAG 2.2 Conformance Levels</a></h3>
<p><strong>Level A</strong> (minimum, legal requirement in many jurisdictions):</p>
<ul>
<li>Examples: 1.3.1 Info and Relationships, 2.1.1 Keyboard, 3.3.1 Error Identification</li>
</ul>
<p><strong>Level AA</strong> (target for most organisations):</p>
<ul>
<li>Examples: 1.4.3 Contrast (Minimum), 2.4.7 Focus Visible, 4.1.3 Status Messages</li>
</ul>
<p><strong>Level AAA</strong> (enhanced, not always achievable):</p>
<ul>
<li>Examples: 1.4.6 Contrast (Enhanced, 7:1), 2.1.3 Keyboard (No Exception)</li>
</ul>
<p><strong>COMP2850 target</strong>: AA compliance (industry standard).</p>
<h3 id="3-severity-scoring-comp2850-framework"><a class="header" href="#3-severity-scoring-comp2850-framework">3. Severity Scoring (COMP2850 Framework)</a></h3>
<p><strong>High (3 points)</strong>:</p>
<ul>
<li>Blocks task completion entirely (e.g., form unsubmittable via keyboard)</li>
<li>Excludes entire group (e.g., no screen reader access)</li>
<li>WCAG Level A failure</li>
</ul>
<p><strong>Medium (2 points)</strong>:</p>
<ul>
<li>Makes task significantly harder (e.g., poor contrast, slow to navigate)</li>
<li>Affects multiple groups (e.g., keyboard + screen reader)</li>
<li>WCAG Level AA failure</li>
</ul>
<p><strong>Low (1 point)</strong>:</p>
<ul>
<li>Minor friction (e.g., missing hint text, suboptimal label)</li>
<li>Affects niche scenario (e.g., rare browser/AT combination)</li>
<li>WCAG AAA or best practice (not required)</li>
</ul>
<h3 id="4-inclusion-risk-tagging"><a class="header" href="#4-inclusion-risk-tagging">4. Inclusion Risk Tagging</a></h3>
<p><strong>Tags</strong> identify who's affected:</p>
<ul>
<li><strong>SR</strong> (Screen reader): NVDA, JAWS, VoiceOver, TalkBack</li>
<li><strong>Keyboard</strong>: Keyboard-only users, motor impairments, RSI</li>
<li><strong>Cognitive</strong>: ADHD, dyslexia, memory impairments</li>
<li><strong>Low vision</strong>: Magnification users, high contrast needs</li>
<li><strong>Motor</strong>: Tremor, limited dexterity, switch users</li>
<li><strong>Hearing</strong>: Caption/transcript needs (not applicable to this project yet)</li>
<li><strong>Situational</strong>: Bright light, broken mouse, noisy environment</li>
</ul>
<p><strong>Example</strong>: "Delete button lacks keyboard access" = <strong>Keyboard + Motor</strong> tags.</p>
<h3 id="5-nielsens-10-usability-heuristics-applied-to-accessibility"><a class="header" href="#5-nielsens-10-usability-heuristics-applied-to-accessibility">5. Nielsen's 10 Usability Heuristics (Applied to Accessibility)</a></h3>
<ol>
<li><strong>Visibility of system status</strong>: Screen readers announce state changes</li>
<li><strong>Match between system and real world</strong>: Plain language (not jargon)</li>
<li><strong>User control and freedom</strong>: Undo, cancel actions</li>
<li><strong>Consistency and standards</strong>: Follow ARIA patterns, GOV.UK conventions</li>
<li><strong>Error prevention</strong>: Validation before submission</li>
<li><strong>Recognition rather than recall</strong>: Labels visible (not just placeholders)</li>
<li><strong>Flexibility and efficiency of use</strong>: Keyboard shortcuts for power users</li>
<li><strong>Aesthetic and minimalist design</strong>: No clutter (easier for SR/cognitive users)</li>
<li><strong>Help people recognise, diagnose, and recover from errors</strong>: Specific error messages</li>
<li><strong>Help and documentation</strong>: Context-sensitive help text</li>
</ol>
<hr />
<h2 id="activity-1-automated-audit-with-axe-devtools"><a class="header" href="#activity-1-automated-audit-with-axe-devtools">Activity 1: Automated Audit with axe DevTools</a></h2>
<p><strong>Time</strong>: 20 minutes
<strong>Materials</strong>: Chrome/Firefox with axe DevTools extension</p>
<h3 id="step-1-install-axe-devtools"><a class="header" href="#step-1-install-axe-devtools">Step 1: Install axe DevTools</a></h3>
<p><strong>Chrome</strong>:</p>
<ol>
<li>Visit <a href="https://chrome.google.com/webstore">Chrome Web Store</a></li>
<li>Search "axe DevTools"</li>
<li>Install extension</li>
</ol>
<p><strong>Firefox</strong>:</p>
<ol>
<li>Visit <a href="https://addons.mozilla.org/">Firefox Add-ons</a></li>
<li>Search "axe DevTools"</li>
<li>Install add-on</li>
</ol>
<h3 id="step-2-run-automated-scan"><a class="header" href="#step-2-run-automated-scan">Step 2: Run Automated Scan</a></h3>
<ol>
<li><strong>Open http://localhost:8080/tasks</strong> (ensure server running)</li>
<li><strong>Open DevTools</strong> (F12)</li>
<li><strong>Navigate to "axe DevTools" tab</strong></li>
<li><strong>Click "Scan ALL of my page"</strong></li>
<li><strong>Wait 5-10 seconds</strong> for results</li>
</ol>
<h3 id="step-3-review-findings"><a class="header" href="#step-3-review-findings">Step 3: Review Findings</a></h3>
<p>axe categorises issues:</p>
<div class="table-wrapper"><table><thead><tr><th>Category</th><th>Severity</th><th>Action</th></tr></thead><tbody>
<tr><td><strong>Critical</strong></td><td>Blocks access (Level A failures)</td><td>Must fix</td></tr>
<tr><td><strong>Serious</strong></td><td>Major barriers (Level A/AA failures)</td><td>Should fix</td></tr>
<tr><td><strong>Moderate</strong></td><td>Noticeable issues (Level AA/AAA)</td><td>Consider fixing</td></tr>
<tr><td><strong>Minor</strong></td><td>Best practice violations</td><td>Low priority</td></tr>
</tbody></table>
</div>
<h3 id="step-4-document-automated-findings"><a class="header" href="#step-4-document-automated-findings">Step 4: Document Automated Findings</a></h3>
<p>Create <code>wk07/audit/axe-report.md</code>:</p>
<pre><code class="language-markdown"># axe DevTools Audit Report ‚Äî Week 7

**Date**: [YYYY-MM-DD]
**URL**: http://localhost:8080/tasks
**Tool**: axe DevTools 4.x
**Scope**: Full page scan (add form + task list)

---

## Summary
- **Critical**: 0
- **Serious**: 2
- **Moderate**: 1
- **Minor**: 3
- **Total**: 6 issues

---

## Critical Issues
None detected.

---

## Serious Issues

### Issue 1: Form label missing (Serious)
**Element**: `&lt;input id="title" name="title"&gt;`
**Rule**: `label` (WCAG 1.3.1, 4.1.2)
**Description**: Form element does not have an associated label.
**Impact**: Screen readers don't know what the input is for.
**Fix**: Ensure `&lt;label for="title"&gt;Title&lt;/label&gt;` exists and is visible (not visually-hidden).
**Status**: ‚ùå **FALSE POSITIVE** ‚Äî Label exists in template. Possible axe bug or dynamic rendering issue. Verify manually.

### Issue 2: Insufficient color contrast (Serious)
**Element**: `&lt;button type="submit"&gt;Delete&lt;/button&gt;`
**Rule**: `color-contrast` (WCAG 1.4.3)
**Description**: Text color #6c757d on white background = 4.2:1 (fails AA 4.5:1)
**Impact**: People with low vision struggle to read button text.
**Fix**: Change button color to #495057 (darker gray, 7:1 contrast).
**Status**: ‚úÖ **CONFIRMED** ‚Äî Add to backlog as High severity.

---

## Moderate Issues

### Issue 3: Skip link not keyboard-accessible (Moderate)
**Element**: `&lt;a href="#main" class="skip-link"&gt;`
**Rule**: `skip-link` (best practice)
**Description**: Skip link exists but positioned off-screen; unclear if focus visible.
**Impact**: Keyboards may not discover skip link.
**Fix**: Ensure `:focus` pseudo-class makes skip link visible (already implemented in CSS, but verify).
**Status**: ‚úÖ **VERIFIED** ‚Äî Tab reveals skip link. No action needed.

---

## Minor Issues

### Issue 4-6: [Document remaining minor issues]
[Low priority, defer to Semester 2]

---

## Actions
1. **False positive (Issue 1)**: Verify label exists with manual inspection
2. **High priority (Issue 2)**: Fix contrast ratio ‚Üí Add to backlog
3. **Verified (Issue 3)**: No action needed

---

**Next step**: Manual testing to catch issues axe misses (focus order, SR announcements, keyboard traps).
</code></pre>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ axe scan completed</li>
<li>‚úÖ Findings documented in <code>axe-report.md</code></li>
<li>‚úÖ At least 1 serious issue identified (contrast, label, etc.)</li>
</ul>
<hr />
<h2 id="activity-2-manual-wcag-checklist"><a class="header" href="#activity-2-manual-wcag-checklist">Activity 2: Manual WCAG Checklist</a></h2>
<p><strong>Time</strong>: 30 minutes
<strong>Materials</strong>: WCAG 2.2 Quick Reference, keyboard, screen reader</p>
<h3 id="step-1-create-wcag-checklist-template"><a class="header" href="#step-1-create-wcag-checklist-template">Step 1: Create WCAG Checklist Template</a></h3>
<p>Create <code>wk07/audit/wcag-checklist.md</code>:</p>
<pre><code class="language-markdown"># WCAG 2.2 AA Checklist ‚Äî Week 7

**Date**: [YYYY-MM-DD]
**Scope**: Task manager (add, edit, delete flows)
**Tester**: [Your Name]

---

## Perceivable (Principle 1)

### 1.1 Text Alternatives
| Criterion | Level | Status | Evidence | Notes |
|-----------|-------|--------|----------|-------|
| 1.1.1 Non-text Content | A | N/A | No images yet | Will add in Week 8 |

### 1.3 Adaptable
| Criterion | Level | Status | Evidence | Notes |
|-----------|-------|--------|----------|-------|
| 1.3.1 Info and Relationships | A | ‚úÖ Pass | `&lt;label for="title"&gt;` links to input | Semantic HTML (`&lt;main&gt;`, `&lt;section&gt;`, `&lt;ul&gt;`) |
| 1.3.2 Meaningful Sequence | A | ‚úÖ Pass | Tab order: skip link ‚Üí add form ‚Üí task list | Logical reading order |

### 1.4 Distinguishable
| Criterion | Level | Status | Evidence | Notes |
|-----------|-------|--------|----------|-------|
| 1.4.3 Contrast (Minimum) | AA | ‚ùå Fail | Delete button #6c757d = 4.2:1 | Needs 4.5:1 (AA) |
| 1.4.11 Non-text Contrast | AA | ‚úÖ Pass | Focus outline 3px solid #1976d2 | Sufficient contrast |

---

## Operable (Principle 2)

### 2.1 Keyboard Accessible
| Criterion | Level | Status | Evidence | Notes |
|-----------|-------|--------|----------|-------|
| 2.1.1 Keyboard | A | ‚úÖ Pass | All features accessible via Tab/Enter/Space | Tested: add, edit, delete, cancel |
| 2.1.2 No Keyboard Trap | A | ‚úÖ Pass | No traps detected | Can Tab out of all forms |

### 2.4 Navigable
| Criterion | Level | Status | Evidence | Notes |
|-----------|-------|--------|----------|-------|
| 2.4.1 Bypass Blocks | A | ‚úÖ Pass | Skip link appears on Tab, jumps to #main | Tested with keyboard |
| 2.4.3 Focus Order | A | ‚úÖ Pass | Tab order: Edit ‚Üí Title ‚Üí Save ‚Üí Cancel | Logical sequence |
| 2.4.7 Focus Visible | AA | ‚ö†Ô∏è Partial | Pico.css default outline visible, but faint | Consider custom outline (3px solid) |

---

## Understandable (Principle 3)

### 3.2 Predictable
| Criterion | Level | Status | Evidence | Notes |
|-----------|-------|--------|----------|-------|
| 3.2.1 On Focus | A | ‚úÖ Pass | No context change on focus | Only explicit button clicks trigger actions |
| 3.2.2 On Input | A | ‚úÖ Pass | No auto-submit on input change | Form submits only on button click |

### 3.3 Input Assistance
| Criterion | Level | Status | Evidence | Notes |
|-----------|-------|--------|----------|-------|
| 3.3.1 Error Identification | A | ‚úÖ Pass | Error: "Title is required. Please enter at least one character." | Specific, actionable |
| 3.3.2 Labels or Instructions | A | ‚úÖ Pass | All inputs have `&lt;label&gt;` + hint text | `aria-describedby` links to hint |
| 3.3.3 Error Suggestion | AA | ‚úÖ Pass | Error message includes correction hint | "Please enter at least one character" |

---

## Robust (Principle 4)

### 4.1 Compatible
| Criterion | Level | Status | Evidence | Notes |
|-----------|-------|--------|----------|-------|
| 4.1.2 Name, Role, Value | A | ‚úÖ Pass | All buttons have accessible names | `aria-label="Edit task: Buy milk"` |
| 4.1.3 Status Messages | AA | ‚úÖ Pass | `&lt;div role="status" aria-live="polite"&gt;` | Tested with NVDA |

---

## Summary
- **Total criteria evaluated**: 18
- **Pass**: 15
- **Fail**: 1 (1.4.3 Contrast)
- **Partial**: 1 (2.4.7 Focus Visible)
- **N/A**: 1

---

## High-Priority Failures
1. **1.4.3 Contrast (Minimum, AA)**: Delete button text fails 4.5:1 ratio
   - **Action**: Change Pico.css button color or add custom CSS

2. **2.4.7 Focus Visible (AA, Partial)**: Default outline may be too faint
   - **Action**: Add custom `:focus` styles (3px solid #1976d2)

---

**Next**: Add these findings to backlog with severity scores.
</code></pre>
<h3 id="step-2-test-each-criterion"><a class="header" href="#step-2-test-each-criterion">Step 2: Test Each Criterion</a></h3>
<p><strong>Keyboard testing</strong> (2.1.1, 2.1.2, 2.4.3):</p>
<ol>
<li>Tab through entire page</li>
<li>Activate all buttons with Enter/Space</li>
<li>Check for keyboard traps (can you Tab out of forms?)</li>
</ol>
<p><strong>Screen reader testing</strong> (4.1.2, 4.1.3):</p>
<ol>
<li>Start NVDA/VoiceOver</li>
<li>Navigate to each form field (listen for labels + hints)</li>
<li>Trigger error (listen for <code>role="alert"</code> announcement)</li>
<li>Save successfully (listen for status message)</li>
</ol>
<p><strong>Contrast testing</strong> (1.4.3):</p>
<ol>
<li>Open DevTools ‚Üí Inspect element</li>
<li>Check computed color values</li>
<li>Use <a href="https://webaim.org/resources/contrastchecker/">WebAIM Contrast Checker</a>
<ul>
<li>Foreground: #6c757d</li>
<li>Background: #ffffff</li>
<li><strong>Result</strong>: 4.2:1 (fails AA)</li>
</ul>
</li>
</ol>
<p><strong>Focus visible testing</strong> (2.4.7):</p>
<ol>
<li>Tab to each interactive element</li>
<li>Can you clearly see which element has focus?</li>
<li>Take screenshot of focus indicator</li>
</ol>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ WCAG checklist completed (at least 15 criteria)</li>
<li>‚úÖ Pass/Fail status recorded</li>
<li>‚úÖ Evidence cited (screenshot, manual test, tool output)</li>
</ul>
<hr />
<h2 id="activity-3-heuristic-evaluation"><a class="header" href="#activity-3-heuristic-evaluation">Activity 3: Heuristic Evaluation</a></h2>
<p><strong>Time</strong>: 20 minutes
<strong>Materials</strong>: Nielsen's heuristics, Shneiderman's Golden Rules</p>
<h3 id="step-1-apply-nielsens-heuristics"><a class="header" href="#step-1-apply-nielsens-heuristics">Step 1: Apply Nielsen's Heuristics</a></h3>
<p>Create <code>wk07/audit/heuristics.md</code>:</p>
<pre><code class="language-markdown"># Heuristic Evaluation ‚Äî Week 7

**Evaluator**: [Your Name]
**Date**: [YYYY-MM-DD]
**Method**: Nielsen's 10 Usability Heuristics + Shneiderman's Golden Rules

---

## Nielsen's Heuristics

### 1. Visibility of System Status
**Rating**: 4/5 (Good)
**Evidence**:
- ‚úÖ Status messages announce add/delete/edit actions
- ‚úÖ ARIA live region updates (`role="status"`)
- ‚ö†Ô∏è No loading indicator for HTMX requests (instant for now, but could be slow on poor network)

**Accessibility implication**: Screen readers get confirmation via live region (WCAG 4.1.3).

**Issue identified**: None (meets WCAG). Enhancement: Add `hx-indicator` for slow requests.

---

### 2. Match Between System and Real World
**Rating**: 5/5 (Excellent)
**Evidence**:
- ‚úÖ Plain language: "Add Task", "Edit", "Delete" (not technical jargon)
- ‚úÖ Confirmation messages in natural language: "Task 'Buy milk' added successfully"

**Accessibility implication**: Simple language benefits cognitive disabilities, low digital literacy.

**Issue identified**: None.

---

### 3. Customer Control and Freedom
**Rating**: 4/5 (Good)
**Evidence**:
- ‚úÖ Cancel button in edit mode (escape hatch)
- ‚ùå No undo for delete (permanent action)

**Accessibility implication**: People with motor impairments may accidentally trigger delete.

**Issue identified**: **Medium severity** ‚Äî Add confirmation dialog or undo feature for delete.

---

### 4. Consistency and Standards
**Rating**: 5/5 (Excellent)
**Evidence**:
- ‚úÖ Semantic HTML (`&lt;button&gt;`, not `&lt;div onclick&gt;`)
- ‚úÖ Follows ARIA patterns (errors use `role="alert"`)
- ‚úÖ Consistent with GOV.UK patterns (error summary, hints)

**Accessibility implication**: Consistency reduces learning curve for AT.

**Issue identified**: None.

---

### 5. Error Prevention
**Rating**: 3/5 (Fair)
**Evidence**:
- ‚úÖ Client-side `required` attribute prevents blank submission
- ‚ö†Ô∏è Server-side validation catches blank titles (good), but no prevention of accidental delete

**Accessibility implication**: BenefitS from preventing errors before they happen.

**Issue identified**: **Medium severity** ‚Äî Delete button too easy to trigger accidentally (no confirmation).

---

### 6. Recognition Rather Than Recall
**Rating**: 4/5 (Good)
**Evidence**:
- ‚úÖ Labels always visible (not just placeholders)
- ‚úÖ Hint text persists below input (`aria-describedby`)
- ‚ö†Ô∏è Error message only appears after submission (could preview validation on blur)

**Accessibility implication**: Persistent labels help cognitive disabilities, memory impairments.

**Issue identified**: None (meets WCAG). Enhancement: Live validation on blur.

---

### 7. Flexibility and Efficiency of Use
**Rating**: 3/5 (Fair)
**Evidence**:
- ‚úÖ Keyboard shortcuts work (Enter submits, Escape cancels in some browsers)
- ‚ùå No custom shortcuts (e.g., Ctrl+E to edit first task)

**Accessibility implication**: Power keyboard users could benefit from shortcuts.

**Issue identified**: **Low severity** ‚Äî Add keyboard shortcuts (defer to Semester 2).

---

### 8. Aesthetic and Minimalist Design
**Rating**: 5/5 (Excellent)
**Evidence**:
- ‚úÖ No clutter (only essential fields shown)
- ‚úÖ Edit form appears inline (progressive disclosure)
- ‚úÖ Status messages dismiss automatically (don't accumulate)

**Accessibility implication**: Minimalism reduces cognitive load, SR navigation time.

**Issue identified**: None.

---

### 9. Help People Recognise, Diagnose, and Recover from Errors
**Rating**: 5/5 (Excellent)
**Evidence**:
- ‚úÖ Error message specific: "Title is required. Please enter at least one character."
- ‚úÖ Error programmatically associated (`aria-describedby`, `role="alert"`)
- ‚úÖ Recovery path clear (fix input, resubmit)

**Accessibility implication**: Meets WCAG 3.3.1 (Error Identification, A) and 3.3.3 (Error Suggestion, AA).

**Issue identified**: None.

---

### 10. Help and Documentation
**Rating**: 2/5 (Poor)
**Evidence**:
- ‚ùå No help text beyond inline hints
- ‚ùå No "What is this?" links for fields

**Accessibility implication**: Cognitive users, first-time users may struggle without documentation.

**Issue identified**: **Low severity** ‚Äî Add help tooltips or links to docs (defer to Semester 2).

---

## Summary of Issues

| Heuristic | Issue | Severity | Inclusion Risk |
|-----------|-------|----------|----------------|
| 3 (Control &amp; Freedom) | No undo for delete | Medium | Motor, Cognitive |
| 5 (Error Prevention) | Delete lacks confirmation | Medium | Motor, Cognitive |
| 7 (Flexibility) | No keyboard shortcuts | Low | Keyboard (power users) |
| 10 (Help) | No help documentation | Low | Cognitive, Low digital literacy |

---

**Next**: Add these to backlog.
</code></pre>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ Heuristic evaluation completed (10 heuristics)</li>
<li>‚úÖ Ratings assigned (1-5 scale)</li>
<li>‚úÖ Issues identified with severity</li>
</ul>
<hr />
<h2 id="activity-4-update-inclusive-backlog"><a class="header" href="#activity-4-update-inclusive-backlog">Activity 4: Update Inclusive Backlog</a></h2>
<p><strong>Time</strong>: 25 minutes
<strong>Materials</strong>: <code>backlog/backlog.csv</code>, audit findings</p>
<h3 id="step-1-consolidate-findings"><a class="header" href="#step-1-consolidate-findings">Step 1: Consolidate Findings</a></h3>
<p>Merge findings from:</p>
<ul>
<li>axe DevTools (<code>axe-report.md</code>)</li>
<li>WCAG checklist (<code>wcag-checklist.md</code>)</li>
<li>Heuristics (<code>heuristics.md</code>)</li>
<li>Week 6 needs-finding interviews</li>
</ul>
<h3 id="step-2-add-new-backlog-items"><a class="header" href="#step-2-add-new-backlog-items">Step 2: Add New Backlog Items</a></h3>
<p>Edit <code>backlog/backlog.csv</code>:</p>
<pre><code class="language-csv">id,title,story_ref,story_type,need,type,severity,inclusion_risk,evidence,notes,candidate_fix
9,Delete button text contrast 4.2:1 (fails AA),wk07/audit/axe-report.md#Issue2,WCAG violation,Visibility,Accessibility,High,"Low vision,Situational","axe: color-contrast; WCAG 1.4.3","Pico.css default gray #6c757d on white = 4.2:1; needs 4.5:1",true
10,Focus outline too faint (Pico.css default),wk07/audit/wcag-checklist.md#2.4.7,WCAG partial,Visibility,Accessibility,Medium,Keyboard,"Manual test: outline visible but faint","Add custom :focus { outline: 3px solid #1976d2; }",true
11,No confirmation for delete action,wk07/audit/heuristics.md#H3,Heuristic violation,Error prevention,Usability,Medium,"Motor,Cognitive","Nielsen H3 + H5","Accidental clicks cause permanent deletion; add confirmation dialog",false
12,No undo feature for delete,wk07/audit/heuristics.md#H3,Heuristic violation,Customer control,Usability,Low,"Motor,
Cognitive","Nielsen H3","Defer to Semester 2; requires state management",false
13,No help documentation or tooltips,wk07/audit/heuristics.md#H10,Heuristic violation,Learning support,Usability,Low,Cognitive,"Nielsen H10","Defer to Semester 2; low priority",false
</code></pre>
<h3 id="step-3-prioritise-with-scoring"><a class="header" href="#step-3-prioritise-with-scoring">Step 3: Prioritise with Scoring</a></h3>
<p><strong>Formula</strong>: <code>Priority = (Severity √ó 2) + (Inclusion Weight) + (WCAG Bonus)</code></p>
<ul>
<li><strong>Severity</strong>: High=3, Medium=2, Low=1 (√ó2 weighting)</li>
<li><strong>Inclusion Weight</strong>: +1 per group affected (max +3)</li>
<li><strong>WCAG Bonus</strong>: Level A failure=+2, Level AA failure=+1</li>
</ul>
<p><strong>Example (Item 9: Contrast)</strong>:</p>
<ul>
<li>Severity: High (3) √ó 2 = 6</li>
<li>Inclusion: Low vision + Situational = +2</li>
<li>WCAG: Level AA (1.4.3) = +1</li>
<li><strong>Total</strong>: 6 + 2 + 1 = <strong>9 (highest priority)</strong></li>
</ul>
<p><strong>Example (Item 11: Delete confirmation)</strong>:</p>
<ul>
<li>Severity: Medium (2) √ó 2 = 4</li>
<li>Inclusion: Motor + Cognitive = +2</li>
<li>WCAG: N/A = 0</li>
<li><strong>Total</strong>: 4 + 2 + 0 = <strong>6 (medium priority)</strong></li>
</ul>
<h3 id="step-4-select-candidate-fix"><a class="header" href="#step-4-select-candidate-fix">Step 4: Select Candidate Fix</a></h3>
<p>Mark <strong>1-2 items</strong> with <code>candidate_fix=true</code>. Criteria:</p>
<ul>
<li>Highest priority score</li>
<li>Fixable in 30-40 minutes (lab time constraint)</li>
<li>Clear success criteria (WCAG pass = verifiable)</li>
</ul>
<p><strong>Recommended fixes</strong>:</p>
<ol>
<li><strong>Item 9</strong> (Contrast): Change button color in CSS (10 min fix)</li>
<li><strong>Item 10</strong> (Focus outline): Add custom <code>:focus</code> styles (15 min fix)</li>
</ol>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ Backlog updated with 5+ new items from audits</li>
<li>‚úÖ Priority scores calculated</li>
<li>‚úÖ 1-2 items marked <code>candidate_fix=true</code></li>
</ul>
<hr />
<h2 id="activity-5-implement-one-priority-fix"><a class="header" href="#activity-5-implement-one-priority-fix">Activity 5: Implement One Priority Fix</a></h2>
<p><strong>Time</strong>: 35 minutes
<strong>Materials</strong>: Backlog, code editor</p>
<h3 id="step-1-choose-fix-target"><a class="header" href="#step-1-choose-fix-target">Step 1: Choose Fix Target</a></h3>
<p><strong>Selected</strong>: Item 9 (Delete button contrast)</p>
<p><strong>Why</strong>: Highest priority (WCAG AA failure), quick fix, measurable success.</p>
<h3 id="step-2-create-fix-plan"><a class="header" href="#step-2-create-fix-plan">Step 2: Create Fix Plan</a></h3>
<p>Create <code>wk07/fixes/fix09-contrast.md</code>:</p>
<pre><code class="language-markdown"># Fix 09: Delete Button Contrast (WCAG 1.4.3)

**Backlog ID**: 9
**WCAG Criterion**: 1.4.3 Contrast (Minimum, Level AA)
**Priority**: 9 (highest)

---

## Problem Statement
Delete button text color (#6c757d) on white background (#ffffff) = 4.2:1 contrast ratio.
**Fails**: WCAG AA requires 4.5:1 for normal text.

**Evidence**:
- axe DevTools: color-contrast (Serious)
- WebAIM Contrast Checker: 4.2:1 (Fail AA)
- Screenshot: `wk07/evidence/contrast-before.png`

---

## Target State
Contrast ratio ‚â• 4.5:1 (AA) or ‚â• 7:1 (AAA).

---

## Solution
Override Pico.css button color with darker gray or custom color.

**Option A**: Darker gray (#495057 = 7:1 contrast, passes AAA)
**Option B**: Custom blue (#1976d2 = 5.2:1 contrast, passes AA)

**Chosen**: Option A (darker gray) for consistency with Pico theme.

---

## Implementation

### Before (Current CSS)
Pico.css default:
```css
button {
  color: #6c757d; /* 4.2:1 contrast */
}
</code></pre>
<h3 id="after-custom-css"><a class="header" href="#after-custom-css">After (Custom CSS)</a></h3>
<p>Add to <code>base.peb</code> <code>&lt;style&gt;</code>:</p>
<pre><code class="language-css">button[type="submit"],
button {
  color: #495057 !important; /* 7:1 contrast (AAA) */
}
</code></pre>
<hr />
<h2 id="verification"><a class="header" href="#verification">Verification</a></h2>
<h3 id="step-1-visual-inspection"><a class="header" href="#step-1-visual-inspection">Step 1: Visual Inspection</a></h3>
<ul>
<li>Load http://localhost:8080/tasks</li>
<li>Inspect "Delete" button</li>
<li>Confirm text appears darker</li>
</ul>
<h3 id="step-2-contrast-check"><a class="header" href="#step-2-contrast-check">Step 2: Contrast Check</a></h3>
<ul>
<li>Use WebAIM Contrast Checker</li>
<li>Foreground: #495057</li>
<li>Background: #ffffff</li>
<li><strong>Expected</strong>: 7:1 (Pass AAA)</li>
</ul>
<h3 id="step-3-re-run-axe"><a class="header" href="#step-3-re-run-axe">Step 3: Re-run axe</a></h3>
<ul>
<li>Open axe DevTools</li>
<li>Scan page</li>
<li><strong>Expected</strong>: color-contrast issue resolved</li>
</ul>
<h3 id="step-4-screenshot"><a class="header" href="#step-4-screenshot">Step 4: Screenshot</a></h3>
<ul>
<li>Save <code>wk07/evidence/contrast-after.png</code></li>
<li>Show button with new color</li>
</ul>
<hr />
<h2 id="evidence"><a class="header" href="#evidence">Evidence</a></h2>
<ul>
<li>Before: <code>wk07/evidence/contrast-before.png</code></li>
<li>After: <code>wk07/evidence/contrast-after.png</code></li>
<li>axe report: <code>wk07/evidence/axe-after.png</code> (0 serious issues)</li>
</ul>
<hr />
<h2 id="commit"><a class="header" href="#commit">Commit</a></h2>
<p><code>git commit -m "Fix #9: Increase button contrast to 7:1 (WCAG 1.4.3 AAA)"</code></p>
<pre><code>
### Step 3: Implement Fix

**Edit `src/main/resources/templates/base.peb`**:

Add inside `&lt;style&gt;` block:

```css
/* Override Pico.css button color for WCAG 1.4.3 AA compliance */
button[type="submit"],
button {
  color: #495057 !important; /* 7:1 contrast (passes AAA) */
}
</code></pre>
<p><strong>Reload page</strong>, inspect button:</p>
<ul>
<li><strong>Before</strong>: #6c757d (light gray)</li>
<li><strong>After</strong>: #495057 (dark gray)</li>
</ul>
<h3 id="step-4-verify-fix"><a class="header" href="#step-4-verify-fix">Step 4: Verify Fix</a></h3>
<p><strong>1. Visual check</strong>:</p>
<pre><code class="language-bash"># Reload http://localhost:8080/tasks
# Confirm button text darker
</code></pre>
<p><strong>2. Contrast calculator</strong>:</p>
<ul>
<li>Visit <a href="https://webaim.org/resources/contrastchecker/">WebAIM Contrast Checker</a></li>
<li>Foreground: #495057</li>
<li>Background: #ffffff</li>
<li><strong>Result</strong>: 7.0:1 (Pass AAA) ‚úÖ</li>
</ul>
<p><strong>3. Re-run axe</strong>:</p>
<ul>
<li>Open axe DevTools</li>
<li>Scan page</li>
<li><strong>Expected</strong>: 0 serious issues (contrast resolved)</li>
</ul>
<p><strong>4. Screenshot</strong>:</p>
<pre><code class="language-bash"># Save screenshot to wk07/evidence/contrast-after.png
</code></pre>
<h3 id="step-5-document-verification"><a class="header" href="#step-5-document-verification">Step 5: Document Verification</a></h3>
<p>Create <code>wk07/fixes/verification.md</code>:</p>
<pre><code class="language-markdown"># Verification Log ‚Äî Fix 09

**Date**: [YYYY-MM-DD]
**Fix**: Delete button contrast (WCAG 1.4.3)

---

## Before State
- **Color**: #6c757d (Pico.css default)
- **Contrast**: 4.2:1 (Fail AA)
- **axe**: 1 serious issue (color-contrast)

## After State
- **Color**: #495057 (custom override)
- **Contrast**: 7.0:1 (Pass AAA)
- **axe**: 0 serious issues

---

## Tests Performed

### Test 1: Contrast Calculation
**Tool**: WebAIM Contrast Checker
**Foreground**: #495057
**Background**: #ffffff
**Result**: ‚úÖ 7.0:1 (Pass AAA)

### Test 2: Visual Inspection
**Action**: Loaded http://localhost:8080/tasks, inspected "Delete" button
**Result**: ‚úÖ Text noticeably darker, easier to read

### Test 3: Automated Re-scan
**Tool**: axe DevTools 4.x
**Result**: ‚úÖ 0 critical, 0 serious (contrast issue resolved)

### Test 4: Regression Check
**Action**: Tested add, edit, delete flows
**Result**: ‚úÖ No regressions, all features work

---

## Evidence
- Before screenshot: `wk07/evidence/contrast-before.png`
- After screenshot: `wk07/evidence/contrast-after.png`
- Contrast checker result: `wk07/evidence/webaim-contrast-7-1.png`
- axe report (after): `wk07/evidence/axe-after.png`

---

## WCAG Compliance
**Criterion**: 1.4.3 Contrast (Minimum, Level AA)
**Status**: ‚úÖ Pass (7.0:1 exceeds 4.5:1 requirement)

**Bonus**: Also passes AAA (7:1 threshold)

---

## Commit
SHA: [abc123f]
Message: "Fix #9: Increase button contrast to 7:1 (WCAG 1.4.3 AAA)"
Files changed: `base.peb` (+3 lines)
</code></pre>
<p><strong>Stop and check</strong>:</p>
<ul>
<li>‚úÖ Fix implemented (CSS change)</li>
<li>‚úÖ Contrast verified (7:1, Pass AAA)</li>
<li>‚úÖ axe re-scan shows 0 serious issues</li>
<li>‚úÖ Evidence collected (screenshots, verification log)</li>
</ul>
<hr />
<h2 id="reflection-questions-2"><a class="header" href="#reflection-questions-2">Reflection Questions</a></h2>
<ol>
<li>
<p><strong>Automated vs. manual testing</strong>: axe found the contrast issue, but did it catch the focus outline being faint? Why do we need both automated and manual testing?</p>
</li>
<li>
<p><strong>Prioritisation</strong>: You had 5 new backlog items. How did the scoring formula (severity √ó inclusion √ó WCAG) change
which one you fixed first? Would your decision differ if time wasn't limited?</p>
</li>
<li>
<p><strong>Evidence chains</strong>: Trace the evidence chain for your fix: audit finding ‚Üí backlog item ‚Üí fix implementation ‚Üí verification. What would happen if you skipped any step?</p>
</li>
<li>
<p><strong>Regression risk</strong>: After fixing contrast, did you verify all buttons still work? Why is regression testing important?</p>
</li>
</ol>
<hr />
<h2 id="further-reading-2"><a class="header" href="#further-reading-2">Further Reading</a></h2>
<p><strong>WCAG 2.2 &amp; auditing</strong></p>
<ul>
<li>W3C (2024). <em>WCAG 2.2 Quick Reference</em>. <a href="https://www.w3.org/WAI/WCAG22/quickref/">https://www.w3.org/WAI/WCAG22/quickref/</a></li>
<li>Deque (2024). <em>axe DevTools Documentation</em>. <a href="https://www.deque.com/axe/devtools/">https://www.deque.com/axe/devtools/</a></li>
<li>WebAIM (2024). <em>WCAG 2 Checklist</em>. <a href="https://webaim.org/standards/wcag/checklist">https://webaim.org/standards/wcag/checklist</a></li>
</ul>
<p><strong>Heuristic evaluation</strong></p>
<ul>
<li>Nielsen, J. (1994). "Heuristic Evaluation." <em>Usability Inspection Methods</em>, 25-62.</li>
<li>Shneiderman, B. et al. (2016). <em>Designing the User Interface</em> (6th ed.), Ch. 3.</li>
</ul>
<p><strong>Inclusive backlogs</strong></p>
<ul>
<li>Cohn, M. (2004). <em>User Stories Applied</em>. Addison-Wesley.</li>
<li>Microsoft (2024). <em>Inclusive Design Toolkit</em>. <a href="https://inclusive.microsoft.design/">https://inclusive.microsoft.design/</a></li>
</ul>
<hr />
<h2 id="glossary-summary-2"><a class="header" href="#glossary-summary-2">Glossary Summary</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Term</th><th>Definition</th><th>Example/Context</th></tr></thead><tbody>
<tr><td><strong>Accessibility audit</strong></td><td>Systematic evaluation against WCAG criteria</td><td>axe scan + manual keyboard/SR testing</td></tr>
<tr><td><strong>Automated testing</strong></td><td>Tools that scan code for issues (20-30% coverage)</td><td>axe DevTools, WAVE, Lighthouse</td></tr>
<tr><td><strong>Manual testing</strong></td><td>Human evaluation (keyboard, SR, heuristics)</td><td>Tab through page, listen with NVDA</td></tr>
<tr><td><strong>Severity</strong></td><td>Impact on task completion (High/Medium/Low)</td><td>High = blocks; Medium = hinders; Low = cosmetic</td></tr>
<tr><td><strong>Inclusion risk</strong></td><td>Who's affected (SR, Keyboard, Cognitive, etc.)</td><td>"Affects SR + Keyboard users"</td></tr>
<tr><td><strong>Heuristic evaluation</strong></td><td>Expert review using usability principles</td><td>Nielsen's 10 Heuristics, Shneiderman's Golden Rules</td></tr>
<tr><td><strong>Contrast ratio</strong></td><td>Luminance difference (text vs. background)</td><td>4.5:1 (AA), 7:1 (AAA)</td></tr>
<tr><td><strong>Regression testing</strong></td><td>Verifying fixes don't break existing features</td><td>After contrast fix, confirm buttons still work</td></tr>
<tr><td><strong>Evidence chain</strong></td><td>Traceable path: audit ‚Üí backlog ‚Üí fix ‚Üí verification</td><td>Finding ‚Üí Item #9 ‚Üí CSS change ‚Üí 7:1 verified</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="lab-checklist-2"><a class="header" href="#lab-checklist-2">Lab Checklist</a></h2>
<p>Before leaving lab, confirm:</p>
<ul>
<li><input disabled="" type="checkbox"/>
<strong>Automated audit completed</strong>: axe DevTools scan, report saved</li>
<li><input disabled="" type="checkbox"/>
<strong>WCAG checklist filled</strong>: At least 15 criteria evaluated (Pass/Fail/N/A)</li>
<li><input disabled="" type="checkbox"/>
<strong>Heuristic evaluation done</strong>: Nielsen's 10 applied, issues logged</li>
<li><input disabled="" type="checkbox"/>
<strong>Backlog updated</strong>: 5+ new items added with severity + inclusion risk</li>
<li><input disabled="" type="checkbox"/>
<strong>One fix implemented</strong>: Code changed, committed</li>
<li><input disabled="" type="checkbox"/>
<strong>Fix verified</strong>: Contrast/tool re-scan shows success</li>
<li><input disabled="" type="checkbox"/>
<strong>Evidence collected</strong>: Before/after screenshots, verification log</li>
<li><input disabled="" type="checkbox"/>
<strong>Code committed</strong>: <code>git add .</code>, <code>git commit -m "wk7-lab2: audit + fix #9 (contrast)"</code></li>
</ul>
<hr />
<h2 id="next-steps-2"><a class="header" href="#next-steps-2">Next Steps</a></h2>
<p>In <strong>Week 8 Lab 1</strong> you will:</p>
<ol>
<li>Add partials and pagination to task list (Pebble template patterns)</li>
<li>Implement filtering with constraint-based design</li>
<li>Test dual-path filtering (HTMX + no-JS)</li>
</ol>
<p>In <strong>Week 8 Lab 2</strong> you will:</p>
<ol>
<li>Verify routing parity (HTMX vs. no-JS)</li>
<li>Document trade-offs (performance, complexity, accessibility)</li>
<li>Run no-JS verification script</li>
</ol>
<p><strong>Preparation</strong>:</p>
<ul>
<li>Ensure backlog up-to-date with Week 7 findings</li>
<li>Have working task manager (add, edit, delete functional)</li>
<li>Review audit evidence (you'll reference it in Task 1)</li>
</ul>
<hr />
<p><strong>Lab authored by</strong>: COMP2850 Teaching Team, University of Leeds
<strong>Last updated</strong>: 2025-01-14
<strong>Licence</strong>: Academic use only (not for redistribution)</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="code-resources-1"><a class="header" href="#code-resources-1">Code Resources</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-8--lab-1--prototyping-with-constraints-partials-pagination-filtering"><a class="header" href="#week-8--lab-1--prototyping-with-constraints-partials-pagination-filtering">Week 8 ‚Ä¢ Lab 1 ‚Äî Prototyping with Constraints: Partials, Pagination, Filtering</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-8-orange" alt="Week 8" />
<img src="https://img.shields.io/badge/Lab-1-green" alt="Lab 1" />
<img src="https://img.shields.io/badge/Status-Draft-yellow" alt="Status" /></p>
<blockquote>
<p>We keep saying ‚Äúserver-first for everyone, HTMX for enhancement.‚Äù Scaling that pattern to dozens or hundreds of tasks introduces new constraints. Today you will factor templates, add filtering and pagination, and document the trade-offs you are making.</p>
</blockquote>
<hr />
<h2 id="why-this-lab-matters"><a class="header" href="#why-this-lab-matters">Why this lab matters</a></h2>
<ul>
<li>Template partials reduce duplication and keep accessibility fixes in one place.</li>
<li>Pagination and filtering control cognitive load and network cost when lists grow.</li>
<li>History (<code>hx-push-url</code>) and live status updates maintain web affordances (back button, result count) for all participants.</li>
<li>Documented trade-offs help you justify design decisions in critiques and assessments.</li>
</ul>
<p>This lab feeds directly into Week 8 Lab 2 (no-JS parity verification) and sets up metrics collection in Week 9.</p>
<hr />
<h2 id="pre-lab-reading-15-min"><a class="header" href="#pre-lab-reading-15-min">Pre-lab reading (15 min)</a></h2>
<ul>
<li><a href="https://htmx.org/examples/active-search/">HTMX Examples ‚Äî Active Search</a></li>
<li><a href="https://htmx.org/attributes/hx-push-url/">HTMX reference: <code>hx-push-url</code></a> and <a href="https://htmx.org/attributes/hx-trigger/"><code>hx-trigger</code></a></li>
<li><a href="https://pebbletemplates.io/wiki/tag/extends/">Pebble template inheritance</a> and include syntax</li>
</ul>
<p>Keep the <a href="wk08/../references/pebble-cheatsheet.html">Pebble Cheatsheet</a> and <a href="wk08/../references/htmx-patterns.html">HTMX Patterns</a> open for reference.</p>
<hr />
<h2 id="learning-focus-4"><a class="header" href="#learning-focus-4">Learning Focus</a></h2>
<h3 id="lab-objectives-4"><a class="header" href="#lab-objectives-4">Lab Objectives</a></h3>
<p>By the end of this session, you will have:</p>
<ul>
<li>Factored the tasks page into reusable Pebble partials (<code>_layout</code>, <code>_list</code>, <code>_item</code>, <code>_pager</code>)</li>
<li>Added production-ready UI with header, navigation, and footer partials</li>
<li>Implemented filtering + pagination with a dual-path architecture (full-page and HTMX fragment routes)</li>
<li>Maintained accessible result announcements (<code>aria-describedby</code>) and predictable focus</li>
<li>Used <code>hx-push-url</code> so history and bookmarking work across pages</li>
<li>Documented trade-offs in server-side vs client-side filtering</li>
</ul>
<h3 id="learning-outcomes-addressed-4"><a class="header" href="#learning-outcomes-addressed-4">Learning Outcomes Addressed</a></h3>
<p>This lab contributes to the following module Learning Outcomes (<a href="wk08/../references/learning-outcomes.html">full definitions</a>):</p>
<ul>
<li><strong>LO5</strong>: Create interface prototypes ‚Äî evidenced by HTMX partials implementation</li>
<li><strong>LO7</strong>: Analyse design constraints ‚Äî evidenced by pagination trade-offs document</li>
<li><strong>LO13</strong>: Integrate HCI with SE ‚Äî evidenced by server-rendered fragments</li>
</ul>
<hr />
<hr />
<h2 id="background-inclusive-prototyping-at-scale"><a class="header" href="#background-inclusive-prototyping-at-scale">Background: Inclusive prototyping at scale</a></h2>
<p>Why refactor now? As lists grow, duplication becomes dangerous: accessibility fixes, aria hooks, and HTMX attributes drift if they live in multiple places. Partials keep the source of truth in one file so every flow (full page and fragment) inherits the same semantics.</p>
<p>Pagination and filtering are not just performance tricks; they control cognitive load, especially for screen-reader participants who would otherwise wade through hundreds of list items. Implement them with inclusive defaults: predictable focus, result announcements, and URLs that respect the back button.</p>
<p>Keep these references handy while you work:</p>
<ul>
<li><a href="wk08/references/pebble-cheatsheet.html">Pebble Cheatsheet</a></li>
<li><code>../references/template-map-week8.md</code> (visual map of the partials you are about to create)</li>
<li><code>../references/htmx-pattern-cheatsheet.md</code> (Active Search, OOB status, indicators)</li>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/Accessibility/Understanding_WCAG/Navigation_and_orienting#pagination">MDN: Accessible Pagination Patterns</a></li>
</ul>
<blockquote>
<p><strong>Visual</strong>: Template hierarchy for the tasks UI</p>
</blockquote>
<pre class="mermaid">graph TD
  Base[_layout/base.peb&lt;br/&gt;skip link, live region, Pico.css]
  Base --&gt; Index[tasks/index.peb]
  Index --&gt; List[tasks/_list.peb]
  List --&gt; Item[tasks/_item.peb]
  Index --&gt; Pager[tasks/_pager.peb]
  Item --&gt;|Forms| Routes[(Ktor routes)]
  Pager --&gt;|Links| Routes
  Routes --&gt; HTMX[HTMX fragment responses]
  Routes --&gt; PRG[Full-page PRG responses]
</pre>
<p><small>Full legend in <a href="wk08/../references/process-visuals.html#template-hierarchy">Process Visuals</a>.</small></p>
<h3 id="worked-example-active-search-with-parity"><a class="header" href="#worked-example-active-search-with-parity">Worked example: Active Search with parity</a></h3>
<p>The filter form uses HTMX for fast updates, but must still function when JS is disabled. Compare the enhanced and fallback behaviours:</p>
<pre><code class="language-html">&lt;form action="/tasks" method="get"
      hx-get="/tasks/fragment"
      hx-target="#task-area"
      hx-trigger="keyup changed delay:300ms, submit from:closest(form)"
      hx-push-url="true"&gt;
  &lt;label for="q"&gt;Filter tasks&lt;/label&gt;
  &lt;input id="q" name="q" value="{{ query|default('') }}" type="search"
         aria-describedby="q-hint"&gt;
  &lt;small id="q-hint"&gt;Type to filter; works without JavaScript.&lt;/small&gt;
  &lt;button type="submit"&gt;Apply&lt;/button&gt;
&lt;/form&gt;
</code></pre>
<ul>
<li><strong>HTMX path</strong>: typing triggers <code>/tasks/fragment</code>, which returns <code>_list</code> + <code>_pager</code> + a status update (<code>Found X tasks</code>). <code>hx-push-url"true"</code> keeps the URL in sync so back/forward works.</li>
<li><strong>No-JS path</strong>: pressing Enter submits the form to <code>/tasks</code>; the full page renders using the same partials. Because labels and hints live in the partial, accessibility remains intact in both cases.</li>
</ul>
<p>When verifying parity, disable JS and watch the address bar: URLs should still reflect the current query and page so participants can bookmark or share the state.</p>
<hr />
<h2 id="0-baseline-check-5-min"><a class="header" href="#0-baseline-check-5-min">0. Baseline check (5 min)</a></h2>
<p>Run <code>./gradlew run</code> and load <code>http://localhost:8080/tasks</code>:</p>
<ul>
<li>Confirm add/edit/delete from Week 7 still work with JS on.</li>
<li>Disable JavaScript and re-run the same flows to ensure parity.</li>
<li>If anything regressed, fix it before adding complexity.</li>
</ul>
<hr />
<h2 id="1-factor-templates-into-partials-40-min"><a class="header" href="#1-factor-templates-into-partials-40-min">1. Factor templates into partials (40 min)</a></h2>
<blockquote>
<p><strong>üí° Template Naming Convention: Underscore Prefix</strong></p>
<p>Starting in Week 8, we adopt a <strong>underscore prefix</strong> (<code>_</code>) for <strong>partial templates</strong>:</p>
<div class="table-wrapper"><table><thead><tr><th>Name</th><th>Type</th><th>Purpose</th><th>Example</th></tr></thead><tbody>
<tr><td><code>index.peb</code></td><td><strong>Full page</strong></td><td>Complete HTML document (extends base)</td><td><code>tasks/index.peb</code></td></tr>
<tr><td><code>_item.peb</code></td><td><strong>Partial</strong></td><td>Fragment included in other templates</td><td><code>tasks/_item.peb</code></td></tr>
<tr><td><code>_list.peb</code></td><td><strong>Partial</strong></td><td>Reusable component (used multiple times)</td><td><code>tasks/_list.peb</code></td></tr>
<tr><td><code>_layout/base.peb</code></td><td><strong>Layout</strong></td><td>Shared page structure</td><td><code>_layout/base.peb</code></td></tr>
</tbody></table>
</div>
<p><strong>Why the underscore?</strong></p>
<ul>
<li><strong>Visual distinction</strong>: Instantly recognizable as a partial (not a standalone page)</li>
<li><strong>Common convention</strong>: Used by Rails, Jekyll, Sass, and other template systems</li>
<li><strong>Prevent direct access</strong>: In some frameworks, <code>_</code> files are not served directly</li>
</ul>
<p><strong>Rule of thumb</strong>:</p>
<ul>
<li><strong>No underscore</strong> = Full page that can be rendered directly (e.g., <code>/tasks</code> ‚Üí <code>tasks/index.peb</code>)</li>
<li><strong>Underscore</strong> = Fragment included via <code>{% include %}</code> or HTMX <code>hx-get</code></li>
</ul>
<p><strong>This week's structure</strong>:</p>
<pre><code>templates/
‚îú‚îÄ‚îÄ _layout/
‚îÇ   ‚îî‚îÄ‚îÄ base.peb        ‚Üê Shared layout (underscore because it's a partial)
‚îî‚îÄ‚îÄ tasks/
    ‚îú‚îÄ‚îÄ index.peb       ‚Üê Full page (no underscore)
    ‚îú‚îÄ‚îÄ _item.peb       ‚Üê Partial: single task &lt;li&gt;
    ‚îú‚îÄ‚îÄ _list.peb       ‚Üê Partial: task list &lt;ul&gt;
    ‚îî‚îÄ‚îÄ _pager.peb      ‚Üê Partial: pagination nav
</code></pre>
</blockquote>
<p>We want a structure like the one in <code>../references/template-map-week8.md</code>.</p>
<h3 id="11-base-layout"><a class="header" href="#11-base-layout">1.1 Base layout</a></h3>
<p>Create <code>templates/_layout/base.peb</code> with the shared head, status region, skip link, Pico CSS, HTMX script, and utility classes. This keeps accessibility hooks (live region, focus outline, visually hidden class) in a single place.</p>
<h3 id="12-task-item-partial"><a class="header" href="#12-task-item-partial">1.2 Task item partial</a></h3>
<p>Create <code>templates/tasks/_item.peb</code> that renders a single <code>&lt;li&gt;</code> with:</p>
<ul>
<li>Stable id <code>task-{{ t.id }}</code>.</li>
<li>The title and the Edit/Delete forms from Week 7 (keep ARIA labels and dual attributes).</li>
<li>No inline business logic‚Äîjust markup and data from the model.</li>
</ul>
<h3 id="13-task-list-partial"><a class="header" href="#13-task-list-partial">1.3 Task list partial</a></h3>
<p>Create <code>templates/tasks/_list.peb</code> containing:</p>
<pre><code class="language-pebble">&lt;ul id="task-list" aria-describedby="result-count"&gt;
  {% for task in page.items %}
    {% include "tasks/_item.peb" with {"task": task} %}
  {% endfor %}
&lt;/ul&gt;
&lt;p id="result-count" class="visually-hidden"&gt;
  Showing {{ page.items|length }} of {{ page.totalItems }} tasks{% if query %} matching "{{ query }}"{% endif %}
&lt;/p&gt;
</code></pre>
<p>This ensures screen readers hear the result count whenever the list changes.</p>
<h3 id="14-update-index-page"><a class="header" href="#14-update-index-page">1.4 Update index page</a></h3>
<p>Modify <code>templates/tasks/index.peb</code> so it extends <code>_layout/base.peb</code>, renders the add form, and includes <code>_list.peb</code> and <code>_pager.peb</code> inside a <code>&lt;div id="task-area"&gt;</code> container (we will populate <code>_pager.peb</code> shortly).</p>
<p>‚úã <strong>Checkpoint</strong>: restart the server and confirm the tasks page renders exactly as before (no functionality has changed yet). If anything broke, inspect your partials and template paths.</p>
<h3 id="15-add-production-ready-ui-with-headernavfooter-partials-15-min"><a class="header" href="#15-add-production-ready-ui-with-headernavfooter-partials-15-min">1.5 Add production-ready UI with header/nav/footer partials (15 min)</a></h3>
<p>Now that you understand the partial pattern, let's apply it to create a more polished, production-ready UI. We'll factor the base layout into reusable header, navigation, and footer components.</p>
<p><strong>Why add this now?</strong></p>
<ul>
<li><strong>Maintainability</strong>: Accessibility features (skip links, ARIA live regions) stay in one place</li>
<li><strong>Reusability</strong>: Header and footer will be consistent across all pages</li>
<li><strong>Professionalism</strong>: Navigation and session info help users understand context</li>
<li><strong>Best practice</strong>: Industry-standard template organization (header/nav/footer separation)</li>
</ul>
<p><strong>What you're building:</strong></p>
<pre><code>templates/_layout/
‚îú‚îÄ‚îÄ base.peb         ‚Üê Updated to include partials
‚îú‚îÄ‚îÄ _header.peb      ‚Üê Skip link, ARIA live region, includes nav
‚îú‚îÄ‚îÄ _nav.peb         ‚Üê Site branding, main navigation links
‚îî‚îÄ‚îÄ _footer.peb      ‚Üê University branding, helpful links, session info
</code></pre>
<h4 id="151-create-header-partial"><a class="header" href="#151-create-header-partial">1.5.1 Create header partial</a></h4>
<p>Create <code>templates/_layout/_header.peb</code>:</p>
<pre><code class="language-pebble">{# Header partial with navigation and branding #}
{# WCAG 2.4.1: Skip link for keyboard navigation #}
&lt;a class="skip-link" href="#main"&gt;Skip to main content&lt;/a&gt;

{# WCAG 4.1.3: ARIA live region for dynamic status announcements #}
{# Polite: non-interrupting announcements after current speech finishes #}
&lt;div id="status" role="status" aria-live="polite" aria-atomic="true" class="visually-hidden"&gt;&lt;/div&gt;

&lt;header&gt;
  {% include "_layout/_nav.peb" %}
&lt;/header&gt;
</code></pre>
<p><strong>Key accessibility features:</strong></p>
<ul>
<li><strong>Skip link</strong>: Keyboard users can jump directly to main content (WCAG 2.4.1)</li>
<li><strong>Live region</strong>: Screen readers announce status updates without interrupting navigation (WCAG 4.1.3)</li>
<li><strong>Semantic <code>&lt;header&gt;</code></strong>: Screen readers identify site header as a landmark</li>
</ul>
<h4 id="152-create-navigation-partial"><a class="header" href="#152-create-navigation-partial">1.5.2 Create navigation partial</a></h4>
<p>Create <code>templates/_layout/_nav.peb</code>:</p>
<pre><code class="language-pebble">{# Navigation partial with site branding and main menu #}
{# WCAG 1.3.1: Semantic nav element for screen readers #}
&lt;nav aria-label="Main navigation"&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;strong&gt;COMP2850 Task Manager&lt;/strong&gt;&lt;/li&gt;
  &lt;/ul&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href="/tasks"&gt;Tasks&lt;/a&gt;&lt;/li&gt;
    &lt;li&gt;&lt;a href="/health"&gt;Health&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/nav&gt;
</code></pre>
<p><strong>Pico CSS pattern</strong>: Pico's <code>&lt;nav&gt;</code> styling automatically creates a horizontal navigation bar with the first <code>&lt;ul&gt;</code> on the left (branding) and second <code>&lt;ul&gt;</code> on the right (links).</p>
<p><strong>Why <code>aria-label</code>?</strong>: If you have multiple <code>&lt;nav&gt;</code> elements on a page, labels like <code>aria-label="Main navigation"</code> help screen reader users distinguish between them.</p>
<h4 id="153-create-footer-partial"><a class="header" href="#153-create-footer-partial">1.5.3 Create footer partial</a></h4>
<p>Create <code>templates/_layout/_footer.peb</code>:</p>
<pre><code class="language-pebble">{# Footer partial with helpful links and session info #}
{# WCAG 1.3.1: Semantic footer element #}
&lt;footer&gt;
  &lt;div class="container"&gt;
    &lt;p&gt;
      &lt;small&gt;
        COMP2850 HCI &amp;bull; Server-first architecture &amp;bull;
        &lt;a href="https://htmx.org/docs/" target="_blank" rel="noopener"&gt;HTMX Docs&lt;/a&gt; &amp;bull;
        &lt;a href="https://www.w3.org/WAI/WCAG22/quickref/" target="_blank" rel="noopener"&gt;WCAG 2.2&lt;/a&gt;
      &lt;/small&gt;
    &lt;/p&gt;
    &lt;p&gt;
      &lt;small&gt;
        Session: {{ sessionId | default('N/A') }} &amp;bull;
        Mode: {% if isHtmx %}HTMX{% else %}No-JS{% endif %}
      &lt;/small&gt;
    &lt;/p&gt;
  &lt;/div&gt;
&lt;/footer&gt;
</code></pre>
<p><strong>What the footer provides:</strong></p>
<ul>
<li><strong>Context links</strong>: Quick access to HTMX and WCAG documentation</li>
<li><strong>Session visibility</strong>: Helps with debugging (which session is active?)</li>
<li><strong>Mode indicator</strong>: Shows whether HTMX is working (useful for verifying parity)</li>
</ul>
<p><strong>Security note</strong>: <code>target="_blank"</code> requires <code>rel="noopener"</code> to prevent the new page from accessing <code>window.opener</code>.</p>
<h4 id="154-update-base-layout-to-use-partials"><a class="header" href="#154-update-base-layout-to-use-partials">1.5.4 Update base layout to use partials</a></h4>
<p>Now update <code>templates/_layout/base.peb</code> to include these partials. Replace your current base.peb with:</p>
<pre><code class="language-pebble">&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
  &lt;meta charset="utf-8" /&gt;
  &lt;meta name="viewport" content="width=device-width, initial-scale=1" /&gt;
  &lt;title&gt;{% block title %}COMP2850 Task Manager{% endblock %}&lt;/title&gt;

  {# Pico CSS for baseline accessible styles (WCAG 2.2 AA compliant) #}
  &lt;link rel="stylesheet" href="https://unpkg.com/@picocss/pico@2/css/pico.min.css"&gt;

  {# HTMX for progressive enhancement #}
  &lt;script src="https://unpkg.com/htmx.org@1.9.12"&gt;&lt;/script&gt;

  &lt;style&gt;
    /* Visually hidden but accessible to screen readers (WCAG 1.3.1) */
    .visually-hidden {
      position: absolute !important;
      height: 1px;
      width: 1px;
      overflow: hidden;
      clip: rect(1px, 1px, 1px, 1px);
      white-space: nowrap;
    }

    /* Skip link for keyboard navigation (WCAG 2.4.1) */
    .skip-link {
      position: absolute;
      left: -10000px;
      width: 1px;
      height: 1px;
      overflow: hidden;
    }
    .skip-link:focus {
      position: static;
      width: auto;
      height: auto;
      background: #1976d2;
      color: white;
      padding: 0.5rem 1rem;
      text-decoration: none;
      font-weight: bold;
      z-index: 9999;
    }

    /* Pagination styles */
    .pagination {
      display: flex;
      gap: 0.5rem;
      align-items: center;
    }
  &lt;/style&gt;
&lt;/head&gt;
&lt;body&gt;
  {# Include header with navigation and accessibility features #}
  {% include "_layout/_header.peb" %}

  {# Main landmark for screen readers (WCAG 1.3.1) #}
  {# tabindex="-1" allows programmatic focus for skip link #}
  &lt;main id="main" class="container" tabindex="-1"&gt;
    {% block content %}
    {# Page-specific content goes here #}
    {% endblock %}
  &lt;/main&gt;

  {# Include footer with helpful links and session info #}
  {% include "_layout/_footer.peb" %}
&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<p><strong>What changed:</strong></p>
<ul>
<li>Moved skip link and live region to <code>_header.peb</code></li>
<li>Added navigation via <code>_nav.peb</code></li>
<li>Added footer with helpful links and session info</li>
<li>Enhanced CSS for skip link visibility on focus</li>
<li>Added <code>{% block title %}</code> so pages can customize the <code>&lt;title&gt;</code> tag</li>
</ul>
<h4 id="155-update-route-handlers-to-pass-session-data"><a class="header" href="#155-update-route-handlers-to-pass-session-data">1.5.5 Update route handlers to pass session data</a></h4>
<p>For the footer to display session info, update your route handlers to include <code>sessionId</code> and <code>isHtmx</code> in the template model:</p>
<pre><code class="language-kotlin">get("/tasks") {
    val query = call.request.queryParameters["q"].orEmpty()
    val page = call.request.queryParameters["page"]?.toIntOrNull() ?: 1
    val data = repo.search(query = query, page = page, size = 10)

    // Add session info for footer
    val sessionId = call.sessions.get&lt;UserSession&gt;()?.id ?: "guest"
    val isHtmx = call.request.headers["HX-Request"]?.equals("true", ignoreCase = true) == true

    val model = mapOf(
        "title" to "Tasks",
        "page" to data,
        "query" to query,
        "sessionId" to sessionId,
        "isHtmx" to isHtmx
    )
    call.respondHtml(PebbleRender.render("tasks/index.peb", model))
}
</code></pre>
<p><strong>Note</strong>: If you don't have session support yet, you can pass a placeholder value like <code>"dev-session"</code> for now.</p>
<p>‚úã <strong>Checkpoint</strong>: restart the server and verify:</p>
<ul>
<li><strong>Navigation bar</strong> appears at the top with "COMP2850 Task Manager" branding and Tasks/Health links</li>
<li><strong>Skip link</strong> becomes visible when you press Tab (test keyboard navigation)</li>
<li><strong>Footer</strong> shows at the bottom with helpful links and session info</li>
<li><strong>All existing functionality</strong> still works (add/edit/delete tasks)</li>
<li><strong>Accessibility</strong>: Skip link works, navigation is keyboard-accessible, footer links open in new tabs</li>
</ul>
<p><strong>Benefits of this refactoring:</strong></p>
<ul>
<li>üé® <strong>Professional appearance</strong>: Navigation and branding make it look like a real web app</li>
<li>‚ôø <strong>Accessibility maintained</strong>: Skip links and ARIA regions still work</li>
<li>üîß <strong>Easier maintenance</strong>: Update navigation in one place, all pages inherit it</li>
<li>üìö <strong>Learning transfer</strong>: This pattern applies to any server-rendered web app</li>
</ul>
<hr />
<h2 id="2-add-pagination-and-filtering-35-min"><a class="header" href="#2-add-pagination-and-filtering-35-min">2. Add pagination and filtering (35 min)</a></h2>
<h3 id="21-repository-paging-helper"><a class="header" href="#21-repository-paging-helper">2.1 Repository paging helper</a></h3>
<p>Add a <code>Page&lt;T&gt;</code> data class and a <code>search(query, page, size)</code> helper in your repository or service layer so routes can request paged data. Keep the page number clamped (<code>coerceIn</code>) to valid bounds.</p>
<h3 id="22-pager-partial"><a class="header" href="#22-pager-partial">2.2 Pager partial</a></h3>
<p>Create <code>templates/tasks/_pager.peb</code>:</p>
<pre><code class="language-pebble">&lt;nav aria-label="Pagination"&gt;
  &lt;ul class="pagination"&gt;
    {% if page.currentPage &gt; 1 %}
      &lt;li&gt;
        &lt;a href="/tasks?q={{ query|default('') }}&amp;page={{ page.currentPage - 1 }}"
           hx-get="/tasks/fragment?q={{ query|default('') }}&amp;page={{ page.currentPage - 1 }}"
           hx-target="#task-area"
           hx-push-url="true"&gt;
          Previous
        &lt;/a&gt;
      &lt;/li&gt;
    {% endif %}
    &lt;li aria-current="page"&gt;Page {{ page.currentPage }} of {{ page.totalPages }}&lt;/li&gt;
    {% if page.currentPage &lt; page.totalPages %}
      &lt;li&gt;
        &lt;a href="/tasks?q={{ query|default('') }}&amp;page={{ page.currentPage + 1 }}"
           hx-get="/tasks/fragment?q={{ query|default('') }}&amp;page={{ page.currentPage + 1 }}"
           hx-target="#task-area"
           hx-push-url="true"&gt;
          Next
        &lt;/a&gt;
      &lt;/li&gt;
    {% endif %}
  &lt;/ul&gt;
&lt;/nav&gt;
</code></pre>
<p>Dual attributes guarantee the pager works both with and without HTMX.</p>
<h3 id="23-filter-form"><a class="header" href="#23-filter-form">2.3 Filter form</a></h3>
<p>Above the task area add a filter form:</p>
<pre><code class="language-pebble">&lt;form action="/tasks" method="get"
      hx-get="/tasks/fragment"
      hx-target="#task-area"
      hx-trigger="keyup changed delay:300ms, submit from:closest(form)"
      hx-push-url="true"&gt;
  &lt;label for="q"&gt;Filter tasks&lt;/label&gt;
  &lt;input id="q" name="q" value="{{ query|default('') }}" type="search"
         aria-describedby="q-hint"&gt;
  &lt;small id="q-hint"&gt;Type to filter; works without JavaScript.&lt;/small&gt;
  &lt;button type="submit"&gt;Apply&lt;/button&gt;
&lt;/form&gt;
</code></pre>
<p>The visible submit button provides the no-JS fallback; HTMX enhances with Active Search. Use the indicator pattern from the cheat sheet if you want to show loading state.</p>
<h3 id="24-routes"><a class="header" href="#24-routes">2.4 Routes</a></h3>
<p>Add two GET handlers in your Ktor routing block:</p>
<pre><code class="language-kotlin">get("/tasks") {
    val query = call.request.queryParameters["q"].orEmpty()
    val page = call.request.queryParameters["page"]?.toIntOrNull() ?: 1
    val data = repo.search(query = query, page = page, size = 10)
    val model = mapOf("title" to "Tasks", "page" to data, "query" to query)
    call.respondHtml(PebbleRender.render("tasks/index.peb", model))
}

get("/tasks/fragment") {
    val query = call.request.queryParameters["q"].orEmpty()
    val page = call.request.queryParameters["page"]?.toIntOrNull() ?: 1
    val data = repo.search(query = query, page = page, size = 10)
    val list = PebbleRender.render("tasks/_list.peb", mapOf("page" to data, "query" to query))
    val pager = PebbleRender.render("tasks/_pager.peb", mapOf("page" to data, "query" to query))
    val status = """&lt;div id="status" hx-swap-oob="true"&gt;Found ${data.total} tasks.&lt;/div&gt;"""
    call.respondText(list + pager + status, ContentType.Text.Html)
}
</code></pre>
<p><code>/tasks</code> handles full-page renders. <code>/tasks/fragment</code> returns fragments + an out-of-band status update for HTMX.</p>
<p>‚úã <strong>Checkpoint</strong>:</p>
<ul>
<li>Filter form updates the list as you type (HTMX) and on submit (no-JS).</li>
<li>Pager links update the list and URL with HTMX; back/forward work.</li>
<li>Live region announces ‚ÄúFound X tasks.‚Äù</li>
<li>With JavaScript disabled, the filter submits and redraws the whole page; pager links still navigate correctly.</li>
</ul>
<hr />
<h2 id="3-test-with-assistive-technology-10-min"><a class="header" href="#3-test-with-assistive-technology-10-min">3. Test with assistive technology (10 min)</a></h2>
<p>Use the checklist:</p>
<ul>
<li>Keyboard-only: Tab through filter form, pagination links, and tasks. Focus order should make sense and remain visible.</li>
<li>Screen reader: Trigger a filter change and ensure the result count is announced. Navigate the pager links; confirm <code>aria-current</code> is read out.</li>
<li>No-JS parity: Disable JS and confirm filtering/paging still work via full-page loads.</li>
<li>History: After filtering, use the back button‚Äîdoes the list revert? If not, check <code>hx-push-url</code> and your full-page route.</li>
</ul>
<p>Record outcomes in <code>wk08/docs/prototyping-constraints.md</code> under an ‚ÄúAccessibility verification‚Äù section.</p>
<hr />
<h2 id="4-document-trade-offs-15-min"><a class="header" href="#4-document-trade-offs-15-min">4. Document trade-offs (15 min)</a></h2>
<p>Open <code>wk08/docs/prototyping-constraints.starter.md</code> (or create <code>prototyping-constraints.md</code>) and note:</p>
<ul>
<li>Rendering splits (full page vs fragments).</li>
<li>Accessibility hooks (result count, live region, focus handling).</li>
<li>State management decisions (query parameter naming, page size choices).</li>
<li>Risks you introduced (duplicate HTML fragments, maintaining <code>_list</code> and <code>_pager</code>, potential 404 on out-of-range pages).</li>
</ul>
<p>This documentation is evidence for Week 10 prioritisation and helps staff review your implementation quickly.</p>
<hr />
<h2 id="commit-guidance"><a class="header" href="#commit-guidance">Commit guidance</a></h2>
<pre><code class="language-bash">git add templates/_layout/base.peb templates/tasks/_*.peb templates/tasks/index.peb src/main/kotlin wk08/docs/prototyping-constraints.md

git commit -m "wk8s1: partials + pagination/filter with hx-push-url" --no-verify
</code></pre>
<p>Suggested commit body:</p>
<pre><code>- factored tasks templates into base layout, list, item, pager partials
- added search form with dual-path (HTMX + full-page) handling
- implemented pagination routes returning fragments + status announcements
- verified keyboard, screen reader, JS-off parity
- documented rendering splits and trade-offs in wk08/docs/prototyping-constraints.md
</code></pre>
<hr />
<h2 id="advanced-template-view-adapter-pattern-optional"><a class="header" href="#advanced-template-view-adapter-pattern-optional">Advanced: Template View Adapter Pattern (Optional)</a></h2>
<p><strong>For students comfortable with abstraction layers</strong>:</p>
<p>The current approach passes the <code>Page</code> object directly to templates (<code>"page" to data</code>), which keeps templates coupled to the Kotlin data class structure. If you change <code>Page.currentPage</code> to <code>Page.number</code>, all templates break.</p>
<p><strong>Alternative: View adapter method</strong></p>
<p>Add a <code>toPebbleContext()</code> method to <code>Page</code> that flattens properties into template-friendly names:</p>
<pre><code class="language-kotlin">fun toPebbleContext(itemsKey: String = "items"): Map&lt;String, Any&gt; = mapOf(
    itemsKey to items,
    "currentPage" to currentPage,
    "totalPages" to totalPages,
    "totalItems" to totalItems,
    "pageSize" to pageSize,
    "hasPrevious" to hasPrevious,
    "hasNext" to hasNext,
    "previousPage" to previousPage,
    "nextPage" to nextPage
)
</code></pre>
<p>Then routes can use:</p>
<pre><code class="language-kotlin">val model = page.toPebbleContext("tasks") + mapOf("query" to query)
</code></pre>
<p>And templates access flattened variables:</p>
<pre><code class="language-pebble">{{ tasks|length }} of {{ totalItems }}
&lt;li&gt;Page {{ currentPage }} of {{ totalPages }}&lt;/li&gt;
</code></pre>
<p><strong>Trade-offs</strong>:</p>
<ul>
<li>‚úÖ Decouples templates from Kotlin internals (can rename properties safely)</li>
<li>‚úÖ Cleaner template syntax (shorter variable names)</li>
<li>‚ùå Extra abstraction layer to understand</li>
<li>‚ùå "Magic" variable names (harder to trace where they come from)</li>
</ul>
<p><strong>When to use</strong>: Production codebases where template stability matters. For learning, the direct approach (<code>page.items</code>, <code>page.page</code>) is clearer.</p>
<hr />
<h2 id="whats-next"><a class="header" href="#whats-next">What's next?</a></h2>
<p>Week 8 Lab 2 focuses on wiring additional routes, error handling, and no-JS verification scripts. Keep your server running and your documentation open‚Äîwe will extend the same patterns immediately.</p>
<p>Optional stretch this week: add a "mark complete" flow using the same partials and log any accessibility considerations.</p>
<hr />
<h2 id="further-resources"><a class="header" href="#further-resources">Further resources</a></h2>
<ul>
<li><a href="https://htmx.org/examples/active-search/">HTMX Examples ‚Äî Active Search</a></li>
<li><a href="https://developer.mozilla.org/en-US/docs/Web/Accessibility/Understanding_WCAG/Navigation_and_orienting#pagination">MDN ‚Äî Accessible Pagination Patterns</a></li>
</ul>
<p>You now have a scalable, accessible list structure ready for deeper evaluation and instrumentation.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-8--lab-2--wire-routes-verify-no-js-parity-capture-trade-offs"><a class="header" href="#week-8--lab-2--wire-routes-verify-no-js-parity-capture-trade-offs">Week 8 ‚Ä¢ Lab 2 ‚Äî Wire Routes, Verify No-JS Parity, Capture Trade-offs</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-8-orange" alt="Week 8" />
<img src="https://img.shields.io/badge/Lab-2-green" alt="Lab 2" />
<img src="https://img.shields.io/badge/Status-Draft-yellow" alt="Status" /></p>
<hr />
<h2 id="before-lab-required-reading-15-mins"><a class="header" href="#before-lab-required-reading-15-mins">Before Lab: Required Reading (15 mins)</a></h2>
<p>üìñ <strong>Essential</strong></p>
<ul>
<li>Ensure Week 8 starter repo updates (pagination work) are committed/pushed</li>
<li><a href="https://htmx.org/reference/#events">HTMX: Events Reference</a> (htmx:responseError, htmx:beforeSwap)</li>
<li><a href="https://htmx.org/attributes/hx-confirm/">HTMX: hx-confirm</a></li>
<li><a href="https://webaim.org/articles/formvalidation/">WebAIM: Forms - Accessible Error Identification</a></li>
</ul>
<p>üìñ <strong>Contextual</strong>:</p>
<ul>
<li>Review <a href="wk08/../references/htmx-pattern-cheatsheet.html">HTMX Pattern Cheatsheet</a> (OOB pattern)</li>
<li>Review <a href="wk08/../references/assistive-testing-checklist.html">Assistive Testing Checklist</a></li>
<li>Review Week 7 Lab 1 inline edit implementation</li>
</ul>
<hr />
<h2 id="introduction-from-prototype-to-production-ready"><a class="header" href="#introduction-from-prototype-to-production-ready">Introduction: From Prototype to Production-Ready</a></h2>
<p>Yesterday (Week 8 Lab 1) you added pagination and filtering. The <strong>happy path</strong> works: people can browse, filter, and page through tasks.</p>
<p><strong>Today's reality check</strong>: What happens when:</p>
<ul>
<li>Someone submits an empty form?</li>
<li>JavaScript is disabled or fails to load?</li>
<li>A person uses only keyboard navigation?</li>
<li>Network drops mid-request?</li>
</ul>
<p><strong>Production systems must handle failure gracefully</strong>. This lab hardens your prototype:</p>
<ol>
<li><strong>Validation</strong>: Server-side validation with accessible error messaging</li>
<li><strong>Parity</strong>: Identical functionality with/without JavaScript</li>
<li><strong>Testing</strong>: Repeatable verification scripts</li>
<li><strong>Documentation</strong>: Trade-offs, risks, mitigations</li>
</ol>
<p><strong>HCI Connection</strong>: Robust error handling is an <strong>inclusion imperative</strong>‚Äîvalidation errors disproportionately affect people with cognitive disabilities, screen reader users, and those with unreliable connectivity. WCAG 3.3 (Input Assistance) requires clear, accessible error identification.</p>
<hr />
<h2 id="learning-focus-5"><a class="header" href="#learning-focus-5">Learning Focus</a></h2>
<h3 id="lab-objectives-5"><a class="header" href="#lab-objectives-5">Lab Objectives</a></h3>
<p>By the end of this session, you will have:</p>
<ul>
<li>Validated form inputs with accessible error messaging</li>
<li>Ensured create/edit/delete work identically with and without JavaScript</li>
<li>Tested no-JS parity with repeatable scripts</li>
<li>Documented design trade-offs (progressive enhancement vs SPA) and mitigation strategies</li>
<li>Verified accessibility of error states with keyboard and screen reader</li>
</ul>
<h3 id="learning-outcomes-addressed-5"><a class="header" href="#learning-outcomes-addressed-5">Learning Outcomes Addressed</a></h3>
<p>This lab contributes to the following module Learning Outcomes (<a href="wk08/../references/learning-outcomes.html">full definitions</a>):</p>
<ul>
<li><strong>LO7</strong>: Analyse design constraints ‚Äî evidenced by no-JS parity testing + trade-offs doc</li>
<li><strong>LO9</strong>: Apply inclusive design ‚Äî evidenced by no-JS accessibility verification</li>
<li><strong>LO13</strong>: Integrate HCI with SE ‚Äî evidenced by routing patterns</li>
</ul>
<hr />
<h2 id="key-concepts-4"><a class="header" href="#key-concepts-4">Key Concepts</a></h2>
<h3 id="server-side-validation"><a class="header" href="#server-side-validation">Server-Side Validation</a></h3>
<blockquote>
<p><strong>Server-Side Validation</strong> [GLOSSARY]</p>
<p>Validation logic executed on the server (not browser). <strong>Always required</strong>, even with client-side validation.</p>
<p><strong>Why</strong>:</p>
<ul>
<li>Client-side can be bypassed (disabled JS, malicious requests)</li>
<li>Security boundary: never trust client input</li>
<li>Accessibility: server can return appropriate error responses for HTMX and no-JS paths</li>
</ul>
<p><strong>Pattern</strong>:</p>
<pre><code class="language-kotlin">val title = call.receiveParameters()["title"].orEmpty().trim()
if (title.isBlank()) {
    // Return error response (HTML for HTMX, redirect for no-JS)
}
</code></pre>
<p><strong>HCI Connection</strong>: Server validation enables <strong>progressive enhancement</strong>‚Äîsame validation logic serves both enhanced (HTMX) and baseline (HTML-only) experiences.</p>
<p>üîó <a href="https://cheatsheetseries.owasp.org/cheatsheets/Input_Validation_Cheat_Sheet.html">OWASP: Input Validation</a></p>
</blockquote>
<h3 id="post-redirect-get-prg-pattern"><a class="header" href="#post-redirect-get-prg-pattern">Post-Redirect-Get (PRG) Pattern</a></h3>
<blockquote>
<p><strong>Post-Redirect-Get (PRG)</strong> [GLOSSARY]</p>
<p>Respond to successful POST with redirect (303) instead of HTML. Prevents duplicate submissions on browser refresh.</p>
<p><strong>Flow</strong>:</p>
<ol>
<li>Person submits form ‚Üí <code>POST /tasks</code></li>
<li>Server validates, saves task</li>
<li>Server responds <code>303 See Other</code> ‚Üí <code>Location: /tasks</code></li>
<li>Browser follows redirect ‚Üí <code>GET /tasks</code></li>
<li>Person sees updated task list</li>
</ol>
<p><strong>Why</strong>:</p>
<ul>
<li>Refresh reloads <code>GET /tasks</code> (safe), not <code>POST /tasks</code> (duplicate)</li>
<li>Back button works predictably</li>
<li>URL reflects current state</li>
</ul>
<p><strong>Kotlin (Ktor)</strong>:</p>
<pre><code class="language-kotlin">post("/tasks") {
    // Validate and save...
    if (!call.isHtmx()) {
        call.respondRedirect("/tasks", permanent = false)
    }
}
</code></pre>
<p><strong>HCI Connection</strong>: PRG reduces cognitive load‚Äîback/forward/refresh do what people expect. Critical for accessibility (people often use back button to recover from errors).</p>
<p>üîó <a href="https://en.wikipedia.org/wiki/Post/Redirect/Get">Wikipedia: Post/Redirect/Get</a></p>
</blockquote>
<h3 id="dual-path-architecture"><a class="header" href="#dual-path-architecture">Dual-Path Architecture</a></h3>
<blockquote>
<p><strong>Dual-Path Architecture</strong> [GLOSSARY]</p>
<p>Single server route handles both HTMX (enhanced) and no-JS (baseline) requests with different responses.</p>
<p><strong>Detection</strong>:</p>
<pre><code class="language-kotlin">fun ApplicationCall.isHtmx(): Boolean =
    request.headers["HX-Request"]?.equals("true", ignoreCase = true) == true
</code></pre>
<p><strong>Response Strategy</strong>:</p>
<ul>
<li><strong>HTMX path</strong>: Return HTML fragment + OOB status</li>
<li><strong>No-JS path</strong>: Return full page or redirect (PRG)</li>
</ul>
<p><strong>Example</strong>:</p>
<pre><code class="language-kotlin">post("/tasks") {
    val title = call.receiveParameters()["title"].orEmpty().trim()
    if (title.isBlank()) {
        if (call.isHtmx()) {
            val status = """&lt;div id="status" hx-swap-oob="true"&gt;Title is required.&lt;/div&gt;"""
            return@post call.respondText(status, ContentType.Text.Html, HttpStatusCode.BadRequest)
        } else {
            return@post call.respondRedirect("/tasks?error=title")
        }
    }
    // Success path...
}
</code></pre>
<p><strong>HCI Connection</strong>: Dual-path ensures <strong>functional parity</strong> across technical contexts‚Äîequivalent experience regardless of JavaScript availability.</p>
<p>üîó <a href="https://hypermedia.systems/progressive-enhancement/">hypermedia.systems: Progressive Enhancement</a></p>
</blockquote>
<h3 id="accessible-error-identification"><a class="header" href="#accessible-error-identification">Accessible Error Identification</a></h3>
<blockquote>
<p><strong>Accessible Error Identification</strong> [GLOSSARY]</p>
<p>WCAG 3.3.1 (Level A): Errors must be identified in text and associated with the problematic input.</p>
<p><strong>Requirements</strong>:</p>
<ol>
<li>Error message in text (not just colour/icon)</li>
<li>Programmatic association (<code>aria-describedby</code> or <code>aria-errormessage</code>)</li>
<li>Focus management (keyboard users land on/near error)</li>
<li>Screen reader announcement (live region or summary)</li>
</ol>
<p><strong>Pattern (inline)</strong>:</p>
<pre><code class="language-html">&lt;label for="title"&gt;Task title&lt;/label&gt;
&lt;input id="title" name="title" aria-describedby="title-error" aria-invalid="true"&gt;
&lt;p id="title-error" role="alert"&gt;Title is required. Please enter at least one character.&lt;/p&gt;
</code></pre>
<p><strong>Pattern (summary)</strong>:</p>
<pre><code class="language-html">&lt;div role="alert" aria-live="assertive" tabindex="-1" id="error-summary"&gt;
  &lt;h2&gt;There is a problem&lt;/h2&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href="#title"&gt;Title is required&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/div&gt;
</code></pre>
<p><strong>HCI Connection</strong>: Clear error identification reduces cognitive load and is critical for screen reader users who can't see visual error states.</p>
<p>üîó <a href="https://www.w3.org/WAI/WCAG22/Understanding/error-identification.html">WCAG 3.3.1: Error Identification</a>
üîó <a href="https://design-system.service.gov.uk/components/error-message/">GOV.UK: Error Message Pattern</a></p>
</blockquote>
<h3 id="no-js-parity-testing"><a class="header" href="#no-js-parity-testing">No-JS Parity Testing</a></h3>
<blockquote>
<p><strong>No-JS Parity Testing</strong> [GLOSSARY]</p>
<p>Verifying that all functionality works identically with JavaScript disabled.</p>
<p><strong>Why</strong>:</p>
<ul>
<li>JavaScript may fail to load (network, CDN, blocker)</li>
<li>Some organisations disable JS for security</li>
<li>Testing baseline ensures server-first architecture is sound</li>
<li>Legal requirement in some jurisdictions (accessibility standards)</li>
</ul>
<p><strong>Methods</strong>:</p>
<ol>
<li><strong>Browser DevTools</strong>: Settings ‚Üí Disable JavaScript</li>
<li><strong>Command-line</strong>: <code>curl</code>, <code>wget</code>, <code>httpie</code></li>
<li><strong>Automated</strong>: Playwright with JS disabled, or server-side rendering tests</li>
</ol>
<p><strong>Checklist items</strong>:</p>
<ul>
<li>Forms submit and validate</li>
<li>Navigation works (links, pagination)</li>
<li>Error messages appear and are accessible</li>
<li>Success feedback is visible</li>
<li>Browser history behaves predictably</li>
</ul>
<p><strong>HCI Connection</strong>: No-JS parity is <strong>progressive enhancement</strong> verification‚Äîensures you're truly building server-first, not HTMX-first.</p>
<p>üîó <a href="https://www.gov.uk/service-manual/technology/using-progressive-enhancement">GOV.UK: Building a resilient frontend</a></p>
</blockquote>
<hr />
<h2 id="activity-a-harden-create-flow-35-min"><a class="header" href="#activity-a-harden-create-flow-35-min">Activity A: Harden Create Flow (35 min)</a></h2>
<p>Yesterday you built <code>POST /tasks</code> for the happy path. Now add validation and dual-path error handling.</p>
<h3 id="step-1-add-server-side-validation-10-min"><a class="header" href="#step-1-add-server-side-validation-10-min">Step 1: Add server-side validation (10 min)</a></h3>
<p><strong>Current code</strong> (Week 8 Lab 1):</p>
<pre><code class="language-kotlin">post("/tasks") {
    val title = call.receiveParameters()["title"].orEmpty().trim()
    val task = repo.add(title)
    if (call.isHtmx()) {
        val item = PebbleRender.render("tasks/_item.peb", mapOf("t" to task))
        val status = """&lt;div id="status" hx-swap-oob="true"&gt;Added "${task.title}".&lt;/div&gt;"""
        return@post call.respondText(item + status, ContentType.Text.Html)
    }
    call.respondRedirect("/tasks")
}
</code></pre>
<p><strong>Problem</strong>: No validation. Empty/whitespace titles are accepted.</p>
<p><strong>Add validation</strong>:</p>
<pre><code class="language-kotlin">post("/tasks") {
    val title = call.receiveParameters()["title"].orEmpty().trim()

    // Validation
    if (title.isBlank()) {
        if (call.isHtmx()) {
            val status = """&lt;div id="status" hx-swap-oob="true"&gt;Title is required.&lt;/div&gt;"""
            return@post call.respondText(status, ContentType.Text.Html, HttpStatusCode.BadRequest)
        } else {
            // No-JS: redirect with error query param
            return@post call.respondRedirect("/tasks?error=title")
        }
    }

    if (title.length &gt; 200) {
        if (call.isHtmx()) {
            val status = """&lt;div id="status" hx-swap-oob="true"&gt;Title too long (max 200 chars).&lt;/div&gt;"""
            return@post call.respondText(status, ContentType.Text.Html, HttpStatusCode.BadRequest)
        } else {
            return@post call.respondRedirect("/tasks?error=title&amp;msg=too_long")
        }
    }

    // Success path
    val task = repo.add(title)
    if (call.isHtmx()) {
        val item = PebbleRender.render("tasks/_item.peb", mapOf("t" to task))
        val status = """&lt;div id="status" hx-swap-oob="true"&gt;Added "${task.title}".&lt;/div&gt;"""
        return@post call.respondText(item + status, ContentType.Text.Html)
    }
    call.respondRedirect("/tasks")
}
</code></pre>
<p><strong>Key points</strong>:</p>
<ul>
<li>Always validate on server (never trust client)</li>
<li>Return <code>400 Bad Request</code> for HTMX errors (semantic HTTP)</li>
<li>Use query parameters for no-JS errors (preserve form state)</li>
</ul>
<h3 id="step-2-update-template-to-show-no-js-errors-15-min"><a class="header" href="#step-2-update-template-to-show-no-js-errors-15-min">Step 2: Update template to show no-JS errors (15 min)</a></h3>
<p><strong>Update <code>templates/tasks/index.peb</code></strong>:</p>
<p>Add error summary at top (before form):</p>
<pre><code class="language-twig">{% if error %}
&lt;div role="alert" aria-live="assertive" class="error-summary" id="error-summary" tabindex="-1"&gt;
  &lt;h2&gt;There is a problem&lt;/h2&gt;
  &lt;ul&gt;
    {% if error == "title" %}
    &lt;li&gt;&lt;a href="#title"&gt;{% if msg == "too_long" %}Title is too long (max 200 characters){% else %}Title is required{% endif %}&lt;/a&gt;&lt;/li&gt;
    {% endif %}
  &lt;/ul&gt;
&lt;/div&gt;
{% endif %}
</code></pre>
<p><strong>Update form input</strong>:</p>
<pre><code class="language-twig">&lt;label for="title"&gt;Task title&lt;/label&gt;
&lt;input id="title" name="title" type="text"
       {% if error == "title" %}aria-invalid="true" aria-describedby="title-error"{% endif %}
       required&gt;
{% if error == "title" %}
&lt;p id="title-error" class="error-message"&gt;
  {% if msg == "too_long" %}Title is too long (max 200 characters){% else %}Title is required{% endif %}
&lt;/p&gt;
{% endif %}
</code></pre>
<p><strong>Update GET /tasks route</strong> to pass error params:</p>
<pre><code class="language-kotlin">get("/tasks") {
    val error = call.request.queryParameters["error"]
    val msg = call.request.queryParameters["msg"]
    val q = call.request.queryParameters["q"].orEmpty()
    val page = call.request.queryParameters["page"]?.toIntOrNull() ?: 1
    val data = repo.search(q, page)

    val model = mapOf(
        "title" to "Tasks",
        "page" to data,
        "q" to q,
        "error" to error,
        "msg" to msg
    )

    val html = PebbleRender.render("tasks/index.peb", model)
    call.respondText(html, ContentType.Text.Html)
}
</code></pre>
<p><strong>Add CSS for error states</strong> (<code>static/style.css</code> or Pico CSS variables):</p>
<pre><code class="language-css">.error-summary {
  background: #fef7f7;
  border: 2px solid #d32f2f;
  padding: 1rem;
  margin-bottom: 1rem;
  border-radius: 4px;
}

.error-summary h2 {
  color: #d32f2f;
  font-size: 1.2rem;
  margin-top: 0;
}

.error-message {
  color: #d32f2f;
  font-size: 0.9rem;
  margin-top: 0.25rem;
}

input[aria-invalid="true"] {
  border-color: #d32f2f;
}
</code></pre>
<h3 id="step-3-test-both-paths-10-min"><a class="header" href="#step-3-test-both-paths-10-min">Step 3: Test both paths (10 min)</a></h3>
<p><strong>HTMX path</strong>:</p>
<ol>
<li>With JS enabled, submit empty form</li>
<li>Expect: Status message "Title is required." appears in <code>#status</code> live region</li>
<li>Form remains on page, input keeps focus</li>
<li>Try typing and submitting‚Äîshould succeed</li>
</ol>
<p><strong>No-JS path</strong>:</p>
<ol>
<li>Disable JS (DevTools ‚Üí Settings ‚Üí Disable JavaScript)</li>
<li>Submit empty form</li>
<li>Expect: Full page reload with error summary at top</li>
<li>Click error link ‚Üí focus moves to <code>#title</code> input</li>
<li>Fill form, submit ‚Üí redirect to <code>/tasks</code> with new task visible</li>
</ol>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Both paths show validation errors</li>
<li><input disabled="" type="checkbox"/>
HTMX errors use live region (announced by screen reader)</li>
<li><input disabled="" type="checkbox"/>
No-JS errors use summary with focusable link</li>
<li><input disabled="" type="checkbox"/>
Error messages are specific and actionable</li>
<li><input disabled="" type="checkbox"/>
Success path still works for both</li>
</ul>
<hr />
<h2 id="activity-b-harden-delete-flow-25-min"><a class="header" href="#activity-b-harden-delete-flow-25-min">Activity B: Harden Delete Flow (25 min)</a></h2>
<p>Delete is destructive‚Äîmust confirm and handle both JS/no-JS.</p>
<h3 id="step-1-add-confirmation-dialog-10-min"><a class="header" href="#step-1-add-confirmation-dialog-10-min">Step 1: Add confirmation dialog (10 min)</a></h3>
<p><strong>Update <code>templates/tasks/_item.peb</code></strong>:</p>
<p>Current button:</p>
<pre><code class="language-twig">&lt;button type="button" hx-delete="/tasks/{{ t.id }}" hx-target="#task-{{ t.id }}" hx-swap="outerHTML"&gt;
  Delete
&lt;/button&gt;
</code></pre>
<p><strong>Add confirmation + accessible label</strong>:</p>
<pre><code class="language-twig">&lt;button type="button"
        hx-delete="/tasks/{{ t.id }}"
        hx-target="#task-{{ t.id }}"
        hx-swap="outerHTML"
        hx-confirm="Delete the task '{{ t.title }}'?"
        aria-label="Delete task: {{ t.title }}"&gt;
  Delete
&lt;/button&gt;
</code></pre>
<p><strong>Why</strong>:</p>
<ul>
<li><code>hx-confirm</code> prompts before request (HTMX feature)</li>
<li><code>aria-label</code> provides context for screen readers (otherwise just "Delete Delete Delete..." in a list)</li>
</ul>
<h3 id="step-2-add-no-js-delete-support-15-min"><a class="header" href="#step-2-add-no-js-delete-support-15-min">Step 2: Add no-JS delete support (15 min)</a></h3>
<p><strong>Problem</strong>: <code>hx-delete</code> requires JavaScript. No-JS needs a form.</p>
<p><strong>Dual-path solution</strong>:</p>
<p>Replace button with <strong>form</strong> that works both ways:</p>
<pre><code class="language-twig">&lt;form action="/tasks/{{ t.id }}/delete" method="post" style="display: inline;"&gt;
  &lt;button type="submit"
          hx-delete="/tasks/{{ t.id }}"
          hx-target="#task-{{ t.id }}"
          hx-swap="outerHTML"
          hx-confirm="Delete the task '{{ t.title }}'?"
          aria-label="Delete task: {{ t.title }}"&gt;
    Delete
  &lt;/button&gt;
&lt;/form&gt;
</code></pre>
<p><strong>Explanation</strong>:</p>
<ul>
<li><strong>No-JS</strong>: Form submits <code>POST /tasks/{id}/delete</code></li>
<li><strong>HTMX</strong>: <code>hx-delete</code> intercepts, sends <code>DELETE /tasks/{id}</code> instead</li>
<li>Both paths work!</li>
</ul>
<p><strong>Update routes</strong> (<code>src/main/kotlin/routes/Tasks.kt</code>):</p>
<pre><code class="language-kotlin">// HTMX path (HTTP DELETE)
delete("/tasks/{id}") {
    val id = call.parameters["id"]?.toIntOrNull() ?: return@delete call.respond(HttpStatusCode.BadRequest)
    val task = repo.get(id)
    repo.delete(id)

    val status = """&lt;div id="status" hx-swap-oob="true"&gt;Deleted "${task?.title ?: "task"}".&lt;/div&gt;"""
    // Return empty string (outerHTML swap removes the &lt;li&gt;)
    call.respondText(status, ContentType.Text.Html)
}

// No-JS path (POST fallback)
post("/tasks/{id}/delete") {
    val id = call.parameters["id"]?.toIntOrNull() ?: return@post call.respond(HttpStatusCode.BadRequest)
    repo.delete(id)
    call.respondRedirect("/tasks")
}
</code></pre>
<p><strong>Trade-off to document</strong>: No-JS delete has no confirmation (browser POST doesn't prompt). Options:</p>
<ol>
<li>Accept the trade-off (document in constraints doc)</li>
<li>Add intermediate confirmation page (<code>GET /tasks/{id}/delete/confirm</code>)</li>
<li>Use client-side confirmation (but that requires JS...)</li>
</ol>
<p>For this lab, <strong>accept and document</strong> the trade-off.</p>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
HTMX delete shows confirmation dialog</li>
<li><input disabled="" type="checkbox"/>
After confirm, task disappears with status message</li>
<li><input disabled="" type="checkbox"/>
No-JS delete submits form and redirects</li>
<li><input disabled="" type="checkbox"/>
Screen reader announces "Deleted [title]" (HTMX) or reads updated page (no-JS)</li>
</ul>
<hr />
<h2 id="activity-c-script-no-js-verification-20-min"><a class="header" href="#activity-c-script-no-js-verification-20-min">Activity C: Script No-JS Verification (20 min)</a></h2>
<p>Create a repeatable test script so anyone (teammate, tutor, future you) can verify parity.</p>
<h3 id="step-1-create-verification-document-15-min"><a class="header" href="#step-1-create-verification-document-15-min">Step 1: Create verification document (15 min)</a></h3>
<p><strong>Create <code>wk08/lab-w8/scripts/nojs-check.md</code></strong>:</p>
<pre><code class="language-markdown"># No-JS Parity Verification Script ‚Äî Week 8

**Purpose**: Verify all task flows work identically with JavaScript disabled.

**Setup**:
1. Open Chrome DevTools ‚Üí Settings ‚Üí Preferences ‚Üí Disable JavaScript
2. Alternatively: Use Firefox ‚Üí Settings ‚Üí Privacy &amp; Security ‚Üí Permissions ‚Üí Uncheck JavaScript
3. Hard refresh (Ctrl+Shift+R / Cmd+Shift+R) to clear cached JS

---

## Test 1: Add Task (Happy Path)

**Steps**:
1. Navigate to `/tasks`
2. Enter title "No-JS test task"
3. Click "Add Task"

**Expected**:
- Full page reload (check Network tab: only HTML request)
- New task appears in list
- URL remains `/tasks` (PRG redirect)
- No error messages

**Evidence**: Screenshot of task list with new task visible.

**Result**: [ ] Pass  [ ] Fail

---

## Test 2: Add Task (Validation Error)

**Steps**:
1. Leave title field empty
2. Click "Add Task"

**Expected**:
- Full page reload
- URL shows `/tasks?error=title`
- Error summary appears at top: "There is a problem"
- Link to "#title" input
- Input has red border, error message below
- Focus can navigate to error link and then to input

**Evidence**: Screenshot of error summary and highlighted input.

**Result**: [ ] Pass  [ ] Fail

---

## Test 3: Filter Tasks

**Steps**:
1. Add tasks "Alpha", "Bravo", "Charlie"
2. Enter "ra" in filter box
3. Click "Apply" or submit form

**Expected**:
- Full page reload
- URL shows `/tasks?q=ra&amp;page=1`
- Only "Bravo" and "Charlie" visible (partial match)
- Result count updates: "Showing 2 tasks"

**Evidence**: Screenshot of filtered results with URL visible.

**Result**: [ ] Pass  [ ] Fail

---

## Test 4: Pagination

**Steps**:
1. Add 15 tasks (assuming page size = 10)
2. Navigate to page 2 using "Next" link

**Expected**:
- Full page reload
- URL shows `/tasks?page=2`
- Tasks 11-15 visible
- "Previous" link appears
- "Next" link disabled or hidden

**Evidence**: Screenshot of page 2 with navigation controls.

**Result**: [ ] Pass  [ ] Fail

---

## Test 5: Edit Task (inline)

**Steps**:
1. Click "Edit" on a task
2. Change title to "Updated via no-JS"
3. Submit

**Expected**:
- Full page reload (or inline form renders in server response)
- URL remains `/tasks` or shows task context
- Updated title visible
- No JavaScript errors (none should exist)

**Evidence**: Screenshot of updated task.

**Result**: [ ] Pass  [ ] Fail

---

## Test 6: Delete Task

**Steps**:
1. Click "Delete" button on a task

**Expected**:
- Form submits to `POST /tasks/{id}/delete`
- Full page reload
- Task removed from list
- URL redirects to `/tasks`
- **No confirmation** (documented trade-off)

**Evidence**: Screenshot of task list with item removed.

**Result**: [ ] Pass  [ ] Fail

---

## Test 7: Keyboard Navigation

**Steps**:
1. Tab through entire page (skip link ‚Üí form ‚Üí tasks ‚Üí pagination)
2. Ensure visible focus indicator at each stop
3. Activate "Add Task" with Enter
4. Navigate to error link with Tab, activate with Enter

**Expected**:
- Focus order matches visual order
- All interactive elements reachable
- Enter activates links/buttons
- Focus visible on all elements

**Evidence**: Notes on tab order, screenshot of visible focus.

**Result**: [ ] Pass  [ ] Fail

---

## Test 8: Browser History

**Steps**:
1. Start at `/tasks`
2. Add task (redirects to `/tasks`)
3. Filter to "test" (reloads to `/tasks?q=test`)
4. Go to page 2 (reloads to `/tasks?q=test&amp;page=2`)
5. Click browser Back button twice

**Expected**:
- Back #1 ‚Üí `/tasks?q=test&amp;page=1` (filtered, page 1)
- Back #2 ‚Üí `/tasks?q=test` (filtered, page 1 implicit)
- Back #3 ‚Üí `/tasks` (no filter)
- History stack matches user intent

**Evidence**: Notes on history behaviour.

**Result**: [ ] Pass  [ ] Fail

---

## Summary

**Passed**: _____ / 8
**Failed**: _____ / 8

**Issues found**: (log in `backlog/backlog.csv` with IDs wk8-XX)

**Notes**:
- Attach screenshots to `evidence/wk8/nojs-parity/`
- Update `docs/prototyping-constraints.md` with any new trade-offs discovered
- Re-run this script after any route or template changes

---

**Verified by**: __________
**Date**: __________
</code></pre>
<h3 id="step-2-run-the-script-5-min"><a class="header" href="#step-2-run-the-script-5-min">Step 2: Run the script (5 min)</a></h3>
<p>Execute Tests 1-6 yourself. Capture screenshots in <code>evidence/wk8/nojs-parity/</code>.</p>
<p>Log any failures in <code>backlog/backlog.csv</code>:</p>
<pre><code class="language-csv">id,week,priority,category,description,wcag,status
wk8-01,8,high,functionality,"Delete has no confirmation in no-JS mode",,open
wk8-02,8,medium,ux,"Filter form submits on Enter but no visual feedback",,open
</code></pre>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Script documents all major flows</li>
<li><input disabled="" type="checkbox"/>
Script is repeatable by someone else</li>
<li><input disabled="" type="checkbox"/>
Evidence captured in structured folder</li>
<li><input disabled="" type="checkbox"/>
Failures logged in backlog</li>
</ul>
<hr />
<h2 id="activity-d-document-trade-offs-and-constraints-15-min"><a class="header" href="#activity-d-document-trade-offs-and-constraints-15-min">Activity D: Document Trade-offs and Constraints (15 min)</a></h2>
<p>Update <code>wk08/docs/prototyping-constraints.md</code> with a section on <strong>dual-path architecture trade-offs</strong>.</p>
<p><strong>Create or extend the file</strong>:</p>
<pre><code class="language-markdown"># Prototyping Constraints and Trade-offs ‚Äî Week 8

## Dual-Path Architecture

### Design Decision
Every route handles both HTMX (enhanced) and no-JS (baseline) requests.

### Benefits
- **Inclusion**: Works for everyone regardless of JS availability
- **Resilience**: Graceful degradation if JS fails to load
- **Testing**: Baseline path proves server-first architecture is sound
- **Progressive enhancement**: Start with accessible baseline, enhance with HTMX

### Costs
- **Code complexity**: Each route has conditional logic (`if (call.isHtmx())`)
- **Response duplication**: Must generate both fragments and full pages
- **Testing burden**: Every feature requires two test paths
- **Performance**: No-JS path triggers full page reloads (slower perceived performance)

### Risks
- **Divergence**: HTMX and no-JS paths could drift if not tested regularly
- **Error handling**: Easy to forget no-JS error path during rapid development
- **Template maintenance**: Changes to page structure must update both full templates and fragments

### Mitigations
- ‚úÖ **Verification script**: `scripts/nojs-check.md` provides repeatable tests
- ‚úÖ **Shared partials**: `_item.peb`, `_list.peb` used by both paths (single source of truth)
- ‚úÖ **Backlog tracking**: Log parity issues immediately (see `backlog/backlog.csv`)
- ‚úÖ **Weekly retesting**: Run no-JS script before each commit
- ‚ö†Ô∏è **Automated tests** (future): Playwright tests with JS disabled

---

## Validation Strategy

### Design Decision
All validation on server. No client-side validation (no `&lt;input required&gt;` enforcement).

### Benefits
- **Security**: Client-side validation can be bypassed (view source, disable JS, curl)
- **Consistency**: Same validation rules for HTMX and no-JS paths
- **Accessibility**: Server returns appropriate error format for each context

### Costs
- **Latency**: Must wait for server round-trip to see validation errors
- **UX**: No instant feedback on typos (could add client-side hints later)

### Risks
- **Frustration**: People might repeatedly submit invalid forms before reading error
- **Network dependency**: Offline users can't get any feedback

### Mitigations
- ‚úÖ **Clear error messages**: Specific, actionable text ("Title is required" not "Invalid input")
- ‚úÖ **Accessible error identification**: WCAG 3.3.1 compliance (aria-invalid, aria-describedby, role=alert)
- ‚úÖ **Focus management**: Error link navigates directly to problematic field
- üîÆ **Future enhancement**: Add client-side hints (maxlength indicator, real-time char count) as progressive enhancement

---

## Delete Confirmation

### Design Decision
HTMX path uses `hx-confirm` (browser confirmation dialog). No-JS path has no confirmation.

### Benefits
- **HTMX**: Prevents accidental deletions for JS-enabled users
- **Implementation simplicity**: No intermediate confirmation page needed

### Costs
- **Inconsistency**: Different UX depending on JS availability
- **Accessibility**: Browser confirm dialogs are not customisable (can't improve copy)

### Risks
- **Accidental deletion**: No-JS users might delete tasks by mistake
- **Compliance**: Depending on context, irreversible actions might require confirmation (WCAG 2.2.1 Timing Adjustable, 3.3.4 Error Prevention)

### Mitigations
- ‚úÖ **Documentation**: Trade-off explicitly noted in constraints doc
- ‚úÖ **Backlog item**: Consider adding `/tasks/{id}/delete/confirm` page for no-JS (low priority)
- ‚ö†Ô∏è **User research** (Week 9): Test whether delete accidents occur in pilots
- üîÆ **Future option**: Add "Undo" feature (restore from soft-delete within 30s)

---

## State Management

### Design Decision
Use query parameters for filter and page state (`?q=search&amp;page=2`).

### Benefits
- **Shareable**: URL captures full state (can bookmark or share filtered view)
- **History**: Back/forward buttons work predictably
- **No-JS compatible**: Query params work without JavaScript
- **Stateless server**: No session state needed for pagination

### Costs
- **URL pollution**: Long query strings for complex filters
- **Encoding**: Must properly encode/decode special characters
- **Analytics**: Harder to track "unique pages" if many query variations exist

### Risks
- **Drift**: If fragment requests use different query params than full page, state can desync
- **Limits**: Some servers/proxies have URL length limits (~2000 chars)

### Mitigations
- ‚úÖ **Consistent param names**: Use `q` and `page` everywhere
- ‚úÖ **Validation**: Sanitise and bound page numbers (reject negative, exceeds max)
- ‚úÖ **Encoding**: Use `call.request.queryParameters` (Ktor handles encoding)
- üîÆ **Future**: If filters grow complex, consider POST with session state

---

## Performance Considerations

### Active Search Debounce
- **Decision**: 300ms debounce on `hx-trigger="keyup changed delay:300ms"`
- **Benefit**: Reduces server load (doesn't fire on every keystroke)
- **Cost**: 300ms perceived latency before filter applies
- **Mitigation**: Show loading indicator (`hx-indicator`) during request

### Page Size
- **Decision**: 10 tasks per page
- **Benefit**: Fast page loads, manageable scroll
- **Cost**: More pagination clicks for large datasets
- **Mitigation**: Could add page size selector (10/25/50) in future

### Fragment Size
- **Decision**: Return `_list + _pager + status` (~2-5KB) instead of full page (~15KB)
- **Benefit**: 70% bandwidth reduction on filter/pagination
- **Cost**: Requires dual-path logic
- **Measurement**: Use browser DevTools Network tab to verify savings

---

## Evidence and Testing

**Verification scripts**: `wk08/lab-w8/scripts/nojs-check.md`
**Evidence folder**: `evidence/wk8/nojs-parity/`
**Backlog references**: IDs `wk8-01` to `wk8-XX`

**Review schedule**: Re-run parity tests after:
- Any route changes
- Template structure updates
- Before Week 9 instrumentation (ensure baseline is solid)
- Before Gradescope Task 1 submission

**Ownership**: Entire team responsible for verifying parity. Pair on changes: one person tests HTMX, another tests no-JS.
</code></pre>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Document includes design decisions, benefits, costs, risks, mitigations</li>
<li><input disabled="" type="checkbox"/>
Each trade-off links to evidence or backlog items</li>
<li><input disabled="" type="checkbox"/>
Future improvements noted with üîÆ prefix</li>
<li><input disabled="" type="checkbox"/>
Clear ownership and review schedule</li>
</ul>
<hr />
<h2 id="activity-e-retest-with-assistive-technology-20-min"><a class="header" href="#activity-e-retest-with-assistive-technology-20-min">Activity E: Retest with Assistive Technology (20 min)</a></h2>
<p>Now that error handling and delete confirmation are in place, verify accessibility.</p>
<h3 id="step-1-keyboard-testing-5-min"><a class="header" href="#step-1-keyboard-testing-5-min">Step 1: Keyboard testing (5 min)</a></h3>
<p><strong>Test error recovery</strong>:</p>
<ol>
<li>Submit empty form</li>
<li>Tab to error summary link</li>
<li>Press Enter ‚Üí focus moves to <code>#title</code> input</li>
<li>Type title, press Enter to submit</li>
<li>Verify success message appears</li>
</ol>
<p><strong>Test delete</strong>:</p>
<ol>
<li>Tab to Delete button</li>
<li>Press Enter ‚Üí confirmation dialog appears</li>
<li>Press Enter again to confirm</li>
<li>Verify screen reader announces deletion status</li>
</ol>
<p>‚úã Check:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Error link is keyboard-accessible</li>
<li><input disabled="" type="checkbox"/>
Error link moves focus to input when activated</li>
<li><input disabled="" type="checkbox"/>
Delete button keyboard-accessible</li>
<li><input disabled="" type="checkbox"/>
Confirmation dialog keyboard-accessible</li>
</ul>
<h3 id="step-2-screen-reader-testing-10-min"><a class="header" href="#step-2-screen-reader-testing-10-min">Step 2: Screen reader testing (10 min)</a></h3>
<p><strong>Use NVDA (Windows) or Orca (Linux)</strong>:</p>
<p><strong>Test error announcement (HTMX)</strong>:</p>
<ol>
<li>Forms mode (<code>F</code> key in NVDA) ‚Üí navigate to Add Task form</li>
<li>Leave title empty, submit</li>
<li>Listen for status region update: "Title is required."</li>
<li>Verify SR announces the error (live region should trigger)</li>
</ol>
<p><strong>Test error summary (no-JS)</strong>:</p>
<ol>
<li>Disable JS, submit empty form</li>
<li>SR should read: "Alert. There is a problem. List with 1 item. Link. Title is required."</li>
<li>Activate link ‚Üí SR announces: "Edit. Title."</li>
</ol>
<p><strong>Test delete status</strong>:</p>
<ol>
<li>Navigate to Delete button</li>
<li>SR announces: "Delete task: [title]. Button."</li>
<li>Activate, confirm</li>
<li>SR announces: "Deleted [title]." (from live region)</li>
</ol>
<p>‚úã Check:</p>
<ul>
<li><input disabled="" type="checkbox"/>
HTMX errors announced via live region</li>
<li><input disabled="" type="checkbox"/>
No-JS errors announced via alert role</li>
<li><input disabled="" type="checkbox"/>
Delete button has accessible name</li>
<li><input disabled="" type="checkbox"/>
Delete confirmation accessible</li>
<li><input disabled="" type="checkbox"/>
Status messages announced</li>
</ul>
<h3 id="step-3-no-js-screen-reader-test-5-min"><a class="header" href="#step-3-no-js-screen-reader-test-5-min">Step 3: No-JS screen reader test (5 min)</a></h3>
<p>Disable JS and repeat error flow with screen reader:</p>
<ol>
<li>Submit empty form (no-JS)</li>
<li>SR reads error summary</li>
<li>Activate error link</li>
<li>Verify focus lands on input</li>
<li>Fill form, submit</li>
<li>Verify SR reads updated page</li>
</ol>
<p>‚úã Check:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Error summary is first thing announced after page load</li>
<li><input disabled="" type="checkbox"/>
Error links are navigable</li>
<li><input disabled="" type="checkbox"/>
Focus management works</li>
<li><input disabled="" type="checkbox"/>
Success state is clear</li>
</ul>
<p><strong>Document findings</strong>: Add any issues to <code>backlog/backlog.csv</code>. Capture screen reader output in <code>evidence/wk8/sr-testing.txt</code>.</p>
<hr />
<h2 id="commit--reflect-10-min"><a class="header" href="#commit--reflect-10-min">Commit &amp; Reflect (10 min)</a></h2>
<h3 id="commit-message"><a class="header" href="#commit-message">Commit message</a></h3>
<pre><code class="language-bash">git add src/main/kotlin/routes/Tasks.kt templates/tasks/index.peb templates/tasks/_item.peb wk08/lab-w8/scripts/nojs-check.md wk08/docs/prototyping-constraints.md evidence/wk8/ backlog/backlog.csv

git commit -m "$(cat &lt;&lt;'EOF'
wk8s2: dual-path validation, no-JS parity, trade-offs doc

- Added server-side validation for create (blank, max length)
- Dual-path error handling: HTMX (OOB status) vs no-JS (redirect + summary)
- Accessible error identification: aria-invalid, aria-describedby, role=alert
- Hardened delete flow: hx-confirm for HTMX, form fallback for no-JS
- Created repeatable no-JS verification script (scripts/nojs-check.md)
- Documented dual-path trade-offs, risks, mitigations (docs/prototyping-constraints.md)
- Tested with keyboard and screen reader (NVDA/Orca)
- Evidence captured in evidence/wk8/nojs-parity/

Trade-off accepted: No-JS delete has no confirmation (documented in constraints)
EOF
)"
</code></pre>
<h3 id="reflection-questions-3"><a class="header" href="#reflection-questions-3">Reflection questions</a></h3>
<p><strong>Answer in <code>wk08/reflection.md</code></strong>:</p>
<ol>
<li>
<p><strong>Dual-path complexity</strong>: Was it harder to maintain HTMX and no-JS paths than you expected? What helped keep them in sync?</p>
</li>
<li>
<p><strong>Error handling</strong>: How did accessible error identification change your approach? Did you discover any WCAG requirements you hadn't considered?</p>
</li>
<li>
<p><strong>Trade-offs</strong>: Which trade-off (e.g., no-JS delete confirmation) felt most significant? Would you design it differently with more time?</p>
</li>
<li>
<p><strong>Testing</strong>: How useful was the scripted no-JS verification? Will you use similar scripts in future projects?</p>
</li>
<li>
<p><strong>Inclusion impact</strong>: Who specifically benefits from the dual-path architecture? Think about connectivity, device age, organisational policies.</p>
</li>
<li>
<p><strong>Next steps</strong>: What would you improve before Week 9 instrumentation? Any technical debt to address?</p>
</li>
</ol>
<hr />
<h2 id="looking-ahead-week-9-evaluation"><a class="header" href="#looking-ahead-week-9-evaluation">Looking Ahead: Week 9 Evaluation</a></h2>
<p>Next week you'll instrument your prototype to capture metrics during peer pilots:</p>
<ul>
<li><strong>Task completion time</strong>: How long to add/edit/delete tasks</li>
<li><strong>Error rates</strong>: How often do validation errors occur</li>
<li><strong>No-JS performance</strong>: Compare HTMX vs no-JS completion times</li>
<li><strong>Confidence ratings</strong>: Post-task subjective feedback</li>
</ul>
<p><strong>Why this week matters</strong>: You can't evaluate a prototype that doesn't handle errors gracefully. Week 8 Lab 2 ensures your baseline is solid before adding instrumentation.</p>
<p><strong>Preparation</strong>:</p>
<ul>
<li>Verify all flows work (HTMX + no-JS)</li>
<li>Ensure backlog is up to date</li>
<li>Review <a href="wk08/../references/evaluation-metrics-quickref.html">Evaluation Metrics Quick Reference</a> to understand what data you'll collect</li>
</ul>
<hr />
<h2 id="further-reading--resources"><a class="header" href="#further-reading--resources">Further Reading &amp; Resources</a></h2>
<h3 id="essential"><a class="header" href="#essential">Essential</a></h3>
<ul>
<li><a href="https://www.w3.org/WAI/WCAG22/Understanding/input-assistance">WCAG 3.3: Input Assistance</a> ‚Äî Error identification and prevention</li>
<li><a href="https://design-system.service.gov.uk/components/error-message/">GOV.UK: Error Message Pattern</a> ‚Äî Accessible error design</li>
<li><a href="https://webaim.org/articles/formvalidation/">WebAIM: Form Validation</a> ‚Äî Screen reader considerations</li>
</ul>
<h3 id="htmx-patterns"><a class="header" href="#htmx-patterns">HTMX Patterns</a></h3>
<ul>
<li><a href="wk08/../references/htmx-pattern-cheatsheet.html">HTMX Pattern Cheatsheet</a> ‚Äî OOB status, confirmation, error handling</li>
<li><a href="https://htmx.org/examples/inline-validation/">HTMX: Validation Example</a> ‚Äî Alternative inline pattern</li>
<li><a href="https://htmx.org/attributes/hx-confirm/">HTMX: hx-confirm</a> ‚Äî Confirmation dialogs</li>
</ul>
<h3 id="testing"><a class="header" href="#testing">Testing</a></h3>
<ul>
<li><a href="wk08/../references/assistive-testing-checklist.html">Assistive Testing Checklist</a> ‚Äî Weekly testing checklist</li>
<li><a href="https://www.gov.uk/service-manual/technology/testing-with-assistive-technologies">GOV.UK: Testing with Assistive Technologies</a></li>
<li><a href="https://webaim.org/articles/screenreader_testing/">WebAIM: Screen Reader Testing</a></li>
</ul>
<h3 id="progressive-enhancement"><a class="header" href="#progressive-enhancement">Progressive Enhancement</a></h3>
<ul>
<li><a href="https://alistapart.com/article/understandingprogressiveenhancement/">A List Apart: Understanding Progressive Enhancement</a></li>
<li><a href="https://hypermedia.systems/progressive-enhancement/">hypermedia.systems: Progressive Enhancement</a></li>
<li><a href="https://www.gov.uk/service-manual/technology/using-progressive-enhancement">GOV.UK: Building a Resilient Frontend</a></li>
</ul>
<h3 id="academic"><a class="header" href="#academic">Academic</a></h3>
<ul>
<li><strong>Nielsen, J. (1994).</strong> <em>Heuristic evaluation.</em> In <em>Usability inspection methods</em> (pp. 25-62). ‚Äî Error prevention heuristic</li>
<li><strong>W3C (2023).</strong> <em>Web Content Accessibility Guidelines (WCAG) 2.2.</em> ‚Äî 3.3.1, 3.3.3, 4.1.3</li>
</ul>
<hr />
<h2 id="glossary-summary-3"><a class="header" href="#glossary-summary-3">Glossary Summary</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Term</th><th>One-line definition</th></tr></thead><tbody>
<tr><td><strong>Server-side validation</strong></td><td>Validation logic executed on the server; required for security and no-JS parity</td></tr>
<tr><td><strong>Post-Redirect-Get (PRG)</strong></td><td>Pattern where POST responds with redirect to prevent duplicate submissions</td></tr>
<tr><td><strong>Dual-path architecture</strong></td><td>Single route handles both HTMX (fragment) and no-JS (full page) requests</td></tr>
<tr><td><strong>Accessible error identification</strong></td><td>WCAG 3.3.1: Errors identified in text and programmatically associated with inputs</td></tr>
<tr><td><strong>No-JS parity testing</strong></td><td>Verifying all functionality works identically with JavaScript disabled</td></tr>
<tr><td><strong>Progressive enhancement</strong></td><td>Build accessible baseline first, then enhance with JavaScript as enhancement layer</td></tr>
<tr><td><strong>Live region</strong></td><td>ARIA region (<code>role="status"</code> or <code>aria-live</code>) that announces dynamic content changes</td></tr>
<tr><td><strong>hx-confirm</strong></td><td>HTMX attribute that shows browser confirmation dialog before sending request</td></tr>
<tr><td><strong>aria-invalid</strong></td><td>ARIA attribute indicating field contains validation error (<code>true</code>/<code>false</code>)</td></tr>
<tr><td><strong>aria-describedby</strong></td><td>ARIA attribute linking field to descriptive text (hint or error message)</td></tr>
</tbody></table>
</div>
<hr />
<p><strong>Lab complete!</strong> You now have a robust, accessible, dual-path prototype ready for evaluation instrumentation in Week 9.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="code-resources-2"><a class="header" href="#code-resources-2">Code Resources</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-9--lab-1--evaluation-plan-metrics-schema-and-instrumentation"><a class="header" href="#week-9--lab-1--evaluation-plan-metrics-schema-and-instrumentation">Week 9 ‚Ä¢ Lab 1 ‚Äî Evaluation Plan, Metrics Schema, and Instrumentation</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-9-orange" alt="Week 9" />
<img src="https://img.shields.io/badge/Lab-1-green" alt="Lab 1" />
<img src="https://img.shields.io/badge/Status-Draft-yellow" alt="Status" /></p>
<hr />
<h2 id="before-lab-required-reading-20-mins"><a class="header" href="#before-lab-required-reading-20-mins">Before Lab: Required Reading (20 mins)</a></h2>
<p>üìñ <strong>Essential</strong></p>
<ul>
<li>Pull Week 9 starter repo branch (baseline instrumentation stubs):</li>
<li><a href="https://www.nngroup.com/articles/usability-testing-101/">Nielsen Norman Group: How to Conduct a Usability Test</a></li>
<li><a href="https://www.w3.org/WAI/test-evaluate/metrics/">W3C: Measuring Accessibility</a></li>
<li>Review <a href="wk09/../references/evaluation-metrics-quickref.html">Evaluation Metrics Quick Reference</a></li>
<li>Review <a href="wk09/../references/consent-pii-faq.html">Consent and PII FAQ</a></li>
</ul>
<p>üìñ <strong>Contextual</strong>:</p>
<ul>
<li><a href="https://hypermedia.systems/">hypermedia.systems: Instrumentation</a> (optional chapter if available)</li>
<li><a href="https://www.gov.uk/service-manual/user-research/plan-a-research-session">GOV.UK: Planning user research</a></li>
</ul>
<hr />
<h2 id="introduction-from-prototype-to-evidence"><a class="header" href="#introduction-from-prototype-to-evidence">Introduction: From Prototype to Evidence</a></h2>
<p>Weeks 6‚Äì8 built a functional, accessible task list prototype. <strong>Now the critical question</strong>: Does it actually work for real people?</p>
<p><strong>HCI is empirical</strong>. We can't claim "this is usable" without evidence. This week you:</p>
<ol>
<li>Design an evaluation plan (what to measure, how)</li>
<li>Instrument your prototype to capture objective data</li>
<li>Prepare for peer pilots (Week 9 Lab 2)</li>
</ol>
<p><strong>Why this matters</strong>:</p>
<ul>
<li><strong>Gradescope Task 2</strong> requires quantitative data (completion times, error rates) + qualitative insights</li>
<li><strong>Week 10 redesign</strong> depends on identifying real bottlenecks (not guesses)</li>
<li><strong>Week 11 portfolio</strong> needs evidence chains: problem ‚Üí measurement ‚Üí fix ‚Üí verification</li>
<li><strong>Industry practice</strong>: Product decisions backed by data, not opinions</li>
</ul>
<p><strong>Ethical imperative</strong>: Evaluation must respect privacy. We follow <strong>low-risk peer study protocols</strong>‚Äîno recordings, no PII, informed consent, opt-out honoured.</p>
<hr />
<h2 id="learning-focus-6"><a class="header" href="#learning-focus-6">Learning Focus</a></h2>
<h3 id="lab-objectives-6"><a class="header" href="#lab-objectives-6">Lab Objectives</a></h3>
<blockquote>
<p><strong>Staff reference</strong>: Full instrumentation implementation lives in the <a href="wk09/../../resources/code-resources.html#week-9">solution repository</a>.
By the end of this session, you will have:</p>
</blockquote>
<ul>
<li>Designed task-based evaluation protocol with 3+ tasks and clear success criteria</li>
<li>Defined metrics (time-on-task, errors, SUS, confidence)</li>
<li>Written an ethical, repeatable protocol for peer pilots</li>
<li>Instrumented codebase to capture metrics (server-side logging)</li>
<li>Verified instrumentation captures data correctly for JS-on and JS-off paths</li>
</ul>
<h3 id="learning-outcomes-addressed-6"><a class="header" href="#learning-outcomes-addressed-6">Learning Outcomes Addressed</a></h3>
<p>This lab contributes to the following module Learning Outcomes (<a href="wk09/../references/learning-outcomes.html">full definitions</a>):</p>
<ul>
<li><strong>LO1</strong>: Differentiate people-centred methods ‚Äî evidenced by method selection rationale</li>
<li><strong>LO8</strong>: Design and execute evaluation ‚Äî evidenced by protocol + metrics + instrumentation</li>
<li><strong>LO13</strong>: Integrate HCI with SE ‚Äî evidenced by server-side instrumentation code</li>
</ul>
<hr />
<h2 id="key-concepts-5"><a class="header" href="#key-concepts-5">Key Concepts</a></h2>
<h3 id="usability-evaluation"><a class="header" href="#usability-evaluation">Usability Evaluation</a></h3>
<blockquote>
<p><strong>Usability Evaluation</strong> [GLOSSARY]</p>
<p>Systematic assessment of how well people can use a system to achieve goals. <strong>Formative</strong> (improve design during development) vs <strong>Summative</strong> (measure final quality).</p>
<p><strong>This module uses formative evaluation</strong>: gather data during development (Week 9), redesign (Week 10), verify improvements (Week 10/11).</p>
<p><strong>Components</strong>:</p>
<ul>
<li><strong>Tasks</strong>: Realistic scenarios with measurable outcomes</li>
<li><strong>Metrics</strong>: Objective (time, errors) + subjective (satisfaction, confidence)</li>
<li><strong>Participants</strong>: Peers, representative of target population</li>
<li><strong>Protocol</strong>: Step-by-step procedure ensuring consistency</li>
</ul>
<p><strong>HCI Connection</strong>: ISO 9241-11 defines usability as "extent to which a product can be used by specified users to achieve specified goals with effectiveness, efficiency, and satisfaction."</p>
<p><strong>Academic rigour</strong>: Evaluation design determines validity of findings. Poor tasks ‚Üí biased data ‚Üí wrong redesign decisions.</p>
<p>üîó <a href="https://www.iso.org/standard/63500.html">ISO 9241-11:2018 Usability</a>
üîó <a href="https://www.nngroup.com/articles/usability-101-introduction-to-usability/">Nielsen: Usability 101</a></p>
</blockquote>
<h3 id="task-based-evaluation"><a class="header" href="#task-based-evaluation">Task-Based Evaluation</a></h3>
<blockquote>
<p><strong>Task-Based Evaluation</strong> [GLOSSARY]</p>
<p>Participants complete realistic tasks while researchers observe and measure. Contrasts with feature walkthroughs or preference surveys.</p>
<p><strong>Task characteristics</strong>:</p>
<ul>
<li><strong>Realistic</strong>: Matches actual use context ("Find invoices" not "Use filter")</li>
<li><strong>Measurable</strong>: Clear success condition (found correct result, completed within time)</li>
<li><strong>Scoped</strong>: Completable in 2-5 minutes per task</li>
<li><strong>Representative</strong>: Covers critical flows identified in backlog</li>
</ul>
<p><strong>Example</strong>:</p>
<pre><code>Task T1: Search for Tasks
Scenario: "You need to find all tasks containing the word 'invoice'.
           Use the filter to show only matching tasks and count how many remain."
Success: Reports correct count within 2 minutes, no validation errors
</code></pre>
<p><strong>Why not feature-based?</strong> "Test the filter" is vague‚Äîparticipants don't know when they've succeeded. Task-based evaluation mirrors real-world goals.</p>
<p><strong>HCI Connection</strong>: Tasks ground evaluation in <strong>ecological validity</strong>‚Äîfindings generalize to real use.</p>
<p>üîó <a href="https://www.nngroup.com/articles/task-scenarios-usability-testing/">Nielsen: Task Scenarios for Usability Testing</a></p>
</blockquote>
<h3 id="objective-vs-subjective-metrics"><a class="header" href="#objective-vs-subjective-metrics">Objective vs Subjective Metrics</a></h3>
<blockquote>
<p><strong>Objective Metrics</strong> [GLOSSARY]</p>
<p>Measurable, observable data: completion time, error count, HTTP status codes. <strong>No interpretation required</strong>.</p>
<p><strong>Examples</strong>:</p>
<ul>
<li><strong>Time-on-task</strong>: Milliseconds from task start to completion (server-timed)</li>
<li><strong>Completion rate</strong>: Did participant achieve goal? (0 = fail, 1 = success)</li>
<li><strong>Error rate</strong>: <code>validation_error / (success + validation_error)</code></li>
<li><strong>Click/keystroke count</strong>: Efficiency measure (lower is better for same outcome)</li>
</ul>
<p><strong>Benefits</strong>: Repeatable, comparable across participants, statistically analysable
<strong>Limitations</strong>: Don't capture frustration, confusion, satisfaction</p>
<hr />
<p><strong>Subjective Metrics</strong> [GLOSSARY]</p>
<p>Self-reported feelings, perceptions, attitudes. Require interpretation.</p>
<p><strong>Examples</strong>:</p>
<ul>
<li><strong>Confidence rating</strong>: "How confident are you that you completed the task correctly?" (1‚Äì5 scale)</li>
<li><strong>Difficulty rating</strong>: "How difficult was this task?" (1‚Äì7 scale)</li>
<li><strong>Satisfaction</strong>: Post-session questionnaire (SUS, UMUX-Lite)</li>
<li><strong>Qualitative notes</strong>: Open-ended feedback ("I wasn't sure if it saved")</li>
</ul>
<p><strong>Benefits</strong>: Capture affective response, uncover unexpected issues
<strong>Limitations</strong>: Vary by person, memory biases, social desirability</p>
<p><strong>HCI Connection</strong>: Both required. ISO 9241-11 defines usability as <strong>effectiveness</strong> (objective: completion), <strong>efficiency</strong> (objective: time), and <strong>satisfaction</strong> (subjective).</p>
<p>üîó <a href="https://measuringux.com/">Measuring UX</a> ‚Äî Quantitative UX metrics handbook</p>
</blockquote>
<h3 id="server-side-instrumentation"><a class="header" href="#server-side-instrumentation">Server-Side Instrumentation</a></h3>
<blockquote>
<p><strong>Server-Side Instrumentation</strong> [GLOSSARY]</p>
<p>Logging application events at the server (not client). Data captured regardless of JavaScript availability.</p>
<p><strong>Why server-side?</strong></p>
<ul>
<li><strong>Reliability</strong>: Can't be blocked by ad blockers, disabled JS, browser crashes</li>
<li><strong>Privacy</strong>: No third-party analytics (e.g., Google Analytics) that track across sites</li>
<li><strong>Parity</strong>: Same data structure for HTMX and no-JS paths</li>
<li><strong>Control</strong>: You own the data (no GDPR concerns with external processors)</li>
</ul>
<p><strong>Pattern</strong>:</p>
<pre><code class="language-kotlin">post("/tasks/{id}/edit") {
    val start = System.currentTimeMillis()
    // ... validation, update logic ...
    val duration = System.currentTimeMillis() - start
    Logger.write(session, reqId, "T2_edit", "success", "", duration, 200, jsMode)
}
</code></pre>
<p><strong>Log structure</strong> (CSV):</p>
<pre><code class="language-csv">ts_iso,session_id,request_id,task_code,step,outcome,ms,http_status,js_mode
2025-10-13T14:23:01Z,abc123,r001,T1_filter,success,,1847,200,on
2025-10-13T14:23:15Z,abc123,r002,T2_edit,validation_error,blank_title,234,400,on
</code></pre>
<p><strong>HCI Connection</strong>: Instrumentation enables <strong>empirical HCI</strong>‚Äîquantify behaviour at scale (beyond 5 pilot peers).</p>
<p>üîó <a href="https://www.exp-platform.com/">Kohavi et al.: Online Controlled Experiments</a> ‚Äî Industry practice</p>
</blockquote>
<h3 id="privacy-by-design-revisited"><a class="header" href="#privacy-by-design-revisited">Privacy by Design (Revisited)</a></h3>
<blockquote>
<p><strong>Privacy by Design</strong> [GLOSSARY]</p>
<p>Build data minimization and privacy into system architecture (not bolt on later).</p>
<p><strong>Week 9 requirements</strong>:</p>
<ul>
<li><strong>Anonymous session IDs</strong>: Random tokens (e.g., <code>sid=X7kL9p</code>), not names/emails</li>
<li><strong>No PII in logs</strong>: No IP addresses, device fingerprints, real names</li>
<li><strong>Opt-out mechanism</strong>: Participants can request data deletion (delete rows matching session_id)</li>
<li><strong>Local storage</strong>: Logs stay in private repo, not synced to public forks</li>
<li><strong>Consent clarity</strong>: Protocol explains what's logged and why</li>
</ul>
<p><strong>Example ‚Äî BAD</strong>:</p>
<pre><code class="language-csv">timestamp,email,task,duration
2025-10-13,alice@leeds.ac.uk,T1,1800
</code></pre>
<p>‚ùå Email is PII, violates GDPR</p>
<p><strong>Example ‚Äî GOOD</strong>:</p>
<pre><code class="language-csv">ts_iso,session_id,task_code,ms,js_mode
2025-10-13T14:23:01Z,X7kL9p,T1,1800,on
</code></pre>
<p>‚úÖ Anonymous, minimal, fit-for-purpose</p>
<p><strong>UK context</strong>: Data Protection Act 2018 + UK GDPR require <strong>lawful basis</strong> for processing. Low-risk peer studies at universities typically use "legitimate interest" or "consent" basis. <strong>Must document</strong> in protocol.</p>
<p>üîó Review <a href="wk09/../references/consent-pii-faq.html">Consent and PII FAQ</a> for full guidance
üîó <a href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/accountability-and-governance/guide-to-accountability-and-governance/accountability-and-governance/data-protection-by-design-and-default/">ICO: Privacy by Design</a></p>
</blockquote>
<h3 id="median-vs-mean"><a class="header" href="#median-vs-mean">Median vs Mean</a></h3>
<blockquote>
<p><strong>Median</strong> [GLOSSARY]</p>
<p>Middle value in sorted dataset. <strong>Resistant to outliers</strong>.</p>
<p><strong>Example</strong>: Task completion times [10s, 12s, 15s, 18s, 120s]</p>
<ul>
<li>Mean = (10+12+15+18+120)/5 = <strong>35s</strong> ‚Üê skewed by 120s outlier</li>
<li>Median = <strong>15s</strong> ‚Üê middle value, represents typical experience</li>
</ul>
<p><strong>Why use median in HCI?</strong> Completion times often have outliers (someone distracted, interrupted, confused). Median tells you what most people experienced.</p>
<p><strong>Median Absolute Deviation (MAD)</strong>: Robust measure of spread.</p>
<pre><code>MAD = median(|x_i - median(x)|)
</code></pre>
<p>Less sensitive to outliers than standard deviation.</p>
<p><strong>HCI Connection</strong>: Report median + MAD for timing data. Use mean for Likert scales (confidence ratings) where outliers are meaningful.</p>
<p>üîó <a href="https://measuringux.com/median/">Measuring UX: Why Median?</a></p>
</blockquote>
<hr />
<h2 id="activity-a-define-evaluation-tasks-30-min"><a class="header" href="#activity-a-define-evaluation-tasks-30-min">Activity A: Define Evaluation Tasks (30 min)</a></h2>
<p><strong>Goal</strong>: Create 3-4 realistic tasks that cover critical flows and accessibility concerns.</p>
<h3 id="step-1-review-backlog-and-audit-findings-10-min"><a class="header" href="#step-1-review-backlog-and-audit-findings-10-min">Step 1: Review backlog and audit findings (10 min)</a></h3>
<p>Open <code>backlog/backlog.csv</code> and identify:</p>
<ul>
<li>High-priority features (create, edit, delete, filter)</li>
<li>Accessibility fixes from Week 7 (inline edit, status announcements)</li>
<li>No-JS parity concerns from Week 8</li>
</ul>
<p><strong>Example backlog snippet</strong>:</p>
<pre><code class="language-csv">id,week,priority,category,description,wcag,status
wk7-03,7,high,a11y,"Status messages not announced in no-JS mode",4.1.3,fixed
wk8-01,8,high,parity,"Delete confirmation missing in no-JS",3.3.4,open
wk8-05,8,medium,ux,"Filter doesn't show 'no results' message",3.3.1,open
</code></pre>
<p><strong>Identify task candidates</strong>:</p>
<ul>
<li><strong>T1</strong>: Filter tasks (tests search, result announcement, no-results state)</li>
<li><strong>T2</strong>: Edit task inline (tests validation, focus management, status announcement)</li>
<li><strong>T3</strong>: Add task (tests create flow, PRG, error handling)</li>
<li><strong>T4</strong>: Delete task (tests confirmation, dual-path, status)</li>
</ul>
<h3 id="step-2-write-task-scenarios-15-min"><a class="header" href="#step-2-write-task-scenarios-15-min">Step 2: Write task scenarios (15 min)</a></h3>
<p><strong>Create <code>wk09/lab-wk9/research/tasks.md</code></strong>:</p>
<pre><code class="language-markdown"># Evaluation Tasks ‚Äî Week 9

## Task T1: Filter Tasks

**Scenario**:
"You've been asked to find all tasks containing the word 'report'. Use the filter box to show only matching tasks, then count how many tasks remain."

**Setup**:
- Pre-populate task list with 10 tasks, 3 containing "report" in title
- Example: "Submit expense report", "Draft annual report", "Review quarterly report", plus 7 others

**Success criteria**:
- Participant uses filter box (types "report")
- Participant reports correct count (3 tasks)
- Completed within 2 minutes
- No validation errors

**Metrics**:
- Time from page load to stating count (ms)
- Completion (0 = fail, 1 = success)
- Validation errors (count)
- Confidence rating (1‚Äì5): "How confident are you that you found all matching tasks?"

**Accessibility checks**:
- Result count announced by screen reader?
- Keyboard-only completion possible?
- Works with JS disabled?

---

## Task T2: Edit Task Title

**Scenario**:
"The task 'Submit invoices' has a typo. Change it to 'Submit invoices by Friday' and save the change."

**Setup**:
- Task ID 5: "Submit invoices" (visible in list)
- Participant must click Edit, change text, save

**Success criteria**:
- Participant activates edit mode
- Participant updates title correctly
- Change persists after save
- Completed within 90 seconds
- No validation errors

**Metrics**:
- Time from click Edit to save confirmation (ms)
- Completion (0/1)
- Validation errors (e.g., blank title submitted by mistake)
- Confidence rating (1‚Äì5)

**Accessibility checks**:
- Status message "Updated [title]" announced?
- Focus remains on/near edited task?
- Works with keyboard only?
- Works with JS disabled?

---

## Task T3: Add New Task

**Scenario**:
"You need to remember to 'Call supplier about delivery'. Add this as a new task."

**Setup**:
- Empty or partially filled task list
- Form visible at top of page

**Success criteria**:
- Participant types exact title (or close match)
- Submits form
- New task appears in list
- Completed within 60 seconds

**Metrics**:
- Time from focus in input to confirmation (ms)
- Completion (0/1)
- Validation errors (if they submit blank by accident)
- Confidence rating (1‚Äì5)

**Accessibility checks**:
- Status message "Added [title]" announced?
- Form remains usable after error (if triggered)?
- Works with JS disabled (PRG)?

---

## Task T4: Delete Task

**Scenario**:
"The task 'Test entry' is no longer needed. Delete it from the list."

**Setup**:
- Task ID 8: "Test entry" (visible in list)

**Success criteria**:
- Participant clicks Delete button
- Confirms deletion (HTMX path) or submits form (no-JS)
- Task removed from list
- Completed within 45 seconds

**Metrics**:
- Time from click Delete to confirmation (ms)
- Completion (0/1)
- Confirmation dialog acknowledged (HTMX only)
- Confidence rating (1‚Äì5)

**Accessibility checks**:
- Delete button has accessible name ("Delete task: Test entry")?
- Status message "Deleted [title]" announced (HTMX)?
- Works with keyboard only?
- Works with JS disabled (no confirmation, but functions)?

---

## Task Order

**Recommended sequence**:
1. **Warm-up** (not timed): "Browse the task list and familiarize yourself with the interface."
2. T3 (Add) ‚Äî Low cognitive load, builds confidence
3. T1 (Filter) ‚Äî Medium complexity, tests search
4. T2 (Edit) ‚Äî Tests inline interaction, validation
5. T4 (Delete) ‚Äî Destructive action, tests confirmation
6. **Debrief** (qualitative): Open-ended questions

**Counterbalance** if testing multiple participants: alternate T1/T2 order to avoid learning effects.

---

## Notes for Facilitator

- **Do not help** unless participant is completely stuck (&gt;3 min). Note as "facilitated" in observations.
- **Think-aloud optional**: Ask participants to narrate their thoughts if comfortable. Don't force.
- **Screen reader users**: Allow extra time for navigation. Log SR-specific observations separately.
- **Keyboard-only**: Offer keyboard-only variant to 1-2 participants for comparison.
- **No-JS**: Test at least 1 participant with JS disabled to verify parity.

---

## Success Definitions

**Completion codes**:
- `1` = Task fully completed, correct outcome
- `0.5` = Partial completion (e.g., found filter but wrong count)
- `0` = Failed or abandoned

**Time bounds**:
- T1: 120s
- T2: 90s
- T3: 60s
- T4: 45s

If participant exceeds time, prompt: "Would you like to continue, or shall we move to the next task?"
</code></pre>
<h3 id="step-3-validate-tasks-with-team-5-min"><a class="header" href="#step-3-validate-tasks-with-team-5-min">Step 3: Validate tasks with team (5 min)</a></h3>
<p>Walk through each task with your pair/team:</p>
<ul>
<li>Are scenarios realistic?</li>
<li>Are success criteria measurable?</li>
<li>Do they cover your backlog priorities?</li>
<li>Can they be completed in allocated time?</li>
</ul>
<p>Adjust wording if anything is ambiguous.</p>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
3-4 tasks defined with clear scenarios</li>
<li><input disabled="" type="checkbox"/>
Success criteria objective and measurable</li>
<li><input disabled="" type="checkbox"/>
Metrics list includes objective + subjective</li>
<li><input disabled="" type="checkbox"/>
Accessibility checks specified per task</li>
<li><input disabled="" type="checkbox"/>
Task order and timing planned</li>
</ul>
<hr />
<h2 id="activity-b-define-metrics-and-measures-20-min"><a class="header" href="#activity-b-define-metrics-and-measures-20-min">Activity B: Define Metrics and Measures (20 min)</a></h2>
<p><strong>Goal</strong>: Specify exactly how you'll calculate each metric. Prevents ambiguity during analysis (Week 10).</p>
<p><strong>Create <code>wk09/lab-wk9/research/measures.md</code></strong>:</p>
<pre><code class="language-markdown"># Metrics Definitions ‚Äî Week 9

Reference: [Evaluation Metrics Quick Reference](../references/evaluation-metrics-quickref.md)

---

## Objective Metrics

### 1. Completion Rate

**Definition**: Proportion of participants who successfully complete the task.

**Calculation**:
</code></pre>
<p>Completion rate = (# successes) / (# attempts)</p>
<pre><code>
**Data source**: Manual observation + server logs (look for `step=success`)

**Reporting**: Percentage per task (e.g., "T1: 4/5 = 80%")

**Split by**:
- JS-on vs JS-off
- Keyboard-only vs mouse
- Screen reader vs visual

---

### 2. Time-on-Task

**Definition**: Duration from task start to completion or abandonment.

**Calculation**:
- **Server-timed**: `ms` column in metrics.csv (start to success event)
- **Backup**: Facilitator stopwatch (start when participant reads scenario, stop when they say "done")

**Reporting**:
- **Median** (primary): Middle value, resistant to outliers
- **MAD**: Median absolute deviation for spread
- **Range**: Min-max for context

**Example**:
</code></pre>
<p>T1 (Filter):
Median: 24s
MAD: 6s
Range: 12s‚Äì58s (n=5)</p>
<pre><code>
**Split by**: JS-on vs JS-off (expect no-JS to be slower due to full page reloads)

---

### 3. Error Rate

**Definition**: Proportion of attempts that trigger validation errors.

**Calculation**:
</code></pre>
<p>Error rate = (# validation_error events) / (# total attempts)</p>
<pre><code>
**Data source**: `data/metrics.csv` where `step=validation_error`

**Reporting**: Percentage per task + qualitative notes on error type

**Example**:
</code></pre>
<p>T3 (Add Task):
Error rate: 2/5 = 40%
Errors: 1√ó blank title, 1√ó exceeded max length</p>
<pre><code>
**HCI insight**: High error rates ‚Üí poor affordances, unclear constraints, or accessibility issues

---

### 4. Validation Error Count

**Definition**: Number of validation errors per participant per task.

**Calculation**: Count rows in `metrics.csv` with `step=validation_error` for given session + task

**Reporting**: Mean errors per task

**Example**:
</code></pre>
<p>T2 (Edit):
Mean errors per participant: 0.4 (2 errors across 5 participants)</p>
<pre><code>
---

## Subjective Metrics

### 5. Confidence Rating

**Definition**: Self-reported confidence that task was completed correctly.

**Scale**: 1 (not at all confident) ‚Üí 5 (very confident)

**Collection method**: Ask immediately after each task:
&gt; "On a scale of 1 to 5, how confident are you that you completed that task correctly?"

**Reporting**:
- Mean + standard deviation
- Distribution (how many rated 1, 2, 3, 4, 5)

**Example**:
</code></pre>
<p>T1 (Filter):
Mean confidence: 4.2 ¬± 0.8
Distribution: 0√ó1, 0√ó2, 1√ó3, 2√ó4, 2√ó5</p>
<pre><code>
**HCI insight**: Low confidence despite successful completion ‚Üí interface doesn't provide sufficient feedback

---

### 6. Difficulty Rating (optional)

**Definition**: Perceived difficulty of task.

**Scale**: 1 (very easy) ‚Üí 7 (very difficult)

**Collection method**: Post-task question:
&gt; "How difficult was that task?"

**Reporting**: Mean ¬± SD per task

---

### 7. Post-Session Satisfaction (optional)

**Method**: 2-question UMUX-Lite (if time permits):
1. "This system's capabilities meet my requirements" (1‚Äì7: strongly disagree ‚Üí strongly agree)
2. "This system is easy to use" (1‚Äì7: strongly disagree ‚Üí strongly agree)

**Calculation**: Average of the two responses (higher = better perceived usability)

**Reporting**: Mean score across all participants

**Note**: UMUX-Lite takes &lt;30 seconds, validated proxy for SUS (System Usability Scale)

---

## Qualitative Observations

### 8. Facilitator Notes

**Capture**:
- Hesitations ("Participant paused 10s before clicking filter")
- Verbalizations ("I'm not sure if it saved")
- Accessibility issues ("Screen reader didn't announce result count")
- Workarounds ("Used Ctrl+F instead of built-in filter")

**Format**: Timestamped notes in `pilot-notes.md`

**Analysis**: Thematic coding in Week 10 (group similar issues, link to backlog items)

---

## Accessibility-Specific Metrics

### 9. Keyboard-Only Completion

**Definition**: Can task be completed using only keyboard (no mouse)?

**Measurement**: Binary per task (yes/no)

**Reporting**: "T1: Keyboard-accessible ‚úÖ" or "T3: Tab order broken, failed ‚úó"

---

### 10. Screen Reader Announcement Quality

**Definition**: Are status messages and result counts announced appropriately?

**Measurement**: Qualitative note per task (announced / not announced / partial)

**Reporting**: List issues with WCAG references (4.1.3 Status Messages)

---

## Data Integrity Checks

Before analysis (Week 10):
- **Completeness**: All tasks have `session_id`, `task_code`, `step`
- **Plausibility**: Times within expected ranges (12s‚Äì120s for T1)
- **Consistency**: JS-mode matches observed condition
- **Outliers**: Flag times &gt;3√ó median for review

Document any anomalies in `wk09/lab-wk9/research/data-notes.md`

---

## Summary Table

| Metric | Type | Source | Calculation | Reporting |
|--------|------|--------|-------------|-----------|
| Completion rate | Objective | Manual + logs | successes / attempts | % per task |
| Time-on-task | Objective | Server logs | Median + MAD | Seconds |
| Error rate | Objective | Server logs | errors / attempts | % per task |
| Confidence | Subjective | Post-task question | Mean ¬± SD | 1‚Äì5 scale |
| Facilitator notes | Qualitative | Manual observation | Thematic coding | Categories |
| KB-only completion | Accessibility | Manual test | Binary | ‚úÖ/‚úó |
| SR announcements | Accessibility | SR observation | Qualitative | Issues list |
</code></pre>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Every metric has clear definition</li>
<li><input disabled="" type="checkbox"/>
Calculation methods specified</li>
<li><input disabled="" type="checkbox"/>
Data sources identified (logs vs manual)</li>
<li><input disabled="" type="checkbox"/>
Reporting format decided (median vs mean, etc.)</li>
<li><input disabled="" type="checkbox"/>
Accessibility metrics included</li>
</ul>
<hr />
<h2 id="activity-c-write-ethical-protocol-25-min"><a class="header" href="#activity-c-write-ethical-protocol-25-min">Activity C: Write Ethical Protocol (25 min)</a></h2>
<p><strong>Goal</strong>: Document the procedure so it's repeatable and ethical.</p>
<p><strong>Create <code>wk09/lab-wk9/research/protocol.md</code></strong>:</p>
<pre><code class="language-markdown"># Peer Pilot Protocol ‚Äî Week 9

## Study Overview

**Purpose**: Evaluate usability and accessibility of task list prototype with peer participants.

**Type**: Low-risk formative evaluation, peer-to-peer within module.

**Scope**:
- 5‚Äì6 participants (lab pairs)
- 4 tasks per session (~15‚Äì20 minutes)
- No audio/video recording
- No personally identifiable information collected

**Ethical approval**: Covered by module's blanket low-risk consent for peer learning activities (verified with module leader).

**Data retention**: Anonymised logs stored in private repo for academic year, deleted after module assessment complete.

---

## Participant Requirements

**Inclusion**:
- Enrolled in COMP2850
- Comfortable using web browsers
- Able to provide informed consent

**Exclusion**:
- None (module is inclusive by design)

**Accessibility accommodations**:
- Screen reader users: allowed extra time, SR-specific observations recorded separately
- Keyboard-only users: explicitly invited to test no-mouse variant
- No-JS users: at least one session conducted with JS disabled

---

## Consent Process

**Before starting** (read aloud):

&gt; "Thanks for agreeing to pilot our prototype. This is a quick usability test‚Äîabout 15 minutes. I'll ask you to complete 4 tasks while I observe and take notes. I'm testing the interface, not you, so there are no wrong answers.
&gt;
&gt; **What we're collecting**:
&gt; - Task completion times (from server logs)
&gt; - Whether you complete each task successfully
&gt; - Errors or validation issues
&gt; - Your confidence ratings after each task
&gt; - My notes on any hesitations or accessibility issues
&gt;
&gt; **What we're NOT collecting**:
&gt; - Your name, email, or student ID
&gt; - Screen recordings or audio
&gt; - Your device details beyond 'keyboard-only' or 'screen reader'
&gt;
&gt; I'll assign you a random session code (like `sid=X7kL9p`) which will appear in the logs. You can request that I delete all data linked to your session code at any time, even after today.
&gt;
&gt; **You can stop at any time**, no questions asked, and it won't affect your grade.
&gt;
&gt; Do you have any questions before we start?"

**Verbal consent**: "Are you happy to proceed?"

Record in `wk09/lab-wk9/research/consent-log.md`:
</code></pre>
<p>Date: 2025-10-15
Participant code: P1
Session ID: X7kL9p
Consent: Verbal consent given
Notes: Requested keyboard-only variant</p>
<pre><code>
**Opt-out path**: If participant requests deletion:
1. Open `data/metrics.csv`
2. Delete all rows where `session_id=X7kL9p`
3. Note in `consent-log.md`: "Data deleted on request [date]"

---

## Session Setup

**Environment**:
- Quiet space in lab (not open-plan area)
- Participant laptop/desktop with browser open to prototype
- Facilitator laptop for notes (don't share screen)

**Pre-pilot**:
1. Generate random session ID: `openssl rand -hex 3` ‚Üí e.g., `7a9f2c`
2. Set cookie in participant browser:
   ```javascript
   document.cookie = "sid=7a9f2c; path=/";
</code></pre>
<ol start="3">
<li>Navigate to <code>/tasks</code> (should be pre-populated with seed data)</li>
<li>Position facilitator to side (not behind‚Äîfeels invasive)</li>
</ol>
<p><strong>Materials</strong>:</p>
<ul>
<li>Printed task scenarios (or read aloud)</li>
<li><code>pilot-notes.md</code> template open</li>
<li>Stopwatch (backup timing)</li>
</ul>
<hr />
<h2 id="session-flow"><a class="header" href="#session-flow">Session Flow</a></h2>
<h3 id="0-introduction-2-min"><a class="header" href="#0-introduction-2-min">0. Introduction (2 min)</a></h3>
<ul>
<li>Consent process (see above)</li>
<li>Explain think-aloud (optional): "Feel free to say what you're thinking as you go, but no pressure."</li>
<li>Set expectations: "I won't help unless you're stuck for &gt;3 minutes."</li>
</ul>
<h3 id="1-warm-up-2-min-not-timed"><a class="header" href="#1-warm-up-2-min-not-timed">1. Warm-up (2 min, not timed)</a></h3>
<p>"Take a minute to browse the task list. Click around, get familiar. Let me know when you're ready to start the timed tasks."</p>
<h3 id="2-task-t3-add-task-60s-limit"><a class="header" href="#2-task-t3-add-task-60s-limit">2. Task T3: Add Task (60s limit)</a></h3>
<p><strong>Read scenario</strong>:
"You need to remember to 'Call supplier about delivery'. Add this as a new task."</p>
<p><strong>Start timing</strong> when participant focuses in input field (or reads scenario, if using stopwatch).</p>
<p><strong>Observe</strong>:</p>
<ul>
<li>Do they find the form immediately?</li>
<li>Do they submit blank by mistake?</li>
<li>Do they notice the success confirmation?</li>
</ul>
<p><strong>Post-task question</strong>:
"On a scale of 1 to 5, how confident are you that you completed that correctly?"</p>
<p><strong>Record</strong>: Completion (0/1), confidence, notes</p>
<hr />
<h3 id="3-task-t1-filter-tasks-120s-limit"><a class="header" href="#3-task-t1-filter-tasks-120s-limit">3. Task T1: Filter Tasks (120s limit)</a></h3>
<p><strong>Read scenario</strong>:
"You've been asked to find all tasks containing the word 'report'. Use the filter to show only matching tasks, then count how many remain."</p>
<p><strong>Observe</strong>:</p>
<ul>
<li>Do they find the filter box?</li>
<li>Do they read the result count?</li>
<li>Do they manually count items?</li>
</ul>
<p><strong>Post-task</strong>: Confidence rating</p>
<hr />
<h3 id="4-task-t2-edit-task-90s-limit"><a class="header" href="#4-task-t2-edit-task-90s-limit">4. Task T2: Edit Task (90s limit)</a></h3>
<p><strong>Read scenario</strong>:
"The task 'Submit invoices' has a typo. Change it to 'Submit invoices by Friday' and save the change."</p>
<p><strong>Observe</strong>:</p>
<ul>
<li>Do they find Edit button?</li>
<li>Do they trigger validation errors?</li>
<li>Do they check that change persisted?</li>
</ul>
<p><strong>Post-task</strong>: Confidence rating</p>
<hr />
<h3 id="5-task-t4-delete-task-45s-limit"><a class="header" href="#5-task-t4-delete-task-45s-limit">5. Task T4: Delete Task (45s limit)</a></h3>
<p><strong>Read scenario</strong>:
"The task 'Test entry' is no longer needed. Delete it."</p>
<p><strong>Observe</strong>:</p>
<ul>
<li>Confirmation dialog (HTMX) or direct submit (no-JS)?</li>
<li>Do they verify deletion succeeded?</li>
</ul>
<p><strong>Post-task</strong>: Confidence rating</p>
<hr />
<h3 id="6-debrief-3-min"><a class="header" href="#6-debrief-3-min">6. Debrief (3 min)</a></h3>
<p><strong>Ask</strong>:</p>
<ol>
<li>"Which task felt most difficult?"</li>
<li>"Did anything surprise you or not work as you expected?"</li>
<li>"Were there any points where you weren't sure if something had worked?"</li>
<li>"(For SR/keyboard users) Did you encounter any accessibility barriers?"</li>
</ol>
<p><strong>Record</strong> verbatim quotes in notes.</p>
<p><strong>Thank participant</strong>:
"That's really helpful, thank you. Your feedback will directly improve the prototype."</p>
<hr />
<h2 id="facilitator-guidelines"><a class="header" href="#facilitator-guidelines">Facilitator Guidelines</a></h2>
<p><strong>Do</strong>:</p>
<ul>
<li>Remain neutral (don't lead: "Did you see the status message?")</li>
<li>Take detailed notes (timestamps, direct quotes)</li>
<li>Allow silence (don't fill pauses)</li>
<li>Note when you intervene ("Prompted after 3min stuck")</li>
</ul>
<p><strong>Don't</strong>:</p>
<ul>
<li>Explain the interface before tasks</li>
<li>Show participant how to do something (defeats the test)</li>
<li>Justify design choices ("It's supposed to work like this...")</li>
<li>Make participant feel judged</li>
</ul>
<p><strong>If participant is completely stuck</strong>:</p>
<ul>
<li>Wait 3 minutes</li>
<li>Ask: "What are you looking for?" (diagnostic question)</li>
<li>If still stuck: "Let's move to the next task"</li>
<li><strong>Mark task as failed, note reason</strong></li>
</ul>
<hr />
<h2 id="data-recording"><a class="header" href="#data-recording">Data Recording</a></h2>
<p><strong>Automated</strong> (server logs ‚Üí <code>data/metrics.csv</code>):</p>
<ul>
<li>Timestamp, session_id, task_code, step (start/success/validation_error), ms, js_mode</li>
</ul>
<p><strong>Manual</strong> (<code>wk09/lab-wk9/research/pilot-notes.md</code>):</p>
<pre><code>Session: P1 (sid=7a9f2c)
Date: 2025-10-15
Variant: Keyboard-only, JS-on

| Time | Task | Observation | Tag |
|------|------|-------------|-----|
| 14:23 | T3 | Participant hesitated before submitting‚Äîunsure if 'Enter' or button | ux-feedback |
| 14:25 | T3 | Success message not noticed initially | a11y-status |
| 14:26 | T1 | Typed 'report' slowly, watching for instant results | ux-expectation |
| 14:27 | T1 | Screen reader announced "Showing 3 tasks" ‚úì | a11y-pass |
| 14:29 | T2 | Clicked Edit, validation error triggered (blank submission) | error-handling |
| 14:30 | T2 | Recovered from error, completed successfully | resilience |

Debrief notes:
- "I liked that the filter worked without clicking a button"
- "I wasn't sure the edit saved‚Äîmaybe make the message more obvious?"
- SR announced status messages correctly throughout
</code></pre>
<p><strong>Subjective ratings</strong> (post-task, in notes):</p>
<pre><code>Confidence ratings (1‚Äì5):
  T3: 5
  T1: 4
  T2: 3 ("not sure it saved")
  T4: 5
</code></pre>
<hr />
<h2 id="post-session"><a class="header" href="#post-session">Post-Session</a></h2>
<p><strong>Immediate</strong>:</p>
<ol>
<li>Save notes to <code>wk09/lab-wk9/research/pilots/P1-notes.md</code></li>
<li>Check <code>data/metrics.csv</code> for completeness (all tasks logged?)</li>
<li>Note any missing data or anomalies</li>
</ol>
<p><strong>After all pilots</strong>:</p>
<ol>
<li>Copy <code>data/metrics.csv</code> to <code>wk09/lab-wk9/submission/task1-draft/results.csv</code></li>
<li>Aggregate notes into themes (Week 10 lab)</li>
<li>Calculate medians, error rates (Week 10 lab)</li>
</ol>
<hr />
<h2 id="accessibility-variants"><a class="header" href="#accessibility-variants">Accessibility Variants</a></h2>
<h3 id="keyboard-only-session"><a class="header" href="#keyboard-only-session">Keyboard-Only Session</a></h3>
<ul>
<li>Participant uses Tab, Enter, Space only (no mouse)</li>
<li>Observe tab order, focus visibility, keyboard traps</li>
<li>Note any unreachable elements</li>
</ul>
<h3 id="screen-reader-session"><a class="header" href="#screen-reader-session">Screen Reader Session</a></h3>
<ul>
<li>Participant uses NVDA (Windows) or Orca (Linux)</li>
<li>Allow 2√ó time for navigation</li>
<li>Note announcements, label quality, live region behaviour</li>
<li>Capture SR output in notes (verbatim if possible)</li>
</ul>
<h3 id="no-js-session"><a class="header" href="#no-js-session">No-JS Session</a></h3>
<ul>
<li>Disable JavaScript in browser settings before starting</li>
<li>Expect slower times (full page reloads)</li>
<li>Verify all tasks still function (parity check)</li>
<li>Note any missing features or broken flows</li>
</ul>
<hr />
<h2 id="risk-mitigation"><a class="header" href="#risk-mitigation">Risk Mitigation</a></h2>
<p><strong>Participant distress</strong>: If participant becomes frustrated:</p>
<ul>
<li>Reassure: "This is really helpful feedback‚Äîit's the interface, not you."</li>
<li>Offer to skip task or stop session</li>
</ul>
<p><strong>Technical failure</strong>: If server crashes mid-session:</p>
<ul>
<li>Restart server, reload page</li>
<li>Resume from next task (don't re-run completed tasks)</li>
<li>Note incident in data-notes.md</li>
</ul>
<p><strong>Data loss</strong>: If logs don't record correctly:</p>
<ul>
<li>Use facilitator stopwatch times as backup</li>
<li>Note in data-notes.md: "Session P3: server logs incomplete, used manual timing"</li>
</ul>
<hr />
<h2 id="summary-checklist"><a class="header" href="#summary-checklist">Summary Checklist</a></h2>
<p>Before each session:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Generate session ID, set cookie</li>
<li><input disabled="" type="checkbox"/>
Seed task database with test data</li>
<li><input disabled="" type="checkbox"/>
Print or queue task scenarios</li>
<li><input disabled="" type="checkbox"/>
Open pilot-notes template</li>
<li><input disabled="" type="checkbox"/>
Confirm server running</li>
</ul>
<p>During session:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Read consent script, obtain verbal consent</li>
<li><input disabled="" type="checkbox"/>
Record session metadata (P code, sid, date)</li>
<li><input disabled="" type="checkbox"/>
Time each task (automated + backup)</li>
<li><input disabled="" type="checkbox"/>
Collect confidence ratings</li>
<li><input disabled="" type="checkbox"/>
Take qualitative notes with timestamps</li>
<li><input disabled="" type="checkbox"/>
Debrief open questions</li>
</ul>
<p>After session:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Save notes to pilots/ directory</li>
<li><input disabled="" type="checkbox"/>
Verify logs in metrics.csv</li>
<li><input disabled="" type="checkbox"/>
Thank participant, reiterate opt-out path</li>
</ul>
<pre><code>
‚úã **Stop and check**:
- [ ] Consent process clear and ethical
- [ ] Session flow structured and timed
- [ ] Facilitator guidelines prevent bias
- [ ] Data recording specified (auto + manual)
- [ ] Accessibility variants documented
- [ ] Risk mitigation addressed

---

## Activity D: Implement Instrumentation (35 min)

**Goal**: Add server-side logging to capture task events.

### Step 1: Define schema (5 min)

**Create `wk09/lab-wk9/instr/schema.md`**:

```markdown
# Metrics CSV Schema

**File**: `data/metrics.csv`

**Columns**:
```csv
ts_iso,session_id,request_id,task_code,step,outcome,ms,http_status,js_mode
</code></pre>
<div class="table-wrapper"><table><thead><tr><th>Column</th><th>Type</th><th>Description</th><th>Example</th></tr></thead><tbody>
<tr><td><code>ts_iso</code></td><td>ISO 8601 timestamp</td><td>Event timestamp (UTC)</td><td><code>2025-10-13T14:23:01.832Z</code></td></tr>
<tr><td><code>session_id</code></td><td>String (6-12 chars)</td><td>Anonymous session identifier</td><td><code>X7kL9p</code></td></tr>
<tr><td><code>request_id</code></td><td>String</td><td>Unique request identifier</td><td><code>r001</code></td></tr>
<tr><td><code>task_code</code></td><td>String</td><td>Task identifier from evaluation plan</td><td><code>T1_filter</code>, <code>T2_edit</code>, <code>T3_add</code>, <code>T4_delete</code></td></tr>
<tr><td><code>step</code></td><td>Enum</td><td>Event type</td><td><code>start</code>, <code>success</code>, <code>validation_error</code>, <code>fail</code>, <code>server_error</code></td></tr>
<tr><td><code>outcome</code></td><td>String</td><td>Specific outcome (for errors)</td><td><code>blank_title</code>, <code>max_length</code>, empty for success</td></tr>
<tr><td><code>ms</code></td><td>Integer</td><td>Duration in milliseconds (start to event)</td><td><code>1847</code></td></tr>
<tr><td><code>http_status</code></td><td>Integer</td><td>HTTP status code</td><td><code>200</code>, <code>400</code>, <code>500</code></td></tr>
<tr><td><code>js_mode</code></td><td>Enum</td><td>JavaScript availability</td><td><code>on</code> (HTMX), <code>off</code> (no-JS)</td></tr>
</tbody></table>
</div>
<p><strong>Example rows</strong>:</p>
<pre><code class="language-csv">ts_iso,session_id,request_id,task_code,step,outcome,ms,http_status,js_mode
2025-10-13T14:23:01.832Z,X7kL9p,r001,T1_filter,success,,1847,200,on
2025-10-13T14:25:12.123Z,X7kL9p,r002,T3_add,validation_error,blank_title,234,400,on
2025-10-13T14:26:03.456Z,X7kL9p,r003,T3_add,success,,567,200,on
2025-10-13T14:28:15.789Z,X7kL9p,r004,T2_edit,success,,1234,200,on
</code></pre>
<blockquote>
<p><strong>üìä Walkthrough: Understanding a User Session</strong></p>
<p>Let's trace <strong>one participant</strong> (session <code>X7kL9p</code>) through their tasks:</p>
<div class="table-wrapper"><table><thead><tr><th>#</th><th>Time</th><th>Task</th><th>What Happened</th><th><code>step</code></th><th><code>outcome</code></th><th><code>ms</code></th><th><code>js_mode</code></th></tr></thead><tbody>
<tr><td><strong>1</strong></td><td>14:23:01</td><td><strong>T1</strong> (Filter)</td><td>‚úÖ Successfully filtered tasks</td><td><code>success</code></td><td><em>(empty)</em></td><td>1847ms</td><td><code>on</code> (HTMX)</td></tr>
<tr><td><strong>2</strong></td><td>14:25:12</td><td><strong>T3</strong> (Add)</td><td>‚ùå Tried to add blank title</td><td><code>validation_error</code></td><td><code>blank_title</code></td><td>234ms</td><td><code>on</code> (HTMX)</td></tr>
<tr><td><strong>3</strong></td><td>14:26:03</td><td><strong>T3</strong> (Add)</td><td>‚úÖ Retry succeeded</td><td><code>success</code></td><td><em>(empty)</em></td><td>567ms</td><td><code>on</code> (HTMX)</td></tr>
<tr><td><strong>4</strong></td><td>14:28:15</td><td><strong>T2</strong> (Edit)</td><td>‚úÖ Edited task inline</td><td><code>success</code></td><td><em>(empty)</em></td><td>1234ms</td><td><code>on</code> (HTMX)</td></tr>
</tbody></table>
</div>
<p><strong>Observations</strong>:</p>
<ul>
<li><strong>Same <code>session_id</code></strong> (<code>X7kL9p</code>) = all rows belong to one participant's session</li>
<li><strong>Row 2 ‚Üí Row 3</strong>: User made a validation error (<code>blank_title</code>), then retried successfully</li>
<li><strong><code>ms</code> column</strong>: Row 2 is fast (234ms) because validation happens server-side instantly, Row 1 is slower (1847ms) because filtering queries the database</li>
<li><strong><code>js_mode=on</code></strong>: This participant had JavaScript enabled (HTMX working)</li>
<li><strong><code>outcome</code> empty for success</strong>: Only populated when <code>step=validation_error</code> or <code>fail</code></li>
</ul>
<p><strong>Why this matters for analysis</strong>:</p>
<ul>
<li><strong>Error rate</strong>: 1 error / 4 attempts = 25% error rate for this participant</li>
<li><strong>Recovery</strong>: User recovered from error (Row 3 success after Row 2 error) = good resilience</li>
<li><strong>Time-to-task</strong>: Row 1 took 1.8 seconds (reasonable for filter operation)</li>
<li><strong>Comparison</strong>: We can compare this participant's times against median times for T1, T2, T3, T4</li>
</ul>
</blockquote>
<p><strong>Notes</strong>:</p>
<ul>
<li><code>ms</code> measures server-side duration only (not client rendering)</li>
<li><code>start</code> events optional (can derive from first log per task per session)</li>
<li><code>outcome</code> field allows filtering by specific error types in analysis</li>
</ul>
<pre><code>
### Step 2: Create Logger helper (10 min)

**Create `src/main/kotlin/utils/Logger.kt`**:

```kotlin
package utils

import java.io.File
import java.time.Instant
import java.time.format.DateTimeFormatter

/**
 * Simple CSV logger for HCI evaluation metrics.
 * Thread-safe, appends to data/metrics.csv.
 *
 * Privacy: Ensure session_id is anonymous (no PII).
 */
object Logger {
    private val file = File("data/metrics.csv").apply {
        parentFile?.mkdirs()
        if (!exists()) {
            writeText("ts_iso,session_id,request_id,task_code,step,outcome,ms,http_status,js_mode\n")
        }
    }

    /**
     * Write a single log entry.
     *
     * @param session Anonymous session ID (e.g., from cookie)
     * @param req Request ID (unique per request, for tracing)
     * @param task Task code (T1_filter, T2_edit, etc.)
     * @param step Event type (start, success, validation_error, fail, server_error)
     * @param outcome Specific outcome for errors (blank_title, max_length, etc.)
     * @param ms Duration in milliseconds (0 if not applicable)
     * @param status HTTP status code (200, 400, 500, etc.)
     * @param js JavaScript mode ("on" or "off")
     */
    @Synchronized
    fun write(
        session: String,
        req: String,
        task: String,
        step: String,
        outcome: String,
        ms: Long,
        status: Int,
        js: String
    ) {
        val ts = DateTimeFormatter.ISO_INSTANT.format(Instant.now())
        file.appendText("$ts,$session,$req,$task,$step,$outcome,$ms,$status,$js\n")
    }

    /**
     * Convenience: log validation error with outcome.
     */
    fun validationError(
        session: String,
        req: String,
        task: String,
        outcome: String,
        ms: Long,
        js: String
    ) {
        write(session, req, task, "validation_error", outcome, ms, 400, js)
    }

    /**
     * Convenience: log success.
     */
    fun success(
        session: String,
        req: String,
        task: String,
        ms: Long,
        js: String
    ) {
        write(session, req, task, "success", "", ms, 200, js)
    }
}
</code></pre>
<h3 id="step-3-create-timing-helper-10-min"><a class="header" href="#step-3-create-timing-helper-10-min">Step 3: Create timing helper (10 min)</a></h3>
<p><strong>Create <code>src/main/kotlin/utils/Timing.kt</code></strong>:</p>
<pre><code class="language-kotlin">package utils

import io.ktor.server.application.*
import io.ktor.util.*

/**
 * Timing helper for HCI evaluation.
 * Wraps a block of code, measures duration, logs result.
 */

// AttributeKey for storing request start time
val RequestStartTimeKey = AttributeKey&lt;Long&gt;("RequestStartTime")

// AttributeKey for request ID
val RequestIdKey = AttributeKey&lt;String&gt;("RequestId")

/**
 * Extension function to time a block of code and log the result.
 *
 * Usage:
 *   call.timed(taskCode = "T1_filter", jsMode = "on") {
 *       // ... validation, processing, etc.
 *       // If validation fails, throw exception or return early
 *   }
 *
 * Automatically logs success or captures exceptions.
 */
suspend fun ApplicationCall.timed(
    taskCode: String,
    jsMode: String,
    block: suspend ApplicationCall.() -&gt; Unit
) {
    val start = System.currentTimeMillis()
    call.attributes.put(RequestStartTimeKey, start)

    val session = request.cookies["sid"] ?: "anon"
    val reqId = attributes.getOrNull(RequestIdKey) ?: newReqId()

    try {
        block()
        val duration = System.currentTimeMillis() - start
        Logger.success(session, reqId, taskCode, duration, jsMode)
    } catch (e: Exception) {
        val duration = System.currentTimeMillis() - start
        Logger.write(session, reqId, taskCode, "server_error", e.message ?: "unknown", duration, 500, jsMode)
        throw e
    }
}

/**
 * Helper to detect JavaScript mode from HTMX header.
 */
fun ApplicationCall.isHtmx(): Boolean =
    request.headers["HX-Request"]?.equals("true", ignoreCase = true) == true

fun ApplicationCall.jsMode(): String =
    if (isHtmx()) "on" else "off"

/**
 * Generate a unique request ID.
 */
private var requestCounter = 0
fun newReqId(): String = "r${String.format("%04d", ++requestCounter)}"
</code></pre>
<h3 id="step-4-instrument-routes-10-min"><a class="header" href="#step-4-instrument-routes-10-min">Step 4: Instrument routes (10 min)</a></h3>
<p><strong>Update <code>src/main/kotlin/routes/Tasks.kt</code></strong> (example for POST /tasks):</p>
<pre><code class="language-kotlin">post("/tasks") {
    val reqId = newReqId()
    call.attributes.put(RequestIdKey, reqId)

    val session = call.request.cookies["sid"] ?: "anon"
    val jsMode = call.jsMode()

    call.timed(taskCode = "T3_add", jsMode = jsMode) {
        val title = call.receiveParameters()["title"].orEmpty().trim()

        // Validation
        if (title.isBlank()) {
            Logger.validationError(session, reqId, "T3_add", "blank_title", 0, jsMode)
            if (call.isHtmx()) {
                val status = """&lt;div id="status" hx-swap-oob="true"&gt;Title is required.&lt;/div&gt;"""
                return@timed call.respondText(status, ContentType.Text.Html, HttpStatusCode.BadRequest)
            } else {
                return@timed call.respondRedirect("/tasks?error=title")
            }
        }

        if (title.length &gt; 200) {
            Logger.validationError(session, reqId, "T3_add", "max_length", 0, jsMode)
            if (call.isHtmx()) {
                val status = """&lt;div id="status" hx-swap-oob="true"&gt;Title too long (max 200 chars).&lt;/div&gt;"""
                return@timed call.respondText(status, ContentType.Text.Html, HttpStatusCode.BadRequest)
            } else {
                return@timed call.respondRedirect("/tasks?error=title&amp;msg=too_long")
            }
        }

        // Success path
        val task = repo.add(title)
        if (call.isHtmx()) {
            val item = PebbleRender.render("tasks/_item.peb", mapOf("t" to task))
            val status = """&lt;div id="status" hx-swap-oob="true"&gt;Added "${task.title}".&lt;/div&gt;"""
            call.respondText(item + status, ContentType.Text.Html)
        } else {
            call.respondRedirect("/tasks")
        }
    }
}
</code></pre>
<p><strong>Similarly instrument</strong>:</p>
<ul>
<li><code>GET /tasks</code> with <code>T1_filter</code> (if query param <code>q</code> present)</li>
<li><code>POST /tasks/{id}/edit</code> with <code>T2_edit</code></li>
<li><code>DELETE /tasks/{id}</code> with <code>T4_delete</code></li>
</ul>
<p><strong>Note on task codes</strong>:</p>
<ul>
<li><strong>Evaluation tasks</strong> (T1-T4): These match the tasks defined in your evaluation protocol
<ul>
<li><code>T1_filter</code> ‚Äî Search and filter the task list</li>
<li><code>T2_edit</code> ‚Äî Edit or toggle task status</li>
<li><code>T3_add</code> ‚Äî Add a new task</li>
<li><code>T4_delete</code> ‚Äî Delete a task</li>
</ul>
</li>
<li><strong>Baseline logging</strong> (optional): You may also log general interactions not part of the evaluation
<ul>
<li><code>T0_list</code> ‚Äî General task list view (not timed in evaluation)</li>
<li>Helps distinguish evaluation sessions from general usage analytics</li>
</ul>
</li>
</ul>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Logger.kt compiles and creates metrics.csv</li>
<li><input disabled="" type="checkbox"/>
Timing.kt provides timed{} helper</li>
<li><input disabled="" type="checkbox"/>
At least one route instrumented (POST /tasks)</li>
<li><input disabled="" type="checkbox"/>
Validation errors logged explicitly</li>
</ul>
<hr />
<h2 id="activity-e-dry-run-and-verify-10-min"><a class="header" href="#activity-e-dry-run-and-verify-10-min">Activity E: Dry Run and Verify (10 min)</a></h2>
<p><strong>Goal</strong>: Confirm instrumentation works before real pilots.</p>
<h3 id="step-1-set-session-cookie-2-min"><a class="header" href="#step-1-set-session-cookie-2-min">Step 1: Set session cookie (2 min)</a></h3>
<p>Open browser DevTools Console:</p>
<pre><code class="language-javascript">document.cookie = "sid=DRY_RUN_01; path=/";
</code></pre>
<p>Reload page.</p>
<h3 id="step-2-execute-test-tasks-5-min"><a class="header" href="#step-2-execute-test-tasks-5-min">Step 2: Execute test tasks (5 min)</a></h3>
<p><strong>With JS enabled</strong>:</p>
<ol>
<li>Add task "Test task 1" ‚Üí expect success row in metrics.csv</li>
<li>Submit empty form ‚Üí expect validation_error row</li>
<li>Add task "Test task 2" ‚Üí expect success row</li>
<li>Edit a task ‚Üí expect T2_edit success row</li>
<li>Delete a task ‚Üí expect T4_delete success row</li>
</ol>
<p><strong>Disable JS</strong>:
6. Repeat add task (empty + valid) ‚Üí expect js_mode=off rows</p>
<h3 id="step-3-inspect-logs-3-min"><a class="header" href="#step-3-inspect-logs-3-min">Step 3: Inspect logs (3 min)</a></h3>
<p>Open <code>data/metrics.csv</code>:</p>
<p><strong>Expected columns</strong>:</p>
<pre><code class="language-csv">ts_iso,session_id,request_id,task_code,step,outcome,ms,http_status,js_mode
</code></pre>
<p><strong>Example rows</strong>:</p>
<pre><code class="language-csv">2025-10-13T15:01:23.456Z,DRY_RUN_01,r001,T3_add,success,,567,200,on
2025-10-13T15:01:45.789Z,DRY_RUN_01,r002,T3_add,validation_error,blank_title,0,400,on
2025-10-13T15:02:10.123Z,DRY_RUN_01,r003,T3_add,success,,432,200,on
2025-10-13T15:03:00.000Z,DRY_RUN_01,r004,T2_edit,success,,1234,200,on
2025-10-13T15:03:30.500Z,DRY_RUN_01,r005,T4_delete,success,,210,200,on
2025-10-13T15:04:15.800Z,DRY_RUN_01,r006,T3_add,success,,3456,200,off
</code></pre>
<p><strong>Verify</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
All columns present</li>
<li><input disabled="" type="checkbox"/>
Timestamps in ISO 8601 format</li>
<li><input disabled="" type="checkbox"/>
session_id consistent (DRY_RUN_01)</li>
<li><input disabled="" type="checkbox"/>
task_code matches your task definitions</li>
<li><input disabled="" type="checkbox"/>
js_mode correct (on for HTMX, off for no-JS)</li>
<li><input disabled="" type="checkbox"/>
Durations plausible (not negative, not absurdly high)</li>
<li><input disabled="" type="checkbox"/>
HTTP status codes correct (200 success, 400 validation error)</li>
</ul>
<p><strong>If anything is wrong</strong>: Fix Logger.kt or route instrumentation, re-run dry run.</p>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Dry run completed with JS-on and JS-off paths</li>
<li><input disabled="" type="checkbox"/>
metrics.csv contains valid rows</li>
<li><input disabled="" type="checkbox"/>
Validation errors logged correctly</li>
<li><input disabled="" type="checkbox"/>
Durations captured</li>
</ul>
<hr />
<h2 id="commit--reflect-10-min-1"><a class="header" href="#commit--reflect-10-min-1">Commit &amp; Reflect (10 min)</a></h2>
<h3 id="commit-message-1"><a class="header" href="#commit-message-1">Commit message</a></h3>
<pre><code class="language-bash">git add wk09/lab-wk9/research wk09/lab-wk9/instr src/main/kotlin/utils data/metrics.csv

git commit -m "$(cat &lt;&lt;'EOF'
wk9s1: evaluation plan + server-side instrumentation

- Defined 4 tasks (filter, edit, add, delete) with success criteria
- Documented objective + subjective metrics (completion, time, errors, confidence)
- Created ethical protocol with consent process, session flow, accessibility variants
- Implemented Logger.kt (CSV appender, thread-safe)
- Implemented Timing.kt (timed{} helper, jsMode detection)
- Instrumented POST /tasks with T3_add logging + validation errors
- Dry-run verified: metrics.csv captures correct data for JS-on/off paths
- Scaffolded Task 1 draft evidence pack (eval-plan.md, protocol.md)

Ready for peer pilots in Week 9 Lab 2.


EOF
)"
</code></pre>
<h3 id="reflection-questions-4"><a class="header" href="#reflection-questions-4">Reflection questions</a></h3>
<p><strong>Answer in <code>wk09/reflection.md</code></strong>:</p>
<ol>
<li>
<p><strong>Metrics selection</strong>: Which metrics will be most useful for identifying usability issues? Why did you prioritize objective vs subjective data?</p>
</li>
<li>
<p><strong>Ethical considerations</strong>: What was most challenging about designing a privacy-respecting evaluation? How did you ensure no PII would be collected?</p>
</li>
<li>
<p><strong>Instrumentation trade-offs</strong>: Server-side logging has limitations (doesn't capture client-side rendering time, scroll behaviour, etc.). What gaps might this create in your analysis?</p>
</li>
<li>
<p><strong>Task design</strong>: How realistic are your task scenarios? Would they generalize to non-peer participants (e.g., non-CS students)?</p>
</li>
<li>
<p><strong>Accessibility</strong>: How confident are you that your instrumentation will capture accessibility issues (SR announcements, keyboard traps)? What additional data would you need?</p>
</li>
<li>
<p><strong>Pilot readiness</strong>: What could go wrong during Week 9 Lab 2 pilots? How have you mitigated those risks?</p>
</li>
</ol>
<hr />
<h2 id="looking-ahead-week-9-lab-2-pilots"><a class="header" href="#looking-ahead-week-9-lab-2-pilots">Looking Ahead: Week 9 Lab 2 Pilots</a></h2>
<p>Next session (Lab 2):</p>
<ul>
<li>Run 5‚Äì6 peer pilots using your protocol</li>
<li>Collect metrics.csv data + qualitative notes</li>
<li>Debrief participants</li>
<li>Prepare draft evidence pack for Task 1</li>
</ul>
<p><strong>Before Lab 2</strong>:</p>
<ul>
<li>Review protocol with your pair (practice reading consent script)</li>
<li>Test dry-run one more time (ensure nothing broke)</li>
<li>Prepare seed data (task list with known tasks for T1/T2/T4)</li>
<li>Print task scenarios or have them ready to read</li>
</ul>
<p><strong>Week 10</strong> will analyse this data‚Äîsolid planning now saves hours of confusion later.</p>
<hr />
<h2 id="further-reading--resources-1"><a class="header" href="#further-reading--resources-1">Further Reading &amp; Resources</a></h2>
<h3 id="essential-1"><a class="header" href="#essential-1">Essential</a></h3>
<ul>
<li><a href="wk09/../references/evaluation-metrics-quickref.html">Evaluation Metrics Quick Reference</a> ‚Äî Median, MAD, error rate calculations</li>
<li><a href="wk09/../references/consent-pii-faq.html">Consent and PII FAQ</a> ‚Äî PII definitions, opt-out procedures</li>
<li><a href="https://www.nngroup.com/articles/how-many-test-users/">Nielsen: How Many Test Users?</a> ‚Äî 5 users find 85% of issues</li>
</ul>
<h3 id="hci-evaluation-methods"><a class="header" href="#hci-evaluation-methods">HCI Evaluation Methods</a></h3>
<ul>
<li><strong>Lazar et al. (2017).</strong> <em>Research Methods in Human-Computer Interaction</em> (2nd ed.). Chapters 5-6 (usability testing, metrics)</li>
<li><a href="https://dl.acm.org/doi/book/10.5555/291224">SIGCHI: Usability Evaluation</a> ‚Äî Academic grounding</li>
<li><a href="https://measuringux.com/">Measuring UX</a> ‚Äî Practical guide to quantitative UX</li>
</ul>
<h3 id="ethics--privacy-1"><a class="header" href="#ethics--privacy-1">Ethics &amp; Privacy</a></h3>
<ul>
<li><a href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/accountability-and-governance/guide-to-accountability-and-governance/accountability-and-governance/data-protection-by-design-and-default/">ICO: Data Protection by Design</a></li>
<li><a href="https://www.bps.org.uk/guideline/code-ethics-and-conduct">BPS Code of Ethics</a> ‚Äî UK professional standards for research</li>
<li><a href="https://researchsupport.leeds.ac.uk/research-ethics/">University of Leeds Research Ethics</a> ‚Äî Institutional policy</li>
</ul>
<h3 id="instrumentation"><a class="header" href="#instrumentation">Instrumentation</a></h3>
<ul>
<li><a href="https://www.exp-platform.com/">Kohavi et al.: Online Controlled Experiments</a> ‚Äî A/B testing at scale (industry context)</li>
<li><a href="https://developers.google.com/analytics/devguides/collection/protocol/ga4">Google Analytics 4: Measurement Protocol</a> ‚Äî Example of event-based logging (we avoid third-party but shows patterns)</li>
</ul>
<h3 id="accessibility-evaluation"><a class="header" href="#accessibility-evaluation">Accessibility Evaluation</a></h3>
<ul>
<li><a href="https://webaim.org/articles/evaluatingcognitive/">WebAIM: Evaluating Accessibility</a> ‚Äî Cognitive disabilities focus</li>
<li><a href="https://www.w3.org/WAI/test-evaluate/involving-users/">W3C: Involving Users in Evaluating Web Accessibility</a></li>
</ul>
<hr />
<h2 id="glossary-summary-4"><a class="header" href="#glossary-summary-4">Glossary Summary</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Term</th><th>One-line definition</th></tr></thead><tbody>
<tr><td><strong>Usability evaluation</strong></td><td>Systematic assessment of how well people can use a system to achieve goals</td></tr>
<tr><td><strong>Task-based evaluation</strong></td><td>Participants complete realistic scenarios while researchers observe and measure</td></tr>
<tr><td><strong>Objective metrics</strong></td><td>Measurable, observable data (time, errors, completion) without interpretation</td></tr>
<tr><td><strong>Subjective metrics</strong></td><td>Self-reported feelings, perceptions, attitudes (confidence, satisfaction)</td></tr>
<tr><td><strong>Server-side instrumentation</strong></td><td>Logging events at the server; reliable, privacy-respecting, works regardless of JS</td></tr>
<tr><td><strong>Privacy by Design</strong></td><td>Build data minimization and privacy into system architecture from the start</td></tr>
<tr><td><strong>Median</strong></td><td>Middle value in sorted dataset; resistant to outliers</td></tr>
<tr><td><strong>MAD</strong></td><td>Median Absolute Deviation; robust measure of spread</td></tr>
<tr><td><strong>Informed consent</strong></td><td>Participants understand what data is collected, how it's used, and can opt out</td></tr>
<tr><td><strong>Low-risk study</strong></td><td>Peer-to-peer evaluation with minimal data collection, no vulnerable groups</td></tr>
</tbody></table>
</div>
<hr />
<p><strong>Lab complete!</strong> You have a comprehensive evaluation plan, ethical protocol, and working instrumentation. Week 9 Lab 2 will collect real data from peer pilots.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-9--lab-2--peer-pilots-debrief-and-task-1-draft-pack"><a class="header" href="#week-9--lab-2--peer-pilots-debrief-and-task-1-draft-pack">Week 9 ‚Ä¢ Lab 2 ‚Äî Peer Pilots, Debrief, and Task 1 Draft Pack</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-9-orange" alt="Week 9" />
<img src="https://img.shields.io/badge/Lab-2-green" alt="Lab 2" />
<img src="https://img.shields.io/badge/Status-Draft-yellow" alt="Status" /></p>
<hr />
<h2 id="before-lab-required-reading-10-mins"><a class="header" href="#before-lab-required-reading-10-mins">Before Lab: Required Reading (10 mins)</a></h2>
<p>üìñ <strong>Essential</strong>:</p>
<ul>
<li>Push/log Week 9 starter repo instrumentation before pilots</li>
<li>Review your Week 9 Lab 1 protocol (<code>wk09/lab-wk9/research/protocol.md</code>)</li>
<li>Review <code>references/consent-pii-faq.md</code></li>
<li><a href="https://www.nngroup.com/articles/how-many-test-users/">Nielsen: How Many Test Users in Usability Studies?</a></li>
</ul>
<p>üìñ <strong>Quick reference</strong>:</p>
<ul>
<li><a href="wk09/../references/evaluation-metrics-quickref.html">Evaluation Metrics Quick Reference</a></li>
<li><a href="wk09/../references/assistive-testing-checklist.html">Assistive Testing Checklist</a></li>
<li><a href="wk09/../references/screenshot-guide.html">Screenshot Evidence Guide</a></li>
</ul>
<hr />
<h2 id="introduction-from-plan-to-data"><a class="header" href="#introduction-from-plan-to-data">Introduction: From Plan to Data</a></h2>
<p>Week 9 Lab 1 built the evaluation infrastructure. <strong>Today you execute</strong>.</p>
<p>Running peer pilots is <strong>the most critical empirical HCI activity</strong> in this module:</p>
<ul>
<li><strong>Data collection</strong>: Objective metrics (time, errors, completion) + subjective (confidence, satisfaction)</li>
<li><strong>Qualitative insights</strong>: Observe real struggles, accessibility barriers, unexpected behaviours</li>
<li><strong>Evidence generation</strong>: Logs, notes, screenshots for Gradescope Task 1 and Week 11 portfolio</li>
</ul>
<p><strong>Why this matters</strong>:</p>
<ul>
<li>Week 10 redesign <strong>depends on</strong> identifying real problems (not assumed ones)</li>
<li>Task 1 grade depends on evidence quality (traceability from raw data ‚Üí findings ‚Üí mitigations)</li>
<li>Professional practice: Decisions backed by data, not opinions</li>
</ul>
<p><strong>Ethical imperative</strong>: Participants are peers, not research subjects. Treat them respectfully, honour consent, protect privacy.</p>
<hr />
<h2 id="learning-focus-7"><a class="header" href="#learning-focus-7">Learning Focus</a></h2>
<h3 id="lab-objectives-7"><a class="header" href="#lab-objectives-7">Lab Objectives</a></h3>
<blockquote>
<p><strong>Staff reference</strong>: Sample data + completed pilot pack available in the <a href="wk09/../../resources/code-resources.html#week-9">solution repository</a>.
By the end of this session, you will have:</p>
</blockquote>
<ul>
<li>Conducted 4 peer pilots following ethical protocol</li>
<li>Collected quantitative data (time-on-task, errors, SUS) and qualitative observations</li>
<li>Taken observer notes (quotes, errors, time-on-task)</li>
<li>Debriefed with participants and synthesised findings</li>
<li>Documented findings with evidence chains (raw data ‚Üí issue ‚Üí backlog item)</li>
<li>Assembled draft Task 1 evidence pack</li>
</ul>
<h3 id="learning-outcomes-addressed-7"><a class="header" href="#learning-outcomes-addressed-7">Learning Outcomes Addressed</a></h3>
<p>This lab contributes to the following module Learning Outcomes (<a href="wk09/../references/learning-outcomes.html">full definitions</a>):</p>
<ul>
<li><strong>LO6</strong>: Apply iterative design ‚Äî evidenced by pilot data ‚Üí findings synthesis</li>
<li><strong>LO8</strong>: Design and execute evaluation ‚Äî evidenced by 4 pilot sessions + data</li>
<li><strong>LO11</strong>: Collaborate in teams ‚Äî evidenced by peer pilot facilitation + observer role</li>
<li><strong>LO12</strong>: Demonstrate professionalism ‚Äî evidenced by consent adherence + respectful facilitation</li>
</ul>
<hr />
<h2 id="key-concepts-6"><a class="header" href="#key-concepts-6">Key Concepts</a></h2>
<h3 id="pilot-study"><a class="header" href="#pilot-study">Pilot Study</a></h3>
<blockquote>
<p><strong>Pilot Study</strong> [GLOSSARY]</p>
<p>Small-scale preliminary study to test evaluation protocol and gather initial data. <strong>Formative</strong> (improve design) vs <strong>Summative</strong> (final quality assessment).</p>
<p><strong>This module uses formative pilots</strong>: Identify issues to fix in Week 10, not measure final quality.</p>
<p><strong>Characteristics</strong>:</p>
<ul>
<li>Small sample (5‚Äì10 participants typical for qualitative insights)</li>
<li>Controlled tasks (defined in Week 9 Lab 1)</li>
<li>Mixed methods (quantitative metrics + qualitative observation)</li>
<li>Iterative (findings inform redesign)</li>
</ul>
<p><strong>Nielsen's 5-user rule</strong>: 5 participants find ~85% of usability issues. Diminishing returns after that for formative testing.</p>
<p><strong>HCI Connection</strong>: Empirical HCI requires <strong>ecological validity</strong>‚Äîtest with real people doing realistic tasks, not just hypothetical analysis.</p>
<p>üîó <a href="https://www.nngroup.com/articles/why-you-only-need-to-test-with-5-users/">Nielsen: Why You Only Need to Test with 5 Users</a></p>
</blockquote>
<h3 id="qualitative-vs-quantitative-data"><a class="header" href="#qualitative-vs-quantitative-data">Qualitative vs Quantitative Data</a></h3>
<blockquote>
<p><strong>Quantitative Data</strong> [GLOSSARY]</p>
<p>Numerical measurements: times, counts, percentages. <strong>Objective</strong>, statistically analysable.</p>
<p><strong>Examples from this module</strong>:</p>
<ul>
<li>Task completion time: Median 24s (MAD 6s)</li>
<li>Error rate: 2/5 = 40%</li>
<li>Completion rate: 4/5 = 80%</li>
</ul>
<p><strong>Strengths</strong>: Comparable, repeatable, supports statistical tests
<strong>Limitations</strong>: Doesn't explain "why"‚Äîneed qualitative data to interpret</p>
<hr />
<p><strong>Qualitative Data</strong> [GLOSSARY]</p>
<p>Non-numerical observations: quotes, behaviours, patterns. <strong>Subjective</strong>, interpretive.</p>
<p><strong>Examples from this module</strong>:</p>
<ul>
<li>"Participant paused 10s, said 'I'm not sure if it saved'"</li>
<li>"Screen reader did not announce filter result count"</li>
<li>"Participant used Ctrl+F instead of built-in filter"</li>
</ul>
<p><strong>Strengths</strong>: Reveals "why" issues occur, uncovers unexpected problems
<strong>Limitations</strong>: Varies by participant, researcher bias, harder to generalize</p>
<p><strong>HCI Connection</strong>: Best practice = <strong>mixed methods</strong> (both quant + qual). Numbers show <em>what</em> happened, observations show <em>why</em>.</p>
<p>üîó <a href="https://dl.acm.org/doi/book/10.5555/2737875">Lazar et al.: Research Methods in HCI</a> ‚Äî Chapter 9</p>
</blockquote>
<h3 id="think-aloud-protocol"><a class="header" href="#think-aloud-protocol">Think-Aloud Protocol</a></h3>
<blockquote>
<p><strong>Think-Aloud Protocol</strong> [GLOSSARY]</p>
<p>Participants verbalize their thoughts while completing tasks. Reveals cognitive process, confusion points, expectations.</p>
<p><strong>Types</strong>:</p>
<ul>
<li><strong>Concurrent</strong>: Talk while doing task (can be distracting, slower)</li>
<li><strong>Retrospective</strong>: Explain after completing (less disruptive but memory decay)</li>
</ul>
<p><strong>For this module</strong>: <strong>Optional concurrent</strong> (invite, don't force). Some participants find it natural, others find it intrusive.</p>
<p><strong>Example quote captured</strong>:</p>
<blockquote>
<p>"I'm looking for a filter... is this the search box? I'll try typing here."</p>
</blockquote>
<p><strong>HCI Connection</strong>: Think-aloud reveals <strong>mental models</strong>‚Äîhow people understand the interface vs how it actually works.</p>
<p><strong>Accessibility note</strong>: Think-aloud can be difficult for screen reader users (talking competes with SR audio). Allow silence.</p>
<p>üîó <a href="https://www.nngroup.com/articles/thinking-aloud-the-1-usability-tool/">Nielsen: Thinking Aloud: The #1 Usability Tool</a></p>
</blockquote>
<h3 id="evidence-chain"><a class="header" href="#evidence-chain">Evidence Chain</a></h3>
<blockquote>
<p><strong>Evidence Chain</strong> [GLOSSARY]</p>
<p>Traceability from raw data ‚Üí finding ‚Üí backlog item ‚Üí fix ‚Üí verification. Critical for academic rigour and professional practice.</p>
<p><strong>Example chain</strong>:</p>
<ol>
<li><strong>Raw data</strong>: <code>metrics.csv</code> shows <code>T2_edit, validation_error, blank_title</code> for session <code>WK9A03</code></li>
<li><strong>Observation</strong>: Pilot notes say "Participant didn't notice error message, submitted blank again"</li>
<li><strong>Finding</strong>: "Error messages not accessible to screen readers (WCAG 4.1.3 violation)"</li>
<li><strong>Backlog item</strong>: <code>wk9-05: Add role=alert to validation errors</code></li>
<li><strong>Fix</strong> (Week 10): Update template with <code>&lt;p role="alert"&gt;</code></li>
<li><strong>Verification</strong>: Retest with screen reader, confirm announcement</li>
</ol>
<p><strong>Why this matters</strong>:</p>
<ul>
<li><strong>Gradescope Task 1</strong>: Markers check evidence chains (no evidence = no marks)</li>
<li><strong>Professional practice</strong>: Design decisions require justification</li>
<li><strong>Accreditation</strong>: External panels expect rigorous HCI process</li>
</ul>
<p><strong>HCI Connection</strong>: Evidence chains demonstrate <strong>systematic design process</strong>, not ad-hoc changes.</p>
<p>üîó <a href="https://www.gov.uk/service-manual/measuring-success/using-data-to-improve-your-service">GOV.UK Service Manual: Using data in service design</a></p>
</blockquote>
<h3 id="thematic-coding"><a class="header" href="#thematic-coding">Thematic Coding</a></h3>
<blockquote>
<p><strong>Thematic Coding</strong> [GLOSSARY]</p>
<p>Systematic process of identifying patterns (themes) in qualitative data. Used to analyse pilot notes.</p>
<p><strong>Process</strong>:</p>
<ol>
<li><strong>Read notes</strong>: Familiarize yourself with all observations</li>
<li><strong>Code</strong>: Label each observation with tags (e.g., "sr-announcement", "validation-error", "focus-management")</li>
<li><strong>Group</strong>: Cluster similar codes into themes (e.g., all "sr-announcement" issues ‚Üí theme: "Status feedback")</li>
<li><strong>Interpret</strong>: What do these themes tell us about usability/accessibility?</li>
</ol>
<p><strong>Example</strong> (simplified):</p>
<pre><code>Observation: "Participant didn't notice success message" ‚Üí Code: feedback-timing
Observation: "SR didn't announce deletion" ‚Üí Code: sr-announcement
Observation: "Participant asked 'did it save?'" ‚Üí Code: feedback-clarity

Theme: "Success feedback insufficient" (3 codes)
Priority: High (affects confidence, inclusion)
</code></pre>
<p><strong>This module</strong>: Light-touch thematic coding in Week 10. Full formal coding (inter-rater reliability, etc.) is postgraduate-level.</p>
<p>üîó <a href="https://www.tandfonline.com/doi/abs/10.1191/1478088706qp063oa">Braun &amp; Clarke: Thematic Analysis</a> ‚Äî Academic reference</p>
</blockquote>
<hr />
<h2 id="activity-a-pilot-preparation-10-min"><a class="header" href="#activity-a-pilot-preparation-10-min">Activity A: Pilot Preparation (10 min)</a></h2>
<p><strong>Goal</strong>: Ensure everything is ready before first participant arrives.</p>
<h3 id="step-1-technical-setup-5-min"><a class="header" href="#step-1-technical-setup-5-min">Step 1: Technical setup (5 min)</a></h3>
<ol>
<li><strong>Start server</strong>: <code>./gradlew run</code> (or IDE run configuration)</li>
<li><strong>Test routes</strong>: Visit <code>/tasks</code>, confirm prototype works (add/edit/filter/delete)</li>
<li><strong>Clear old data</strong> (optional): If <code>data/metrics.csv</code> contains dry-run rows, either delete them or note the starting row number so you know which rows are real pilot data</li>
</ol>
<p><strong>Verify instrumentation</strong>:</p>
<ul>
<li>Submit a test task ‚Üí check <code>metrics.csv</code> for new row</li>
<li>Submit empty form ‚Üí check for <code>validation_error</code> row</li>
<li>Disable JS, repeat ‚Üí check <code>js_mode=off</code> appears</li>
</ul>
<p>If anything's broken, <strong>fix it now</strong> (don't waste participants' time).</p>
<h3 id="step-2-materials-ready-3-min"><a class="header" href="#step-2-materials-ready-3-min">Step 2: Materials ready (3 min)</a></h3>
<p><strong>Physical/digital checklists</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Protocol document (<code>wk09/lab-wk9/research/protocol.md</code>) printed or on second screen</li>
<li><input disabled="" type="checkbox"/>
Task scenarios ready to read aloud</li>
<li><input disabled="" type="checkbox"/>
Consent script ready (memorize or have visible)</li>
<li><input disabled="" type="checkbox"/>
<code>pilot-notes.md</code> template open in editor</li>
<li><input disabled="" type="checkbox"/>
Stopwatch/timer (backup for server timing)</li>
<li><input disabled="" type="checkbox"/>
Post-task questions printed (confidence rating 1‚Äì5)</li>
</ul>
<p><strong>Participant setup</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Clean browser session (clear cookies, cache)</li>
<li><input disabled="" type="checkbox"/>
Navigate to prototype homepage</li>
<li><input disabled="" type="checkbox"/>
DevTools closed (don't intimidate participant with console)</li>
</ul>
<h3 id="step-3-role-allocation-2-min"><a class="header" href="#step-3-role-allocation-2-min">Step 3: Role allocation (2 min)</a></h3>
<p><strong>Work in pairs or triads</strong>:</p>
<ul>
<li><strong>Facilitator</strong>: Reads scenarios, asks questions, manages timing</li>
<li><strong>Note-taker</strong>: Records observations, direct quotes, timestamps</li>
<li><strong>Participant</strong>: Completes tasks</li>
</ul>
<p><strong>Rotate roles</strong> after each pilot (everyone gets experience facilitating and participating).</p>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Server running, prototype functional</li>
<li><input disabled="" type="checkbox"/>
metrics.csv logging correctly</li>
<li><input disabled="" type="checkbox"/>
Protocol and materials ready</li>
<li><input disabled="" type="checkbox"/>
Roles assigned</li>
</ul>
<hr />
<h2 id="activity-b-run-pilot-sessions-6080-min"><a class="header" href="#activity-b-run-pilot-sessions-6080-min">Activity B: Run Pilot Sessions (60‚Äì80 min)</a></h2>
<p><strong>Goal</strong>: Conduct 5‚Äì6 peer pilots following your ethical protocol.</p>
<p><strong>Timing</strong>:</p>
<ul>
<li>~15 minutes per pilot (4 tasks + debrief)</li>
<li>~5 minutes between pilots (swap roles, generate new session ID)</li>
<li>Total: 5 pilots √ó 20 min = ~100 min</li>
</ul>
<p><strong>If time is tight</strong>: Minimum 3 pilots (one with keyboard-only, one with JS-off, one standard).</p>
<h3 id="pilot-1-standard-htmx-mouse-js-on"><a class="header" href="#pilot-1-standard-htmx-mouse-js-on">Pilot 1: Standard (HTMX, mouse, JS-on)</a></h3>
<h4 id="setup-3-min"><a class="header" href="#setup-3-min">Setup (3 min)</a></h4>
<ol>
<li>
<p><strong>Generate session ID</strong>:</p>
<pre><code class="language-bash">openssl rand -hex 3  # Example output: 7a9f2c
</code></pre>
<p>Or use: <code>https://www.random.org/strings/</code> (6 chars, alphanumeric)</p>
</li>
<li>
<p><strong>Set cookie</strong> in participant browser (DevTools Console):</p>
<pre><code class="language-javascript">document.cookie = "sid=P1_7a9f; path=/";
</code></pre>
</li>
<li>
<p><strong>Record in consent log</strong> (<code>wk09/lab-wk9/research/consent-log.md</code>):</p>
<pre><code class="language-markdown">## Pilot 1
Date: 2025-10-15
Participant code: P1
Session ID: P1_7a9f
Variant: Standard (HTMX, mouse, JS-on)
Consent: Verbal consent given at 14:15
Notes: None
</code></pre>
</li>
</ol>
<h4 id="consent-process-2-min"><a class="header" href="#consent-process-2-min">Consent process (2 min)</a></h4>
<p><strong>Read script</strong> (from protocol.md):</p>
<blockquote>
<p>"Thanks for agreeing to pilot our prototype. This is a quick usability test‚Äîabout 15 minutes. I'll ask you to complete 4 tasks while I observe and take notes. I'm testing the interface, not you, so there are no wrong answers.</p>
<p><strong>What we're collecting</strong>: task times, whether you complete successfully, any errors, your confidence ratings, and my notes on any issues.</p>
<p><strong>What we're NOT collecting</strong>: your name, email, student ID, or any recordings.</p>
<p>Your session code is <code>P1_7a9f</code>. You can request data deletion anytime.</p>
<p><strong>You can stop at any time.</strong> Do you have questions?"</p>
</blockquote>
<p><strong>Wait for verbal consent</strong>: "Are you happy to proceed?"</p>
<p>If participant declines or seems uncertain, thank them and find another volunteer.</p>
<h4 id="warm-up-2-min-not-timed"><a class="header" href="#warm-up-2-min-not-timed">Warm-up (2 min, not timed)</a></h4>
<p>"Take a minute to browse the task list. Click around, get familiar. Think aloud if you're comfortable‚Äîsay what you're thinking‚Äîbut no pressure. Let me know when you're ready for the first task."</p>
<p><strong>Note-taker observes</strong>: Initial reactions, confusion points, do they notice key UI elements?</p>
<h4 id="task-t3-add-task-60s-limit"><a class="header" href="#task-t3-add-task-60s-limit">Task T3: Add Task (60s limit)</a></h4>
<p><strong>Facilitator reads</strong>:</p>
<blockquote>
<p>"You need to remember to 'Call supplier about delivery'. Add this as a new task."</p>
</blockquote>
<p><strong>Start timing</strong>: When participant focuses in input or begins typing.</p>
<p><strong>Note-taker records</strong>:</p>
<ul>
<li>Timestamp (e.g., <code>14:18</code>)</li>
<li>Did they find form immediately?</li>
<li>Did they hesitate or look confused?</li>
<li>Did they submit blank by mistake?</li>
<li>Did they notice success confirmation?</li>
</ul>
<p><strong>Post-task question</strong>:</p>
<blockquote>
<p>"On a scale of 1 to 5, how confident are you that you completed that correctly?"</p>
</blockquote>
<p>Record answer: <code>Confidence: 5</code></p>
<p><strong>Check logs</strong>: Open <code>data/metrics.csv</code>, verify new row with <code>task_code=T3_add, step=success, session_id=P1_7a9f</code>.</p>
<hr />
<h4 id="task-t1-filter-tasks-120s-limit"><a class="header" href="#task-t1-filter-tasks-120s-limit">Task T1: Filter Tasks (120s limit)</a></h4>
<p><strong>Facilitator reads</strong>:</p>
<blockquote>
<p>"You've been asked to find all tasks containing the word 'report'. Use the filter to show only matching tasks, then count how many remain."</p>
</blockquote>
<p><strong>Note-taker records</strong>:</p>
<ul>
<li>How long to find filter box?</li>
<li>Did they type "report" or "Report" (case sensitivity)?</li>
<li>Did they notice result count indicator?</li>
<li>Did they manually count items vs read count?</li>
</ul>
<p><strong>Post-task question</strong>: Confidence (1‚Äì5)</p>
<hr />
<h4 id="task-t2-edit-task-90s-limit"><a class="header" href="#task-t2-edit-task-90s-limit">Task T2: Edit Task (90s limit)</a></h4>
<p><strong>Facilitator reads</strong>:</p>
<blockquote>
<p>"The task 'Submit invoices' has a typo. Change it to 'Submit invoices by Friday' and save the change."</p>
</blockquote>
<p><strong>Note-taker records</strong>:</p>
<ul>
<li>How quickly did they find Edit button?</li>
<li>Any validation errors triggered?</li>
<li>Did they verify edit saved?</li>
<li>Any confusion about inline vs full-page edit?</li>
</ul>
<p><strong>Post-task question</strong>: Confidence (1‚Äì5)</p>
<hr />
<h4 id="task-t4-delete-task-45s-limit"><a class="header" href="#task-t4-delete-task-45s-limit">Task T4: Delete Task (45s limit)</a></h4>
<p><strong>Facilitator reads</strong>:</p>
<blockquote>
<p>"The task 'Test entry' is no longer needed. Delete it."</p>
</blockquote>
<p><strong>Note-taker records</strong>:</p>
<ul>
<li>Confirmation dialog appeared? (HTMX)</li>
<li>Did they expect confirmation?</li>
<li>Did they verify deletion succeeded?</li>
</ul>
<p><strong>Post-task question</strong>: Confidence (1‚Äì5)</p>
<hr />
<h4 id="debrief-3-min"><a class="header" href="#debrief-3-min">Debrief (3 min)</a></h4>
<p><strong>Facilitator asks</strong>:</p>
<ol>
<li>"Which task felt most difficult?"</li>
<li>"Did anything surprise you or not work as expected?"</li>
<li>"Were there any points where you weren't sure if something had worked?"</li>
</ol>
<p><strong>Record verbatim quotes</strong> in notes:</p>
<pre><code>Debrief P1:
- "T2 edit was hardest‚ÄîI wasn't sure if it saved"
- "T1 filter was easy once I found the box"
- "Success messages were subtle, I had to look for them"
</code></pre>
<p><strong>Thank participant</strong>:</p>
<blockquote>
<p>"That's really helpful, thank you. Your feedback will directly improve the prototype."</p>
</blockquote>
<hr />
<h3 id="pilot-2-keyboard-only-variant"><a class="header" href="#pilot-2-keyboard-only-variant">Pilot 2: Keyboard-Only Variant</a></h3>
<p>Repeat entire process with new participant, <strong>new session ID</strong> (e.g., <code>P2_4d8e</code>).</p>
<p><strong>Key difference</strong>: Participant uses <strong>Tab, Enter, Space only</strong> (no mouse).</p>
<p><strong>Record variant</strong> in consent log: <code>Variant: Keyboard-only, JS-on</code></p>
<p><strong>Additional observations to capture</strong>:</p>
<ul>
<li>Tab order logical?</li>
<li>All interactive elements reachable?</li>
<li>Focus visible on all stops?</li>
<li>Any keyboard traps?</li>
<li>Skip link working?</li>
</ul>
<p><strong>Expected</strong>: May be slower (tabbing takes time). Note accessibility issues (missing focus indicators, unreachable buttons).</p>
<hr />
<h3 id="pilot-3-no-js-variant"><a class="header" href="#pilot-3-no-js-variant">Pilot 3: No-JS Variant</a></h3>
<p><strong>Key difference</strong>: Disable JavaScript before starting.</p>
<p><strong>Setup</strong>:</p>
<ol>
<li>Chrome DevTools ‚Üí Settings ‚Üí Preferences ‚Üí Disable JavaScript (checkbox)</li>
<li>Hard refresh (Ctrl+Shift+R / Cmd+Shift+R)</li>
</ol>
<p><strong>Record variant</strong>: <code>Variant: No-JS (JS-off)</code></p>
<p><strong>Additional observations</strong>:</p>
<ul>
<li>Full page reloads on every form submit?</li>
<li>Error messages visible after redirect?</li>
<li>PRG pattern working (refresh doesn't duplicate submission)?</li>
<li>Confirmation missing for delete? (expected trade-off)</li>
</ul>
<p><strong>Expected</strong>: Slower task times (full page reloads). Verify <code>metrics.csv</code> shows <code>js_mode=off</code>.</p>
<hr />
<h3 id="pilots-46-standard-or-screen-reader"><a class="header" href="#pilots-46-standard-or-screen-reader">Pilots 4‚Äì6: Standard or Screen Reader</a></h3>
<p><strong>Standard</strong>: Repeat Pilot 1 process with new participants for more data points.</p>
<p><strong>Screen Reader</strong> (if time permits):</p>
<ul>
<li>Participant uses NVDA (Windows) or Orca (Linux)</li>
<li>Allow 2√ó time (SR navigation slower)</li>
<li>Facilitator <strong>silent</strong> unless participant asks questions (talking competes with SR audio)</li>
</ul>
<p><strong>SR-specific observations</strong>:</p>
<ul>
<li>Are labels announced correctly?</li>
<li>Are status messages announced (<code>role="status"</code>)?</li>
<li>Are error messages linked to inputs (<code>aria-describedby</code>)?</li>
<li>Can participant complete tasks independently?</li>
</ul>
<p><strong>Record variant</strong>: <code>Variant: Screen reader (NVDA), keyboard-only, JS-on</code></p>
<hr />
<h3 id="between-pilots-5-min-each"><a class="header" href="#between-pilots-5-min-each">Between Pilots (5 min each)</a></h3>
<ol>
<li><strong>Save notes</strong>: Copy notes to <code>wk09/lab-wk9/research/pilots/P1-notes.md</code> (or keep in single file with headings)</li>
<li><strong>Check logs</strong>: Verify <code>metrics.csv</code> has rows for all completed tasks</li>
<li><strong>Swap roles</strong>: Next person facilitates, previous facilitator becomes note-taker or participant</li>
<li><strong>Generate new session ID</strong>: Never reuse (contaminates data)</li>
<li><strong>Clear browser state</strong>: Delete cookies, close tabs, fresh start</li>
</ol>
<hr />
<h3 id="facilitator-guidelines-reference"><a class="header" href="#facilitator-guidelines-reference">Facilitator Guidelines (Reference)</a></h3>
<p><strong>Do</strong>:</p>
<ul>
<li>Stay neutral (tone, facial expressions)</li>
<li>Allow silence (don't fill pauses‚Äîpeople think quietly)</li>
<li>Record exact quotes when possible</li>
<li>Note timestamps for key events</li>
</ul>
<p><strong>Don't</strong>:</p>
<ul>
<li>Explain interface ("The filter is at the top")</li>
<li>Justify design ("It's supposed to work like this")</li>
<li>Lead participant ("Did you see the success message?")</li>
<li>Show impatience (sighs, tapping, checking watch)</li>
</ul>
<p><strong>If participant stuck (&gt;3 min)</strong>:</p>
<ol>
<li>Ask diagnostic question: "What are you looking for?"</li>
<li>If still stuck: "Let's move to the next task"</li>
<li>Mark task as <code>completion=0</code>, note reason in pilot-notes</li>
</ol>
<p><strong>If participant becomes frustrated</strong>:</p>
<ul>
<li>Reassure: "This is really helpful feedback‚Äîit's the interface, not you."</li>
<li>Offer break or stop session</li>
<li>Never pressure to continue</li>
</ul>
<hr />
<p>‚úã <strong>Stop and check</strong> (after completing pilots):</p>
<ul>
<li><input disabled="" type="checkbox"/>
3‚Äì6 pilots completed with different variants</li>
<li><input disabled="" type="checkbox"/>
Consent logged for each participant</li>
<li><input disabled="" type="checkbox"/>
metrics.csv contains rows for all tasks (check session_ids)</li>
<li><input disabled="" type="checkbox"/>
Pilot notes saved with timestamps, quotes, observations</li>
<li><input disabled="" type="checkbox"/>
Subjective ratings captured (confidence 1‚Äì5)</li>
</ul>
<hr />
<h2 id="activity-c-data-verification-and-initial-analysis-15-min"><a class="header" href="#activity-c-data-verification-and-initial-analysis-15-min">Activity C: Data Verification and Initial Analysis (15 min)</a></h2>
<p><strong>Goal</strong>: Ensure collected data is complete and usable before leaving lab.</p>
<h3 id="step-1-check-metricscsv-completeness-5-min"><a class="header" href="#step-1-check-metricscsv-completeness-5-min">Step 1: Check metrics.csv completeness (5 min)</a></h3>
<p>Open <code>data/metrics.csv</code> and verify:</p>
<p><strong>Expected structure</strong>:</p>
<pre><code class="language-csv">ts_iso,session_id,request_id,task_code,step,outcome,ms,http_status,js_mode
2025-10-15T14:18:23.456Z,P1_7a9f,r001,T3_add,success,,567,200,on
2025-10-15T14:19:45.789Z,P1_7a9f,r002,T1_filter,success,,1847,200,on
2025-10-15T14:21:12.123Z,P1_7a9f,r003,T2_edit,validation_error,blank_title,0,400,on
2025-10-15T14:21:34.456Z,P1_7a9f,r004,T2_edit,success,,1234,200,on
2025-10-15T14:22:10.789Z,P1_7a9f,r005,T4_delete,success,,210,200,on
</code></pre>
<p><strong>Checklist</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
All session_ids present (P1, P2, P3, ...)</li>
<li><input disabled="" type="checkbox"/>
All task_codes present (T1, T2, T3, T4) per session</li>
<li><input disabled="" type="checkbox"/>
<code>step</code> values valid (success, validation_error, fail)</li>
<li><input disabled="" type="checkbox"/>
Timestamps in chronological order</li>
<li><input disabled="" type="checkbox"/>
<code>js_mode</code> matches variant (off for Pilot 3)</li>
<li><input disabled="" type="checkbox"/>
Durations plausible (not negative, not absurdly high like 999999ms)</li>
</ul>
<p><strong>If data missing</strong>:</p>
<ul>
<li>Note in <code>wk09/lab-wk9/research/data-notes.md</code>:
<pre><code>Pilot 2 (P2_4d8e): Task T4 not logged due to server restart. Used facilitator stopwatch time: 38s.
</code></pre>
</li>
</ul>
<h3 id="step-2-calculate-quick-summary-stats-5-min"><a class="header" href="#step-2-calculate-quick-summary-stats-5-min">Step 2: Calculate quick summary stats (5 min)</a></h3>
<p><strong>Use spreadsheet or manual calculation</strong>:</p>
<p><strong>Completion rates</strong> (per task):</p>
<pre><code>T1 (Filter):    5 success / 5 attempts = 100%
T2 (Edit):      4 success / 5 attempts = 80% (1 participant gave up)
T3 (Add):       5 success / 5 attempts = 100%
T4 (Delete):    5 success / 5 attempts = 100%
</code></pre>
<p><strong>Median times</strong> (from <code>ms</code> column, filter <code>step=success</code>):</p>
<pre><code>T1: [1847, 2103, 1654, 2345, 1899] ‚Üí Median = 1899ms (~19s)
T2: [1234, 1567, 1123, 1890] ‚Üí Median = 1400ms (~14s)
T3: [567, 432, 689, 543, 601] ‚Üí Median = 567ms (~6s)
T4: [210, 198, 234, 221, 205] ‚Üí Median = 210ms (~2s)
</code></pre>
<p><strong>Error rates</strong>:</p>
<pre><code>T2: 2 validation_error events / 6 total attempts = 33%
T3: 1 validation_error / 5 attempts = 20%
</code></pre>
<p><strong>Record in <code>wk09/lab-wk9/research/summary-stats.md</code></strong>:</p>
<pre><code class="language-markdown"># Pilot Summary Stats (n=5)

## Completion Rates
| Task | Completion | Notes |
|------|-----------|-------|
| T1 (Filter) | 5/5 (100%) | All participants successful |
| T2 (Edit) | 4/5 (80%) | P3 gave up after 2 validation errors |
| T3 (Add) | 5/5 (100%) | 1 validation error (P2 submitted blank) |
| T4 (Delete) | 5/5 (100%) | No issues |

## Median Times (success only)
| Task | Median (ms) | Median (s) | Range |
|------|------------|------------|-------|
| T1 | 1899 | 19s | 16s‚Äì23s |
| T2 | 1400 | 14s | 11s‚Äì19s |
| T3 | 567 | 6s | 4s‚Äì7s |
| T4 | 210 | 2s | 2s‚Äì2.3s |

## Error Rates
| Task | Validation Errors | Rate | Notes |
|------|------------------|------|-------|
| T2 | 2 errors (P2, P3) | 33% | Blank title submitted |
| T3 | 1 error (P2) | 20% | Blank title submitted |

## JS-On vs JS-Off (T3 comparison)
- JS-on (n=4): Median 567ms
- JS-off (n=1, P3): 3456ms (full page reload)
- **Difference**: ~6√ó slower without JS (expected)
</code></pre>
<h3 id="step-3-flag-anomalies-5-min"><a class="header" href="#step-3-flag-anomalies-5-min">Step 3: Flag anomalies (5 min)</a></h3>
<p><strong>Look for</strong>:</p>
<ul>
<li>Outliers: Times &gt;3√ó median (distraction? confusion? technical issue?)</li>
<li>Missing data: Tasks with no log entries</li>
<li>Impossible values: Negative times, empty session_ids</li>
<li>Inconsistencies: <code>js_mode=on</code> for Pilot 3 (should be <code>off</code>)</li>
</ul>
<p><strong>Document in data-notes.md</strong>:</p>
<pre><code class="language-markdown"># Data Quality Notes

## Anomalies
- Pilot 1, T1: Duration 1847ms is within normal range ‚úì
- Pilot 3, T3: Duration 3456ms (no-JS) is expected (full page reload) ‚úì
- Pilot 4, T2: Missing log entry‚Äîserver crashed, used stopwatch: 17s

## Exclusions
- None (all data usable)

## Notes
- P3 (no-JS) consistently slower‚Äîconfirms dual-path performance difference
- P2 triggered 2 validation errors (blank submissions)‚Äîpossible focus management issue
</code></pre>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
metrics.csv verified complete</li>
<li><input disabled="" type="checkbox"/>
Summary stats calculated (completion, median times, error rates)</li>
<li><input disabled="" type="checkbox"/>
Anomalies documented</li>
<li><input disabled="" type="checkbox"/>
Data quality acceptable for Week 10 analysis</li>
</ul>
<hr />
<h2 id="activity-d-translate-findings-to-backlog-20-min"><a class="header" href="#activity-d-translate-findings-to-backlog-20-min">Activity D: Translate Findings to Backlog (20 min)</a></h2>
<p><strong>Goal</strong>: Create evidence chains from pilot observations to actionable backlog items.</p>
<h3 id="step-1-review-pilot-notes-5-min"><a class="header" href="#step-1-review-pilot-notes-5-min">Step 1: Review pilot notes (5 min)</a></h3>
<p><strong>Read through all pilot notes</strong> (<code>pilots/P1-notes.md</code>, etc.) and highlight:</p>
<ul>
<li><strong>Accessibility issues</strong>: SR didn't announce, keyboard trap, missing label</li>
<li><strong>Usability issues</strong>: Confusion, hesitation, unexpected behaviour</li>
<li><strong>Error patterns</strong>: Multiple participants hit same validation error</li>
<li><strong>Positive observations</strong>: What worked well (keep in redesign)</li>
</ul>
<p><strong>Example notes</strong>:</p>
<pre><code class="language-markdown">## Pilot 1 (P1_7a9f)
- 14:18 T3: Participant hesitated before clicking "Add Task" button‚Äîunsure if Enter would work
- 14:19 T1: Typed "report", waited, then said "is it filtering automatically?"‚Äîexpected to click button
- 14:21 T2: Validation error (blank submission), participant said "I didn't see an error message"
- 14:22 T4: Delete confirmation dialog appeared, participant confirmed without hesitation ‚úì

## Pilot 2 (P2_4d8e, keyboard-only)
- 14:35 T3: Tab order correct, focus visible ‚úì
- 14:37 T1: Result count not announced by screen reader (tested with NVDA for demo) ‚úó
- 14:39 T2: Blank submission error‚ÄîSR didn't announce error message ‚úó
- 14:40 T4: Delete button accessible, confirmation worked ‚úì

## Pilot 3 (P3_1f2a, no-JS)
- 15:00 T3: Full page reload after submit‚Äîslower but functional ‚úì
- 15:02 T1: Filter worked with form submit‚Äîno issues ‚úì
- 15:04 T2: Gave up after 2 validation errors‚Äîerror summary not focusable ‚úó
- 15:05 T4: No confirmation dialog (expected trade-off), task completed ‚úì
</code></pre>
<h3 id="step-2-identify-themes-5-min"><a class="header" href="#step-2-identify-themes-5-min">Step 2: Identify themes (5 min)</a></h3>
<p><strong>Group similar issues</strong>:</p>
<div class="table-wrapper"><table><thead><tr><th>Theme</th><th>Code</th><th>Observations</th></tr></thead><tbody>
<tr><td><strong>Status feedback</strong></td><td>sr-announcement</td><td>P1: "didn't see error", P2: SR didn't announce, P3: error not focusable</td></tr>
<tr><td><strong>Filter expectations</strong></td><td>ux-expectation</td><td>P1: expected button, not auto-filter</td></tr>
<tr><td><strong>Validation errors</strong></td><td>error-handling</td><td>P2, P3: blank submissions frequent</td></tr>
<tr><td><strong>Keyboard accessibility</strong></td><td>a11y-keyboard</td><td>P2: tab order good ‚úì</td></tr>
<tr><td><strong>No-JS parity</strong></td><td>parity-nojs</td><td>P3: slower but functional ‚úì</td></tr>
</tbody></table>
</div>
<h3 id="step-3-create-backlog-items-10-min"><a class="header" href="#step-3-create-backlog-items-10-min">Step 3: Create backlog items (10 min)</a></h3>
<p><strong>Open <code>backlog/backlog.csv</code></strong> and add entries for significant issues.</p>
<p><strong>Template</strong>:</p>
<pre><code class="language-csv">id,week,priority,category,description,wcag,status,evidence,mitigation,candidate_fix
</code></pre>
<p><strong>Example entries</strong>:</p>
<pre><code class="language-csv">wk9-01,9,high,a11y,"Validation errors not announced by screen readers",4.1.3,open,"data/metrics.csv#P2_4d8e T2 validation_error; pilots/P2-notes.md L12; pilots/P3-notes.md L8","Add role=alert to error messages, aria-describedby for input association",true

wk9-02,9,medium,ux,"Filter auto-search confuses some participants (expected button)",,"open","pilots/P1-notes.md L6","Consider adding visible 'Apply' button or help text",false

wk9-03,9,high,a11y,"Error summary not keyboard-focusable in no-JS mode",3.2.1,open,"pilots/P3-notes.md L10; data/metrics.csv#P3_1f2a T2 fail","Add tabindex=-1 to error summary, focus on page load",true

wk9-04,9,low,ux,"Delete confirmation missing in no-JS (documented trade-off)",3.3.4,open,"pilots/P3-notes.md L12; wk08/docs/prototyping-constraints.md L78","Consider adding /tasks/{id}/delete/confirm page",false

wk9-05,9,high,a11y,"Result count after filter not announced to SR",4.1.3,open,"pilots/P2-notes.md L8","Move result count into live region (role=status)",true
</code></pre>
<p><strong>Key fields</strong>:</p>
<ul>
<li><strong>id</strong>: Unique identifier (wk9-01, wk9-02, ...)</li>
<li><strong>priority</strong>: high (blocks task completion or WCAG A/AA violation), medium (impacts efficiency), low (nice-to-have)</li>
<li><strong>wcag</strong>: Reference if applicable (3.3.1, 4.1.3, etc.)</li>
<li><strong>evidence</strong>: Direct links to data sources (file paths, line numbers, session IDs)</li>
<li><strong>mitigation</strong>: Proposed fix (specific, actionable)</li>
<li><strong>candidate_fix</strong>: <code>true</code> if you plan to implement in Week 10 (limit to 2-3)</li>
</ul>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Pilot notes reviewed and themes identified</li>
<li><input disabled="" type="checkbox"/>
backlog.csv updated with evidence-linked items</li>
<li><input disabled="" type="checkbox"/>
Priority set based on inclusion impact + frequency</li>
<li><input disabled="" type="checkbox"/>
2-3 items marked as candidate fixes for Week 10</li>
</ul>
<hr />
<h2 id="activity-e-assemble-task-1-draft-pack-20-min"><a class="header" href="#activity-e-assemble-task-1-draft-pack-20-min">Activity E: Assemble Task 1 Draft Pack (20 min)</a></h2>
<p><strong>Goal</strong>: Create a complete evidence pack for Gradescope Task 1 submission (will be refined in Week 11).</p>
<p><strong>Directory structure</strong>: <code>wk09/lab-wk9/submission/task1-draft/</code></p>
<h3 id="step-1-copy-evaluation-plan-materials-5-min"><a class="header" href="#step-1-copy-evaluation-plan-materials-5-min">Step 1: Copy evaluation plan materials (5 min)</a></h3>
<p><strong>Files to include</strong>:</p>
<ol>
<li>
<p><strong><code>01-evaluation-plan.md</code></strong>: Copy from <code>wk09/lab-wk9/research/tasks.md</code> + <code>measures.md</code></p>
<ul>
<li>Task definitions</li>
<li>Metrics definitions</li>
<li>Success criteria</li>
</ul>
</li>
<li>
<p><strong><code>02-protocol.md</code></strong>: Copy from <code>wk09/lab-wk9/research/protocol.md</code></p>
<ul>
<li>Consent process</li>
<li>Session flow</li>
<li>Facilitator guidelines</li>
<li>Ethical considerations</li>
</ul>
</li>
<li>
<p><strong><code>03-consent-log.md</code></strong>: Copy from <code>wk09/lab-wk9/research/consent-log.md</code></p>
<ul>
<li>Participant codes</li>
<li>Session IDs</li>
<li>Variants tested</li>
<li>Consent confirmation</li>
</ul>
</li>
</ol>
<h3 id="step-2-include-quantitative-data-5-min"><a class="header" href="#step-2-include-quantitative-data-5-min">Step 2: Include quantitative data (5 min)</a></h3>
<p><strong>Create <code>04-results.csv</code></strong>:</p>
<p>Option A: Copy relevant rows from <code>data/metrics.csv</code>:</p>
<pre><code class="language-bash">grep -E "P1_|P2_|P3_|P4_|P5_" data/metrics.csv &gt; wk09/lab-wk9/submission/task1-draft/04-results.csv
</code></pre>
<p>Option B: Symbolic link (keeps data in one place):</p>
<pre><code class="language-bash">ln -s ../../../data/metrics.csv wk09/lab-wk9/submission/task1-draft/04-results.csv
</code></pre>
<p><strong>Include README.md</strong> explaining columns:</p>
<pre><code class="language-markdown"># Results Data

**File**: `04-results.csv`

**Columns**:
- `ts_iso`: Event timestamp (ISO 8601 UTC)
- `session_id`: Anonymous participant identifier (P1_7a9f, etc.)
- `request_id`: Request trace ID
- `task_code`: Task identifier (T1_filter, T2_edit, T3_add, T4_delete)
- `step`: Event type (success, validation_error, fail)
- `outcome`: Specific error type (blank_title, max_length, etc.)
- `ms`: Duration in milliseconds
- `http_status`: HTTP response code (200, 400, 500)
- `js_mode`: JavaScript availability (on, off)

**Sessions**:
- P1_7a9f: Standard (HTMX, mouse, JS-on)
- P2_4d8e: Keyboard-only (JS-on)
- P3_1f2a: No-JS (JS-off)
- P4_8c3b: Standard (HTMX, mouse, JS-on)
- P5_2a7d: Standard (HTMX, mouse, JS-on)

**Analysis**: See `05-findings.md` for summary statistics and interpretation.
</code></pre>
<h3 id="step-3-document-findings-5-min"><a class="header" href="#step-3-document-findings-5-min">Step 3: Document findings (5 min)</a></h3>
<p><strong>Create <code>05-findings.md</code></strong> summarizing key issues with evidence chains and WCAG references (see Week 9 Lab 1 for detailed example format).</p>
<h3 id="step-4-collect-evidence-artefacts-5-min"><a class="header" href="#step-4-collect-evidence-artefacts-5-min">Step 4: Collect evidence artefacts (5 min)</a></h3>
<p><strong>Create <code>06-evidence/</code> directory</strong>:</p>
<pre><code>wk09/lab-wk9/submission/task1-draft/06-evidence/
‚îú‚îÄ‚îÄ screenshots/
‚îÇ   ‚îú‚îÄ‚îÄ t2-validation-error-nojs.png
‚îÇ   ‚îú‚îÄ‚îÄ t1-filter-results.png
‚îÇ   ‚îî‚îÄ‚îÄ annotations.md (descriptions + alt text)
‚îú‚îÄ‚îÄ pilot-notes/
‚îÇ   ‚îú‚îÄ‚îÄ P1-notes.md
‚îÇ   ‚îú‚îÄ‚îÄ P2-notes.md
‚îÇ   ‚îî‚îÄ‚îÄ P3-notes.md
‚îî‚îÄ‚îÄ consent-log.md
</code></pre>
<p><strong>Remove any PII</strong> from screenshots and notes.</p>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Evaluation plan + protocol copied to task1-draft/</li>
<li><input disabled="" type="checkbox"/>
Quantitative data (metrics.csv) included or linked</li>
<li><input disabled="" type="checkbox"/>
Findings document complete with statistics + evidence chains</li>
<li><input disabled="" type="checkbox"/>
Evidence artefacts collected (screenshots, notes)</li>
<li><input disabled="" type="checkbox"/>
All files sanitized (no PII)</li>
</ul>
<hr />
<h2 id="commit--reflect-10-min-2"><a class="header" href="#commit--reflect-10-min-2">Commit &amp; Reflect (10 min)</a></h2>
<h3 id="commit-message-2"><a class="header" href="#commit-message-2">Commit message</a></h3>
<pre><code class="language-bash">git add data/metrics.csv backlog/backlog.csv wk09/lab-wk9/research wk09/lab-wk9/submission

git commit -m "$(cat &lt;&lt;'EOF'
wk9s2: completed peer pilots (n=5), assembled Task 1 draft pack

- Conducted 5 peer pilots: 3 standard (HTMX), 1 keyboard-only, 1 no-JS
- Collected quantitative data: completion rates (80-100%), median times (2s‚Äì19s), error rates (20-33% for T2/T3)
- Captured qualitative observations: validation error accessibility issues, status feedback insufficient, filter UX expectations
- Verified no-JS parity: functional but 6√ó slower (expected)
- Created evidence chains: raw data ‚Üí findings ‚Üí backlog items (wk9-01 to wk9-05)
- Assembled Task 1 draft pack: plan, protocol, results.csv, findings.md, evidence artefacts
- Identified Priority 1 fixes for Week 10: validation error accessibility (role=alert, aria-describedby, focusable summary)

Key findings:
- Validation errors not accessible to SR users (WCAG 4.1.3 violation)
- Error summary not keyboard-focusable in no-JS mode (WCAG 3.2.1)
- Status messages too subtle (affects confidence)
- High error rate on T2 edit (33%‚Äîblank submissions due to focus management)

Ready for Week 10 analysis and redesign.


EOF
)"
</code></pre>
<h3 id="reflection-questions-5"><a class="header" href="#reflection-questions-5">Reflection questions</a></h3>
<p><strong>Answer in <code>wk09/reflection.md</code></strong>:</p>
<ol>
<li>
<p><strong>Pilot experience</strong>: What surprised you most during pilots? Did participants struggle where you expected, or were there unexpected issues?</p>
</li>
<li>
<p><strong>Ethical practice</strong>: How comfortable were participants? Did consent process feel sufficient? Any near-misses on PII collection?</p>
</li>
<li>
<p><strong>Data quality</strong>: How confident are you in the quantitative data (metrics.csv)? Any concerns about accuracy, completeness, or bias?</p>
</li>
<li>
<p><strong>Qualitative insights</strong>: What did observation reveal that logs couldn't capture? How valuable was think-aloud (if used)?</p>
</li>
<li>
<p><strong>Accessibility impact</strong>: Which findings have highest inclusion impact? How would you prioritize fixes if you could only do one?</p>
</li>
<li>
<p><strong>Week 10 readiness</strong>: What are your Priority 1 fixes? How will you verify they worked?</p>
</li>
</ol>
<hr />
<h2 id="looking-ahead-week-10-analysis--redesign"><a class="header" href="#looking-ahead-week-10-analysis--redesign">Looking Ahead: Week 10 Analysis &amp; Redesign</a></h2>
<p>Next week:</p>
<ul>
<li><strong>Lab 1</strong>: Analyse metrics in depth (median, MAD, error rates), prioritize backlog with inclusion √ó impact scores, plan redesign</li>
<li><strong>Lab 2</strong>: Implement Priority 1-2 fixes, re-verify accessibility, update backlog, prepare Task 2 evidence pack</li>
</ul>
<p><strong>Before Week 10</strong>:</p>
<ul>
<li>Review <a href="wk09/../references/evaluation-metrics-quickref.html">Evaluation Metrics Quick Reference</a> for analysis formulas</li>
<li>Refresh WCAG 2.2 guidelines for fixes (3.3.1, 4.1.3)</li>
<li>Think about trade-offs: which fixes are quick wins vs major refactors?</li>
</ul>
<hr />
<h2 id="further-reading--resources-2"><a class="header" href="#further-reading--resources-2">Further Reading &amp; Resources</a></h2>
<h3 id="essential-2"><a class="header" href="#essential-2">Essential</a></h3>
<ul>
<li>Review Week 9 Lab 1 (evaluation planning) for context</li>
<li><a href="wk09/../references/evaluation-metrics-quickref.html">Evaluation Metrics Quick Reference</a> ‚Äî Median, MAD, error rate formulas</li>
<li><a href="https://www.gov.uk/service-manual/user-research/analyse-a-research-session">GOV.UK: Analysing user research</a></li>
</ul>
<h3 id="hci-evaluation"><a class="header" href="#hci-evaluation">HCI Evaluation</a></h3>
<ul>
<li><a href="https://www.nngroup.com/articles/usability-testing-101/">Nielsen: How to Conduct a Usability Test</a></li>
<li><a href="https://dl.acm.org/doi/book/10.5555/2737875">Lazar et al.: Research Methods in HCI</a> ‚Äî Chapters 9-10 (qualitative methods)</li>
<li><a href="https://measuringux.com/">Measuring UX</a> ‚Äî Quantitative analysis techniques</li>
</ul>
<h3 id="qualitative-analysis"><a class="header" href="#qualitative-analysis">Qualitative Analysis</a></h3>
<ul>
<li><a href="https://www.tandfonline.com/doi/abs/10.1191/1478088706qp063oa">Braun &amp; Clarke: Thematic Analysis</a></li>
<li><a href="https://www.gov.uk/service-manual/user-research/analyse-a-research-session">GOV.UK: Analysing qualitative data</a></li>
</ul>
<h3 id="ethics"><a class="header" href="#ethics">Ethics</a></h3>
<ul>
<li>Review <code>references/consent-pii-faq.md</code></li>
<li><a href="https://www.bps.org.uk/guideline/code-ethics-and-conduct">BPS Code of Ethics</a></li>
</ul>
<hr />
<h2 id="glossary-summary-5"><a class="header" href="#glossary-summary-5">Glossary Summary</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Term</th><th>One-line definition</th></tr></thead><tbody>
<tr><td><strong>Pilot study</strong></td><td>Small-scale preliminary study to test protocol and gather initial data</td></tr>
<tr><td><strong>Quantitative data</strong></td><td>Numerical measurements (times, counts, percentages); objective, statistical</td></tr>
<tr><td><strong>Qualitative data</strong></td><td>Non-numerical observations (quotes, behaviours, patterns); subjective, interpretive</td></tr>
<tr><td><strong>Think-aloud protocol</strong></td><td>Participants verbalize thoughts while completing tasks; reveals mental models</td></tr>
<tr><td><strong>Evidence chain</strong></td><td>Traceability from raw data ‚Üí finding ‚Üí backlog item ‚Üí fix ‚Üí verification</td></tr>
<tr><td><strong>Thematic coding</strong></td><td>Systematic process of identifying patterns (themes) in qualitative data</td></tr>
<tr><td><strong>Median</strong></td><td>Middle value in sorted dataset; resistant to outliers</td></tr>
<tr><td><strong>MAD</strong></td><td>Median Absolute Deviation; robust measure of spread</td></tr>
<tr><td><strong>Completion rate</strong></td><td>Proportion of participants who successfully complete a task</td></tr>
<tr><td><strong>Error rate</strong></td><td>Proportion of attempts that trigger validation errors</td></tr>
</tbody></table>
</div>
<hr />
<p><strong>Lab complete!</strong> You have real pilot data, evidence chains, and a draft Task 1 pack. Week 10 will analyse this data rigorously and implement prioritised fixes.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="code-resources-3"><a class="header" href="#code-resources-3">Code Resources</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-10--lab-1--analyse-metrics-prioritise-fixes-plan-inclusive-redesign"><a class="header" href="#week-10--lab-1--analyse-metrics-prioritise-fixes-plan-inclusive-redesign">Week 10 ‚Ä¢ Lab 1 ‚Äî Analyse Metrics, Prioritise Fixes, Plan Inclusive Redesign</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-10-orange" alt="Week 10" />
<img src="https://img.shields.io/badge/Lab-1-green" alt="Lab 1" />
<img src="https://img.shields.io/badge/Status-Draft-yellow" alt="Status" /></p>
<hr />
<h2 id="before-lab-required-reading-15-mins-1"><a class="header" href="#before-lab-required-reading-15-mins-1">Before Lab: Required Reading (15 mins)</a></h2>
<p>üìñ <strong>Essential</strong>:</p>
<ul>
<li>Review <a href="wk10/../references/evaluation-metrics-quickref.html">Evaluation Metrics Quick Reference</a> (formulas for median, MAD, error rates)</li>
<li>Review Week 9 Lab 2 findings (<code>wk09/lab-wk9/submission/task1-draft/05-findings.md</code>)</li>
<li><a href="https://www.nngroup.com/articles/how-to-rate-the-severity-of-usability-problems/">Nielsen: Prioritizing Web Usability Issues</a></li>
</ul>
<p>üìñ <strong>Contextual</strong>:</p>
<ul>
<li><a href="https://www.gov.uk/service-manual/measuring-success/using-data-to-improve-your-service">GOV.UK: Using data to improve your service</a></li>
<li><a href="https://www.w3.org/WAI/test-evaluate/report/">W3C: Prioritizing Accessibility Issues</a></li>
</ul>
<hr />
<h2 id="introduction-from-data-to-decisions"><a class="header" href="#introduction-from-data-to-decisions">Introduction: From Data to Decisions</a></h2>
<p>Week 9 collected raw pilot data: logs, times, errors, quotes. <strong>Today you turn that data into actionable insights</strong>.</p>
<p><strong>Data analysis is NOT just number-crunching</strong>. It's:</p>
<ul>
<li><strong>Interpretation</strong>: What do the numbers <em>mean</em> for real people?</li>
<li><strong>Prioritisation</strong>: Which issues matter most for inclusion + usability?</li>
<li><strong>Planning</strong>: What specific changes will fix the highest-impact problems?</li>
</ul>
<p><strong>Why this matters</strong>:</p>
<ul>
<li><strong>Gradescope Task 2</strong>: Requires before/after metrics + evidence of data-driven redesign</li>
<li><strong>Week 10 Lab 2</strong>: You'll implement Priority 1 fixes‚Äîplanning today prevents thrashing tomorrow</li>
<li><strong>Professional practice</strong>: Product decisions require justification (stakeholders ask "why this fix?")</li>
</ul>
<p><strong>Inclusion lens</strong>: Numbers alone don't show <strong>who</strong> is excluded. Must combine quantitative (completion rates, times) with qualitative (SR didn't announce, keyboard trap) to understand barriers.</p>
<hr />
<h2 id="learning-focus-8"><a class="header" href="#learning-focus-8">Learning Focus</a></h2>
<h3 id="lab-objectives-8"><a class="header" href="#lab-objectives-8">Lab Objectives</a></h3>
<p>By the end of this session, you will have:</p>
<ul>
<li>Calculated summary statistics (median, MAD, completion rate, error rate) per task</li>
<li>Analysed pilot data (quantitative + qualitative)</li>
<li>Interpreted metrics to identify inclusion impacts (SR users, keyboard-only, no-JS)</li>
<li>Prioritised issues using (Impact + Inclusion) ‚Äì Effort matrix</li>
<li>Created redesign brief with evidence chains</li>
</ul>
<h3 id="learning-outcomes-addressed-8"><a class="header" href="#learning-outcomes-addressed-8">Learning Outcomes Addressed</a></h3>
<p>This lab contributes to the following module Learning Outcomes (<a href="wk10/../references/learning-outcomes.html">full definitions</a>):</p>
<ul>
<li><strong>LO6</strong>: Apply iterative design ‚Äî evidenced by data-driven prioritisation</li>
<li><strong>LO8</strong>: Design and execute evaluation ‚Äî evidenced by metric analysis</li>
<li><strong>LO9</strong>: Apply inclusive design ‚Äî evidenced by inclusion weighting in prioritisation</li>
</ul>
<hr />
<h2 id="key-concepts-7"><a class="header" href="#key-concepts-7">Key Concepts</a></h2>
<h3 id="descriptive-statistics"><a class="header" href="#descriptive-statistics">Descriptive Statistics</a></h3>
<blockquote>
<p><strong>Descriptive Statistics</strong> [GLOSSARY]</p>
<p>Summarize and describe main features of a dataset. <strong>Not inferential</strong> (we don't generalize beyond our 5 pilots).</p>
<p><strong>Key measures for HCI</strong>:</p>
<ul>
<li><strong>Median</strong>: Middle value when sorted (50th percentile)</li>
<li><strong>MAD</strong>: Median Absolute Deviation (robust measure of spread)</li>
<li><strong>Range</strong>: Min‚Äìmax (shows extremes)</li>
<li><strong>Count</strong>: Number of observations (sample size)</li>
</ul>
<p><strong>Why median, not mean?</strong> Completion times are often skewed (outliers from distractions, confusion). Median represents "typical" experience.</p>
<p><strong>Example</strong>:
Task times: [12s, 15s, 18s, 20s, 120s]</p>
<ul>
<li>Mean = 37s ‚Üê skewed by 120s outlier</li>
<li>Median = 18s ‚Üê typical experience</li>
</ul>
<p><strong>HCI Connection</strong>: Descriptive stats make evaluation findings <strong>communicable</strong>‚Äîstakeholders understand "typical task takes 18s" better than raw logs.</p>
<p>üîó <a href="https://measuringux.com/median/">Measuring UX: Median</a></p>
</blockquote>
<h3 id="median-absolute-deviation-mad"><a class="header" href="#median-absolute-deviation-mad">Median Absolute Deviation (MAD)</a></h3>
<blockquote>
<p><strong>MAD (Median Absolute Deviation)</strong> [GLOSSARY]</p>
<p>Robust measure of variability. Less sensitive to outliers than standard deviation.</p>
<p><strong>Formula</strong>:</p>
<pre><code>MAD = median(|x_i - median(x)|)
</code></pre>
<p><strong>Steps</strong>:</p>
<ol>
<li>Find median of dataset</li>
<li>Calculate absolute deviations: <code>|each value - median|</code></li>
<li>Find median of those deviations</li>
</ol>
<p><strong>Example</strong>:
Times: [12s, 15s, 18s, 20s, 25s]</p>
<ol>
<li>Median = 18s</li>
<li>Deviations: |12-18|=6, |15-18|=3, |18-18|=0, |20-18|=2, |25-18|=7</li>
<li>MAD = median([6, 3, 0, 2, 7]) = 3s</li>
</ol>
<p><strong>Interpretation</strong>: Low MAD (e.g., 2s) = consistent experiences. High MAD (e.g., 15s) = varied experiences‚Äîoften signals accessibility barriers (some participants breeze through, others struggle).</p>
<p><strong>HCI Connection</strong>: MAD flags <strong>inclusion issues</strong>‚Äîif SR users take 40s and sighted users take 15s, MAD will be high.</p>
<p>üîó <a href="https://en.wikipedia.org/wiki/Median_absolute_deviation">Wikipedia: Median Absolute Deviation</a></p>
</blockquote>
<h3 id="completion-rate"><a class="header" href="#completion-rate">Completion Rate</a></h3>
<blockquote>
<p><strong>Completion Rate</strong> [GLOSSARY]</p>
<p>Proportion of task attempts that succeeded.</p>
<p><strong>Formula</strong>:</p>
<pre><code>Completion rate = n_success / n_total_attempts
</code></pre>
<p><strong>Range</strong>: 0 (no one succeeded) to 1.0 (everyone succeeded)</p>
<p><strong>Example</strong>:</p>
<ul>
<li>4 participants completed T2 successfully</li>
<li>1 participant gave up (marked <code>fail</code> in logs)</li>
<li>Total: 5 attempts</li>
<li>Completion rate = 4/5 = 0.80 = 80%</li>
</ul>
<p><strong>Interpretation</strong>:</p>
<ul>
<li><strong>1.0</strong>: Task is achievable by all participants (baseline expectation)</li>
<li><strong>0.8‚Äì0.99</strong>: Minor issues‚Äîsome participants struggled but most succeeded</li>
<li><strong>&lt;0.8</strong>: Serious usability/accessibility problem‚Äî1 in 5+ people can't complete</li>
</ul>
<p><strong>Split by js_mode</strong>: If <code>js_mode=on</code> has 1.0 but <code>js_mode=off</code> has 0.5, you have <strong>parity failure</strong> (no-JS path broken).</p>
<p><strong>HCI Connection</strong>: Completion rate is <strong>effectiveness</strong> measure (ISO 9241-11). If people can't complete tasks, system is not usable.</p>
<p>üîó <a href="https://www.iso.org/standard/63500.html">ISO 9241-11: Usability Definitions</a></p>
</blockquote>
<h3 id="error-rate"><a class="header" href="#error-rate">Error Rate</a></h3>
<blockquote>
<p><strong>Error Rate</strong> [GLOSSARY]</p>
<p>Proportion of task attempts that triggered validation errors.</p>
<p><strong>Formula</strong>:</p>
<pre><code>Error rate = n_validation_errors / (n_success + n_validation_errors)
</code></pre>
<p><strong>Example</strong>:</p>
<ul>
<li>T3 (Add Task): 5 success, 1 validation_error (blank title submitted)</li>
<li>Error rate = 1 / (5 + 1) = 0.17 = 17%</li>
</ul>
<p><strong>Interpretation</strong>:</p>
<ul>
<li><strong>0‚Äì10%</strong>: Acceptable‚Äîrare mistakes</li>
<li><strong>10‚Äì30%</strong>: Moderate‚Äîform could be clearer</li>
<li><strong>&gt;30%</strong>: High‚Äîlikely affordance issues, missing labels, or confusing instructions</li>
</ul>
<p><strong>Root causes</strong>:</p>
<ul>
<li>Missing affordances ("I didn't know it was required")</li>
<li>Unclear constraints ("How long can the title be?")</li>
<li>Focus management ("I accidentally submitted blank")</li>
<li>Cognitive load ("Too many fields, got confused")</li>
</ul>
<p><strong>HCI Connection</strong>: Error rate measures <strong>efficiency</strong> (ISO 9241-11). High error rates ‚Üí wasted time, frustration, accessibility barriers.</p>
<p>üîó <a href="https://www.w3.org/WAI/WCAG22/Understanding/input-assistance">WCAG 3.3: Input Assistance</a></p>
</blockquote>
<h3 id="prioritisation-framework"><a class="header" href="#prioritisation-framework">Prioritisation Framework</a></h3>
<blockquote>
<p><strong>Prioritisation Framework</strong> [GLOSSARY]</p>
<p>Systematic method to rank backlog items by urgency/importance.</p>
<p><strong>This module's framework</strong>:</p>
<pre><code>Priority score = (Impact + Inclusion) - Effort
</code></pre>
<p><strong>Dimensions (1‚Äì5 scale)</strong>:</p>
<ul>
<li><strong>Impact</strong>: How many people affected? How severe?
<ul>
<li>5 = Blocks task completion for most participants</li>
<li>3 = Slows down or frustrates some participants</li>
<li>1 = Minor annoyance, rare</li>
</ul>
</li>
<li><strong>Inclusion</strong>: Does it disproportionately affect disabled people?
<ul>
<li>5 = SR/keyboard/cognitive disability users can't complete</li>
<li>3 = Affects some disabled participants (e.g., low vision)</li>
<li>1 = Affects everyone equally</li>
</ul>
</li>
<li><strong>Effort</strong>: How hard to fix?
<ul>
<li>5 = Major refactor, &gt;8 hours</li>
<li>3 = Moderate, 2‚Äì4 hours</li>
<li>1 = Quick fix, &lt;1 hour</li>
</ul>
</li>
</ul>
<p><strong>Score interpretation</strong>:</p>
<ul>
<li><strong>8‚Äì10</strong>: Critical‚Äîfix immediately (Week 10 Lab 2)</li>
<li><strong>5‚Äì7</strong>: High priority‚Äîfix if time permits</li>
<li><strong>&lt;5</strong>: Defer or document as known issue</li>
</ul>
<p><strong>Example</strong>:
Issue: "Validation errors not announced by SR"</p>
<ul>
<li>Impact: 5 (blocks T2 completion for SR users)</li>
<li>Inclusion: 5 (disproportionately affects SR users)</li>
<li>Effort: 2 (add <code>role=alert</code>, update template)</li>
<li><strong>Score</strong>: (5+5)-2 = <strong>8</strong> ‚Üí <strong>Priority 1</strong></li>
</ul>
<p><strong>HCI Connection</strong>: Prioritisation makes <strong>inclusion explicit</strong>‚Äînot just "fix the bugs" but "fix barriers first."</p>
<p>üîó <a href="https://www.w3.org/WAI/test-evaluate/report/#prioritise">W3C: Prioritizing Accessibility Issues</a></p>
</blockquote>
<h3 id="evidence-chain-revisited"><a class="header" href="#evidence-chain-revisited">Evidence Chain (Revisited)</a></h3>
<blockquote>
<p><strong>Evidence Chain</strong> [GLOSSARY]</p>
<p>Traceability from raw data ‚Üí analysis ‚Üí finding ‚Üí fix ‚Üí verification.</p>
<p><strong>Week 10 adds analysis layer</strong>:</p>
<ol>
<li><strong>Raw data</strong>: <code>metrics.csv</code> shows <code>T2_edit, js_mode=off, completion_rate=0.5</code></li>
<li><strong>Analysis</strong>: <code>analysis/analysis.csv</code> confirms: median 2300ms, MAD 450ms, error rate 0.5</li>
<li><strong>Interpretation</strong>: No-JS path lacks accessible error feedback (pilot notes confirm)</li>
<li><strong>Finding</strong>: "No-JS edit has 50% completion due to non-focusable error summary"</li>
<li><strong>Prioritisation</strong>: Impact=5, Inclusion=5, Effort=2 ‚Üí Score=8 (Priority 1)</li>
<li><strong>Fix plan</strong>: Add <code>tabindex="-1"</code> to error summary, auto-focus on page load</li>
<li><strong>Verification</strong> (Week 10 Lab 2): Retest with no-JS, measure completion rate ‚â•0.9</li>
</ol>
<p><strong>Gradescope Task 2 requires</strong>:</p>
<ul>
<li>Before metrics (Week 9)</li>
<li>Analysis + prioritisation (Week 10 Lab 1)</li>
<li>After metrics (Week 10 Lab 2)</li>
<li>Evidence chain documented throughout</li>
</ul>
<p>üîó Review Week 9 Lab 2 for initial evidence chain guidance</p>
</blockquote>
<hr />
<h2 id="activity-a-prepare-analysis-workspace-5-min"><a class="header" href="#activity-a-prepare-analysis-workspace-5-min">Activity A: Prepare Analysis Workspace (5 min)</a></h2>
<p><strong>Goal</strong>: Set up directory structure and verify data integrity before analysis.</p>
<h3 id="step-1-create-analysis-directory-2-min"><a class="header" href="#step-1-create-analysis-directory-2-min">Step 1: Create analysis directory (2 min)</a></h3>
<pre><code class="language-bash">mkdir -p analysis
mkdir -p wk10/lab-wk10/docs
mkdir -p wk10/gradescope/task2
</code></pre>
<h3 id="step-2-verify-raw-data-3-min"><a class="header" href="#step-2-verify-raw-data-3-min">Step 2: Verify raw data (3 min)</a></h3>
<p><strong>Open <code>data/metrics.csv</code></strong> and check:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Contains rows for all 5 pilots (session IDs: P1, P2, P3, P4, P5)</li>
<li><input disabled="" type="checkbox"/>
All task codes present (T1, T2, T3, T4)</li>
<li><input disabled="" type="checkbox"/>
<code>step</code> values valid (<code>success</code>, <code>validation_error</code>, <code>fail</code>)</li>
<li><input disabled="" type="checkbox"/>
Durations plausible (not negative, not &gt;10000ms unless noted)</li>
<li><input disabled="" type="checkbox"/>
<code>js_mode</code> correctly set (<code>on</code> for Pilots 1,2,4,5; <code>off</code> for Pilot 3)</li>
</ul>
<p><strong>If issues found</strong>: Review Week 9 <code>data-notes.md</code> for documented anomalies. Exclude corrupt rows or correct manually.</p>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
<code>analysis/</code> directory exists</li>
<li><input disabled="" type="checkbox"/>
<code>data/metrics.csv</code> verified complete</li>
<li><input disabled="" type="checkbox"/>
Ready to run analysis script</li>
</ul>
<hr />
<h2 id="activity-b-calculate-summary-statistics-25-min"><a class="header" href="#activity-b-calculate-summary-statistics-25-min">Activity B: Calculate Summary Statistics (25 min)</a></h2>
<p><strong>Goal</strong>: Generate <code>analysis/analysis.csv</code> with median, MAD, completion, error rates per task.</p>
<h3 id="step-1-run-analysis-script-15-min"><a class="header" href="#step-1-run-analysis-script-15-min">Step 1: Run analysis script (15 min)</a></h3>
<p><strong>Option A: Use provided Kotlin script</strong> (if available at <code>wk10/lab-wk10/scripts/Analyse.kt</code>):</p>
<pre><code class="language-bash">kotlinc wk10/lab-wk10/scripts/Analyse.kt -include-runtime -d analyse.jar
java -jar analyse.jar
</code></pre>
<p><strong>Option B: Manual calculation with spreadsheet</strong>:</p>
<ol>
<li>Import <code>data/metrics.csv</code> into Google Sheets / Excel</li>
<li>Create pivot table grouping by <code>task_code</code> + <code>js_mode</code></li>
<li>Calculate for each group:</li>
</ol>
<p><strong>Median time</strong> (filter <code>step=success</code> only):</p>
<pre><code>=MEDIAN(IF((task=$A2)*(step="success"), ms, ""))
</code></pre>
<p><strong>MAD</strong> (median absolute deviation):</p>
<pre><code>1. Calculate median for group
2. Create column: ABS(ms - median)
3. MEDIAN of that column
</code></pre>
<p><strong>Completion rate</strong>:</p>
<pre><code>=COUNTIF(step, "success") / (COUNTIF(step, "success") + COUNTIF(step, "fail"))
</code></pre>
<p><strong>Error rate</strong>:</p>
<pre><code>=COUNTIF(step, "validation_error") / (COUNTIF(step, "success") + COUNTIF(step, "validation_error"))
</code></pre>
<p><strong>Option C: Python script</strong>:</p>
<pre><code class="language-python">import pandas as pd
import numpy as np

# Load data
df = pd.read_csv('data/metrics.csv')

# Filter success rows for timing
success = df[df['step'] == 'success']

# Group by task and js_mode
grouped = success.groupby(['task_code', 'js_mode'])

# Calculate statistics
stats = grouped['ms'].agg([
    ('n_success', 'count'),
    ('median_ms', 'median'),
    ('mad_ms', lambda x: np.median(np.abs(x - np.median(x))))
]).reset_index()

# Calculate completion rate (per task+js_mode)
total_attempts = df.groupby(['task_code', 'js_mode']).size().reset_index(name='n_total')
success_count = df[df['step']=='success'].groupby(['task_code', 'js_mode']).size().reset_index(name='n_success')
completion = total_attempts.merge(success_count, on=['task_code', 'js_mode'], how='left')
completion['completion_rate'] = completion['n_success'] / completion['n_total']

# Calculate error rate
errors = df[df['step']=='validation_error'].groupby(['task_code', 'js_mode']).size().reset_index(name='n_errors')
error_rate = success_count.merge(errors, on=['task_code', 'js_mode'], how='left').fillna(0)
error_rate['error_rate'] = error_rate['n_errors'] / (error_rate['n_success'] + error_rate['n_errors'])

# Merge all
final = stats.merge(completion[['task_code', 'js_mode', 'completion_rate']], on=['task_code', 'js_mode'])
final = final.merge(error_rate[['task_code', 'js_mode', 'error_rate']], on=['task_code', 'js_mode'])

# Save
final.to_csv('analysis/analysis.csv', index=False)
print(final)
</code></pre>
<h3 id="step-2-verify-output-5-min"><a class="header" href="#step-2-verify-output-5-min">Step 2: Verify output (5 min)</a></h3>
<p><strong>Open <code>analysis/analysis.csv</code></strong>:</p>
<p><strong>Expected columns</strong>:</p>
<pre><code class="language-csv">task_code,js_mode,n_success,median_ms,mad_ms,completion_rate,error_rate
T1_filter,on,5,1899,203,1.00,0.00
T1_filter,off,1,3245,0,1.00,0.00
T2_edit,on,4,1400,184,0.80,0.33
T2_edit,off,0,,,0.00,
T3_add,on,5,567,78,1.00,0.20
T3_add,off,1,3456,0,1.00,0.00
T4_delete,on,5,210,12,1.00,0.00
T4_delete,off,1,198,0,1.00,0.00
</code></pre>
<p><strong>Sanity checks</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Median times plausible (T3 &lt; T2 &lt; T1, since T3 is simplest)</li>
<li><input disabled="" type="checkbox"/>
No-JS times slower than JS-on (expected‚Äîfull page reloads)</li>
<li><input disabled="" type="checkbox"/>
Completion rates ‚â§1.0</li>
<li><input disabled="" type="checkbox"/>
Error rates between 0 and 1</li>
<li><input disabled="" type="checkbox"/>
No NaN/blank for tasks with data</li>
</ul>
<p><strong>If anomalies</strong>: Cross-reference with <code>data/metrics.csv</code>. Document in <code>analysis/data-notes.md</code>.</p>
<h3 id="step-3-add-all-js_mode-aggregate-5-min"><a class="header" href="#step-3-add-all-js_mode-aggregate-5-min">Step 3: Add "all" js_mode aggregate (5 min)</a></h3>
<p>Calculate combined stats (all participants regardless of JS):</p>
<pre><code class="language-python"># Add 'all' js_mode (combines on+off)
all_stats = success.groupby(['task_code'])['ms'].agg([
    ('n_success', 'count'),
    ('median_ms', 'median'),
    ('mad_ms', lambda x: np.median(np.abs(x - np.median(x))))
]).reset_index()
all_stats['js_mode'] = 'all'
# ... repeat for completion/error rates, append to analysis.csv
</code></pre>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
<code>analysis/analysis.csv</code> exists with correct columns</li>
<li><input disabled="" type="checkbox"/>
All tasks present (T1, T2, T3, T4)</li>
<li><input disabled="" type="checkbox"/>
Stats calculated for <code>js_mode=on</code>, <code>off</code>, <code>all</code></li>
<li><input disabled="" type="checkbox"/>
Values plausible (no negative times, completion ‚â§1.0)</li>
</ul>
<hr />
<h2 id="activity-c-interpret-metrics-with-inclusion-lens-25-min"><a class="header" href="#activity-c-interpret-metrics-with-inclusion-lens-25-min">Activity C: Interpret Metrics with Inclusion Lens (25 min)</a></h2>
<p><strong>Goal</strong>: Write narrative interpretation of statistics linking to inclusion barriers.</p>
<h3 id="step-1-create-summary-document-5-min"><a class="header" href="#step-1-create-summary-document-5-min">Step 1: Create summary document (5 min)</a></h3>
<p><strong>Create <code>analysis/summary.md</code></strong>:</p>
<pre><code class="language-markdown"># Pilot Data Analysis Summary ‚Äî Week 10

**Study**: Peer pilots (n=5) conducted Week 9
**Purpose**: Identify usability and accessibility barriers through quantitative + qualitative analysis

---

## Summary Statistics

[Insert tables from analysis.csv]

## Task-by-Task Interpretation

[Analysis for each task with inclusion lens]

## Priority Findings

[Top 3-5 issues for redesign]
</code></pre>
<h3 id="step-2-build-metrics-tables-10-min"><a class="header" href="#step-2-build-metrics-tables-10-min">Step 2: Build metrics tables (10 min)</a></h3>
<p><strong>Copy data from <code>analysis/analysis.csv</code> into Markdown tables</strong>:</p>
<pre><code class="language-markdown">## Task Completion Times (Median ¬± MAD)

| Task | JS-On | JS-Off | All | Notes |
|------|-------|--------|-----|-------|
| T1 (Filter) | 1899ms ¬± 203ms (n=5) | 3245ms ¬± 0ms (n=1) | 2015ms ¬± 380ms (n=6) | No-JS 71% slower |
| T2 (Edit) | 1400ms ¬± 184ms (n=4) | ‚Äî (n=0) | 1400ms ¬± 184ms (n=4) | No-JS: 0% completion |
| T3 (Add) | 567ms ¬± 78ms (n=5) | 3456ms ¬± 0ms (n=1) | 850ms ¬± 890ms (n=6) | No-JS 6√ó slower |
| T4 (Delete) | 210ms ¬± 12ms (n=5) | 198ms ¬± 0ms (n=1) | 208ms ¬± 12ms (n=6) | Consistent |

## Completion &amp; Error Rates

| Task | JS-On Completion | JS-Off Completion | JS-On Errors | JS-Off Errors |
|------|------------------|-------------------|--------------|---------------|
| T1 | 5/5 (100%) | 1/1 (100%) | 0% | 0% |
| T2 | 4/5 (80%) | 0/1 (0%) | 33% | ‚Äî |
| T3 | 5/5 (100%) | 1/1 (100%) | 20% | 0% |
| T4 | 5/5 (100%) | 1/1 (100%) | 0% | 0% |
</code></pre>
<h3 id="step-3-write-task-by-task-interpretations-10-min"><a class="header" href="#step-3-write-task-by-task-interpretations-10-min">Step 3: Write task-by-task interpretations (10 min)</a></h3>
<p><strong>For each task, write 2-3 paragraphs</strong>:</p>
<p><strong>Template</strong>:</p>
<pre><code class="language-markdown">### Task T2: Edit Task

**Quantitative findings**:
- JS-on: 80% completion (4/5), median 1400ms, 33% error rate
- JS-off: 0% completion (0/1)‚Äîparticipant gave up after 2 validation errors
- MAD 184ms (moderate variability‚Äîsome participants breezed through, others struggled)

**Qualitative evidence** (from `pilots/P2-notes.md`, `pilots/P3-notes.md`):
- P2 (keyboard-only): "Blank submission error‚ÄîSR didn't announce error message"
- P3 (no-JS): "Gave up after 2 validation errors‚Äîerror summary not focusable, couldn't find it with Tab"

**Inclusion impact**: **Critical**
- Screen reader users: Error messages not announced (`role="status"` missing)
- Keyboard-only users: Error summary exists but not in tab order (`tabindex="-1"` missing)
- No-JS users: Cannot complete task‚Äîerror summary not focusable, no auto-focus on page load

**WCAG violations**:
- 3.3.1 Error Identification (Level A): Errors not programmatically determinable
- 4.1.3 Status Messages (Level AA): Validation errors not announced
- 3.2.1 On Focus (Level A): Focus not managed after error

**Root cause**: Dual-path error handling incomplete. HTMX path has `hx-swap-oob` status but no `role=alert`. No-JS path renders error summary but doesn't set `tabindex="-1"` or auto-focus.

**Proposed fix** (Priority 1):
- Add `role="alert"` to HTMX error responses
- Add `tabindex="-1"` to no-JS error summary `&lt;div id="error-summary"&gt;`
- Auto-focus error summary on page load (server-side or small progressive enhancement script)
- Add `aria-describedby` linking input to error message

**Expected impact**: Completion rate ‚â•90% for all variants, error rate &lt;10% (with improved affordances).
</code></pre>
<p><strong>Repeat for all 4 tasks</strong>, prioritising those with issues.</p>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Metrics tables complete and formatted</li>
<li><input disabled="" type="checkbox"/>
Task-by-task interpretations written</li>
<li><input disabled="" type="checkbox"/>
Inclusion impacts identified (SR, keyboard, no-JS, cognitive)</li>
<li><input disabled="" type="checkbox"/>
WCAG violations referenced</li>
<li><input disabled="" type="checkbox"/>
Root causes hypothesized</li>
</ul>
<hr />
<h2 id="activity-d-prioritise-backlog-with-scoring-20-min"><a class="header" href="#activity-d-prioritise-backlog-with-scoring-20-min">Activity D: Prioritise Backlog with Scoring (20 min)</a></h2>
<p><strong>Goal</strong>: Rank backlog items by Priority score = (Impact + Inclusion) - Effort.</p>
<h3 id="step-1-create-prioritisation-spreadsheet-5-min"><a class="header" href="#step-1-create-prioritisation-spreadsheet-5-min">Step 1: Create prioritisation spreadsheet (5 min)</a></h3>
<p><strong>Create <code>analysis/prioritisation.csv</code></strong>:</p>
<pre><code class="language-csv">id,title,task_code,problem,impact,inclusion,effort,score,evidence,proposed_fix,candidate_fix
</code></pre>
<h3 id="step-2-score-top-issues-10-min"><a class="header" href="#step-2-score-top-issues-10-min">Step 2: Score top issues (10 min)</a></h3>
<p><strong>For each issue identified in Activity C</strong>:</p>
<ol>
<li><strong>Impact</strong> (1‚Äì5): How many participants affected? How severely?</li>
<li><strong>Inclusion</strong> (1‚Äì5): Disproportionate effect on disabled participants?</li>
<li><strong>Effort</strong> (1‚Äì5): Time to implement fix?</li>
<li><strong>Score</strong>: (Impact + Inclusion) - Effort</li>
</ol>
<blockquote>
<p><strong>üéØ Worked Examples: Scoring Prioritisation</strong></p>
<div class="table-wrapper"><table><thead><tr><th>Issue</th><th>Impact</th><th>Inclusion</th><th>Effort</th><th>Score</th><th>Rationale</th></tr></thead><tbody>
<tr><td><strong>Validation errors not announced (SR)</strong></td><td><strong>5</strong></td><td><strong>5</strong></td><td>2</td><td><strong>8</strong></td><td>Impact=5 (all SR users blocked on edit task), Inclusion=5 (SR-specific barrier), Effort=2 (add <code>role=alert</code>), Score=(5+5)-2=8</td></tr>
<tr><td><strong>No-JS error summary not focusable</strong></td><td><strong>5</strong></td><td><strong>5</strong></td><td>2</td><td><strong>8</strong></td><td>Impact=5 (all no-JS users affected), Inclusion=5 (keyboard/no-mouse users can't navigate), Effort=2 (add <code>tabindex=-1</code>), Score=(5+5)-2=8</td></tr>
<tr><td><strong>Filter result count not announced</strong></td><td><strong>3</strong></td><td><strong>4</strong></td><td>1</td><td><strong>6</strong></td><td>Impact=3 (minor: doesn't block task, but confusing), Inclusion=4 (SR users miss feedback), Effort=1 (move text to live region), Score=(3+4)-1=6</td></tr>
<tr><td><strong>Auto-search confuses some</strong></td><td><strong>3</strong></td><td><strong>2</strong></td><td>2</td><td><strong>3</strong></td><td>Impact=3 (affects 2/5 pilots, minor confusion), Inclusion=2 (not equity-specific), Effort=2 (add button + help text), Score=(3+2)-2=3</td></tr>
<tr><td><strong>No-JS delete lacks confirmation</strong></td><td><strong>2</strong></td><td><strong>2</strong></td><td>4</td><td><strong>0</strong></td><td>Impact=2 (rare: only no-JS + delete use case), Inclusion=2 (low risk, recoverable), Effort=4 (new route + page + tests), Score=(2+2)-4=0 ‚Üí <strong>Deprioritise</strong></td></tr>
</tbody></table>
</div>
<p><strong>Key distinctions</strong>:</p>
<ul>
<li><strong>Impact vs Inclusion</strong>: Impact = "how many people?" / Inclusion = "who is disproportionately affected?"
<ul>
<li>Example 1: High impact (5) + high inclusion (5) = SR validation errors block <strong>everyone</strong> using SR</li>
<li>Example 4: Medium impact (3) + low inclusion (2) = auto-search confusion is <strong>general usability</strong> issue, not equity-specific</li>
</ul>
</li>
<li><strong>When Effort &gt; Benefit</strong>: Example 5 scores 0 (even though impact+inclusion=4) because effort=4 makes ROI negative</li>
<li><strong>Tie-breaking</strong>: Examples 1 &amp; 2 both score 8 ‚Üí prioritise together if they relate to same task (T2_edit)</li>
</ul>
<p><strong>Decision-making</strong>:</p>
<ul>
<li><strong>Priority 1</strong> (fix in Lab 2): Score ‚â•8 + WCAG violation + feasible in 2 hours</li>
<li><strong>Priority 2</strong> (semester 2 backlog): Score 5-7</li>
<li><strong>Deprioritise</strong>: Score &lt;5 or effort outweighs benefit</li>
</ul>
</blockquote>
<p><strong>Example entries</strong>:</p>
<pre><code class="language-csv">wk9-01,"Validation errors not announced by SR",T2_edit,"SR users can't identify validation errors",5,5,2,8,"analysis/summary.md#T2; pilots/P2-notes.md L12","Add role=alert + aria-describedby to error messages",true

wk9-03,"No-JS error summary not focusable",T2_edit,"Keyboard users can't navigate to error summary in no-JS mode",5,5,2,8,"analysis/summary.md#T2; pilots/P3-notes.md L10","Add tabindex=-1, auto-focus on page load",true

wk9-05,"Filter result count not announced",T1_filter,"SR users don't hear how many results remain after filtering",3,4,1,6,"pilots/P2-notes.md L8","Move result count into live region (role=status)",false

wk9-02,"Filter auto-search confuses some",T1_filter,"Some participants expected explicit Apply button",3,2,2,3,"pilots/P1-notes.md L6","Add visible Apply button or help text",false

wk9-04,"No-JS delete has no confirmation",T4_delete,"No-JS participants can't confirm before deleting (documented trade-off)",2,2,4,0,"pilots/P3-notes.md L12; wk08/docs/prototyping-constraints.md","Add /tasks/{id}/delete/confirm page",false
</code></pre>
<h3 id="step-3-rank-and-mark-candidates-5-min"><a class="header" href="#step-3-rank-and-mark-candidates-5-min">Step 3: Rank and mark candidates (5 min)</a></h3>
<p><strong>Sort by <code>score</code> descending</strong>.</p>
<p><strong>Mark top 2-3 items</strong> as <code>candidate_fix=true</code> (these are Priority 1 for Week 10 Lab 2).</p>
<p><strong>Criteria for Priority 1</strong>:</p>
<ul>
<li>Score ‚â•8</li>
<li>WCAG Level A or AA violation</li>
<li>Blocks task completion for disabled participants</li>
<li>Feasible to fix in 2-hour lab session</li>
</ul>
<p><strong>In example above</strong>: wk9-01 and wk9-03 both score 8, both relate to T2 edit, both fixable together ‚Üí <strong>Priority 1</strong>.</p>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
<code>analysis/prioritisation.csv</code> complete with scores</li>
<li><input disabled="" type="checkbox"/>
Issues ranked by score (highest first)</li>
<li><input disabled="" type="checkbox"/>
2-3 Priority 1 items marked <code>candidate_fix=true</code></li>
<li><input disabled="" type="checkbox"/>
Evidence links present for all items</li>
</ul>
<hr />
<h2 id="activity-e-draft-inclusive-redesign-brief-20-min"><a class="header" href="#activity-e-draft-inclusive-redesign-brief-20-min">Activity E: Draft Inclusive Redesign Brief (20 min)</a></h2>
<p><strong>Goal</strong>: Document planned fix with measurable goals and acceptance criteria.</p>
<h3 id="step-1-create-redesign-brief-document-5-min"><a class="header" href="#step-1-create-redesign-brief-document-5-min">Step 1: Create redesign brief document (5 min)</a></h3>
<p><strong>Create <code>wk10/lab-wk10/docs/redesign-brief.md</code></strong>:</p>
<pre><code class="language-markdown"># Inclusive Redesign Brief ‚Äî Week 10 Lab 2

**Target**: [Issue title from prioritisation.csv]
**Priority**: 1 (Score: X)
**Assignee**: [Your name/pair]
**Date**: 2025-10-20

---

## Problem Statement

[2-3 sentences describing the issue backed by data]

---

## Goal

[Measurable target improvement]

---

## Inclusion Impact

[Who benefits and why]

---

## Proposed Changes

[Specific implementation steps]

---

## Acceptance Criteria

[How will we know it's fixed?]

---

## Verification Plan

[Testing protocol]

---

## Risk &amp; Constraints

[Trade-offs, technical limitations]
</code></pre>
<h3 id="step-2-fill-in-sections-15-min"><a class="header" href="#step-2-fill-in-sections-15-min">Step 2: Fill in sections (15 min)</a></h3>
<p><strong>Using T2 edit accessibility issue as example</strong>:</p>
<pre><code class="language-markdown"># Inclusive Redesign Brief ‚Äî Week 10 Lab 2

**Target**: Validation errors not announced by screen readers (wk9-01, wk9-03)
**Priority**: 1 (Score: 8)
**Assignee**: [Your name]
**Date**: 2025-10-20

---

## Problem Statement

Task T2 (Edit Task) has 80% completion for JS-on participants and 0% completion for JS-off participants. Analysis shows:
- 33% error rate (2 validation errors in 6 attempts)
- Median time 1400ms with MAD 184ms (moderate variability)
- Qualitative evidence: "SR didn't announce error message" (P2), "Error summary not focusable" (P3)

**Root cause**: Validation error messages not accessible. HTMX path lacks `role="alert"`. No-JS path renders error summary but doesn't focus it or make it keyboard-navigable.

**WCAG violations**: 3.3.1 Error Identification (A), 4.1.3 Status Messages (AA), 3.2.1 On Focus (A)

---

## Goal

**Target metrics** (Week 10 Lab 2 verification):
- T2 completion rate ‚â•90% for all variants (JS-on, JS-off, keyboard-only, SR)
- T2 error rate &lt;10% (improved affordances reduce accidental blank submissions)
- Zero WCAG 3.3.1 / 4.1.3 violations on retest

**Success means**: Screen reader users hear validation errors immediately. Keyboard-only users can navigate to error summary with Tab. No-JS users see error summary on page load with focus.

---

## Inclusion Impact

**Who benefits**:
- **Screen reader users** (estimated 2-5% of UK population): Can identify and recover from errors independently
- **Keyboard-only users** (motor disabilities, power users): Can navigate to error without mouse
- **Cognitive disabilities**: Clear, announced errors reduce confusion and repeated mistakes
- **Low-bandwidth users** (no-JS fallback): Can complete tasks even with JS disabled

**Equity**: Current design excludes disabled participants‚Äîcompletion rate 0% for no-JS, SR users struggled. Fix restores parity.

---

## Proposed Changes

### Change 1: Add ARIA live region for HTMX errors

**File**: `src/main/kotlin/routes/Tasks.kt`

**Before**:
```kotlin
if (title.isBlank()) {
    val status = """&lt;div id="status" hx-swap-oob="true"&gt;Title is required.&lt;/div&gt;"""
    return@post call.respondText(status, ContentType.Text.Html, HttpStatusCode.BadRequest)
}
</code></pre>
<p><strong>After</strong>:</p>
<pre><code class="language-kotlin">if (title.isBlank()) {
    val status = """&lt;div id="status" role="alert" aria-live="assertive" hx-swap-oob="true"&gt;Title is required. Please enter at least one character.&lt;/div&gt;"""
    return@post call.respondText(status, ContentType.Text.Html, HttpStatusCode.BadRequest)
}
</code></pre>
<p><strong>Rationale</strong>: <code>role="alert"</code> + <code>aria-live="assertive"</code> ensures SR announces error immediately.</p>
<hr />
<h3 id="change-2-make-no-js-error-summary-keyboard-focusable"><a class="header" href="#change-2-make-no-js-error-summary-keyboard-focusable">Change 2: Make no-JS error summary keyboard-focusable</a></h3>
<p><strong>File</strong>: <code>templates/tasks/index.peb</code></p>
<p><strong>Before</strong>:</p>
<pre><code class="language-twig">{% if error %}
&lt;div class="error-summary" id="error-summary"&gt;
  &lt;h2&gt;There is a problem&lt;/h2&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href="#title"&gt;Title is required&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/div&gt;
{% endif %}
</code></pre>
<p><strong>After</strong>:</p>
<pre><code class="language-twig">{% if error %}
&lt;div class="error-summary" id="error-summary" tabindex="-1" role="alert" aria-live="assertive"&gt;
  &lt;h2&gt;There is a problem&lt;/h2&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href="#title"&gt;{% if msg == "too_long" %}Title is too long (max 200 characters){% else %}Title is required{% endif %}&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/div&gt;
&lt;script&gt;
  // Progressive enhancement: auto-focus error summary (no-JS users rely on visual scan)
  if (document.getElementById('error-summary')) {
    document.getElementById('error-summary').focus();
  }
&lt;/script&gt;
{% endif %}
</code></pre>
<p><strong>Rationale</strong>:</p>
<ul>
<li><code>tabindex="-1"</code> makes div focusable programmatically (not in natural tab order)</li>
<li><code>role="alert"</code> + <code>aria-live="assertive"</code> announces to SR on page load</li>
<li>Tiny <code>&lt;script&gt;</code> auto-focuses error (progressive enhancement‚Äîstill works if JS fails)</li>
</ul>
<hr />
<h3 id="change-3-link-input-to-error-message"><a class="header" href="#change-3-link-input-to-error-message">Change 3: Link input to error message</a></h3>
<p><strong>File</strong>: <code>templates/tasks/index.peb</code></p>
<p><strong>Update input</strong>:</p>
<pre><code class="language-twig">&lt;input id="title" name="title" type="text"
       {% if error == "title" %}aria-invalid="true" aria-describedby="title-error"{% endif %}
       required&gt;
{% if error == "title" %}
&lt;p id="title-error" class="error-message" role="alert"&gt;
  {% if msg == "too_long" %}Title is too long (max 200 characters){% else %}Title is required{% endif %}
&lt;/p&gt;
{% endif %}
</code></pre>
<p><strong>Rationale</strong>: <code>aria-describedby</code> links input to error message. SR reads error when focus lands on input.</p>
<hr />
<h2 id="acceptance-criteria"><a class="header" href="#acceptance-criteria">Acceptance Criteria</a></h2>
<h3 id="functional"><a class="header" href="#functional">Functional</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
Blank title submission triggers validation error (both HTMX and no-JS)</li>
<li><input disabled="" type="checkbox"/>
HTMX error appears in <code>#status</code> live region with <code>role="alert"</code></li>
<li><input disabled="" type="checkbox"/>
No-JS error summary appears at top of page</li>
<li><input disabled="" type="checkbox"/>
Error summary has <code>tabindex="-1"</code> and receives focus on page load</li>
</ul>
<h3 id="accessibility-wcag-22-level-aa"><a class="header" href="#accessibility-wcag-22-level-aa">Accessibility (WCAG 2.2 Level AA)</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
<strong>3.3.1 Error Identification (A)</strong>: Error described in text ‚úì</li>
<li><input disabled="" type="checkbox"/>
<strong>4.1.3 Status Messages (AA)</strong>: Error announced by SR without focus change ‚úì</li>
<li><input disabled="" type="checkbox"/>
<strong>3.2.1 On Focus (A)</strong>: Focus managed predictably (lands on error summary) ‚úì</li>
<li><input disabled="" type="checkbox"/>
<strong>1.3.1 Info &amp; Relationships (A)</strong>: <code>aria-describedby</code> links input to error ‚úì</li>
</ul>
<h3 id="testing-protocol"><a class="header" href="#testing-protocol">Testing Protocol</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
<strong>Keyboard-only</strong>: Tab to form, submit blank, Tab to error summary link, press Enter ‚Üí focus lands on <code>#title</code> input</li>
<li><input disabled="" type="checkbox"/>
<strong>Screen reader (NVDA/Orca)</strong>: Submit blank ‚Üí SR announces "Alert. Title is required. Please enter at least one character."</li>
<li><input disabled="" type="checkbox"/>
<strong>No-JS</strong>: Disable JS, submit blank ‚Üí page reloads with error summary focused, Tab order correct</li>
<li><input disabled="" type="checkbox"/>
<strong>Re-run T2 pilot</strong>: 3 participants (1 SR, 1 keyboard, 1 no-JS), measure completion rate</li>
</ul>
<hr />
<h2 id="verification-plan"><a class="header" href="#verification-plan">Verification Plan</a></h2>
<h3 id="quantitative-week-10-lab-2"><a class="header" href="#quantitative-week-10-lab-2">Quantitative (Week 10 Lab 2)</a></h3>
<p>Re-run T2 (Edit Task) with 3 participants:</p>
<ol>
<li><strong>P6</strong>: Standard (HTMX, mouse, JS-on)</li>
<li><strong>P7</strong>: Keyboard-only + NVDA (SR)</li>
<li><strong>P8</strong>: No-JS</li>
</ol>
<p><strong>Measure</strong>:</p>
<ul>
<li>Completion rate (target: 3/3 = 100%)</li>
<li>Error rate (target: &lt;1 error across 3 attempts = &lt;33%)</li>
<li>Median time (expect similar to Week 9: ~1400ms for JS-on)</li>
</ul>
<p><strong>Document in</strong>: <code>wk10/lab-wk10/research/verification-notes.md</code></p>
<h3 id="qualitative"><a class="header" href="#qualitative">Qualitative</a></h3>
<ul>
<li>Capture SR output (transcript snippet) confirming error announcement</li>
<li>Screenshot of no-JS error summary with focus indicator visible</li>
<li>Note any remaining confusion or hesitation</li>
</ul>
<h3 id="backlog-update"><a class="header" href="#backlog-update">Backlog Update</a></h3>
<p>Mark wk9-01 and wk9-03 as <code>status=fixed</code>, append evidence links:</p>
<pre><code class="language-csv">wk9-01,...,fixed,"wk10/lab-wk10/research/verification-notes.md; wk10/lab-wk10/evidence/sr-error-announcement.png"
</code></pre>
<hr />
<h2 id="risk--constraints"><a class="header" href="#risk--constraints">Risk &amp; Constraints</a></h2>
<h3 id="technical-constraints"><a class="header" href="#technical-constraints">Technical Constraints</a></h3>
<ul>
<li><strong>No major refactor</strong>: Must stay within 2-hour lab session</li>
<li><strong>Server-first principle</strong>: Keep HTMX enhancement, ensure no-JS parity</li>
<li><strong>Template complexity</strong>: Adding <code>aria-*</code> attributes increases template size‚Äîacceptable trade-off for accessibility</li>
</ul>
<h3 id="potential-issues"><a class="header" href="#potential-issues">Potential Issues</a></h3>
<ul>
<li><strong>Progressive enhancement script</strong>: Tiny <code>&lt;script&gt;</code> auto-focuses error. If JS fails to load, user must visually scan for error summary‚Äî<strong>acceptable fallback</strong> (error still visible, focusable with Tab).</li>
<li><strong>Multiple errors</strong>: Currently handles one error field. If expanding to multiple fields, need error summary list‚Äî<strong>defer to future</strong> (out of scope for Week 10).</li>
</ul>
<h3 id="trade-offs-accepted"><a class="header" href="#trade-offs-accepted">Trade-offs Accepted</a></h3>
<ul>
<li><strong>No client-side validation</strong>: Sticking with server-side only. Could add <code>maxlength</code> attribute for instant feedback‚Äî<strong>defer</strong> (progressive enhancement for later).</li>
</ul>
<hr />
<h2 id="success-criteria-summary"><a class="header" href="#success-criteria-summary">Success Criteria Summary</a></h2>
<p><strong>Definition of Done</strong>:</p>
<ol>
<li>Code changes committed with tests passing</li>
<li>Verification pilots completed (n=3)</li>
<li>T2 completion rate ‚â•90% (all variants)</li>
<li>Zero WCAG 3.3.1 / 4.1.3 violations</li>
<li>Evidence captured (screenshots, SR transcripts, metrics)</li>
<li>Backlog updated (wk9-01, wk9-03 marked fixed)</li>
<li>Task 2 evidence pack updated with before/after data</li>
</ol>
<p><strong>If not met</strong>: Document blockers, revert changes, choose lower-priority fix.</p>
<pre><code>
‚úã **Stop and check**:
- [ ] Redesign brief complete with all sections
- [ ] Problem backed by Week 9 data
- [ ] Changes specific (file paths, before/after code)
- [ ] Acceptance criteria measurable
- [ ] Verification plan includes quantitative + qualitative testing

---

## Commit &amp; Reflect (10 min)

### Commit message

```bash
git add analysis wk10/lab-wk10/docs/redesign-brief.md backlog/backlog.csv

git commit -m "$(cat &lt;&lt;'EOF'
wk10s1: analysed metrics, prioritised fixes, drafted redesign brief

- Generated analysis/analysis.csv: medians, MAD, completion/error rates per task+js_mode
- Interpreted metrics with inclusion lens: T2 edit has 0% no-JS completion, 33% error rate
- Identified WCAG violations: 3.3.1, 4.1.3 (validation errors not announced/focusable)
- Prioritised backlog using (Impact+Inclusion)-Effort: wk9-01/wk9-03 score=8 (Priority 1)
- Drafted inclusive redesign brief targeting T2 validation error accessibility
- Proposed changes: role=alert for HTMX, tabindex=-1 + auto-focus for no-JS, aria-describedby linking
- Defined acceptance criteria: ‚â•90% completion, zero WCAG violations on retest

Key findings:
- T2 (Edit): 80% JS-on completion, 0% JS-off completion ‚Üí parity failure
- T2 error rate: 33% (blank submissions due to poor affordances)
- T1 (Filter): 100% completion but no-JS 71% slower (acceptable‚Äîfunctional parity maintained)

Ready for Week 10 Lab 2 implementation and verification.


EOF
)"
</code></pre>
<h3 id="reflection-questions-6"><a class="header" href="#reflection-questions-6">Reflection questions</a></h3>
<p><strong>Answer in <code>wk10/reflection.md</code></strong>:</p>
<ol>
<li>
<p><strong>Data interpretation</strong>: What surprised you most in the numbers? Were any findings unexpected based on Week 9 observations?</p>
</li>
<li>
<p><strong>Inclusion lens</strong>: How did the prioritisation framework change which issues you focused on? Would you have chosen differently without the Inclusion dimension?</p>
</li>
<li>
<p><strong>Trade-offs</strong>: Which issues did you deprioritise and why? How comfortable are you with those decisions?</p>
</li>
<li>
<p><strong>Redesign confidence</strong>: How confident are you that the proposed fix will achieve ‚â•90% completion? What uncertainties remain?</p>
</li>
<li>
<p><strong>Evidence chains</strong>: Can you trace wk9-01 from raw <code>metrics.csv</code> ‚Üí <code>analysis/summary.md</code> ‚Üí <code>prioritisation.csv</code> ‚Üí <code>redesign-brief.md</code>? Is anything missing?</p>
</li>
<li>
<p><strong>Week 10 Lab 2 readiness</strong>: What could go wrong during implementation? How will you mitigate?</p>
</li>
</ol>
<hr />
<h2 id="looking-ahead-week-10-lab-2"><a class="header" href="#looking-ahead-week-10-lab-2">Looking Ahead: Week 10 Lab 2</a></h2>
<p>Next session:</p>
<ul>
<li><strong>Implement</strong> Priority 1 fix (T2 validation error accessibility)</li>
<li><strong>Verify</strong> with 3 participants (SR, keyboard, no-JS)</li>
<li><strong>Measure</strong> completion rate, error rate, qualitative observations</li>
<li><strong>Update</strong> backlog with verification evidence</li>
<li><strong>Prepare</strong> Task 2 draft pack (before/after metrics, code diffs, evidence)</li>
</ul>
<p><strong>Before Lab 2</strong>:</p>
<ul>
<li>Review redesign brief (<code>wk10/lab-wk10/docs/redesign-brief.md</code>)</li>
<li>Refresh ARIA syntax (<code>role="alert"</code>, <code>aria-describedby</code>, <code>aria-live</code>)</li>
<li>Prepare verification pilot script (similar to Week 9 protocol)</li>
<li>Check that Week 9 data is committed (don't lose baseline!)</li>
</ul>
<hr />
<h2 id="further-reading--resources-3"><a class="header" href="#further-reading--resources-3">Further Reading &amp; Resources</a></h2>
<h3 id="essential-3"><a class="header" href="#essential-3">Essential</a></h3>
<ul>
<li>Review <a href="wk10/../references/evaluation-metrics-quickref.html">Evaluation Metrics Quick Reference</a> (formulas reference)</li>
<li><a href="https://www.gov.uk/service-manual/measuring-success/using-data-to-improve-your-service">GOV.UK: Using data to improve your service</a></li>
</ul>
<h3 id="statistical-analysis"><a class="header" href="#statistical-analysis">Statistical Analysis</a></h3>
<ul>
<li><a href="https://measuringux.com/">Measuring UX</a> ‚Äî Quantitative UX metrics handbook</li>
<li><a href="https://hci-stats.com/">Statistics for HCI</a> ‚Äî Practical guide for small-sample HCI studies</li>
</ul>
<h3 id="prioritisation"><a class="header" href="#prioritisation">Prioritisation</a></h3>
<ul>
<li><a href="https://www.nngroup.com/articles/how-to-rate-the-severity-of-usability-problems/">Nielsen: Prioritizing Web Usability Problems</a></li>
<li><a href="https://www.w3.org/WAI/test-evaluate/report/#prioritise">W3C: Prioritizing Accessibility Issues</a></li>
<li><a href="https://www.gov.uk/service-manual/user-research/analyse-a-research-session#prioritise-findings">GOV.UK: Prioritising user research findings</a></li>
</ul>
<h3 id="inclusive-design"><a class="header" href="#inclusive-design">Inclusive Design</a></h3>
<ul>
<li><a href="https://www.microsoft.com/design/inclusive/">Microsoft Inclusive Design Toolkit</a></li>
<li><a href="https://www.w3.org/WAI/test-evaluate/involving-users/">W3C: Involving Users in Evaluating Web Accessibility</a></li>
</ul>
<h3 id="academic-1"><a class="header" href="#academic-1">Academic</a></h3>
<ul>
<li><strong>Lazar et al. (2017).</strong> <em>Research Methods in Human-Computer Interaction</em> (2nd ed.). Chapter 11: Statistical analysis</li>
<li><strong>Sauro &amp; Lewis (2016).</strong> <em>Quantifying the User Experience</em> (2nd ed.). Chapters 2-5: Metrics selection and interpretation</li>
</ul>
<hr />
<h2 id="glossary-summary-6"><a class="header" href="#glossary-summary-6">Glossary Summary</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Term</th><th>One-line definition</th></tr></thead><tbody>
<tr><td><strong>Descriptive statistics</strong></td><td>Summarize and describe main features of a dataset (median, range, count)</td></tr>
<tr><td><strong>Median</strong></td><td>Middle value in sorted dataset; 50th percentile; resistant to outliers</td></tr>
<tr><td><strong>MAD (Median Absolute Deviation)</strong></td><td>Robust measure of variability; median of</td></tr>
<tr><td><strong>Completion rate</strong></td><td>Proportion of task attempts that succeeded (effectiveness measure)</td></tr>
<tr><td><strong>Error rate</strong></td><td>Proportion of attempts that triggered validation errors</td></tr>
<tr><td><strong>Prioritisation framework</strong></td><td>Systematic method to rank backlog items by (Impact+Inclusion)-Effort</td></tr>
<tr><td><strong>Evidence chain</strong></td><td>Traceability from raw data ‚Üí analysis ‚Üí finding ‚Üí fix ‚Üí verification</td></tr>
<tr><td><strong>Impact</strong></td><td>How many people affected and how severely (1-5 scale)</td></tr>
<tr><td><strong>Inclusion</strong></td><td>Does issue disproportionately affect disabled people? (1-5 scale)</td></tr>
<tr><td><strong>Effort</strong></td><td>Time/complexity to implement fix (1-5 scale)</td></tr>
</tbody></table>
</div>
<hr />
<p><strong>Lab complete!</strong> You have data-driven insights, prioritised backlog, and a detailed redesign plan. Week 10 Lab 2 will implement and verify the fixes.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-10--lab-2--inclusive-redesign-re-verification-task-2-packaging"><a class="header" href="#week-10--lab-2--inclusive-redesign-re-verification-task-2-packaging">Week 10 ‚Ä¢ Lab 2 ‚Äî Inclusive Redesign, Re-Verification, Task 2 Packaging</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-10-orange" alt="Week 10" />
<img src="https://img.shields.io/badge/Lab-2-green" alt="Lab 2" />
<img src="https://img.shields.io/badge/Status-Draft-yellow" alt="Status" /></p>
<hr />
<h2 id="before-lab-required-reading-10-mins-1"><a class="header" href="#before-lab-required-reading-10-mins-1">Before Lab: Required Reading (10 mins)</a></h2>
<p>üìñ <strong>Essential</strong></p>
<ul>
<li>Review your redesign brief (<code>wk10/lab-wk10/docs/redesign-brief.md</code>)</li>
<li>Review <a href="wk10/../references/assistive-testing-checklist.html">Assistive Testing Checklist</a></li>
<li>Skim the <a href="wk10/../references/screenshot-guide.html">Screenshot Evidence Guide</a></li>
<li><a href="https://www.w3.org/WAI/WCAG22/quickref/">WCAG 2.2 Quick Reference</a> (sections 3.3, 4.1)</li>
</ul>
<p>üìñ <strong>Contextual</strong>:</p>
<ul>
<li><a href="https://webaim.org/techniques/forms/">WebAIM: Creating Accessible Forms</a></li>
<li><a href="https://www.gov.uk/service-manual/helping-people-to-use-your-service/making-your-service-accessible-an-introduction">GOV.UK: Making your service accessible</a></li>
</ul>
<hr />
<h2 id="introduction-from-plan-to-implementation"><a class="header" href="#introduction-from-plan-to-implementation">Introduction: From Plan to Implementation</a></h2>
<p>Week 10 Lab 1 identified Priority 1 fixes through data analysis. <strong>Today you implement and verify those fixes</strong>.</p>
<p><strong>This lab is where HCI theory becomes practice</strong>:</p>
<ul>
<li><strong>Implementation</strong>: Server-first code + HTMX enhancements</li>
<li><strong>Verification</strong>: Rigorous accessibility testing (keyboard, SR, no-JS)</li>
<li><strong>Measurement</strong>: Before/after metrics proving improvement</li>
<li><strong>Documentation</strong>: Evidence chains for Gradescope Task 2</li>
</ul>
<p><strong>Why this matters</strong>:</p>
<ul>
<li><strong>Gradescope Task 2</strong>: Requires before/after metrics + code changes + verification evidence</li>
<li><strong>Week 11 portfolio</strong>: This fix becomes a case study (problem ‚Üí data ‚Üí fix ‚Üí verification)</li>
<li><strong>Professional practice</strong>: Inclusive design is iterative‚Äîimplement, test, measure, refine</li>
</ul>
<p><strong>Quality bar</strong>: Changes must improve accessibility <strong>without breaking existing functionality</strong>. Regression testing is critical.</p>
<hr />
<h2 id="learning-focus-9"><a class="header" href="#learning-focus-9">Learning Focus</a></h2>
<h3 id="lab-objectives-9"><a class="header" href="#lab-objectives-9">Lab Objectives</a></h3>
<p>By the end of this session, you will have:</p>
<ul>
<li>Implemented top 3 prioritised fixes (WCAG 2.2 AA)</li>
<li>Run regression testing (axe + manual keyboard, SR, no-JS)</li>
<li>Re-piloted with n=2 to verify improvements</li>
<li>Measured post-change metrics and compared to baseline</li>
<li>Documented evidence chains (code diffs, screenshots, metrics)</li>
<li>Packaged Task 2 submission with before/after data</li>
</ul>
<h3 id="learning-outcomes-addressed-9"><a class="header" href="#learning-outcomes-addressed-9">Learning Outcomes Addressed</a></h3>
<p>This lab contributes to the following module Learning Outcomes (<a href="wk10/../references/learning-outcomes.html">full definitions</a>):</p>
<ul>
<li><strong>LO4</strong>: Evaluate for accessibility ‚Äî evidenced by regression testing</li>
<li><strong>LO6</strong>: Apply iterative design ‚Äî evidenced by redesign ‚Üí re-verification cycle</li>
<li><strong>LO9</strong>: Apply inclusive design ‚Äî evidenced by WCAG-compliant redesign</li>
<li><strong>LO12</strong>: Demonstrate professionalism ‚Äî evidenced by evidence chains in documentation
Maps to WCAG: 2.2 AA (demonstrable compliance)</li>
</ul>
<hr />
<h2 id="key-concepts-8"><a class="header" href="#key-concepts-8">Key Concepts</a></h2>
<h3 id="regression-testing"><a class="header" href="#regression-testing">Regression Testing</a></h3>
<blockquote>
<p><strong>Regression Testing</strong> [GLOSSARY]</p>
<p>Verifying that new changes don't break existing functionality. Critical when fixing accessibility issues.</p>
<p><strong>HCI context</strong>: Fixing one accessibility issue can inadvertently break another. Example:</p>
<ul>
<li>Fix: Add <code>role="alert"</code> to error messages (helps SR users)</li>
<li>Regression: Alert interrupts SR navigation mid-task (too assertive)</li>
<li>Solution: Use <code>aria-live="polite"</code> instead</li>
</ul>
<p><strong>Regression checklist covers</strong>:</p>
<ul>
<li>Keyboard navigation (tab order, focus indicators)</li>
<li>Screen reader announcements (live regions, labels)</li>
<li>No-JS parity (functionality without JavaScript)</li>
<li>Visual rendering (contrast, zoom, reflow)</li>
</ul>
<p><strong>Best practice</strong>: Test with same protocol used in Week 9 pilots‚Äîensures comparability.</p>
<p>üîó <a href="https://www.w3.org/WAI/test-evaluate/combined-expertise/">W3C: Regression Testing for Accessibility</a></p>
</blockquote>
<h3 id="beforeafter-metrics"><a class="header" href="#beforeafter-metrics">Before/After Metrics</a></h3>
<blockquote>
<p><strong>Before/After Metrics</strong> [GLOSSARY]</p>
<p>Quantitative comparison showing improvement from intervention. Core of evidence-based HCI.</p>
<p><strong>Requirement</strong>: Baseline (Week 9) + post-change (Week 10 Lab 2) measured identically.</p>
<p><strong>Example</strong>:</p>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>Before</th><th>After</th><th>Œî</th><th>Interpretation</th></tr></thead><tbody>
<tr><td>T2 completion (no-JS)</td><td>50%</td><td>100%</td><td>+50%</td><td>Fix restored parity</td></tr>
<tr><td>T2 error rate</td><td>33%</td><td>10%</td><td>-23%</td><td>Improved affordances</td></tr>
<tr><td>T2 median time (all)</td><td>1400ms</td><td>1250ms</td><td>-150ms</td><td>Faster (less confusion)</td></tr>
</tbody></table>
</div>
<p><strong>HCI connection</strong>: Before/after metrics demonstrate <strong>measurable impact</strong>‚Äînot just "we fixed it" but "completion improved by 50%."</p>
<p><strong>Gradescope Task 2 requires</strong>: Table + narrative explaining significance (who benefits, why it matters).</p>
<p>üîó <a href="https://measuringux.com/before-after/">Measuring UX: Before/After Studies</a></p>
</blockquote>
<h3 id="accessible-error-handling"><a class="header" href="#accessible-error-handling">Accessible Error Handling</a></h3>
<blockquote>
<p><strong>Accessible Error Handling</strong> [GLOSSARY]</p>
<p>Validation errors must be perceivable, understandable, and recoverable for all participants.</p>
<p><strong>WCAG requirements</strong>:</p>
<ul>
<li><strong>3.3.1 Error Identification (A)</strong>: Errors identified in text and programmatically determinable</li>
<li><strong>3.3.3 Error Suggestion (AA)</strong>: Provide correction suggestions when known</li>
<li><strong>4.1.3 Status Messages (AA)</strong>: Messages announced without focus change</li>
</ul>
<p><strong>Best practices</strong>:</p>
<ul>
<li><strong>Inline errors</strong>: <code>aria-describedby</code> links input to error message</li>
<li><strong>Summary errors</strong>: Page-level alert with links to problem fields</li>
<li><strong>Live regions</strong>: <code>role="alert"</code> for HTMX, <code>aria-live="assertive"</code> for critical errors</li>
<li><strong>Focus management</strong>: Move focus to error summary (no-JS) or keep on input (HTMX)</li>
</ul>
<p><strong>Example (HTMX)</strong>:</p>
<pre><code class="language-html">&lt;!-- OOB status update --&gt;
&lt;div id="status" role="alert" aria-live="assertive" hx-swap-oob="true"&gt;
  Title is required. Please enter at least one character.
&lt;/div&gt;
</code></pre>
<p><strong>Example (no-JS)</strong>:</p>
<pre><code class="language-html">&lt;!-- Error summary at top of page --&gt;
&lt;div id="error-summary" role="alert" tabindex="-1"&gt;
  &lt;h2&gt;There is a problem&lt;/h2&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href="#title"&gt;Title is required&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/div&gt;
&lt;!-- Input with aria-describedby --&gt;
&lt;input id="title" aria-invalid="true" aria-describedby="title-error"&gt;
&lt;p id="title-error"&gt;Title is required. Please enter at least one character.&lt;/p&gt;
</code></pre>
<p>üîó <a href="https://design-system.service.gov.uk/components/error-message/">GOV.UK: Error Message Pattern</a></p>
</blockquote>
<h3 id="code-diffs-for-evidence"><a class="header" href="#code-diffs-for-evidence">Code Diffs for Evidence</a></h3>
<blockquote>
<p><strong>Code Diffs</strong> [GLOSSARY]</p>
<p>Side-by-side comparison showing what changed. Essential for Task 2 evidence.</p>
<p><strong>Format</strong>:</p>
<pre><code class="language-diff">- &lt;div id="status" hx-swap-oob="true"&gt;Title is required.&lt;/div&gt;
+ &lt;div id="status" role="alert" aria-live="assertive" hx-swap-oob="true"&gt;
+   Title is required. Please enter at least one character.
+ &lt;/div&gt;
</code></pre>
<p><strong>What to include</strong>:</p>
<ul>
<li>File path (e.g., <code>src/main/kotlin/routes/Tasks.kt:45</code>)</li>
<li>Before/after code (3-5 lines context)</li>
<li>Brief explanation of change and WCAG impact</li>
</ul>
<p><strong>Generate automatically</strong>:</p>
<pre><code class="language-bash">git diff wk9-baseline..HEAD -- templates/ &gt; wk10/gradescope/task2/04-key-diffs.md
</code></pre>
<p><strong>HCI connection</strong>: Diffs make fixes <strong>transparent and reproducible</strong>‚Äîassessors and peers can see exactly what changed.</p>
<p>üîó <a href="https://git-scm.com/docs/git-diff">Git: Generating Diffs</a></p>
</blockquote>
<hr />
<h2 id="activity-a-implement-priority-1-fix-40-min"><a class="header" href="#activity-a-implement-priority-1-fix-40-min">Activity A: Implement Priority 1 Fix (40 min)</a></h2>
<p><strong>Goal</strong>: Execute redesign plan from Week 10 Lab 1 brief.</p>
<h3 id="step-1-review-redesign-brief-5-min"><a class="header" href="#step-1-review-redesign-brief-5-min">Step 1: Review redesign brief (5 min)</a></h3>
<p>Open <code>wk10/lab-wk10/docs/redesign-brief.md</code> and confirm:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Problem statement clear (backed by Week 9 data)</li>
<li><input disabled="" type="checkbox"/>
Proposed changes specific (file paths, before/after code)</li>
<li><input disabled="" type="checkbox"/>
Acceptance criteria measurable</li>
<li><input disabled="" type="checkbox"/>
Verification plan defined</li>
</ul>
<p><strong>Assign roles</strong> (if pair programming):</p>
<ul>
<li><strong>Driver</strong>: Writes code</li>
<li><strong>Navigator</strong>: Reviews changes, runs tests, checks against brief</li>
</ul>
<p><strong>Swap after 20 min</strong>.</p>
<h3 id="step-2-implement-server-side-changes-15-min"><a class="header" href="#step-2-implement-server-side-changes-15-min">Step 2: Implement server-side changes (15 min)</a></h3>
<p><strong>Example: T2 edit validation error accessibility</strong></p>
<p><strong>File</strong>: <code>src/main/kotlin/routes/Tasks.kt</code></p>
<p><strong>Before</strong> (Week 9 baseline):</p>
<pre><code class="language-kotlin">post("/tasks/{id}/edit") {
    val id = call.parameters["id"]?.toIntOrNull() ?: return@post call.respond(HttpStatusCode.BadRequest)
    val title = call.receiveParameters()["title"].orEmpty().trim()

    if (title.isBlank()) {
        if (call.isHtmx()) {
            val status = """&lt;div id="status" hx-swap-oob="true"&gt;Title is required.&lt;/div&gt;"""
            return@post call.respondText(status, ContentType.Text.Html, HttpStatusCode.BadRequest)
        } else {
            return@post call.respondRedirect("/tasks/{id}/edit?error=title")
        }
    }

    // Success path...
}
</code></pre>
<p><strong>After</strong> (Week 10 fix):</p>
<pre><code class="language-kotlin">post("/tasks/{id}/edit") {
    val id = call.parameters["id"]?.toIntOrNull() ?: return@post call.respond(HttpStatusCode.BadRequest)
    val title = call.receiveParameters()["title"].orEmpty().trim()

    if (title.isBlank()) {
        if (call.isHtmx()) {
            // CHANGE: Added role="alert" + aria-live="assertive" for SR announcement
            val status = """&lt;div id="status" role="alert" aria-live="assertive" hx-swap-oob="true"&gt;
                Title is required. Please enter at least one character.
            &lt;/div&gt;"""
            return@post call.respondText(status, ContentType.Text.Html, HttpStatusCode.BadRequest)
        } else {
            // CHANGE: Redirect to edit page with error param (focus handled in template)
            return@post call.respondRedirect("/tasks?error=title&amp;edit_id=$id")
        }
    }

    // Success path unchanged
    repo.update(id, title)
    if (call.isHtmx()) {
        val item = PebbleRender.render("tasks/_item.peb", mapOf("t" to repo.get(id)))
        val status = """&lt;div id="status" role="status" aria-live="polite" hx-swap-oob="true"&gt;
            Updated "${repo.get(id)?.title}".
        &lt;/div&gt;"""
        call.respondText(item + status, ContentType.Text.Html)
    } else {
        call.respondRedirect("/tasks")
    }
}
</code></pre>
<p><strong>Key changes</strong>:</p>
<ol>
<li><strong>HTMX error</strong>: Added <code>role="alert"</code> + <code>aria-live="assertive"</code> ‚Üí SR announces immediately</li>
<li><strong>HTMX success</strong>: Changed to <code>role="status"</code> + <code>aria-live="polite"</code> ‚Üí less intrusive</li>
<li><strong>No-JS error</strong>: Redirect includes <code>edit_id</code> ‚Üí template can focus correct field</li>
</ol>
<h3 id="step-3-implement-template-changes-15-min"><a class="header" href="#step-3-implement-template-changes-15-min">Step 3: Implement template changes (15 min)</a></h3>
<p><strong>File</strong>: <code>templates/tasks/index.peb</code></p>
<p><strong>Add error summary</strong> (for no-JS path):</p>
<pre><code class="language-twig">{% if error %}
&lt;div id="error-summary" class="error-summary" role="alert" aria-live="assertive" tabindex="-1"&gt;
  &lt;h2&gt;There is a problem&lt;/h2&gt;
  &lt;ul&gt;
    {% if error == "title" %}
    &lt;li&gt;&lt;a href="#title"&gt;Title is required. Please enter at least one character.&lt;/a&gt;&lt;/li&gt;
    {% endif %}
  &lt;/ul&gt;
&lt;/div&gt;
&lt;script&gt;
  // Progressive enhancement: auto-focus error summary
  // Works even if JS loaded late; gracefully degrades if JS disabled after page load
  (function() {
    var errorSummary = document.getElementById('error-summary');
    if (errorSummary) {
      errorSummary.focus();
    }
  })();
&lt;/script&gt;
{% endif %}
</code></pre>
<p><strong>Update form input</strong> (link to error):</p>
<pre><code class="language-twig">&lt;label for="title"&gt;Task title&lt;/label&gt;
&lt;input id="title" name="title" type="text"
       {% if error == "title" %}
       aria-invalid="true"
       aria-describedby="title-hint title-error"
       {% else %}
       aria-describedby="title-hint"
       {% endif %}
       required&gt;

&lt;p id="title-hint" class="hint"&gt;Keep titles short and specific.&lt;/p&gt;

{% if error == "title" %}
&lt;p id="title-error" class="error-message" role="alert"&gt;
  Title is required. Please enter at least one character.
&lt;/p&gt;
{% endif %}
</code></pre>
<p><strong>Key changes</strong>:</p>
<ol>
<li><strong>Error summary</strong>: <code>role="alert"</code> + <code>tabindex="-1"</code> + auto-focus script</li>
<li><strong>Input</strong>: <code>aria-invalid="true"</code> when error present</li>
<li><strong>aria-describedby</strong>: Links input to both hint and error</li>
<li><strong>Inline error</strong>: <code>role="alert"</code> for immediate announcement</li>
</ol>
<h3 id="step-4-test-manually-5-min"><a class="header" href="#step-4-test-manually-5-min">Step 4: Test manually (5 min)</a></h3>
<p><strong>Start server</strong>: <code>./gradlew run</code></p>
<p><strong>Test HTMX path</strong>:</p>
<ol>
<li>Navigate to <code>/tasks</code></li>
<li>Click Edit on a task</li>
<li>Clear title field, click Save</li>
<li><strong>Expected</strong>: Status message appears immediately ("Title is required...")</li>
<li><strong>Verify with SR</strong> (if available): Message should be announced without focus change</li>
</ol>
<p><strong>Test no-JS path</strong>:</p>
<ol>
<li>Disable JavaScript (DevTools ‚Üí Settings ‚Üí Disable JavaScript)</li>
<li>Hard refresh (Ctrl+Shift+R)</li>
<li>Click Edit on a task</li>
<li>Clear title, click Save</li>
<li><strong>Expected</strong>: Page reloads with error summary at top, summary has focus (visible outline)</li>
<li><strong>Verify</strong>: Tab order ‚Üí error summary link ‚Üí click link ‚Üí focus lands on <code>#title</code> input</li>
</ol>
<p><strong>Test keyboard</strong>:</p>
<ol>
<li>Tab through entire flow (Edit ‚Üí clear ‚Üí submit ‚Üí error summary ‚Üí error link ‚Üí input)</li>
<li><strong>Verify</strong>: All elements reachable, focus visible, no keyboard traps</li>
</ol>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
HTMX error path works (status appears, SR announces)</li>
<li><input disabled="" type="checkbox"/>
No-JS error path works (summary focused, link navigates to input)</li>
<li><input disabled="" type="checkbox"/>
Keyboard navigation smooth (no traps, focus visible)</li>
<li><input disabled="" type="checkbox"/>
No console errors</li>
</ul>
<hr />
<h2 id="activity-b-run-regression-checklist-20-min"><a class="header" href="#activity-b-run-regression-checklist-20-min">Activity B: Run Regression Checklist (20 min)</a></h2>
<p><strong>Goal</strong>: Verify fix didn't break existing functionality or introduce new accessibility issues.</p>
<h3 id="step-1-download-regression-checklist-2-min"><a class="header" href="#step-1-download-regression-checklist-2-min">Step 1: Download regression checklist (2 min)</a></h3>
<p><strong>Create <code>wk10/lab-wk10/a11y/regression-checklist.csv</code></strong>:</p>
<pre><code class="language-csv">category,check,pass,notes
Keyboard,All interactive elements reachable with Tab,,
Keyboard,Focus order matches visual order,,
Keyboard,Focus indicators visible on all elements,,
Keyboard,No keyboard traps,,
Keyboard,Skip link functional,,
Screen Reader,All form labels announced,,
Screen Reader,Error messages announced (role=alert),,
Screen Reader,Success messages announced (role=status),,
Screen Reader,Live regions working (filter results count etc),,
Screen Reader,Headings navigable (H key in NVDA/Orca),,
Forms,Errors identified in text,,
Forms,Errors linked to inputs (aria-describedby),,
Forms,aria-invalid set when error present,,
Forms,Error suggestions provided (when applicable),,
No-JS,All tasks completable with JS disabled,,
No-JS,Error summary focusable and keyboard-navigable,,
No-JS,PRG pattern working (refresh doesn't duplicate),,
No-JS,Full page renders vs fragments (correct responses),,
Visual,Contrast meets WCAG AA (4.5:1 text),,
Visual,200% zoom: no horizontal scroll,,
Visual,Error messages visible (not color-only),,
Visual,Focus indicators meet contrast requirements,,
</code></pre>
<h3 id="step-2-execute-checklist-15-min"><a class="header" href="#step-2-execute-checklist-15-min">Step 2: Execute checklist (15 min)</a></h3>
<p><strong>Work through each row systematically</strong>:</p>
<p><strong>Keyboard testing</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Tab from skip link ‚Üí forms ‚Üí buttons ‚Üí tasks ‚Üí pagination</li>
<li><input disabled="" type="checkbox"/>
Shift+Tab reverses order</li>
<li><input disabled="" type="checkbox"/>
Enter activates links/buttons, Space toggles checkboxes</li>
<li><input disabled="" type="checkbox"/>
Escape closes modals (if any)</li>
<li><input disabled="" type="checkbox"/>
Focus visible on all stops (blue outline or similar)</li>
</ul>
<p><strong>Screen reader testing</strong> (NVDA Windows / Orca Linux):</p>
<ul>
<li><input disabled="" type="checkbox"/>
Navigate headings with H key ‚Üí hears "Tasks", "Add Task", etc.</li>
<li><input disabled="" type="checkbox"/>
Forms mode (F key) ‚Üí lands on first input</li>
<li><input disabled="" type="checkbox"/>
Error submission ‚Üí hears "Alert. Title is required..."</li>
<li><input disabled="" type="checkbox"/>
Success submission ‚Üí hears "Updated [title]" (or similar)</li>
<li><input disabled="" type="checkbox"/>
Filter results ‚Üí hears "Showing 3 tasks" (if live region present)</li>
</ul>
<p><strong>No-JS testing</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Disable JS, hard refresh</li>
<li><input disabled="" type="checkbox"/>
Add task ‚Üí works (PRG redirect)</li>
<li><input disabled="" type="checkbox"/>
Submit blank form ‚Üí error summary appears and focused</li>
<li><input disabled="" type="checkbox"/>
Click error link ‚Üí focus moves to input</li>
<li><input disabled="" type="checkbox"/>
Edit task ‚Üí works (full page reload)</li>
<li><input disabled="" type="checkbox"/>
Delete task ‚Üí works (no confirmation expected‚Äîdocumented trade-off)</li>
</ul>
<p><strong>Visual testing</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Use contrast checker (DevTools ‚Üí CSS Overview or extension)</li>
<li><input disabled="" type="checkbox"/>
Zoom to 200% (Ctrl/Cmd + plus) ‚Üí no horizontal scroll</li>
<li><input disabled="" type="checkbox"/>
Error states visible without color (text, icons, position)</li>
</ul>
<h3 id="step-3-document-results-3-min"><a class="header" href="#step-3-document-results-3-min">Step 3: Document results (3 min)</a></h3>
<p><strong>Fill in <code>pass</code> column</strong>: <code>yes</code>, <code>no</code>, <code>n/a</code></p>
<p><strong>Fill in <code>notes</code> column</strong> for failures or concerns:</p>
<p><strong>Example</strong>:</p>
<pre><code class="language-csv">category,check,pass,notes
Screen Reader,Error messages announced (role=alert),yes,"NVDA announces immediately after submit"
No-JS,Error summary focusable and keyboard-navigable,yes,"Focus indicator visible, Tab order correct"
Visual,Focus indicators meet contrast requirements,no,"Blue outline has 2.8:1 contrast‚Äîneeds 3:1. Log backlog item wk10-07"
</code></pre>
<p><strong>If failures found</strong>:</p>
<ul>
<li><strong>Critical</strong> (blocks task completion): Fix immediately before proceeding</li>
<li><strong>High</strong> (accessibility barrier): Log backlog item, document in notes</li>
<li><strong>Medium/Low</strong>: Acceptable if documented in constraints/known issues</li>
</ul>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Regression checklist complete (all rows filled)</li>
<li><input disabled="" type="checkbox"/>
No critical failures (or fixed)</li>
<li><input disabled="" type="checkbox"/>
Evidence captured (screenshots if needed for failures)</li>
</ul>
<hr />
<h2 id="activity-c-collect-post-change-metrics-25-min"><a class="header" href="#activity-c-collect-post-change-metrics-25-min">Activity C: Collect Post-Change Metrics (25 min)</a></h2>
<p><strong>Goal</strong>: Run targeted pilots to measure improvement.</p>
<h3 id="step-1-prepare-verification-pilots-5-min"><a class="header" href="#step-1-prepare-verification-pilots-5-min">Step 1: Prepare verification pilots (5 min)</a></h3>
<p><strong>Minimal protocol</strong> (adapted from Week 9):</p>
<ul>
<li><strong>n=3 participants</strong> (yourself + 2 peers, or 3 quick runs with different variants)</li>
<li><strong>Focus on changed task</strong> (T2 edit in our example)</li>
<li><strong>Variants</strong>: 1√ó standard (HTMX), 1√ó keyboard/SR, 1√ó no-JS</li>
</ul>
<p><strong>Generate session IDs</strong>:</p>
<pre><code class="language-bash"># P6: Standard (HTMX, JS-on)
# P7: Keyboard + NVDA (SR)
# P8: No-JS
</code></pre>
<p><strong>Set cookies</strong>:</p>
<pre><code class="language-javascript">document.cookie = "sid=P6_post; path=/";
</code></pre>
<h3 id="step-2-run-verification-pilots-15-min"><a class="header" href="#step-2-run-verification-pilots-15-min">Step 2: Run verification pilots (15 min)</a></h3>
<p><strong>For each participant</strong>:</p>
<ol>
<li>Read consent (quick version: "Testing post-fix, ~5 min, can stop anytime")</li>
<li>Navigate to <code>/tasks</code></li>
<li>Run T2 (Edit task): "Change 'Submit invoices' to 'Submit invoices by Friday'"</li>
<li><strong>Intentionally trigger error</strong> once (submit blank) to test error handling</li>
<li>Then complete successfully</li>
<li>Note completion (yes/no), errors (count), time (from logs), confidence (1-5)</li>
</ol>
<p><strong>Example pilot P7 (keyboard + SR)</strong>:</p>
<pre><code>P7_post (NVDA, keyboard-only):
- T2 attempt 1: Blank submission ‚Üí Error announced "Alert. Title is required..." ‚úì
- T2 attempt 2: Success ‚Üí "Updated Submit invoices by Friday" announced ‚úì
- Completion: yes
- Errors: 1 (intentional blank)
- Time: 1356ms (from metrics.csv)
- Confidence: 5
- Notes: "Error was clear this time, heard it immediately"
</code></pre>
<h3 id="step-3-analyze-post-change-data-5-min"><a class="header" href="#step-3-analyze-post-change-data-5-min">Step 3: Analyze post-change data (5 min)</a></h3>
<p><strong>Open <code>data/metrics.csv</code></strong>, filter for session IDs <code>P6_post</code>, <code>P7_post</code>, <code>P8_post</code>.</p>
<p><strong>Calculate same metrics as Week 9</strong>:</p>
<ul>
<li>Completion rate: 3/3 = 100% ‚úì (was 80% JS-on, 0% JS-off)</li>
<li>Error rate: 1/4 attempts = 25% (was 33%‚Äîslight improvement)</li>
<li>Median time (success only): median([1356, 1289, 3201]) = 1356ms
<ul>
<li>JS-on: 1322ms (was 1400ms‚Äîfaster)</li>
<li>JS-off: 3201ms (was N/A‚Äînow functional!)</li>
</ul>
</li>
</ul>
<p><strong>Update <code>analysis/summary.md</code></strong>:</p>
<pre><code class="language-markdown">## Before/After Comparison

### Task T2 (Edit Task)

| Metric | Before (Week 9) | After (Week 10) | Œî | Interpretation |
|--------|-----------------|-----------------|---|----------------|
| Completion (JS-on) | 4/5 (80%) | 2/2 (100%) | +20% | All participants succeeded |
| Completion (JS-off) | 0/1 (0%) | 1/1 (100%) | +100% | **Parity restored** |
| Completion (all) | 4/6 (67%) | 3/3 (100%) | +33% | Fix eliminated failures |
| Error rate (all) | 2/6 (33%) | 1/4 (25%) | -8% | Improved affordances |
| Median time (JS-on) | 1400ms | 1322ms | -78ms | Slightly faster (less confusion) |
| Median time (JS-off) | N/A | 3201ms | ‚Äî | Functional (expected slower) |

### Key Improvements

**Accessibility**:
- Screen reader users: Error messages now announced immediately (`role="alert"`)
- Keyboard-only users: Error summary keyboard-navigable (`tabindex="-1"`, auto-focus)
- No-JS users: Can now complete task (was blocked before)

**WCAG Compliance**:
- ‚úÖ 3.3.1 Error Identification (Level A): Errors identified in text and programmatically
- ‚úÖ 4.1.3 Status Messages (Level AA): Validation errors announced without focus change
- ‚úÖ 3.2.1 On Focus (Level A): Focus managed predictably (error summary ‚Üí input)

**Impact**:
- **Who benefits**: Estimated 2-5% UK population (SR users) + keyboard-only + no-JS users
- **Severity**: High ‚Üí Resolved (task was previously impossible for no-JS, difficult for SR)
</code></pre>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Post-change metrics collected (n=3 minimum)</li>
<li><input disabled="" type="checkbox"/>
Before/after comparison table complete</li>
<li><input disabled="" type="checkbox"/>
Narrative interpretation written</li>
<li><input disabled="" type="checkbox"/>
Evidence captured (SR transcript, screenshots)</li>
</ul>
<hr />
<h2 id="activity-d-package-task-2-evidence-bundle-20-min"><a class="header" href="#activity-d-package-task-2-evidence-bundle-20-min">Activity D: Package Task 2 Evidence Bundle (20 min)</a></h2>
<p><strong>Goal</strong>: Assemble all artefacts for Gradescope submission.</p>
<p><strong>Directory structure</strong>: <code>wk10/gradescope/task2/</code></p>
<h3 id="step-1-copycreate-core-documents-10-min"><a class="header" href="#step-1-copycreate-core-documents-10-min">Step 1: Copy/create core documents (10 min)</a></h3>
<p><strong>1. <code>01-redesign-brief.md</code></strong>:</p>
<ul>
<li>Copy from <code>wk10/lab-wk10/docs/redesign-brief.md</code></li>
<li>Update "Success Criteria Summary" section with actual results</li>
</ul>
<p><strong>2. <code>02-regression-checklist.csv</code></strong>:</p>
<ul>
<li>Copy from <code>wk10/lab-wk10/a11y/regression-checklist.csv</code></li>
<li>Ensure all rows filled with pass/notes</li>
</ul>
<p><strong>3. <code>03-before-after-summary.md</code></strong>:</p>
<ul>
<li>Copy before/after table from <code>analysis/summary.md</code></li>
<li>Add 2-3 paragraph narrative:
<ul>
<li>What changed (code + UX)</li>
<li>Who benefits (inclusion impact)</li>
<li>Evidence of improvement (completion +33%, parity restored)</li>
</ul>
</li>
</ul>
<p><strong>Example</strong>:</p>
<pre><code class="language-markdown"># Before/After Summary ‚Äî Task 2

## Problem Addressed

Task T2 (Edit Task) had 67% overall completion in Week 9 pilots, with 0% completion for no-JS participants. Root cause: validation errors not accessible to screen readers or keyboard users.

## Solution Implemented

Added accessible error handling:
- HTMX: `role="alert"` + `aria-live="assertive"` for immediate SR announcement
- No-JS: Error summary with `tabindex="-1"` + auto-focus on page load
- Both: `aria-describedby` linking inputs to error messages

## Results

[Insert before/after table from Activity C]

## Impact

Fix restored functional parity for no-JS users (0% ‚Üí 100% completion) and improved accessibility for screen reader and keyboard-only users. WCAG 2.2 Level AA compliance achieved (3.3.1, 4.1.3, 3.2.1).
</code></pre>
<p><strong>4. <code>04-key-diffs.md</code></strong>:</p>
<p>Generate code diffs:</p>
<pre><code class="language-bash">git diff wk9-baseline..HEAD -- templates/tasks/index.peb src/main/kotlin/routes/Tasks.kt &gt; wk10/gradescope/task2/04-key-diffs.md
</code></pre>
<p>Annotate with explanations:</p>
<pre><code class="language-markdown"># Key Code Changes ‚Äî Task 2

## File: `src/main/kotlin/routes/Tasks.kt` (Line 45)

### Before
```kotlin
val status = """&lt;div id="status" hx-swap-oob="true"&gt;Title is required.&lt;/div&gt;"""
</code></pre>
<h3 id="after"><a class="header" href="#after">After</a></h3>
<pre><code class="language-kotlin">val status = """&lt;div id="status" role="alert" aria-live="assertive" hx-swap-oob="true"&gt;
    Title is required. Please enter at least one character.
&lt;/div&gt;"""
</code></pre>
<p><strong>Change</strong>: Added <code>role="alert"</code> + <code>aria-live="assertive"</code></p>
<p><strong>Rationale</strong>: Ensures screen readers announce validation errors immediately without focus change (WCAG 4.1.3 Status Messages).</p>
<hr />
<h2 id="file-templatestasksindexpeb-line-23"><a class="header" href="#file-templatestasksindexpeb-line-23">File: <code>templates/tasks/index.peb</code> (Line 23)</a></h2>
<h3 id="before"><a class="header" href="#before">Before</a></h3>
<pre><code class="language-twig">{% if error %}
&lt;div class="alert"&gt;Could not save&lt;/div&gt;
{% endif %}
</code></pre>
<h3 id="after-1"><a class="header" href="#after-1">After</a></h3>
<pre><code class="language-twig">{% if error %}
&lt;div id="error-summary" class="error-summary" role="alert" aria-live="assertive" tabindex="-1"&gt;
  &lt;h2&gt;There is a problem&lt;/h2&gt;
  &lt;ul&gt;
    &lt;li&gt;&lt;a href="#title"&gt;Title is required. Please enter at least one character.&lt;/a&gt;&lt;/li&gt;
  &lt;/ul&gt;
&lt;/div&gt;
&lt;script&gt;
  (function() {
    var errorSummary = document.getElementById('error-summary');
    if (errorSummary) { errorSummary.focus(); }
  })();
&lt;/script&gt;
{% endif %}
</code></pre>
<p><strong>Changes</strong>:</p>
<ol>
<li>Structured error summary (heading + list of errors)</li>
<li><code>tabindex="-1"</code> makes div focusable programmatically</li>
<li>Auto-focus script (progressive enhancement)</li>
<li><code>role="alert"</code> announces to SR on page load</li>
</ol>
<p><strong>Rationale</strong>: No-JS users can now navigate to error summary with keyboard, fixing 0% completion rate (WCAG 3.3.1, 3.2.1).</p>
<pre><code>
### Step 2: Collect evidence artefacts (5 min)

**Create `05-evidence/` directory**:

</code></pre>
<p>wk10/gradescope/task2/05-evidence/
‚îú‚îÄ‚îÄ screenshots/
‚îÇ   ‚îú‚îÄ‚îÄ before-htmx-error.png (no role=alert visible in devtools)
‚îÇ   ‚îú‚îÄ‚îÄ after-htmx-error.png (role=alert visible)
‚îÇ   ‚îú‚îÄ‚îÄ before-nojs-error.png (error present but not focused)
‚îÇ   ‚îú‚îÄ‚îÄ after-nojs-error.png (error summary with focus outline)
‚îÇ   ‚îî‚îÄ‚îÄ annotations.md
‚îú‚îÄ‚îÄ sr-transcripts/
‚îÇ   ‚îú‚îÄ‚îÄ before-nvda.txt ("Title is required" not announced)
‚îÇ   ‚îî‚îÄ‚îÄ after-nvda.txt ("Alert. Title is required..." announced)
‚îî‚îÄ‚îÄ metrics/
‚îú‚îÄ‚îÄ before-analysis.csv (copy of Week 9 analysis.csv)
‚îî‚îÄ‚îÄ after-analysis.csv (post-change metrics)</p>
<pre><code>
**Screenshot annotations.md**:
```markdown
# Evidence Annotations

## before-htmx-error.png
**Alt text**: "Browser devtools showing div#status with text 'Title is required' but no ARIA attributes"

**Context**: Week 9 baseline. Error appears visually but screen readers don't announce it.

## after-htmx-error.png
**Alt text**: "Browser devtools showing div#status with role=alert, aria-live=assertive, and text 'Title is required. Please enter at least one character.'"

**Context**: Week 10 fix. Error now has semantic markup for SR announcement.

## after-nojs-error.png
**Alt text**: "Task list page with error summary at top highlighted with blue focus outline. Error reads 'There is a problem' with link to title field."

**Context**: Week 10 fix, no-JS path. Error summary receives focus on page load, keyboard-navigable.
</code></pre>
<h3 id="step-3-create-readme-5-min"><a class="header" href="#step-3-create-readme-5-min">Step 3: Create README (5 min)</a></h3>
<p><strong>Create <code>wk10/gradescope/task2/README.md</code></strong>:</p>
<pre><code class="language-markdown"># COMP2850 HCI ‚Äî Gradescope Task 2 Submission

**Student**: [Your name]
**Date**: 2025-10-22
**Module**: COMP2850 HCI

---

## Contents

1. **01-redesign-brief.md** ‚Äî Problem statement, proposed changes, acceptance criteria
2. **02-regression-checklist.csv** ‚Äî Accessibility verification (keyboard, SR, no-JS)
3. **03-before-after-summary.md** ‚Äî Quantitative metrics comparison (Week 9 vs Week 10)
4. **04-key-diffs.md** ‚Äî Annotated code changes with WCAG rationale
5. **05-evidence/** ‚Äî Screenshots, SR transcripts, metrics CSVs

---

## Summary

**Problem**: Task T2 (Edit Task) had 67% completion rate in Week 9 pilots (0% for no-JS). Validation errors not accessible to screen readers or keyboard users.

**Fix**: Added accessible error handling (`role="alert"`, `aria-describedby`, `tabindex="-1"`, auto-focus).

**Result**: 100% completion rate (all variants), WCAG 2.2 Level AA compliance (3.3.1, 4.1.3, 3.2.1).

**Impact**: Restored functional parity for no-JS users, improved accessibility for SR and keyboard-only users (estimated 2-5% UK population).

---

## Evidence Chain

1. **Raw data**: `05-evidence/metrics/before-analysis.csv` (Week 9 pilots)
2. **Analysis**: `03-before-after-summary.md` (completion 67% ‚Üí 100%)
3. **Prioritisation**: `01-redesign-brief.md` (Priority 1, Score 8)
4. **Implementation**: `04-key-diffs.md` (code changes with WCAG rationale)
5. **Verification**: `02-regression-checklist.csv` + `05-evidence/screenshots/` (post-change testing)
6. **Measurement**: `05-evidence/metrics/after-analysis.csv` (post-change pilots)

All files reference each other for full traceability.
</code></pre>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
All 5 core documents present in <code>task2/</code></li>
<li><input disabled="" type="checkbox"/>
Evidence artefacts organized in <code>05-evidence/</code></li>
<li><input disabled="" type="checkbox"/>
README.md complete with summary</li>
<li><input disabled="" type="checkbox"/>
All files sanitized (no PII)</li>
<li><input disabled="" type="checkbox"/>
File names match spec exactly</li>
</ul>
<hr />
<h2 id="commit--reflect-10-min-3"><a class="header" href="#commit--reflect-10-min-3">Commit &amp; Reflect (10 min)</a></h2>
<h3 id="commit-message-3"><a class="header" href="#commit-message-3">Commit message</a></h3>
<pre><code class="language-bash">git add templates/ src/main/kotlin/ data/metrics.csv analysis/ wk10/gradescope/task2/ wk10/lab-wk10/a11y/ backlog/backlog.csv

git commit -m "$(cat &lt;&lt;'EOF'
wk10s2: implemented inclusive redesign, verified, packaged Task 2

- Implemented Priority 1 fix: accessible validation error handling (T2 edit)
  - HTMX: Added role=alert + aria-live=assertive for SR announcement
  - No-JS: Added error summary with tabindex=-1 + auto-focus
  - Both: Added aria-describedby linking inputs to errors
- Completed accessibility regression checklist (21/22 pass, 1 contrast issue logged)
- Ran verification pilots (n=3): T2 completion 67% ‚Üí 100%, parity restored for no-JS
- Collected before/after metrics: completion +33%, error rate -8%, median time -78ms (JS-on)
- Packaged Gradescope Task 2 bundle: brief, checklist, metrics, code diffs, evidence
- Updated backlog: wk9-01, wk9-03 marked fixed with verification evidence

Key results:
- No-JS users: 0% ‚Üí 100% completion (functional parity restored)
- SR users: Errors now announced immediately (WCAG 4.1.3 compliance)
- Keyboard users: Error summary keyboard-navigable (WCAG 3.2.1 compliance)
- All variants: WCAG 2.2 Level AA achieved (3.3.1, 4.1.3, 3.2.1)

Task 2 ready for submission.


EOF
)"
</code></pre>
<h3 id="reflection-questions-7"><a class="header" href="#reflection-questions-7">Reflection questions</a></h3>
<p><strong>Answer in <code>wk10/reflection.md</code></strong>:</p>
<ol>
<li>
<p><strong>Implementation challenges</strong>: What was harder than expected? Did you encounter unexpected regressions?</p>
</li>
<li>
<p><strong>Verification insights</strong>: Did post-change pilots reveal new issues? How confident are you in the ‚â•90% completion claim?</p>
</li>
<li>
<p><strong>Trade-offs</strong>: Did you make any compromises (e.g., auto-focus script requires JS)? How do you justify them?</p>
</li>
<li>
<p><strong>Before/after impact</strong>: Looking at the metrics table, which improvement matters most for inclusion? Why?</p>
</li>
<li>
<p><strong>Evidence quality</strong>: Is your evidence chain complete (data ‚Üí analysis ‚Üí fix ‚Üí verification)? What's missing or weak?</p>
</li>
<li>
<p><strong>Week 11 readiness</strong>: Can you present this fix in 5 minutes (problem ‚Üí data ‚Üí solution ‚Üí proof)? Practice your narrative.</p>
</li>
</ol>
<hr />
<h2 id="looking-ahead-week-11-studio-crit"><a class="header" href="#looking-ahead-week-11-studio-crit">Looking Ahead: Week 11 Studio Crit</a></h2>
<p>Next week:</p>
<ul>
<li><strong>Lab 1</strong>: Present evidence chains to peers (5 min each)</li>
<li>Receive critique: Is evidence convincing? Are claims justified?</li>
<li>Give critique: Check peers' evidence chains, WCAG compliance</li>
<li><strong>Lab 2</strong>: Final refinements, portfolio assembly, submission prep</li>
</ul>
<p><strong>Before Week 11</strong>:</p>
<ul>
<li>Review Task 2 bundle‚Äîcan you explain every file?</li>
<li>Practice 5-min presentation (problem ‚Üí data ‚Üí fix ‚Üí verification)</li>
<li>Identify 1-2 backup issues (if your main fix gets critiqued)</li>
</ul>
<hr />
<h2 id="further-reading--resources-4"><a class="header" href="#further-reading--resources-4">Further Reading &amp; Resources</a></h2>
<h3 id="essential-4"><a class="header" href="#essential-4">Essential</a></h3>
<ul>
<li>Review <a href="wk10/../references/assistive-testing-checklist.html">Assistive Testing Checklist</a></li>
<li>Skim the <a href="wk10/../references/screenshot-guide.html">Screenshot Evidence Guide</a></li>
<li>Review <a href="wk10/../references/evaluation-metrics-quickref.html">Evaluation Metrics Quick Reference</a></li>
<li><a href="https://www.w3.org/WAI/WCAG22/quickref/">WCAG 2.2 Quick Reference</a></li>
</ul>
<h3 id="accessible-error-handling-1"><a class="header" href="#accessible-error-handling-1">Accessible Error Handling</a></h3>
<ul>
<li><a href="https://webaim.org/techniques/forms/">WebAIM: Creating Accessible Forms</a></li>
<li><a href="https://design-system.service.gov.uk/components/error-message/">GOV.UK: Error Message Pattern</a></li>
<li><a href="https://www.w3.org/WAI/ARIA/apg/patterns/alert/">ARIA Authoring Practices: Alert</a></li>
</ul>
<h3 id="beforeafter-studies"><a class="header" href="#beforeafter-studies">Before/After Studies</a></h3>
<ul>
<li><a href="https://measuringux.com/before-after/">Measuring UX: Before/After Studies</a></li>
<li><a href="https://www.nngroup.com/articles/measure-learnability/">Nielsen: Measuring Improvement</a></li>
</ul>
<h3 id="code-evidence"><a class="header" href="#code-evidence">Code Evidence</a></h3>
<ul>
<li><a href="https://git-scm.com/docs/git-diff">Git: Generating Diffs</a></li>
<li><a href="https://www.gov.uk/service-manual/service-standard/point-15-document-how-you-have-evaluated-your-service">GOV.UK: Documenting decisions</a></li>
</ul>
<h3 id="academic-2"><a class="header" href="#academic-2">Academic</a></h3>
<ul>
<li><strong>Lazar et al. (2017).</strong> <em>Research Methods in HCI</em> (2nd ed.). Chapter 12: Reporting results</li>
<li><strong>Sauro &amp; Lewis (2016).</strong> <em>Quantifying the User Experience</em> (2nd ed.). Chapter 9: Before/after comparisons</li>
</ul>
<hr />
<h2 id="glossary-summary-7"><a class="header" href="#glossary-summary-7">Glossary Summary</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Term</th><th>One-line definition</th></tr></thead><tbody>
<tr><td><strong>Regression testing</strong></td><td>Verifying new changes don't break existing functionality</td></tr>
<tr><td><strong>Before/after metrics</strong></td><td>Quantitative comparison showing improvement from intervention</td></tr>
<tr><td><strong>Accessible error handling</strong></td><td>Errors perceivable, understandable, recoverable for all participants</td></tr>
<tr><td><strong>Code diffs</strong></td><td>Side-by-side comparison showing what changed (for evidence)</td></tr>
<tr><td><strong>role="alert"</strong></td><td>ARIA role announcing content immediately to screen readers</td></tr>
<tr><td><strong>aria-live="assertive"</strong></td><td>Live region that interrupts SR to announce urgent changes</td></tr>
<tr><td><strong>aria-describedby</strong></td><td>Links element to descriptive text (hints, errors)</td></tr>
<tr><td><strong>tabindex="-1"</strong></td><td>Makes non-interactive element focusable programmatically (not in tab order)</td></tr>
<tr><td><strong>Progressive enhancement</strong></td><td>Baseline works without JS; JS adds enhancements</td></tr>
<tr><td><strong>Evidence chain</strong></td><td>Traceability from data ‚Üí analysis ‚Üí fix ‚Üí verification</td></tr>
</tbody></table>
</div>
<hr />
<p><strong>Lab complete!</strong> You have an implemented, verified, documented inclusive redesign ready for Week 11 critique and final submission.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="code-resources-4"><a class="header" href="#code-resources-4">Code Resources</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-11--lab-1--evidence-led-studio-crit"><a class="header" href="#week-11--lab-1--evidence-led-studio-crit">Week 11 ‚Ä¢ Lab 1 ‚Äî Evidence-Led Studio Crit</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-11-orange" alt="Week 11" />
<img src="https://img.shields.io/badge/Lab-1-green" alt="Lab 1" />
<img src="https://img.shields.io/badge/Status-Draft-yellow" alt="Status" /></p>
<hr />
<h2 id="before-lab-required-reading-10-mins-2"><a class="header" href="#before-lab-required-reading-10-mins-2">Before Lab: Required Reading (10 mins)</a></h2>
<p>üìñ <strong>Essential</strong></p>
<ul>
<li><a href="https://www.ideo.com/blog/design-critique">IDEO: The Art of Critique</a> (5 min)</li>
<li>Review your Task 2 bundle (<code>wk10/gradescope/task2/</code>)</li>
<li>Review your analysis summary (<code>analysis/summary.md</code>) for before/after metrics</li>
</ul>
<p>üìñ <strong>Quick reference</strong></p>
<ul>
<li><a href="wk11/../references/assistive-testing-checklist.html">Assistive Testing Checklist</a></li>
<li><a href="wk11/../references/evaluation-metrics-quickref.html">Evaluation Metrics Quick Reference</a></li>
</ul>
<hr />
<h2 id="introduction-from-evidence-to-narrative"><a class="header" href="#introduction-from-evidence-to-narrative">Introduction: From Evidence to Narrative</a></h2>
<p>You've completed the HCI design cycle: audit ‚Üí pilot ‚Üí analyse ‚Üí redesign ‚Üí verify. <strong>Today you present that work to peers</strong>.</p>
<p><strong>This is not "show and tell"</strong>. Studio critique is:</p>
<ul>
<li><strong>Evidence-led</strong>: Every claim backed by data, screenshots, transcripts</li>
<li><strong>Reflective</strong>: Acknowledge limitations, trade-offs, remaining issues</li>
<li><strong>Actionable</strong>: Invite specific feedback, identify next steps</li>
</ul>
<p><strong>Why this matters</strong>:</p>
<ul>
<li><strong>Professional practice</strong>: Design reviews are standard in industry (Google, GOV.UK, Microsoft all use critique protocols)</li>
<li><strong>Accreditation</strong>: External panels assess evidence chains‚Äîthis is rehearsal</li>
<li><strong>Peer learning</strong>: Seeing 5-6 different solutions to same problem builds design vocabulary</li>
</ul>
<p><strong>Format</strong>: 15 min per team (5 min demo, 3 min metrics, 2 min accessibility proof, 5 min Q&amp;A). Tight timing forces clarity.</p>
<blockquote>
<p><strong>Visual</strong>: Evidence-led critique loop</p>
</blockquote>
<pre class="mermaid">graph TD
  Present[Evidence-led demo]
  Present --&gt; Feedback[Peer &amp; staff critique]
  Feedback --&gt; Notes[Crit notes &amp; backlog updates]
  Notes --&gt; Portfolio[Portfolio &amp; wrap-up]
  Portfolio --&gt; Plan[Semester 2 planning]
  Plan --&gt; Present
</pre>
<p><small>See <a href="wk11/../references/process-visuals.html#crit-loop">Process Visuals</a> for captioned steps.</small></p>
<hr />
<h2 id="learning-focus-10"><a class="header" href="#learning-focus-10">Learning Focus</a></h2>
<h3 id="lab-objectives-10"><a class="header" href="#lab-objectives-10">Lab Objectives</a></h3>
<p>By the end of this session, you will have:</p>
<ul>
<li>Presented evidence chains clearly (problem ‚Üí data ‚Üí fix ‚Üí verification)</li>
<li>Demonstrated accessibility improvements (keyboard, SR, no-JS)</li>
<li>Defended design decisions with data (before/after metrics)</li>
<li>Given/received peer feedback using structured rubric</li>
<li>Documented crit insights for portfolio</li>
</ul>
<h3 id="learning-outcomes-addressed-10"><a class="header" href="#learning-outcomes-addressed-10">Learning Outcomes Addressed</a></h3>
<p>This lab contributes to the following module Learning Outcomes (<a href="wk11/../references/learning-outcomes.html">full definitions</a>):</p>
<ul>
<li><strong>LO11</strong>: Collaborate in teams ‚Äî evidenced by peer critique participation</li>
<li><strong>LO12</strong>: Demonstrate professionalism ‚Äî evidenced by constructive feedback + respectful critique
Maps to WCAG: 2.2 AA (demonstrating compliance)</li>
</ul>
<hr />
<h2 id="key-concepts-9"><a class="header" href="#key-concepts-9">Key Concepts</a></h2>
<h3 id="design-critique"><a class="header" href="#design-critique">Design Critique</a></h3>
<blockquote>
<p><strong>Design Critique</strong> (<a href="wk11/../references/glossary.html">Glossary</a>)</p>
<p>Structured peer review of design work. <strong>Not personal feedback</strong>‚Äîfocuses on work, evidence, impact.</p>
<p><strong>Characteristics</strong></p>
<ul>
<li><strong>Specific</strong>: "Error summary not keyboard-focusable" (good) vs "errors bad" (vague)</li>
<li><strong>Constructive</strong>: Suggest alternatives, not just problems</li>
<li><strong>Evidence-based</strong>: Reference data, WCAG, observations (not opinions)</li>
<li><strong>Respectful</strong>: Assume positive intent, acknowledge constraints</li>
</ul>
<p><strong>Format</strong> (this module)</p>
<ul>
<li>Presenter shows work + evidence</li>
<li>Audience asks clarifying questions</li>
<li>Audience offers critique: "I noticed X, have you considered Y?"</li>
<li>Presenter notes feedback (doesn't defend in real-time)</li>
</ul>
<p><strong>HCI Connection</strong>: Critique improves design through <strong>external perspective</strong>‚Äîyou're too close to your work to see all issues.</p>
<p><strong>Not a critique</strong></p>
<ul>
<li>"I don't like the colour" (subjective preference without rationale)</li>
<li>"This sucks" (not constructive)</li>
<li>"You should have..." (hindsight, not helpful)</li>
</ul>
<p><strong>Good critique</strong></p>
<ul>
<li>"The error message says 'Title required' but doesn't explain the max length constraint. Pilot P3 hit this‚Äîcould you add that info?"</li>
</ul>
<p>üîó <a href="https://dschool.stanford.edu/resources/the-art-of-critique">Design Thinking: Critique vs Criticism</a></p>
</blockquote>
<h3 id="evidence-led-presentation"><a class="header" href="#evidence-led-presentation">Evidence-Led Presentation</a></h3>
<blockquote>
<p><strong>Evidence-Led Presentation</strong> (<a href="wk11/../references/glossary.html">Glossary</a>)</p>
<p>Presentation style where every claim is backed by artifacts (data, screenshots, quotes).</p>
<p><strong>Structure</strong></p>
<ol>
<li><strong>Problem</strong>: "T2 edit had 67% completion (0% no-JS)" ‚Üê metric</li>
<li><strong>Root cause</strong>: "Validation errors not announced to SR" ‚Üê pilot quote + WCAG reference</li>
<li><strong>Fix</strong>: "Added <code>role=alert</code>" ‚Üê code diff</li>
<li><strong>Verification</strong>: "Post-change: 100% completion" ‚Üê after-metrics + screenshot</li>
</ol>
<p><strong>What NOT to do</strong></p>
<ul>
<li>"We made it better" (vague‚Äîbetter how?)</li>
<li>"Users struggled" (who? how many? with what?)</li>
<li>"Fixed accessibility" (which criteria? verified how?)</li>
</ul>
<p><strong>HCI Connection</strong>: Evidence separates <strong>opinion</strong> from <strong>fact</strong>. Stakeholders can question interpretation, but not the data.</p>
<p><strong>Academic context</strong>: External examiners check evidence chains. Missing evidence ‚Üí lower marks, even if work was good.</p>
<p>üîó <a href="https://gds.blog.gov.uk/2016/11/18/what-we-mean-when-we-say-show-the-thing/">GOV.UK: Show the thing</a></p>
</blockquote>
<h3 id="accessibility-demonstration"><a class="header" href="#accessibility-demonstration">Accessibility Demonstration</a></h3>
<blockquote>
<p><strong>Accessibility Demonstration</strong> (<a href="wk11/../references/glossary.html">Glossary</a>)</p>
<p>Live proof that inclusive design works. <strong>Show, don't tell</strong>.</p>
<p><strong>Examples</strong></p>
<ul>
<li><strong>Keyboard</strong>: Tab through form ‚Üí submit error ‚Üí Tab to error link ‚Üí press Enter ‚Üí focus lands on input</li>
<li><strong>Screen reader</strong>: Turn on NVDA/Orca ‚Üí navigate to form ‚Üí submit error ‚Üí SR announces "Alert. Title is required"</li>
<li><strong>No-JS</strong>: Disable JavaScript ‚Üí submit form ‚Üí error summary appears and focused</li>
</ul>
<p><strong>Why live demo?</strong> Screenshots can be faked. Live demo proves system works right now.</p>
<p><strong>Backup plan</strong>: If live demo fails (demo gremlins), have <strong>video recording</strong> or <strong>annotated screenshots</strong> ready.</p>
<p><strong>What to show</strong></p>
<ul>
<li>Before state (broken or suboptimal)</li>
<li>After state (fixed)</li>
<li>Evidence it meets WCAG (checklist row, transcript)</li>
</ul>
<p><strong>Common mistakes</strong></p>
<ul>
<li>Only showing HTMX path (ignoring no-JS)</li>
<li>Not narrating what's happening ("I'm pressing Tab, now I'm on the error link...")</li>
<li>Assuming audience sees what you see (make focus indicators obvious, zoom in if needed)</li>
</ul>
<p>üîó <a href="https://webaim.org/articles/demos/">WebAIM: Demonstrating Accessibility</a></p>
</blockquote>
<h3 id="constructive-feedback"><a class="header" href="#constructive-feedback">Constructive Feedback</a></h3>
<blockquote>
<p><strong>Constructive Feedback</strong> (<a href="wk11/../references/glossary.html">Glossary</a>)</p>
<p>Feedback that helps recipient improve. Has three parts: observation + impact + suggestion.</p>
<p><strong>Formula</strong></p>
<ol>
<li><strong>Observation</strong>: "I noticed X" (specific, factual)</li>
<li><strong>Impact</strong>: "This might affect Y" (consequence, not judgment)</li>
<li><strong>Suggestion</strong>: "Have you considered Z?" (alternative, not mandate)</li>
</ol>
<p><strong>Example (good)</strong></p>
<ul>
<li>Observation: "Your error summary uses <code>aria-live=assertive</code>, which I saw announced in your SR demo"</li>
<li>Impact: "In my testing, <code>assertive</code> interrupted mid-sentence when I was reading other content"</li>
<li>Suggestion: "Have you tested with <code>aria-live=polite</code> to see if it's less disruptive? Might be a good trade-off if errors aren't time-critical."</li>
</ul>
<p><strong>Example (bad)</strong></p>
<ul>
<li>"You should use <code>polite</code> not <code>assertive</code>" ‚Üê prescriptive, no context</li>
</ul>
<p><strong>Receiving feedback</strong></p>
<ul>
<li><strong>Listen</strong>: Don't defend immediately (note it, reflect later)</li>
<li><strong>Clarify</strong>: "Can you show me where you saw that?"</li>
<li><strong>Thank</strong>: Even if you disagree, feedback is effort</li>
</ul>
<p>üîó <a href="https://www.radicalcandor.com/">Kim Scott: Radical Candor</a> ‚Äî Framework for constructive feedback</p>
</blockquote>
<hr />
<h2 id="activity-a-prepare-presentation-20-min"><a class="header" href="#activity-a-prepare-presentation-20-min">Activity A: Prepare Presentation (20 min)</a></h2>
<p><strong>Goal</strong>: Assemble evidence into clear 5-slide narrative.</p>
<h3 id="step-1-create-presentation-outline-5-min"><a class="header" href="#step-1-create-presentation-outline-5-min">Step 1: Create presentation outline (5 min)</a></h3>
<p><strong>Use Markdown slides</strong> (e.g., Marp) or <strong>simple slide deck</strong> (Google Slides, PowerPoint).</p>
<p><strong>5-slide structure</strong>:</p>
<ol>
<li><strong>Title slide</strong> ‚Äî Project name, team, date</li>
<li><strong>Problem + Evidence</strong> ‚Äî What was broken? (metrics, quotes, WCAG violations)</li>
<li><strong>Solution</strong> ‚Äî What changed? (code diff, screenshots)</li>
<li><strong>Verification</strong> ‚Äî How do we know it worked? (after-metrics, regression checklist)</li>
<li><strong>Next Steps</strong> ‚Äî What remains? (backlog, Semester 2 plans)</li>
</ol>
<p><strong>Example</strong>:</p>
<p><strong>Slide 2: Problem + Evidence</strong></p>
<pre><code># Problem: Validation Errors Not Accessible

**Week 9 Findings**:
- T2 (Edit Task): 67% completion overall, 0% completion (no-JS)
- Pilot P3: "Gave up after 2 validation errors‚Äîcouldn't find error summary"
- Pilot P2 (NVDA): "SR didn't announce error message"

**Root Cause**:
- HTMX path: Missing `role=alert` (WCAG 4.1.3 violation)
- No-JS path: Error summary not keyboard-focusable (WCAG 3.2.1 violation)

**Impact**: Screen reader users, keyboard-only users, no-JS users excluded

[Screenshot: error summary with no focus indicator]
</code></pre>
<h3 id="step-2-select-key-evidence-artifacts-10-min"><a class="header" href="#step-2-select-key-evidence-artifacts-10-min">Step 2: Select key evidence artifacts (10 min)</a></h3>
<p><strong>From <code>wk10/gradescope/task2/05-evidence/</code></strong>:</p>
<p><strong>Screenshots</strong> (3-4 max):</p>
<ul>
<li>Before: Error present but not accessible (no <code>role=alert</code> in devtools)</li>
<li>After: Error with <code>role=alert</code> visible in devtools</li>
<li>No-JS before: Error summary without focus</li>
<li>No-JS after: Error summary with focus outline</li>
</ul>
<p><strong>Metrics table</strong>:</p>
<pre><code>| Metric | Before | After | Œî |
|--------|--------|-------|---|
| T2 completion (no-JS) | 0% | 100% | +100% |
| T2 completion (all) | 67% | 100% | +33% |
| T2 error rate | 33% | 25% | -8% |
</code></pre>
<p><strong>Code diff</strong> (1 key change):</p>
<pre><code class="language-diff">- val status = """&lt;div id="status" hx-swap-oob="true"&gt;Title is required.&lt;/div&gt;"""
+ val status = """&lt;div id="status" role="alert" aria-live="assertive" hx-swap-oob="true"&gt;
+   Title is required. Please enter at least one character.
+ &lt;/div&gt;"""
</code></pre>
<p><strong>SR transcript snippet</strong>:</p>
<pre><code>Before: [form submitted, no announcement]
After: "Alert. Title is required. Please enter at least one character."
</code></pre>
<h3 id="step-3-prepare-live-demo-script-5-min"><a class="header" href="#step-3-prepare-live-demo-script-5-min">Step 3: Prepare live demo script (5 min)</a></h3>
<p><strong>Create <code>wk11/crit/demo-script.md</code></strong>:</p>
<pre><code class="language-markdown"># Live Demo Script ‚Äî Week 11 Studio Crit

**Timing**: 5 minutes

---

## Setup (30 seconds)
- Navigate to `/tasks`
- Show both browser windows: one with JS enabled, one with JS disabled (or toggle DevTools setting)
- Narrate: "I'll show the HTMX path first, then no-JS path"

---

## Demo 1: HTMX Error Handling (2 min)

**Steps**:
1. Click "Edit" on task "Submit invoices"
2. Clear title field (backspace)
3. Click "Save"
4. **Narrate**: "Notice status message appears: 'Title is required. Please enter at least one character.'"
5. Open DevTools Elements panel ‚Üí show `&lt;div id="status" role="alert" aria-live="assertive"&gt;`
6. **Narrate**: "The `role=alert` ensures screen readers announce this immediately"
7. (If SR available) Turn on NVDA/Orca, repeat steps 1-3
8. **Narrate**: "NVDA announces: 'Alert. Title is required...'"

**Evidence reference**: `05-evidence/sr-transcripts/after-nvda.txt`

---

## Demo 2: No-JS Error Handling (2 min)

**Steps**:
1. Disable JavaScript (DevTools ‚Üí Settings ‚Üí Disable JavaScript, hard refresh)
2. Click "Edit" on same task
3. Clear title, click "Save"
4. **Narrate**: "Page reloads. Notice error summary at top with focus outline‚Äîit's automatically focused."
5. Press Tab ‚Üí focus moves to error link ("Title is required")
6. Press Enter ‚Üí focus moves to `#title` input
7. **Narrate**: "Keyboard-only users can now navigate to the error and fix it. Before, this wasn't possible."

**Evidence reference**: `05-evidence/screenshots/after-nojs-error.png`

---

## Demo 3: Success Path (30 seconds)

**Steps**:
1. (Still in no-JS mode) Type new title: "Submit invoices by Friday"
2. Click "Save"
3. **Narrate**: "Full page reload, task updated. PRG pattern maintains history."
4. Show updated task in list

---

## Backup (if demo fails)

**Video**: `wk11/crit/demo-recording.mp4` (pre-recorded screen capture with narration)

**Screenshots**: Walk through annotated screenshots in `05-evidence/screenshots/` with narration
</code></pre>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
5-slide outline complete</li>
<li><input disabled="" type="checkbox"/>
Evidence artifacts selected (screenshots, metrics, diffs)</li>
<li><input disabled="" type="checkbox"/>
Live demo script written with narration</li>
<li><input disabled="" type="checkbox"/>
Backup plan ready (video or annotated screenshots)</li>
</ul>
<hr />
<h2 id="activity-b-studio-critique-session-60-min"><a class="header" href="#activity-b-studio-critique-session-60-min">Activity B: Studio Critique Session (60 min)</a></h2>
<p><strong>Format</strong>: 5-6 teams √ó 15 min each</p>
<h3 id="presenter-role-when-its-your-turn"><a class="header" href="#presenter-role-when-its-your-turn">Presenter Role (when it's your turn)</a></h3>
<p><strong>Timing breakdown</strong>:</p>
<ul>
<li><strong>0:00-0:30</strong>: Introduce problem (1 slide)</li>
<li><strong>0:30-5:00</strong>: Live demo (narrated, following script)</li>
<li><strong>5:00-8:00</strong>: Show metrics + evidence (slides 2-4)</li>
<li><strong>8:00-10:00</strong>: Accessibility proof (regression checklist, SR transcript)</li>
<li><strong>10:00-15:00</strong>: Q&amp;A + critique</li>
</ul>
<p><strong>Presenting tips</strong>:</p>
<ul>
<li><strong>Narrate everything</strong>: "I'm pressing Tab, now I'm on the error link..."</li>
<li><strong>Point to evidence</strong>: "This is documented in line 23 of our regression checklist..."</li>
<li><strong>Acknowledge limitations</strong>: "We didn't have time to fix wk9-02 (filter UX)‚Äîit's in our Semester 2 backlog"</li>
<li><strong>Invite questions</strong>: "What would you like me to clarify?"</li>
</ul>
<p><strong>During Q&amp;A</strong>:</p>
<ul>
<li><strong>Don't defend</strong>: Listen, note feedback, say "good point, I'll check that"</li>
<li><strong>Clarify if needed</strong>: "Can you show me which screenshot you're referring to?"</li>
<li><strong>Thank reviewers</strong>: Even if feedback stings, they're helping you improve</li>
</ul>
<p><strong>Note feedback</strong> in <code>wk11/crit/feedback-received.md</code>:</p>
<pre><code class="language-markdown">## Feedback from Studio Crit ‚Äî 2025-10-25

### Team Alpha
- **Q**: "Have you tested with VoiceOver (macOS) or just NVDA?"
- **Response**: Only tested NVDA. Should add VoiceOver testing to backlog.
- **Action**: Create backlog item wk11-01: "Verify SR compatibility with VoiceOver"

### Team Beta
- **Observation**: "Your `aria-live=assertive` interrupted my SR mid-sentence during filter demo"
- **Suggestion**: "Try `aria-live=polite` for non-critical messages?"
- **Response**: Good catch. Will test polite vs assertive for status messages.
- **Action**: Update wk10/lab-wk10/docs/redesign-brief.md notes section

### Staff
- **Q**: "Why did you prioritize T2 over T1 when T1 had higher error rate?"
- **Response**: T2 had 0% no-JS completion (complete block) vs T1 100% completion (just slower). Prioritized exclusion over efficiency.
- **Validation**: Staff agreed with prioritization framework logic.
</code></pre>
<h3 id="reviewer-role-when-watching-others"><a class="header" href="#reviewer-role-when-watching-others">Reviewer Role (when watching others)</a></h3>
<p><strong>Use <code>wk11/crit/peer-feedback-TEAM_NAME.md</code> template</strong>:</p>
<pre><code class="language-markdown"># Peer Feedback ‚Äî Team [Name]

**Reviewer**: [Your name]
**Date**: 2025-10-25

---

## Summary

**Problem addressed**: [One sentence]

**Solution**: [One sentence]

**Evidence quality**: [Rating 1-5, brief justification]

---

## Strengths (What worked well)

1. [Specific observation with evidence reference]
2. [Specific observation with evidence reference]
3. [Specific observation with evidence reference]

**Example**:
- Clear before/after metrics table showing 67% ‚Üí 100% completion
- Live SR demo proved `role=alert` works (heard announcement)
- Regression checklist complete (21/22 pass‚Äîimpressive)

---

## Questions / Concerns

1. [Specific question or observation]
2. [Specific question or observation]

**Example**:
- Q: "You mentioned error rate dropped from 33% to 25%. Is that still high? What's causing remaining errors?"
- Concern: "Screenshot shows error summary but I didn't see it tested with keyboard in live demo. Can you Tab to it?"

---

## Suggestions (Constructive)

Use formula: Observation + Impact + Suggestion

1. [Observation] ‚Üí [Impact] ‚Üí [Suggestion]
2. [Observation] ‚Üí [Impact] ‚Üí [Suggestion]

**Example**:
- **Observation**: Error message says "Title is required" but pilot P2 submitted blank because they didn't see the input had focus.
- **Impact**: Focus indicator might be too subtle (low contrast).
- **Suggestion**: Have you checked focus indicator contrast with WCAG contrast checker? Might need to increase from blue (#0000ff) to darker blue (#0000aa) for 3:1 ratio against white background.

---

## Backlog / Next Steps

What should this team consider for Semester 2?

- [Item 1]
- [Item 2]

**Example**:
- Test with VoiceOver (macOS) and JAWS (Windows) to verify SR compatibility beyond NVDA
- Add client-side validation hints (maxlength counter) as progressive enhancement
- Investigate why 25% error rate persists‚Äîmight be focus management issue

---

## Overall Assessment

**Evidence chain completeness**: [Rating 1-5]
- 5 = Complete traceability (data ‚Üí analysis ‚Üí fix ‚Üí verification)
- 3 = Some gaps (e.g., missing SR transcript or before metrics)
- 1 = Weak evidence (claims not backed by data)

**Inclusion impact**: [Rating 1-5]
- 5 = Clear who benefits, why, backed by pilot observations
- 3 = General statements ("helps disabled people") without specifics
- 1 = No inclusion lens evident

**WCAG compliance**: [Pass/Partial/Fail]
- Pass = Demonstrated compliance (checklist, live demo)
- Partial = Some criteria met, gaps acknowledged
- Fail = Claims compliance but no evidence

**Recommended grade** (if this were Task 2 submission): [Estimate 0-100]

**Justification**: [2-3 sentences linking grade to evidence quality, inclusion impact, WCAG compliance]
</code></pre>
<p><strong>Reviewer tips</strong>:</p>
<ul>
<li><strong>Be specific</strong>: Reference line numbers, file names, WCAG criteria</li>
<li><strong>Be kind</strong>: Assume positive intent, acknowledge constraints</li>
<li><strong>Be useful</strong>: Suggest alternatives, not just problems</li>
<li><strong>Be brief</strong>: They have limited time to read feedback‚Äîbullet points better than essays</li>
</ul>
<p>‚úã <strong>Stop and check</strong> (after all presentations):</p>
<ul>
<li><input disabled="" type="checkbox"/>
Presented your work (or scheduled if absent)</li>
<li><input disabled="" type="checkbox"/>
Filled peer feedback forms for 3-5 teams</li>
<li><input disabled="" type="checkbox"/>
Noted feedback received in your own feedback-received.md</li>
<li><input disabled="" type="checkbox"/>
Identified action items for Week 11 Lab 2</li>
</ul>
<hr />
<h2 id="activity-c-post-crit-reflection-and-backlog-update-15-min"><a class="header" href="#activity-c-post-crit-reflection-and-backlog-update-15-min">Activity C: Post-Crit Reflection and Backlog Update (15 min)</a></h2>
<p><strong>Goal</strong>: Process feedback and update backlog.</p>
<h3 id="step-1-review-feedback-received-5-min"><a class="header" href="#step-1-review-feedback-received-5-min">Step 1: Review feedback received (5 min)</a></h3>
<p><strong>Open <code>wk11/crit/feedback-received.md</code></strong> and identify themes:</p>
<p><strong>Categorize</strong>:</p>
<ul>
<li><strong>Critical</strong>: Issues that invalidate claims (e.g., "You said 100% completion but didn't test with SR")</li>
<li><strong>High priority</strong>: Valid suggestions that would significantly improve work</li>
<li><strong>Medium</strong>: Nice-to-haves, future work</li>
<li><strong>Low/Out-of-scope</strong>: Interesting but not actionable this semester</li>
</ul>
<p><strong>Example categorization</strong>:</p>
<pre><code class="language-markdown">## Feedback Themes

### Critical (Address before Task 2 submission)
- Team Beta: "aria-live=assertive too intrusive" ‚Üí Test polite vs assertive
- Staff: "No evidence of VoiceOver testing" ‚Üí Either test or document limitation

### High Priority (Semester 2)
- Team Alpha: "Focus indicator contrast 2.8:1 (below 3:1)" ‚Üí Log backlog item, fix early Sem 2
- Team Gamma: "Error rate still 25%‚Äîwhy?" ‚Üí Investigate root cause (focus management?)

### Medium
- Team Delta: "Add maxlength counter" ‚Üí Progressive enhancement, nice-to-have

### Low/Out-of-Scope
- Team Epsilon: "Redesign entire UI with dark mode" ‚Üí Out of scope for this module
</code></pre>
<h3 id="step-2-update-backlog-5-min"><a class="header" href="#step-2-update-backlog-5-min">Step 2: Update backlog (5 min)</a></h3>
<p><strong>Add new items</strong> to <code>backlog/backlog.csv</code>:</p>
<pre><code class="language-csv">wk11-01,11,high,a11y,"Verify SR compatibility with VoiceOver (macOS)",,"open","wk11/crit/feedback-received.md Team Alpha","Test with VoiceOver, document findings",false

wk11-02,11,medium,a11y,"Focus indicator contrast below WCAG AAA (2.8:1)",1.4.11,open,"wk11/crit/feedback-received.md Team Beta; WCAG 2.2 Focus Appearance","Increase focus outline to darker blue (#0000aa) for 3:1 contrast",true

wk11-03,11,high,ux,"Remaining 25% error rate on T2‚Äîinvestigate cause",,"open","wk10/gradescope/task2/03-before-after-summary.md; wk11/crit/feedback-received.md Staff","Run additional pilot focusing on error triggers, check focus management",false
</code></pre>
<p><strong>Mark completed feedback actions</strong>:</p>
<pre><code class="language-csv">wk9-01,9,high,a11y,"Validation errors not announced by SR",4.1.3,fixed,"data/metrics.csv; wk10/gradescope/task2/05-evidence/sr-transcripts/after-nvda.txt","Addressed in Week 10 Lab 2: added role=alert + aria-live=assertive",true
</code></pre>
<h3 id="step-3-write-reflection-5-min"><a class="header" href="#step-3-write-reflection-5-min">Step 3: Write reflection (5 min)</a></h3>
<p><strong>Update <code>wk11/reflection.md</code></strong>:</p>
<pre><code class="language-markdown"># Week 11 Lab 1 Reflection ‚Äî Studio Crit

## Presentation Experience

**What went well**:
- Live demo worked smoothly (both HTMX and no-JS paths)
- Metrics table clearly showed 67% ‚Üí 100% improvement
- Audience understood the inclusion impact (no-JS users excluded ‚Üí now included)

**What was challenging**:
- Nerves made me rush through SR demo‚Äîshould have slowed down to let audience hear announcement
- Didn't anticipate VoiceOver compatibility question‚Äîassumed NVDA coverage was sufficient
- Q&amp;A revealed gap: didn't investigate why error rate only improved to 25% (not &lt;10% as hoped)

## Feedback Received

**Most valuable critique**:
Team Beta's observation about `aria-live=assertive` being too intrusive. I experienced this myself during testing but dismissed it‚Äîtheir feedback validated my concern. Will test `polite` alternative.

**Most surprising critique**:
Staff asked why I prioritized T2 over T1 when T1 had higher error rate. I explained: T2 had 0% no-JS completion (exclusion) vs T1 100% completion (efficiency). Staff agreed but noted I should have made this explicit in presentation. Lesson: state prioritization criteria upfront.

**Hardest to hear**:
Team Alpha noted focus indicator contrast issue (2.8:1, below 3:1). I checked this in Week 8 but forgot to fix it. Embarrassing oversight‚Äîlogged wk11-02 to address.

## Changes for Task 2 Submission

Based on feedback:
1. **Add VoiceOver testing note** to `02-regression-checklist.csv`: "Tested with NVDA (Windows) and Orca (Linux). VoiceOver (macOS) not tested‚Äîrecommend for Semester 2."
2. **Investigate `aria-live=polite`** alternative: Run quick test, update `01-redesign-brief.md` notes if polite works better
3. **Document focus indicator issue**: Add note to `03-before-after-summary.md`: "Known issue: focus indicator contrast 2.8:1 (WCAG AAA). Logged wk11-02 for Semester 2 fix."

## Giving Feedback

**Teams I reviewed**: Alpha, Beta, Gamma

**Most interesting observation**:
Team Gamma used UMUX-Lite subjective measure (2 questions, 1-7 scale). We didn't‚Äîmight add for Semester 2 to capture perceived usability alongside objective metrics.

**Common pattern**:
3/5 teams struggled with no-JS demos (forgot to disable JS, or JS disabled but cached). Reinforces importance of verification scripts like `wk08/lab-w8/scripts/nojs-check.md`.

## Next Steps

**Before Lab 2** (Final submissions):
1. Test `aria-live=polite` vs `assertive` (30 min)
2. Add VoiceOver limitation note to regression checklist (5 min)
3. Document focus indicator issue in before-after summary (10 min)
4. Final proofread of Task 2 bundle (30 min)

**Semester 2 priorities** (based on backlog):
- Fix focus indicator contrast (wk11-02)
- Investigate remaining error rate (wk11-03)
- Test VoiceOver compatibility (wk11-01)
- Add progressive enhancement hints (maxlength counter, real-time char count)
</code></pre>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Feedback themes identified and categorized</li>
<li><input disabled="" type="checkbox"/>
Backlog updated with new items from critique</li>
<li><input disabled="" type="checkbox"/>
Reflection written (what went well, challenges, changes for submission)</li>
<li><input disabled="" type="checkbox"/>
Action items for Week 11 Lab 2 clear</li>
</ul>
<hr />
<h2 id="commit--reflect-5-min"><a class="header" href="#commit--reflect-5-min">Commit &amp; Reflect (5 min)</a></h2>
<h3 id="commit-message-4"><a class="header" href="#commit-message-4">Commit message</a></h3>
<pre><code class="language-bash">git add wk11/crit/ backlog/backlog.csv wk11/reflection.md

git commit -m "$(cat &lt;&lt;'EOF'
wk11s1: studio crit completed, feedback processed

- Presented inclusive redesign with live demo (HTMX + no-JS paths)
- Demonstrated accessibility improvements: role=alert SR announcement, keyboard-navigable error summary
- Showed before/after metrics: T2 completion 67% ‚Üí 100%, no-JS parity restored
- Received feedback from 3 peer teams + staff (documented in feedback-received.md)
- Identified critical action items: test aria-live=polite, document VoiceOver limitation, note focus contrast issue
- Provided constructive feedback to 3 peer teams (Alpha, Beta, Gamma)
- Updated backlog with new items: wk11-01 (VoiceOver testing), wk11-02 (focus contrast), wk11-03 (error rate investigation)
- Reflected on presentation experience and critique process

Key takeaways:
- Evidence-led presentation effective (audience understood inclusion impact from metrics)
- Need to slow down during SR demos (rushed, hard for audience to hear)
- Prioritization criteria should be explicit upfront (T2 exclusion vs T1 efficiency)
- Focus indicator contrast oversight embarrassing but fixable (logged for Semester 2)

Ready for Week 11 Lab 2 final refinements and submission prep.


EOF
)"
</code></pre>
<hr />
<h2 id="looking-ahead-week-11-lab-2"><a class="header" href="#looking-ahead-week-11-lab-2">Looking Ahead: Week 11 Lab 2</a></h2>
<p>Final session:</p>
<ul>
<li><strong>Polish Task 1 &amp; 2</strong> based on crit feedback</li>
<li><strong>Assemble portfolio</strong> with evidence chains</li>
<li><strong>Practice submission</strong> process (Gradescope upload, file check)</li>
<li><strong>Module reflection</strong> and Semester 2 planning</li>
</ul>
<p><strong>Before Lab 2</strong>:</p>
<ul>
<li>Address critical feedback (test polite, document limitations)</li>
<li>Final proofread all submission files</li>
<li>Check Gradescope submission requirements (file formats, naming)</li>
</ul>
<hr />
<h2 id="further-reading--resources-5"><a class="header" href="#further-reading--resources-5">Further Reading &amp; Resources</a></h2>
<h3 id="essential-5"><a class="header" href="#essential-5">Essential</a></h3>
<ul>
<li>Review Task 2 bundle for gaps</li>
<li><a href="https://www.ideo.com/blog/design-critique">IDEO: The Art of Critique</a></li>
</ul>
<h3 id="presentation-skills"><a class="header" href="#presentation-skills">Presentation Skills</a></h3>
<ul>
<li><a href="https://gds.blog.gov.uk/2016/11/18/what-we-mean-when-we-say-show-the-thing/">GOV.UK: Show the thing</a></li>
<li><a href="https://www.nngroup.com/articles/presenting-findings/">Nielsen: Presenting Usability Findings</a></li>
</ul>
<h3 id="constructive-feedback-1"><a class="header" href="#constructive-feedback-1">Constructive Feedback</a></h3>
<ul>
<li><a href="https://www.radicalcandor.com/">Kim Scott: Radical Candor</a></li>
<li><a href="https://hbr.org/2019/03/the-feedback-fallacy">Harvard Business Review: The Feedback Fallacy</a></li>
</ul>
<h3 id="accessibility-demonstration-1"><a class="header" href="#accessibility-demonstration-1">Accessibility Demonstration</a></h3>
<ul>
<li><a href="https://webaim.org/articles/demos/">WebAIM: Demonstrating Accessibility</a></li>
<li><a href="https://www.deque.com/blog/screen-reader-demonstration-best-practices/">Deque: Screen Reader Demo Best Practices</a></li>
</ul>
<hr />
<h2 id="glossary-summary-8"><a class="header" href="#glossary-summary-8">Glossary Summary</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Term</th><th>One-line definition</th></tr></thead><tbody>
<tr><td><strong>Design critique</strong></td><td>Structured peer review of design work; focuses on evidence, not person</td></tr>
<tr><td><strong>Evidence-led presentation</strong></td><td>Every claim backed by artifacts (data, screenshots, quotes)</td></tr>
<tr><td><strong>Accessibility demonstration</strong></td><td>Live proof that inclusive design works (show, don't tell)</td></tr>
<tr><td><strong>Constructive feedback</strong></td><td>Observation + Impact + Suggestion (not just criticism)</td></tr>
<tr><td><strong>Studio crit</strong></td><td>Group critique session common in design education and practice</td></tr>
<tr><td><strong>Before/after comparison</strong></td><td>Showing improvement through quantitative metrics</td></tr>
<tr><td><strong>Regression checklist</strong></td><td>Systematic verification that fixes didn't break other features</td></tr>
<tr><td><strong>Evidence chain</strong></td><td>Traceability from data ‚Üí analysis ‚Üí fix ‚Üí verification</td></tr>
<tr><td><strong>Backlog refinement</strong></td><td>Updating backlog based on new feedback and discoveries</td></tr>
</tbody></table>
</div>
<hr />
<p><strong>Lab complete!</strong> You've presented your work with evidence, received constructive critique, and prepared for final submissions in Week 11 Lab 2.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="week-11--lab-2-wrap-up-portfolio--submission-readiness"><a class="header" href="#week-11--lab-2-wrap-up-portfolio--submission-readiness">Week 11 ‚Ä¢ Lab 2: Wrap-up, Portfolio &amp; Submission Readiness</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-11-orange" alt="Week 11" />
<img src="https://img.shields.io/badge/Lab-2-green" alt="Lab 2" />
<img src="https://img.shields.io/badge/Status-Draft-yellow" alt="Status" /></p>
<hr />
<h2 id="terminology-note-4"><a class="header" href="#terminology-note-4">Terminology Note</a></h2>
<p>Throughout COMP2850 we use <strong>people-centred language</strong> (e.g., "person using a screen reader") rather than deficit-based terms (e.g., "blind user"). This reflects contemporary inclusive-design practice and acknowledges that disability arises from environmental barriers, not individual impairment.</p>
<hr />
<h2 id="pre-reading-4"><a class="header" href="#pre-reading-4">Pre-reading</a></h2>
<p><strong>Essential</strong></p>
<ul>
<li><a href="https://design-system.service.gov.uk/patterns/validation/">GOV.UK Design System: Form validation</a></li>
<li><a href="https://hypermedia.systems/hypermedia-on-the-web/#_practical_patterns">hypermedia.systems, Ch. 9: Practical Patterns</a></li>
</ul>
<p><strong>Recommended</strong></p>
<ul>
<li><a href="https://www.cs.umd.edu/~ben/papers/">Shneiderman et al. (2016). <em>Designing the User Interface</em>, Ch. 15: Evaluation &amp; Iteration</a></li>
<li><a href="https://www.w3.org/WAI/WCAG22/quickref/?currentsidebar=%23col_customize&amp;levels=aaa">W3C (2024). WCAG 2.2 AA Quick Reference</a></li>
<li><a href="https://www.leeds.ac.uk/arts/info/125218/academic_skills/149/reflective_writing">Academic Skills Centre: Reflective Writing</a></li>
</ul>
<hr />
<h2 id="introduction-4"><a class="header" href="#introduction-4">Introduction</a></h2>
<h3 id="context-4"><a class="header" href="#context-4">Context</a></h3>
<p>This final lab brings your HCI project to completion. Over the past six weeks you have:</p>
<ol>
<li><strong>Needs-finding</strong> (Week 6): Identified stakeholder needs with informed consent</li>
<li><strong>Ethics overlay</strong> (Week 7): Built a privacy-by-design feature</li>
<li><strong>Accessibility audit</strong> (Week 7): Identified and fixed WCAG 2.2 AA violations</li>
<li><strong>Constraint exploration</strong> (Week 8): Verified no-JS parity</li>
<li><strong>Evaluation</strong> (Week 9): Ran task-based pilots and collected metrics</li>
<li><strong>Analysis</strong> (Week 10): Prioritised redesign with (Impact + Inclusion) ‚Äì Effort</li>
<li><strong>Redesign &amp; verification</strong> (Week 10): Fixed priority issues and re-tested</li>
<li><strong>Studio critique</strong> (Week 11 Lab 1): Presented evidence and received peer feedback</li>
</ol>
<p>Today you will <strong>polish your work</strong>, <strong>assemble a portfolio</strong> showing complete evidence chains, and <strong>prepare for Gradescope submission</strong>. This lab emphasises <strong>traceability</strong>: every claim you make must be backed by evidence (code, metrics, screenshots, pilot notes), and every artefact must link to the design decision it supports.</p>
<h3 id="why-this-matters-5"><a class="header" href="#why-this-matters-5">Why This Matters</a></h3>
<p><strong>Professionally</strong>, portfolios demonstrate your ability to:</p>
<ul>
<li>Execute a complete HCI process (needs-finding ‚Üí evaluation ‚Üí iteration)</li>
<li>Communicate design rationale with evidence</li>
<li>Integrate accessibility and ethics from the start (not as afterthoughts)</li>
<li>Manage traceability in complex projects</li>
</ul>
<p><strong>Academically</strong>, reflective portfolios are a recognised pedagogy for consolidating learning (Carson et al., 2020). Research shows that students who explicitly connect theory (e.g., WCAG success criteria) to practice (e.g., code fixes) develop deeper understanding than those who treat labs as discrete tasks.</p>
<h2 id="learning-focus-11"><a class="header" href="#learning-focus-11">Learning Focus</a></h2>
<h3 id="lab-objectives-11"><a class="header" href="#lab-objectives-11">Lab Objectives</a></h3>
<p>By the end of this session, you will have:</p>
<ul>
<li>Assembled a portfolio showing complete evidence chains (raw data ‚Üí analysis ‚Üí fix ‚Üí verification)</li>
<li>Produced reflective writing linking theory (WCAG, privacy principles) to practice (code, metrics)</li>
<li>Reviewed all evidence chains across Tasks 1 &amp; 2</li>
<li>Completed self-assessment against all 13 Learning Outcomes</li>
<li>Verified Gradescope submission readiness (file structure, size limits, naming conventions)</li>
<li>Integrated peer critique feedback into backlog</li>
<li>Finalised portfolio with reflections</li>
</ul>
<h3 id="learning-outcomes-addressed-11"><a class="header" href="#learning-outcomes-addressed-11">Learning Outcomes Addressed</a></h3>
<p>This lab contributes to the following module Learning Outcomes (<a href="wk11/../references/learning-outcomes.html">full definitions</a>):</p>
<ul>
<li><strong>LO12</strong>: Demonstrate professionalism ‚Äî evidenced by complete, honest self-assessment</li>
<li><strong>All 13 LOs</strong> ‚Äî evidenced by portfolio demonstrating cumulative achievement across Weeks 6-11</li>
</ul>
<hr />
<h2 id="key-concepts-10"><a class="header" href="#key-concepts-10">Key Concepts</a></h2>
<h3 id="1-evidence-chain"><a class="header" href="#1-evidence-chain">1. Evidence Chain</a></h3>
<p>An <strong>evidence chain</strong> is a traceable path from raw data through analysis and decision-making to implementation and verification. In HCI, evidence chains demonstrate that design decisions are grounded in observation, not assumption.</p>
<p><strong>Example (accessible error handling)</strong>:</p>
<ol>
<li><strong>Raw data</strong>: Pilot P3 (SR user) took 127 seconds on T3 (add task); pilot notes: "P3 didn't hear validation error"</li>
<li><strong>Analysis</strong>: Median for sighted pilots = 18 s; P3 MAD = 109 s outlier</li>
<li><strong>Finding</strong>: "Validation errors not announced by screen readers" ‚Üí backlog item</li>
<li><strong>Fix</strong>: Added <code>role="alert" aria-live="assertive"</code> to error div (commit abc123)</li>
<li><strong>Verification</strong>: Re-ran P3 with NVDA; time reduced to 22 s; pilot confirmed "error announced immediately"</li>
</ol>
<p><strong>Traceability requirements</strong>:</p>
<ul>
<li>Every finding must cite pilot ID, task code, and metric</li>
<li>Every fix must cite commit hash and file path</li>
<li>Every verification must cite pilot ID, assistive tech, and outcome</li>
</ul>
<h3 id="2-reflective-writing"><a class="header" href="#2-reflective-writing">2. Reflective Writing</a></h3>
<p><strong>Reflective writing</strong> connects theory to practice by answering:</p>
<ul>
<li><strong>What</strong> did I do? (Description)</li>
<li><strong>Why</strong> did I do it? (Theory/rationale)</li>
<li><strong>How</strong> did it work? (Evidence)</li>
<li><strong>What</strong> did I learn? (Insight)</li>
</ul>
<p><strong>Example (Week 7 inline edit)</strong>:</p>
<blockquote>
<p><strong>What</strong>: I implemented an accessible inline edit using HTMX's <code>hx-target</code> and <code>hx-swap="outerHTML"</code>.
<strong>Why</strong>: This approach supports progressive enhancement (WCAG 2.1.1 Keyboard Access) because the edit form is server-rendered, so keyboard and mouse interactions are identical.
<strong>How</strong>: Manual keyboard testing confirmed that Tab navigated to the "Edit" button, Enter activated it, and focus moved to the title input without page refresh. NVDA announced "Edit task, button" and "Title, edit, [existing value]" correctly.
<strong>What I learned</strong>: Server-first patterns simplify accessibility because you don't need custom ARIA or JavaScript focus management‚Äîthe browser handles it. However, I initially forgot to add <code>aria-live="polite"</code> to the success message, which meant SR users didn't hear confirmation. After adding it (commit xyz789), NVDA announced "Task updated" automatically.</p>
</blockquote>
<p><strong>Good reflective writing</strong>:</p>
<ul>
<li>Cites specific code (file paths, line numbers, commit hashes)</li>
<li>Links to theory (WCAG success criteria, HTMX docs, academic sources)</li>
<li>Includes evidence (screenshots, pilot quotes, metrics)</li>
<li>Identifies mistakes and corrections (not just successes)</li>
</ul>
<h3 id="3-portfolio-structure"><a class="header" href="#3-portfolio-structure">3. Portfolio Structure</a></h3>
<p>A <strong>portfolio</strong> is an organised collection of artefacts (code, docs, evidence) with accompanying reflection. For COMP2850, your portfolio includes:</p>
<ol>
<li><strong>Code repository</strong> (GitLab/GitHub): All commits from Week 6‚Äì11</li>
<li><strong>Evidence directory</strong>: Organised by week (<code>evidence/wk6/</code>, <code>evidence/wk7/</code>, etc.)</li>
<li><strong>Task 1 package</strong> (Gradescope): Consent, pilot data, findings, backlog</li>
<li><strong>Task 2 package</strong> (Gradescope): Prioritisation, fix commits, verification, reflection</li>
<li><strong>README</strong> or <strong>reflection doc</strong>: Narrative tying everything together</li>
</ol>
<p><strong>Portfolio quality indicators</strong>:</p>
<ul>
<li>‚úÖ Every claim has a citation (pilot ID, commit, screenshot)</li>
<li>‚úÖ Evidence is organised and easy to navigate</li>
<li>‚úÖ Code is clean (no commented-out blocks, no TODO markers)</li>
<li>‚úÖ Reflection demonstrates learning (mistakes acknowledged, theory applied)</li>
<li>‚ùå Missing evidence (e.g., "P2 struggled" with no pilot notes)</li>
<li>‚ùå Orphaned artefacts (e.g., screenshot with no context)</li>
<li>‚ùå Copy-paste from labs without adaptation</li>
</ul>
<h3 id="4-submission-readiness"><a class="header" href="#4-submission-readiness">4. Submission Readiness</a></h3>
<p><strong>Gradescope</strong> has technical requirements:</p>
<ul>
<li><strong>File size limit</strong>: 100 MB per submission (compress screenshots if needed)</li>
<li><strong>File naming</strong>: Use consistent, descriptive names (e.g., <code>P1_task3_console.png</code>, not <code>Screenshot 2025-01-15.png</code>)</li>
<li><strong>Directory structure</strong>: Flat or shallow hierarchy (Gradescope doesn't preserve nested folders well)</li>
<li><strong>PDF compilation</strong>: Reflection and analysis docs should be PDF (not .docx or .md)</li>
</ul>
<p><strong>Pre-submission checklist</strong>:</p>
<ol>
<li>Run <code>du -sh evidence/</code> to check total size</li>
<li>Verify all screenshots are legible (minimum 1280√ó720 resolution)</li>
<li>Test PDF rendering (check fonts, images, code blocks)</li>
<li>Confirm commit hashes are correct (use <code>git log --oneline</code>)</li>
<li>Spell-check and proofread all written work</li>
</ol>
<hr />
<h2 id="activity-1-polish-task-1-based-on-critique-feedback"><a class="header" href="#activity-1-polish-task-1-based-on-critique-feedback">Activity 1: Polish Task 1 Based on Critique Feedback</a></h2>
<p><strong>Time</strong>: 30 minutes
<strong>Materials</strong>: Studio crit feedback (Lab 1), Task 1 draft package (Week 9)</p>
<h3 id="step-1-review-critique-feedback"><a class="header" href="#step-1-review-critique-feedback">Step 1: Review Critique Feedback</a></h3>
<p>Open your studio crit feedback notes. Look for <strong>suggestions</strong> that apply to <strong>Task 1</strong> (evaluation and instrumentation). Common themes:</p>
<ul>
<li><strong>Pilot protocol clarity</strong>: "I wasn't sure if consent was verbal or signed" ‚Üí add screenshot of consent script</li>
<li><strong>Metrics interpretation</strong>: "Median looks fine, but no discussion of MAD outliers" ‚Üí add MAD analysis</li>
<li><strong>Evidence completeness</strong>: "P3 notes mention 'struggled with SR' but no specifics" ‚Üí add verbatim quotes, timestamps</li>
<li><strong>Backlog traceability</strong>: "Backlog item #7 says 'fix validation' but doesn't cite pilot data" ‚Üí add pilot ID and metric</li>
</ul>
<h3 id="step-2-update-task-1-files"><a class="header" href="#step-2-update-task-1-files">Step 2: Update Task 1 Files</a></h3>
<p>Your Task 1 package should include:</p>
<pre><code>task1/
‚îú‚îÄ‚îÄ consent-script.md          # Informed consent protocol
‚îú‚îÄ‚îÄ pilot-protocol.md          # Step-by-step task execution guide
‚îú‚îÄ‚îÄ metrics.csv                # Raw data (from data/metrics.csv)
‚îú‚îÄ‚îÄ pilot-notes/               # Qualitative observations
‚îÇ   ‚îú‚îÄ‚îÄ P1_notes.md
‚îÇ   ‚îú‚îÄ‚îÄ P2_notes.md
‚îÇ   ‚îú‚îÄ‚îÄ P3_notes.md
‚îÇ   ‚îî‚îÄ‚îÄ P4_notes.md
‚îú‚îÄ‚îÄ analysis.md                # Median, MAD, error rate, completion rate
‚îú‚îÄ‚îÄ findings.md                # Synthesised insights with evidence
‚îú‚îÄ‚îÄ backlog-update.md          # New items added to product backlog
‚îî‚îÄ‚îÄ reflection-task1.pdf       # Reflective writing (compiled)
</code></pre>
<p><strong>Action</strong>: For each critique suggestion, update the relevant file. Example:</p>
<p><strong>Before</strong> (<code>findings.md</code>):</p>
<pre><code class="language-markdown">3. Validation errors not visible to screen reader users.
</code></pre>
<p><strong>After</strong> (<code>findings.md</code>):</p>
<pre><code class="language-markdown">3. **Validation errors not announced by screen readers** (Priority 1)
   - **Evidence**: Pilot P3 (NVDA, keyboard) took 127 s on T3 (add task); median = 18 s, MAD = 10 s ‚Üí P3 is 10.9 MAD outlier. Pilot notes (line 14): "P3 submitted blank form three times; NVDA did not announce 'Title is required' error."
   - **Root cause**: Error div lacks `role="alert"` and `aria-live` region.
   - **Impact**: WCAG 4.1.3 (Status Messages) failure; SR users cannot recover from validation errors.
   - **Backlog item**: #7 "Add role=alert to validation error div" (Priority 1, Effort: 2)
</code></pre>
<h3 id="step-3-compress-and-verify"><a class="header" href="#step-3-compress-and-verify">Step 3: Compress and Verify</a></h3>
<ol>
<li>
<p><strong>Compress screenshots</strong>: If <code>pilot-notes/</code> includes large PNGs, compress them:</p>
<pre><code class="language-bash"># Using ImageMagick (if available)
mogrify -resize 1920x1080 -quality 85 pilot-notes/*.png

# Or use online tool: https://tinypng.com/
</code></pre>
</li>
<li>
<p><strong>Check total size</strong>:</p>
<pre><code class="language-bash">du -sh task1/
# Should be &lt; 50 MB for Task 1 alone
</code></pre>
</li>
<li>
<p><strong>Verify PDF compilation</strong>: Convert <code>reflection-task1.md</code> to PDF:</p>
<pre><code class="language-bash">pandoc reflection-task1.md -o reflection-task1.pdf --pdf-engine=xelatex

# Or use Markdown preview ‚Üí print to PDF in your editor
</code></pre>
</li>
<li>
<p><strong>Test readability</strong>: Open <code>reflection-task1.pdf</code> and check:</p>
<ul>
<li>Code blocks are formatted (monospace font, syntax highlighting preserved)</li>
<li>Screenshots are legible (not pixelated)</li>
<li>Fonts render correctly (no missing glyphs)</li>
</ul>
</li>
</ol>
<p><strong>Stop and check</strong>: Open <code>findings.md</code>. For each finding, verify:</p>
<ul>
<li>‚úÖ Pilot ID cited</li>
<li>‚úÖ Task code cited (T1, T2, T3, T4)</li>
<li>‚úÖ Metric cited (median, MAD, error rate, or qualitative quote)</li>
<li>‚úÖ WCAG criterion or privacy principle cited (if applicable)</li>
<li>‚úÖ Backlog item ID cross-referenced</li>
</ul>
<hr />
<h2 id="activity-2-assemble-task-2-portfolio"><a class="header" href="#activity-2-assemble-task-2-portfolio">Activity 2: Assemble Task 2 Portfolio</a></h2>
<p><strong>Time</strong>: 40 minutes
<strong>Materials</strong>: Task 2 draft (Week 10), regression checklist, verification pilot data, critique feedback</p>
<h3 id="step-1-review-task-2-requirements"><a class="header" href="#step-1-review-task-2-requirements">Step 1: Review Task 2 Requirements</a></h3>
<p>Task 2 focuses on <strong>redesign</strong> and <strong>verification</strong>. Your package must show:</p>
<ol>
<li><strong>Prioritisation rationale</strong>: How you scored issues with (Impact + Inclusion) ‚Äì Effort</li>
<li><strong>Implementation evidence</strong>: Commit hashes, before/after code diffs, WCAG mapping</li>
<li><strong>Regression testing</strong>: Proof that fixes didn't break existing features</li>
<li><strong>Verification pilots</strong>: Re-ran same tasks with same assistive tech; metrics improved</li>
<li><strong>Reflection</strong>: What you learned about inclusive redesign</li>
</ol>
<h3 id="step-2-organise-task-2-files"><a class="header" href="#step-2-organise-task-2-files">Step 2: Organise Task 2 Files</a></h3>
<pre><code>task2/
‚îú‚îÄ‚îÄ prioritisation.md          # Scoring matrix with rationale
‚îú‚îÄ‚îÄ fixes/                     # One file per priority issue
‚îÇ   ‚îú‚îÄ‚îÄ fix01-validation-alert.md
‚îÇ   ‚îú‚îÄ‚îÄ fix02-focus-visible.md
‚îÇ   ‚îî‚îÄ‚îÄ fix03-error-summary.md
‚îú‚îÄ‚îÄ commits.md                 # List of all fix commits with hashes
‚îú‚îÄ‚îÄ regression-checklist.pdf   # Completed checklist (from Week 10)
‚îú‚îÄ‚îÄ verification/              # Re-test data
‚îÇ   ‚îú‚îÄ‚îÄ metrics-after.csv
‚îÇ   ‚îú‚îÄ‚îÄ P3_retest_notes.md
‚îÇ   ‚îî‚îÄ‚îÄ P3_retest_nvda.png     # Screenshot of NVDA announcing error
‚îú‚îÄ‚îÄ wcag-compliance.md         # Mapping fixes ‚Üí WCAG success criteria
‚îî‚îÄ‚îÄ reflection-task2.pdf       # Reflective writing
</code></pre>
<h3 id="step-3-write-fix-documentation"><a class="header" href="#step-3-write-fix-documentation">Step 3: Write Fix Documentation</a></h3>
<p>For each priority issue, create a <code>fix##-description.md</code> file. Use this template:</p>
<pre><code class="language-markdown"># Fix 01: Validation Errors Not Announced by Screen Readers

## Problem Statement
**Evidence**: Pilot P3 (NVDA, keyboard) took 127 s on T3 (add task); median = 18 s. Pilot notes: "P3 didn't hear error message."
**Impact**: WCAG 4.1.3 (Status Messages) failure. SR users cannot recover from validation errors.
**Priority score**: (5 Impact + 5 Inclusion) ‚Äì 2 Effort = 8 (Priority 1)

## Solution
Added `role="alert"` and `aria-live="assertive"` to error div for HTMX path; added error summary for no-JS path.

### Before (Commit 7a3f9b2)
```kotlin
// routes/Tasks.kt, line 45
if (title.isBlank()) {
    if (call.isHtmx()) {
        val status = """&lt;div id="status" hx-swap-oob="true"&gt;Title is required.&lt;/div&gt;"""
        return@post call.respondText(status, ContentType.Text.Html, HttpStatusCode.BadRequest)
    }
    // No-JS path omitted for brevity
}
</code></pre>
<h3 id="after-commit-c8d1e4f"><a class="header" href="#after-commit-c8d1e4f">After (Commit c8d1e4f)</a></h3>
<pre><code class="language-kotlin">// routes/Tasks.kt, line 45
if (title.isBlank()) {
    if (call.isHtmx()) {
        val status = """&lt;div id="status" role="alert" aria-live="assertive" hx-swap-oob="true"&gt;
            Title is required. Please enter at least one character.
        &lt;/div&gt;"""
        return@post call.respondText(status, ContentType.Text.Html, HttpStatusCode.BadRequest)
    }
    // No-JS: redirect to /tasks?error=title, error-summary.peb includes role=alert
}
</code></pre>
<h3 id="wcag-mapping"><a class="header" href="#wcag-mapping">WCAG Mapping</a></h3>
<ul>
<li><strong>4.1.3 Status Messages (AA)</strong>: Error is now programmatically announced to SR users without focus change.</li>
<li><strong>3.3.1 Error Identification (A)</strong>: Error message explicitly states what went wrong and how to fix it.</li>
</ul>
<h2 id="verification-1"><a class="header" href="#verification-1">Verification</a></h2>
<p><strong>Re-test</strong>: Pilot P3, NVDA 2024.1, keyboard-only, JS-on
<strong>Result</strong>: Time reduced to 22 s (within 1 MAD of median). NVDA announced "Title is required" immediately after form submission. P3 confirmed: "Much better‚ÄîI heard the error straight away."</p>
<p><strong>Regression</strong>: Keyboard, mouse, no-JS paths all tested; no regressions (see <code>regression-checklist.pdf</code>).</p>
<h2 id="reflection"><a class="header" href="#reflection">Reflection</a></h2>
<p>This fix taught me that <strong>announcements require explicit ARIA roles</strong>. I initially assumed HTMX's OOB swap would be enough, but SR users rely on live regions to detect dynamic changes. The fix was simple (2 lines), but the impact was huge (10.9 MAD outlier ‚Üí within normal range). This reinforces the principle that <strong>accessibility is often low-effort if designed in from the start</strong>, but expensive to retrofit.</p>
<hr />
<p><strong>Commit</strong>: c8d1e4f
<strong>Files changed</strong>: <code>routes/Tasks.kt</code> (line 45‚Äì52), <code>views/error-summary.peb</code> (added)
<strong>Evidence</strong>: <code>verification/P3_retest_nvda.png</code>, <code>verification/P3_retest_notes.md</code></p>
<pre><code>
**Repeat for all priority fixes** (typically 3‚Äì5 issues).

### Step 4: Complete Regression Checklist

Your regression checklist from Week 10 Lab 2 should be converted to PDF. If incomplete, fill it out now:

| Test | Path | Tool | Result | Notes |
|------|------|------|--------|-------|
| T1 (Filter) | HTMX, mouse | Chrome | ‚úÖ Pass | Filters apply instantly; status updates in #status div |
| T1 (Filter) | No-JS | Chrome | ‚úÖ Pass | Form submission triggers full-page reload; filters persist in query string |
| T2 (Edit) | HTMX, keyboard | Firefox + NVDA | ‚úÖ Pass | Tab to "Edit", Enter activates; focus moves to input; NVDA announces "Title, edit, [value]" |
| T3 (Add) | HTMX, keyboard | Firefox + NVDA | ‚úÖ Pass | Blank submission triggers alert; NVDA announces error |
| T3 (Add) | No-JS | Chrome | ‚úÖ Pass | Redirect to /tasks?error=title; error summary shown with focus on heading |
| T4 (Delete) | HTMX, mouse | Chrome | ‚úÖ Pass | OOB swap removes `&lt;li&gt;`; status confirms deletion |

**Save as PDF**: `regression-checklist.pdf`

### Step 5: Update WCAG Compliance Doc

Create `wcag-compliance.md` mapping all fixes to WCAG 2.2 AA criteria:

```markdown
# WCAG 2.2 AA Compliance Summary

## Level A (Baseline)
- **1.3.1 Info &amp; Relationships**: Semantic HTML (`&lt;button&gt;`, `&lt;label&gt;`, `&lt;ul&gt;`) used throughout; verified with axe DevTools.
- **2.1.1 Keyboard**: All interactive elements accessible via Tab/Enter/Space; no keyboard traps (tested with Firefox + NVDA).
- **3.3.1 Error Identification**: Validation errors explicitly describe problem and solution ("Title is required. Please enter at least one character.").
- **4.1.2 Name, Role, Value**: All form inputs have associated labels; buttons have accessible names.

## Level AA (Target)
- **1.4.3 Contrast (Minimum)**: Error text (`#d32f2f`) on white background = 5.2:1 (tested with Colour Contrast Analyser).
- **2.4.7 Focus Visible**: Custom focus outline (3px solid `#1976d2`) added to all interactive elements (CSS line 45).
- **3.3.3 Error Suggestion**: Validation messages include corrective hint ("Please enter at least one character").
- **4.1.3 Status Messages**: Alerts use `role="alert" aria-live="assertive"`; success messages use `aria-live="polite"`.

## Fixes Mapped to Criteria
| Fix | WCAG Criterion | Commit | Verification |
|-----|---------------|--------|-------------|
| Validation alert | 4.1.3 (AA) | c8d1e4f | P3 retest (NVDA announced error) |
| Focus visible | 2.4.7 (AA) | b9a2c3d | Keyboard-only pilot (focus outline visible) |
| Error summary (no-JS) | 3.3.1 (A) | e7f8a1b | No-JS pilot (error list shown, focus on heading) |

---
**Reference**: [WCAG 2.2 Quick Reference](https://www.w3.org/WAI/WCAG22/quickref/)
</code></pre>
<h3 id="step-6-write-task-2-reflection"><a class="header" href="#step-6-write-task-2-reflection">Step 6: Write Task 2 Reflection</a></h3>
<p>Your <code>reflection-task2.md</code> should answer:</p>
<ol>
<li><strong>What redesign approach did you take?</strong> (Prioritisation framework, fix strategy)</li>
<li><strong>Why these fixes?</strong> (Link to evidence: metrics, pilot quotes, WCAG criteria)</li>
<li><strong>How did you verify impact?</strong> (Re-test results, regression checks)</li>
<li><strong>What did you learn?</strong> (Insights about accessibility, trade-offs, server-first architecture)</li>
</ol>
<p><strong>Example structure</strong> (aim for 800‚Äì1,000 words):</p>
<pre><code class="language-markdown"># Task 2 Reflection: Inclusive Redesign

## Overview
After analysing pilot data from Week 9, I identified 8 accessibility and usability issues. Using the (Impact + Inclusion) ‚Äì Effort prioritisation framework, I focused on the top 3 issues that disproportionately affected screen reader users and keyboard-only users...

## Prioritisation Rationale
I scored each issue on three dimensions:
- **Impact** (1‚Äì5): How much does this block task completion?
- **Inclusion** (1‚Äì5): Does this disproportionately affect people using assistive tech?
- **Effort** (1‚Äì5): How complex is the fix?

The highest-scoring issue was "Validation errors not announced by SR" (Priority: 8). Pilot P3 took 127 s on T3 (median = 18 s), and pilot notes (line 14) stated: "P3 didn't hear error; submitted blank form three times." This is a WCAG 4.1.3 failure (Status Messages) and blocks task completion entirely for SR users...

## Implementation
I implemented three priority fixes:

### Fix 1: Validation Alerts (Commit c8d1e4f)
**Problem**: Error div lacked `role="alert"` and `aria-live` region.
**Solution**: Added `role="alert" aria-live="assertive"` to HTMX error swap (routes/Tasks.kt:47); added error summary with `role="alert"` for no-JS path (views/error-summary.peb).
**Theory**: WCAG 4.1.3 requires status messages to be programmatically announced. ARIA live regions solve this without moving focus (which would disrupt flow).
**Result**: P3 retest reduced time to 22 s (within 1 MAD); NVDA announced error immediately...

[Continue for Fix 2, Fix 3]

## Verification &amp; Regression
I re-ran Pilot P3 with the same tasks (T1‚ÄìT4), assistive tech (NVDA 2024.1), and input method (keyboard-only). Time on T3 dropped from 127 s to 22 s, and P3 confirmed "error announced immediately" (see verification/P3_retest_notes.md).

I also completed a regression checklist covering HTMX, no-JS, keyboard, and mouse paths (see regression-checklist.pdf). No regressions were detected...

## Learning &amp; Trade-offs
This project taught me that **server-first architecture simplifies accessibility** because HTML is semantic by default, and the browser handles focus/tab order/SR announcements. However, I discovered one trade-off: HTMX's OOB swaps don't trigger live region announcements unless you explicitly add `role="alert"`. This is documented in hypermedia.systems (Ch. 9), but I missed it initially.

I also learned that **prioritisation frameworks are essential** when time is limited. I could have fixed all 8 issues, but focusing on the top 3 (total effort: 6 hours) yielded the biggest impact (removed all SR blockers). The remaining 5 issues are in my backlog for Semester 2...

## Conclusion
By grounding decisions in pilot data (median, MAD, qualitative notes) and WCAG criteria, I built an inclusive task manager that works identically with/without JS, with/without a mouse, and with/without a screen reader. This process reinforced that accessibility is not a feature‚Äîit's a design constraint that improves usability for everyone.
</code></pre>
<p><strong>Save as</strong>: <code>reflection-task2.md</code> ‚Üí compile to <code>reflection-task2.pdf</code>.</p>
<p><strong>Stop and check</strong>: Open <code>task2/fixes/</code>. For each fix file, verify:</p>
<ul>
<li>‚úÖ Problem statement cites pilot data (ID, task, metric)</li>
<li>‚úÖ Solution includes before/after code with commit hash</li>
<li>‚úÖ WCAG criterion mapped</li>
<li>‚úÖ Verification evidence cited (retest pilot, screenshot)</li>
<li>‚úÖ Reflection identifies learning or trade-off</li>
</ul>
<hr />
<h2 id="activity-3-final-repository--evidence-review"><a class="header" href="#activity-3-final-repository--evidence-review">Activity 3: Final Repository &amp; Evidence Review</a></h2>
<p><strong>Time</strong>: 20 minutes
<strong>Materials</strong>: Git log, <code>evidence/</code> directory, README</p>
<h3 id="step-1-review-commit-history"><a class="header" href="#step-1-review-commit-history">Step 1: Review Commit History</a></h3>
<p>Run <code>git log --oneline --since="2025-01-01"</code> to see all commits from Weeks 6‚Äì11. Check for:</p>
<ul>
<li>‚úÖ Descriptive commit messages (e.g., "Add role=alert to validation error (WCAG 4.1.3)" not "fix bug")</li>
<li>‚úÖ Consistent branch strategy (e.g., all work on <code>main</code>, or feature branches merged cleanly)</li>
<li>‚ùå Merge conflicts left unresolved</li>
<li>‚ùå Sensitive data in history (e.g., API keys, database passwords)</li>
</ul>
<p>If you find issues, clean them up now:</p>
<pre><code class="language-bash"># Amend last commit message
git commit --amend -m "Add ARIA live region to error div (WCAG 4.1.3)"

# Rebase to clean up history (use with caution)
git rebase -i HEAD~5  # Interactive rebase for last 5 commits
</code></pre>
<p><strong>Create <code>commits.md</code></strong> for Task 2 package:</p>
<pre><code class="language-markdown"># Commit Log: Task 2 Fixes

| Commit | Date | Description | Files |
|--------|------|-------------|-------|
| c8d1e4f | 2025-01-10 | Add role=alert to validation error (WCAG 4.1.3) | routes/Tasks.kt, views/error-summary.peb |
| b9a2c3d | 2025-01-11 | Add focus-visible outline (WCAG 2.4.7) | static/style.css |
| e7f8a1b | 2025-01-12 | Add error summary for no-JS path (WCAG 3.3.1) | views/error-summary.peb, routes/Tasks.kt |

**Full log**: `git log --oneline --since="2025-01-06" --until="2025-01-12"`
</code></pre>
<h3 id="step-2-audit-evidence-directory"><a class="header" href="#step-2-audit-evidence-directory">Step 2: Audit Evidence Directory</a></h3>
<p>Your <code>evidence/</code> folder should be organised by week:</p>
<pre><code>evidence/
‚îú‚îÄ‚îÄ wk6/
‚îÇ   ‚îú‚îÄ‚îÄ consent-screenshot.png
‚îÇ   ‚îî‚îÄ‚îÄ backlog-before.png
‚îú‚îÄ‚îÄ wk7/
‚îÇ   ‚îú‚îÄ‚îÄ axe-audit-before.png
‚îÇ   ‚îú‚îÄ‚îÄ axe-audit-after.png
‚îÇ   ‚îî‚îÄ‚îÄ inline-edit-demo.png
‚îú‚îÄ‚îÄ wk8/
‚îÇ   ‚îú‚îÄ‚îÄ nojs-verification.png
‚îÇ   ‚îî‚îÄ‚îÄ dual-path-trace.md
‚îú‚îÄ‚îÄ wk9/
‚îÇ   ‚îú‚îÄ‚îÄ P1_console.png
‚îÇ   ‚îú‚îÄ‚îÄ P2_console.png
‚îÇ   ‚îú‚îÄ‚îÄ P3_nvda_console.png
‚îÇ   ‚îú‚îÄ‚îÄ P4_nojs_console.png
‚îÇ   ‚îî‚îÄ‚îÄ metrics.csv
‚îú‚îÄ‚îÄ wk10/
‚îÇ   ‚îú‚îÄ‚îÄ prioritisation-matrix.png
‚îÇ   ‚îú‚îÄ‚îÄ fix01-before.png
‚îÇ   ‚îú‚îÄ‚îÄ fix01-after.png
‚îÇ   ‚îî‚îÄ‚îÄ regression-checklist.pdf
‚îî‚îÄ‚îÄ wk11/
    ‚îú‚îÄ‚îÄ crit-slides.pdf
    ‚îú‚îÄ‚îÄ P3_retest_nvda.png
    ‚îî‚îÄ‚îÄ reflection-final.pdf
</code></pre>
<p><strong>Action</strong>: For each directory, check:</p>
<ol>
<li><strong>File naming</strong>: Descriptive, not generic (e.g., <code>P3_nvda_console.png</code> not <code>screenshot.png</code>)</li>
<li><strong>Legibility</strong>: Open each image; confirm text is readable (min 1280√ó720)</li>
<li><strong>Context</strong>: Create a <code>README.md</code> in each week's folder explaining what each file is</li>
</ol>
<p><strong>Example</strong> (<code>evidence/wk9/README.md</code>):</p>
<pre><code class="language-markdown"># Week 9 Evidence: Evaluation &amp; Pilots

- **P1_console.png**: Browser console for Pilot 1 (HTMX, mouse, JS-on); shows Logger entries for T3, T1, T2, T4.
- **P2_console.png**: Browser console for Pilot 2 (HTMX, keyboard, JS-on).
- **P3_nvda_console.png**: Combined screenshot showing NVDA speech viewer + browser console for Pilot 3 (SR, keyboard, JS-on). Note NVDA did NOT announce validation error (fixed in Week 10).
- **P4_nojs_console.png**: Browser console for Pilot 4 (no-JS, mouse); shows full-page reloads on form submit.
- **metrics.csv**: Raw data exported from `data/metrics.csv` after all pilots completed.
</code></pre>
<h3 id="step-3-update-repository-readme"><a class="header" href="#step-3-update-repository-readme">Step 3: Update Repository README</a></h3>
<p>Your main <code>README.md</code> should provide a <strong>portfolio navigation guide</strong>. Example:</p>
<pre><code class="language-markdown"># COMP2850 HCI: Task Manager with Privacy by Design

**Student**: [Your Name]
**Module**: COMP2850 Human-Computer Interaction, University of Leeds
**Academic Year**: 2024/25

---

## Project Overview

This repository contains a **task manager web application** built with **Kotlin/Ktor + HTMX**, demonstrating:
- **Privacy by design**: Anonymous session IDs, no PII collected, UK GDPR compliance
- **WCAG 2.2 AA compliance**: Accessible to keyboard, screen reader, and no-JS users
- **Server-first architecture**: HTML rendered server-side, progressive enhancement with HTMX
- **Evidence-led design**: Evaluated via task-based pilots (n=4); redesigned based on metrics

---

## Portfolio Structure

### Code &amp; Application
- **`src/`**: Kotlin/Ktor routes, models, utilities
- **`views/`**: Pebble templates (HTML)
- **`static/`**: CSS, JS (minimal), HTMX library
- **`data/`**: Anonymised session + metrics CSVs
- **`test/`**: Unit tests (not covered in labs)

### Evidence (by week)
- **`evidence/wk6/`**: Needs-finding, consent protocol, backlog initialisation
- **`evidence/wk7/`**: Ethics overlay (session IDs), accessibility audit (axe DevTools), inline edit fix
- **`evidence/wk8/`**: No-JS verification, dual-path routing, trade-offs doc
- **`evidence/wk9/`**: Pilot protocol, raw metrics, pilot notes, qualitative findings
- **`evidence/wk10/`**: Prioritisation matrix, fix commits, regression checklist, verification pilots
- **`evidence/wk11/`**: Studio crit slides, peer feedback, final reflection

### Gradescope Submissions
- **`task1/`**: Evaluation package (consent, pilots, analysis, findings, backlog)
- **`task2/`**: Redesign package (prioritisation, fixes, verification, reflection)

---

## Key Features

1. **Privacy by Design** (Week 6‚Äì7)
   - Anonymous session IDs (12-char hex) stored in cookies
   - No usernames, emails, or PII collected
   - Data stored in local CSV (not cloud database) with UK GDPR justification

2. **WCAG 2.2 AA Compliance** (Week 7, 10)
   - Semantic HTML (`&lt;button&gt;`, `&lt;label&gt;`, `&lt;ul&gt;`)
   - Keyboard accessible (Tab, Enter, Space)
   - Screen reader tested (NVDA 2024.1, VoiceOver)
   - Error handling: `role="alert" aria-live="assertive"`
   - Focus visible: Custom outline (3px solid #1976d2)

3. **Server-First + HTMX** (Week 6, 8)
   - All state managed server-side (tasks stored in `data/tasks.csv`)
   - HTMX handles dynamic updates (`hx-post`, `hx-target`, `hx-swap`)
   - No-JS parity: All features work with JS disabled (verified in Week 8)

4. **Evaluation &amp; Iteration** (Week 9‚Äì10)
   - Task-based pilots (n=4): T1 (filter), T2 (edit), T3 (add), T4 (delete)
   - Metrics: Median = 18 s, MAD = 10 s; P3 (SR) outlier = 127 s
   - Prioritised fixes: (Impact + Inclusion) ‚Äì Effort scoring
   - Verification: P3 retest reduced to 22 s (within 1 MAD)

---

## Running the Application

```bash
# Prerequisites: JDK 21+, Gradle 8+
./gradlew run

# Application starts on http://localhost:8080/tasks
</code></pre>
<p><strong>Test with different modes</strong>:</p>
<ul>
<li><strong>HTMX + mouse</strong>: Default behaviour (Chrome, Firefox)</li>
<li><strong>HTMX + keyboard</strong>: Tab to navigate, Enter/Space to activate</li>
<li><strong>Screen reader</strong>: NVDA (Windows), VoiceOver (macOS)</li>
<li><strong>No-JS</strong>: Disable JS in browser DevTools (F12 ‚Üí Settings ‚Üí Disable JavaScript)</li>
</ul>
<hr />
<h2 id="commit-highlights"><a class="header" href="#commit-highlights">Commit Highlights</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Commit</th><th>Week</th><th>Description</th></tr></thead><tbody>
<tr><td>abc123</td><td>6</td><td>Initial scaffold: routes, Pebble templates, HTMX setup</td></tr>
<tr><td>def456</td><td>6</td><td>Add session ID generation + cookie storage</td></tr>
<tr><td>ghi789</td><td>7</td><td>Add Logger for metrics instrumentation</td></tr>
<tr><td>jkl012</td><td>7</td><td>Fix inline edit accessibility (focus + ARIA)</td></tr>
<tr><td>mno345</td><td>8</td><td>Add dual-path validation (HTMX + no-JS)</td></tr>
<tr><td>pqr678</td><td>10</td><td>Add role=alert to error div (WCAG 4.1.3)</td></tr>
<tr><td>stu901</td><td>10</td><td>Add focus-visible outline (WCAG 2.4.7)</td></tr>
</tbody></table>
</div>
<p><strong>Full log</strong>: <code>git log --oneline</code></p>
<hr />
<h2 id="references-1"><a class="header" href="#references-1">References</a></h2>
<ul>
<li><strong>HTMX</strong>: <a href="https://hypermedia.systems/">hypermedia.systems</a> (Carson Gross, 2023)</li>
<li><strong>WCAG 2.2</strong>: <a href="https://www.w3.org/WAI/WCAG22/quickref/">W3C Quick Reference</a></li>
<li><strong>Privacy by Design</strong>: <a href="https://ico.org.uk/for-organisations/uk-gdpr-guidance-and-resources/">ICO Guide</a></li>
<li><strong>Ktor</strong>: <a href="https://ktor.io/">ktor.io</a></li>
<li><strong>Pebble Templates</strong>: <a href="https://pebbletemplates.io/">pebbletemplates.io</a></li>
</ul>
<hr />
<h2 id="acknowledgements"><a class="header" href="#acknowledgements">Acknowledgements</a></h2>
<ul>
<li><strong>Module staff</strong>: Dr. [Name], teaching assistants</li>
<li><strong>Peers</strong>: Studio crit feedback from [Team Names]</li>
<li><strong>Tools</strong>: axe DevTools, NVDA, Colour Contrast Analyser, curl</li>
</ul>
<hr />
<p><strong>Licence</strong>: Academic work for COMP2850 (not for redistribution)</p>
<pre><code>
**Stop and check**: Open `README.md` in your repo. Verify:
- ‚úÖ Project overview explains what you built and why
- ‚úÖ Portfolio structure lists all key directories
- ‚úÖ Running instructions work (test with `./gradlew run`)
- ‚úÖ Commit highlights cite key milestones
- ‚úÖ References cite all external sources (HTMX, WCAG, academic papers)

---

## Activity 4: Practice Gradescope Submission

**Time**: 20 minutes
**Materials**: Task 1 and Task 2 packages, Gradescope test environment (if available)

### Step 1: Check File Size Limits

Gradescope has a **100 MB limit per submission**. Check your package sizes:

```bash
du -sh task1/
du -sh task2/

# If over 50 MB, identify large files
du -ah task1/ | sort -rh | head -n 10
du -ah task2/ | sort -rh | head -n 10
</code></pre>
<p><strong>Common culprits</strong>:</p>
<ul>
<li>Uncompressed screenshots (5‚Äì10 MB each)</li>
<li>Video recordings (not required; remove or compress heavily)</li>
<li>Database dumps (not required; use <code>metrics.csv</code> only)</li>
</ul>
<p><strong>Compression tips</strong>:</p>
<pre><code class="language-bash"># Compress PNGs with ImageMagick
mogrify -resize 1920x1080 -quality 85 task1/**/*.png task2/**/*.png

# Or use online tool: https://tinypng.com/

# Compress PDFs with Ghostscript
gs -sDEVICE=pdfwrite -dCompatibilityLevel=1.4 -dPDFSETTINGS=/screen \
   -dNOPAUSE -dQUIET -dBATCH \
   -sOutputFile=reflection-compressed.pdf reflection-task1.pdf
</code></pre>
<h3 id="step-2-create-submission-zips"><a class="header" href="#step-2-create-submission-zips">Step 2: Create Submission ZIPs</a></h3>
<p>Gradescope typically requires a <strong>single ZIP per task</strong>. Create them:</p>
<pre><code class="language-bash"># Task 1
cd task1/
zip -r ../task1-submission.zip .
cd ..

# Task 2
cd task2/
zip -r ../task2-submission.zip .
cd ..

# Verify contents
unzip -l task1-submission.zip
unzip -l task2-submission.zip
</code></pre>
<p><strong>Check</strong>:</p>
<ul>
<li>‚úÖ All required files present (consent, pilots, analysis, reflection)</li>
<li>‚úÖ No extra files (e.g., <code>.DS_Store</code>, <code>Thumbs.db</code>, <code>__MACOSX/</code>)</li>
<li>‚úÖ File paths are flat or shallow (Gradescope doesn't always preserve deep nesting)</li>
</ul>
<h3 id="step-3-test-upload-dry-run"><a class="header" href="#step-3-test-upload-dry-run">Step 3: Test Upload (Dry Run)</a></h3>
<p>If Gradescope has a <strong>draft/test assignment</strong>, upload your ZIPs there. Otherwise, do a local dry run:</p>
<ol>
<li>
<p><strong>Simulate grader view</strong>: Extract your ZIP in a temp directory and navigate it as if you're a marker:</p>
<pre><code class="language-bash">mkdir /tmp/grader-test
cd /tmp/grader-test
unzip ~/comp2850/task1-submission.zip

# Open files in order:
# 1. consent-script.md
# 2. pilot-protocol.md
# 3. analysis.md
# 4. findings.md
# 5. reflection-task1.pdf
</code></pre>
</li>
<li>
<p><strong>Check cross-references</strong>: Do all citations work? (e.g., "See P3_notes.md line 14" ‚Üí open that file and verify line 14 exists)</p>
</li>
<li>
<p><strong>Verify PDFs</strong>: Open <code>reflection-task1.pdf</code> and <code>reflection-task2.pdf</code>:</p>
<ul>
<li>‚úÖ Code blocks formatted correctly</li>
<li>‚úÖ Screenshots embedded and legible</li>
<li>‚úÖ Page numbers visible (if multi-page)</li>
<li>‚úÖ No truncated text or missing images</li>
</ul>
</li>
</ol>
<h3 id="step-4-pre-submission-checklist"><a class="header" href="#step-4-pre-submission-checklist">Step 4: Pre-Submission Checklist</a></h3>
<p>Print this checklist and tick off each item:</p>
<p><strong>Task 1 (Evaluation)</strong></p>
<ul>
<li><input disabled="" type="checkbox"/>
<code>consent-script.md</code> includes informed consent protocol</li>
<li><input disabled="" type="checkbox"/>
<code>pilot-protocol.md</code> includes step-by-step task execution guide</li>
<li><input disabled="" type="checkbox"/>
<code>metrics.csv</code> is anonymised (no real names, emails)</li>
<li><input disabled="" type="checkbox"/>
<code>pilot-notes/</code> includes 4 files (P1, P2, P3, P4) with timestamps and quotes</li>
<li><input disabled="" type="checkbox"/>
<code>analysis.md</code> includes median, MAD, error rate, completion rate</li>
<li><input disabled="" type="checkbox"/>
<code>findings.md</code> synthesises insights with pilot citations</li>
<li><input disabled="" type="checkbox"/>
<code>backlog-update.md</code> lists new items added, with priority scores</li>
<li><input disabled="" type="checkbox"/>
<code>reflection-task1.pdf</code> compiled, readable, includes code examples and theory links</li>
<li><input disabled="" type="checkbox"/>
Total size &lt; 50 MB</li>
<li><input disabled="" type="checkbox"/>
All commit hashes correct (<code>git log --oneline</code> to verify)</li>
</ul>
<p><strong>Task 2 (Redesign)</strong></p>
<ul>
<li><input disabled="" type="checkbox"/>
<code>prioritisation.md</code> includes scoring matrix with rationale</li>
<li><input disabled="" type="checkbox"/>
<code>fixes/</code> directory includes one file per priority issue (typically 3‚Äì5)</li>
<li><input disabled="" type="checkbox"/>
<code>commits.md</code> lists all fix commits with hashes and files changed</li>
<li><input disabled="" type="checkbox"/>
<code>regression-checklist.pdf</code> completed and signed off</li>
<li><input disabled="" type="checkbox"/>
<code>verification/</code> includes retest data (metrics, pilot notes, screenshots)</li>
<li><input disabled="" type="checkbox"/>
<code>wcag-compliance.md</code> maps fixes to WCAG 2.2 success criteria</li>
<li><input disabled="" type="checkbox"/>
<code>reflection-task2.pdf</code> compiled, readable, includes before/after code and learning insights</li>
<li><input disabled="" type="checkbox"/>
Total size &lt; 50 MB</li>
<li><input disabled="" type="checkbox"/>
All WCAG criteria correctly cited (check against <a href="https://www.w3.org/WAI/WCAG22/quickref/">W3C Quick Reference</a>)</li>
</ul>
<p><strong>Repository</strong></p>
<ul>
<li><input disabled="" type="checkbox"/>
<code>README.md</code> includes portfolio navigation and running instructions</li>
<li><input disabled="" type="checkbox"/>
<code>evidence/</code> organised by week with descriptive file names</li>
<li><input disabled="" type="checkbox"/>
Commit history clean (no sensitive data, descriptive messages)</li>
<li><input disabled="" type="checkbox"/>
Application runs locally (<code>./gradlew run</code> works)</li>
</ul>
<h3 id="step-5-backup-strategy"><a class="header" href="#step-5-backup-strategy">Step 5: Backup Strategy</a></h3>
<p>Before final submission:</p>
<ol>
<li>
<p><strong>Tag your repository</strong>:</p>
<pre><code class="language-bash">git tag -a v1.0-task1 -m "Task 1 submission (2025-01-15)"
git tag -a v1.0-task2 -m "Task 2 submission (2025-01-17)"
git push origin --tags
</code></pre>
</li>
<li>
<p><strong>Create backup ZIPs</strong> with date stamps:</p>
<pre><code class="language-bash">cp task1-submission.zip task1-submission-2025-01-15.zip
cp task2-submission.zip task2-submission-2025-01-17.zip
</code></pre>
</li>
<li>
<p><strong>Upload to cloud</strong> (optional but recommended):</p>
<ul>
<li>University OneDrive, Google Drive, or Dropbox</li>
<li>Keeps a timestamped copy in case Gradescope has issues</li>
</ul>
</li>
</ol>
<p><strong>Stop and check</strong>: Unzip <code>task1-submission.zip</code> and <code>task2-submission.zip</code> in a temp directory. Open <code>reflection-task1.pdf</code> and <code>reflection-task2.pdf</code>. For each:</p>
<ul>
<li>‚úÖ All pages render correctly</li>
<li>‚úÖ Code blocks use monospace font</li>
<li>‚úÖ Screenshots are legible (text readable at 100% zoom)</li>
<li>‚úÖ File size &lt; 20 MB each</li>
</ul>
<hr />
<h2 id="activity-5-module-reflection--semester-2-planning"><a class="header" href="#activity-5-module-reflection--semester-2-planning">Activity 5: Module Reflection &amp; Semester 2 Planning</a></h2>
<p><strong>Time</strong>: 20 minutes
<strong>Materials</strong>: Lab notes from Weeks 6‚Äì11, backlog, peer feedback</p>
<h3 id="step-1-self-assessment--learning-outcomes"><a class="header" href="#step-1-self-assessment--learning-outcomes">Step 1: Self-Assessment ‚Äî Learning Outcomes</a></h3>
<p>Review your evidence against all <strong>13 HCI Learning Outcomes</strong> you've addressed across Weeks 6-11. Rate your confidence (1 = not confident, 5 = very confident) and note where the evidence lives.</p>
<p>See <a href="wk11/../references/learning-outcomes.html">Learning Outcomes Reference</a> for full LO definitions.</p>
<div class="table-wrapper"><table><thead><tr><th>LO</th><th>Outcome</th><th>Confidence (1‚Äì5)</th><th>Evidence Location</th></tr></thead><tbody>
<tr><td><strong>LO1</strong></td><td>Differentiate people-centred methods</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W6 L2 job stories, W9 L1 eval plan</td></tr>
<tr><td><strong>LO2</strong></td><td>Design and conduct needs-finding</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W6 L2 consent protocol</td></tr>
<tr><td><strong>LO3</strong></td><td>Analyse ethical implications</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W7 L1 consent modal, privacy audit</td></tr>
<tr><td><strong>LO4</strong></td><td>Evaluate for accessibility</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W7 L2 axe audit, WCAG map</td></tr>
<tr><td><strong>LO5</strong></td><td>Create prototypes</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W8 L1 HTMX features</td></tr>
<tr><td><strong>LO6</strong></td><td>Apply iterative design</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W9 L2 pilots ‚Üí W10 L2 redesign</td></tr>
<tr><td><strong>LO7</strong></td><td>Analyse design constraints</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W8 L2 no-JS trade-offs doc</td></tr>
<tr><td><strong>LO8</strong></td><td>Design and execute evaluation</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W9 L1 metrics + W9 L2 pilots</td></tr>
<tr><td><strong>LO9</strong></td><td>Apply inclusive design</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W7 L2 fix, W10 L2 redesign</td></tr>
<tr><td><strong>LO10</strong></td><td>Critique societal impacts</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W7 L1 ethics reflection</td></tr>
<tr><td><strong>LO11</strong></td><td>Collaborate in teams</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W9 L2 peer pilots, W11 L1 crit</td></tr>
<tr><td><strong>LO12</strong></td><td>Demonstrate professionalism</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>All labs: consent, citations</td></tr>
<tr><td><strong>LO13</strong></td><td>Integrate HCI with SE</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W8 L1 Ktor patterns, W9 L1 instrumentation</td></tr>
</tbody></table>
</div>
<p><strong>Confidence scale</strong>: 1 = Not confident, 3 = Moderately confident, 5 = Very confident</p>
<p><strong>Reflection prompt</strong>:</p>
<ol>
<li>For each LO, locate your evidence (code, docs, reflections)</li>
<li>Note any gaps ‚Äî do you have weak evidence for any LO?</li>
<li>For any outcome rated &lt; 4, what would help you improve? (More practice, more reading, more feedback?)</li>
</ol>
<h3 id="step-2-identify-key-insights"><a class="header" href="#step-2-identify-key-insights">Step 2: Identify Key Insights</a></h3>
<p>Write <strong>3‚Äì5 bullet points</strong> summarising what you learned:</p>
<p><strong>Example</strong>:</p>
<ul>
<li><strong>Server-first simplifies accessibility</strong>: By rendering HTML server-side, I avoided complex ARIA management and focus trapping. This reinforced that progressive enhancement (start with HTML, add JS sparingly) is faster and more robust than JS-heavy SPAs.</li>
<li><strong>Evidence changes everything</strong>: Before Week 9 pilots, I thought my task manager was "fine". Metrics revealed a 10.9 MAD outlier for SR users, forcing me to confront assumptions. Quantitative + qualitative data is essential for inclusive design.</li>
<li><strong>Prioritisation is a skill</strong>: I wanted to fix all 8 issues, but (Impact + Inclusion) ‚Äì Effort scoring helped me focus on the 3 that mattered most. This taught me that good design isn't about perfection‚Äîit's about impact per unit of effort.</li>
<li><strong>Accessibility is iterative</strong>: My first fix (adding <code>role="alert"</code>) didn't work because I forgot <code>aria-live</code>. After reading WCAG 4.1.3 and testing with NVDA, I corrected it. This trial-and-error process is normal and valuable.</li>
<li><strong>Reflection cements learning</strong>: Writing 1,500 words about my redesign forced me to connect theory (WCAG) to practice (code) in a way that coding alone didn't. Research shows that portfolios deepen understanding.</li>
</ul>
<h3 id="step-3-update-backlog-for-semester-2"><a class="header" href="#step-3-update-backlog-for-semester-2">Step 3: Update Backlog for Semester 2</a></h3>
<p>Your product backlog should include:</p>
<ol>
<li><strong>Unfinished Week 11 items</strong> (deprioritised due to time)</li>
<li><strong>Peer feedback</strong> (from studio crit)</li>
<li><strong>New ideas</strong> (from reflection or further reading)</li>
</ol>
<p><strong>Example</strong> (backlog extract):</p>
<div class="table-wrapper"><table><thead><tr><th>ID</th><th>Description</th><th>Priority</th><th>Effort</th><th>Notes</th></tr></thead><tbody>
<tr><td>#8</td><td>Add keyboard shortcut hints (e.g., "Press / to focus search")</td><td>P2</td><td>3</td><td>Feedback from peer review; improves discoverability</td></tr>
<tr><td>#9</td><td>Implement undo for task deletion</td><td>P2</td><td>4</td><td>Not in scope for Task 2, but valuable for real users</td></tr>
<tr><td>#10</td><td>Add dark mode toggle (WCAG 1.4.3 compliance)</td><td>P3</td><td>5</td><td>Low priority; contrast already meets AA</td></tr>
<tr><td>#11</td><td>Explore HTMX websockets for real-time collaboration</td><td>P4</td><td>8</td><td>Stretch goal; requires learning new HTMX feature</td></tr>
<tr><td>#12</td><td>Add automated a11y tests (axe-core in CI/CD pipeline)</td><td>P1</td><td>6</td><td>High priority; prevents regressions in future work</td></tr>
</tbody></table>
</div>
<p><strong>Action</strong>: Add these items to your <code>backlog.md</code> or issue tracker (GitLab/GitHub Issues).</p>
<h3 id="step-4-write-final-reflection-optional-but-recommended"><a class="header" href="#step-4-write-final-reflection-optional-but-recommended">Step 4: Write Final Reflection (Optional but Recommended)</a></h3>
<p>If you have time, write a <strong>500-word final reflection</strong> summarising your journey from Week 6 to Week 11. Save as <code>evidence/wk11/reflection-final.md</code>.</p>
<p><strong>Prompts</strong>:</p>
<ul>
<li>What was the most challenging part of this module?</li>
<li>What surprised you about HCI or accessibility?</li>
<li>How will you apply these skills in future projects (Semester 2, internships, career)?</li>
<li>What would you do differently if you started again?</li>
</ul>
<p><strong>Example</strong> (first 150 words):</p>
<blockquote>
<p>The most challenging part of COMP2850 was shifting from "code-first" to "people-first" thinking. In previous modules (COMP1721, COMP2811), I optimised for elegance (clean OOP, efficient algorithms). In COMP2850, I learned that <strong>usability trumps elegance</strong>. My first instinct was to build a React SPA with complex state management, but the server-first + HTMX approach forced me to prioritise simplicity and robustness. This felt uncomfortable at first‚ÄîI kept wanting to add JS‚Äîbut Week 9 pilots proved that simpler is often better. Pilot P4 (no-JS) completed tasks just as fast as Pilot P1 (HTMX + mouse), which validated the "hypermedia as the engine of application state" philosophy from Carson Gross.</p>
<p>The biggest surprise was how <strong>cheap</strong> accessibility fixes are if you design them in from the start. Adding <code>role="alert"</code> took 2 minutes; adding it <em>after</em> building 500 lines of validation logic took 2 hours (because I had to refactor the error-handling architecture). This taught me...</p>
</blockquote>
<h3 id="step-5-plan-semester-2-goals"><a class="header" href="#step-5-plan-semester-2-goals">Step 5: Plan Semester 2 Goals</a></h3>
<p>COMP2850 continues in Semester 2 with advanced topics. Based on your Week 6‚Äì11 experience, set <strong>3 goals</strong>:</p>
<p><strong>Example</strong>:</p>
<ol>
<li>
<p><strong>Goal 1 (Technical)</strong>: Learn HTMX websockets to add real-time collaboration (backlog #11).</p>
<ul>
<li><strong>How</strong>: Read hypermedia.systems Ch. 11; build a prototype with 2-person task sharing.</li>
<li><strong>Why</strong>: Real-time features are common in industry (Google Docs, Figma); want to understand how to build them accessibly.</li>
</ul>
</li>
<li>
<p><strong>Goal 2 (Research)</strong>: Conduct a formal usability study (n=8, IRB approval) comparing HTMX vs React for accessibility.</p>
<ul>
<li><strong>How</strong>: Replicate Week 9 protocol with 4 HTMX pilots + 4 React pilots; compare median time + SR usability.</li>
<li><strong>Why</strong>: Interested in HCI research as a career; want to publish at CHI or ASSETS.</li>
</ul>
</li>
<li>
<p><strong>Goal 3 (Professional)</strong>: Contribute accessibility fixes to an open-source project.</p>
<ul>
<li><strong>How</strong>: Find a project with open a11y issues (e.g., on GitHub "good first issue" + "accessibility" labels); submit PR.</li>
<li><strong>Why</strong>: Build portfolio, gain experience with real-world codebases, give back to community.</li>
</ul>
</li>
</ol>
<p><strong>Action</strong>: Write these goals in <code>evidence/wk11/semester2-goals.md</code> or a personal notebook.</p>
<p><strong>Stop and check</strong>: Open your backlog (<code>backlog.md</code> or issue tracker). Verify:</p>
<ul>
<li>‚úÖ All incomplete items from Week 6‚Äì11 are listed</li>
<li>‚úÖ Peer feedback suggestions are added (with priority scores)</li>
<li>‚úÖ Semester 2 stretch goals are identified</li>
<li>‚úÖ Each item has a priority (P1‚ÄìP4) and effort estimate (1‚Äì8)</li>
</ul>
<hr />
<h2 id="semester-2-roadmap-building-on-your-foundation"><a class="header" href="#semester-2-roadmap-building-on-your-foundation">Semester 2 Roadmap: Building on Your Foundation</a></h2>
<p><strong>Overview</strong>: In Semester 1 (Weeks 6‚Äì11), you built a <strong>privacy-by-design task manager</strong> with WCAG 2.2 AA compliance, evaluated it with task-based pilots, and iterated based on evidence. Semester 2 builds on this foundation by introducing <strong>advanced HCI topics</strong>: multi-user collaboration, AI-assisted features, performance optimisation, and scaling to production. This section previews key features, technical topics, and skills development paths for Semester 2.</p>
<hr />
<h3 id="features-roadmap"><a class="header" href="#features-roadmap">Features Roadmap</a></h3>
<p>The following features represent typical Semester 2 enhancements. Your backlog (from Activity 5, Step 3) should prioritise 3‚Äì5 of these based on your learning goals.</p>
<div class="table-wrapper"><table><thead><tr><th>Feature</th><th>Description</th><th>HCI Concepts</th><th>Technical Skills</th><th>WCAG Considerations</th></tr></thead><tbody>
<tr><td><strong>1. Pagination</strong></td><td>Display 10 tasks per page with "Previous/Next" navigation</td><td>Information architecture, cognitive load</td><td>Query string parameters, server-side pagination logic</td><td>WCAG 2.4.1 (Bypass Blocks), 2.4.8 (Location)</td></tr>
<tr><td><strong>2. Tag/Category System</strong></td><td>Add multiple tags per task; filter by tag</td><td>Metadata schema, faceted search</td><td>Many-to-many relationships (CSV join table or SQLite)</td><td>WCAG 4.1.2 (Name, Role, Value) for tag buttons</td></tr>
<tr><td><strong>3. Search &amp; Autocomplete</strong></td><td>Full-text search across task titles; suggest as you type</td><td>Search UX patterns, latency perception</td><td>HTMX debouncing, server-side text search</td><td>WCAG 4.1.3 (Status Messages) for result count</td></tr>
<tr><td><strong>4. Multi-User (Sessions)</strong></td><td>Multiple users with separate task lists (no login, session-based)</td><td>Privacy vs collaboration trade-offs</td><td>Session isolation, CSV partitioning by session ID</td><td>WCAG 3.3.8 (Accessible Authentication - Minimum)</td></tr>
<tr><td><strong>5. Real-Time Updates</strong></td><td>When User A adds a task, User B's list auto-updates (via WebSockets)</td><td>Shared awareness, CSCW principles</td><td>HTMX WebSockets extension, Ktor WebSocket plugin</td><td>WCAG 4.1.3 (announce updates via live regions)</td></tr>
<tr><td><strong>6. AI Task Suggestions</strong></td><td>LLM generates task breakdowns (e.g., "Write essay" ‚Üí sub-tasks)</td><td>AI transparency, user agency</td><td>OpenAI API integration, prompt engineering</td><td>WCAG 3.3.2 (Labels or Instructions) for AI disclaimers</td></tr>
<tr><td><strong>7. Offline Mode (PWA)</strong></td><td>Service worker caches app; tasks sync when online</td><td>Network resilience, progressive web apps</td><td>Service Worker API, IndexedDB, background sync</td><td>WCAG 3.2.4 (Consistent Identification) across online/offline</td></tr>
<tr><td><strong>8. Accessibility Dashboard</strong></td><td>Real-time WCAG compliance score; lighthouse metrics</td><td>Automated testing limits, developer tools</td><td>axe-core integration, CI/CD pipeline</td><td>Meta-accessibility: ensuring dashboard itself is accessible</td></tr>
<tr><td><strong>9. Dark Mode</strong></td><td>User-selectable theme (light/dark/high-contrast)</td><td>Personalisation, sensory preferences</td><td>CSS custom properties, <code>prefers-color-scheme</code> media query</td><td>WCAG 1.4.3 (Contrast - Minimum) across all themes</td></tr>
<tr><td><strong>10. Export &amp; Import</strong></td><td>Download tasks as JSON/CSV/PDF; import from Todoist/Trello</td><td>Data portability, interoperability</td><td>CSV/JSON serialisation, PDF generation (iText/PDFKit)</td><td>WCAG 1.1.1 (ensure exported PDFs are tagged/accessible)</td></tr>
</tbody></table>
</div>
<p><strong>Prioritisation guidance</strong>: If your Semester 1 evaluation identified <strong>performance issues</strong> (e.g., slow search), prioritise pagination + search (features 1, 3). If you're interested in <strong>AI/ethics</strong>, prioritise feature 6 + transparency documentation. If you want to explore <strong>real-time collaboration</strong>, prioritise features 4‚Äì5.</p>
<hr />
<h3 id="technical-topics-semester-2-lectureslabs"><a class="header" href="#technical-topics-semester-2-lectureslabs">Technical Topics (Semester 2 Lectures/Labs)</a></h3>
<p>Semester 2 typically covers these advanced HCI topics. Your portfolio work will align with one or more:</p>
<ol>
<li>
<p><strong>Computer-Supported Cooperative Work (CSCW)</strong></p>
<ul>
<li><strong>What</strong>: Design patterns for multi-user collaboration (conflict resolution, awareness, turn-taking)</li>
<li><strong>Application</strong>: Features 4‚Äì5 (multi-user, real-time updates)</li>
<li><strong>Reading</strong>: Grudin (1994) "CSCW: History and Focus"; Schmidt &amp; Bannon (1992) "Taking CSCW Seriously"</li>
</ul>
</li>
<li>
<p><strong>AI &amp; Automation Ethics</strong></p>
<ul>
<li><strong>What</strong>: Transparency, explainability, user agency when integrating AI features</li>
<li><strong>Application</strong>: Feature 6 (AI task suggestions) with clear disclaimers ("AI-generated; verify before relying on")</li>
<li><strong>Reading</strong>: Shneiderman (2022) "Human-Centered AI"; EU AI Act principles</li>
</ul>
</li>
<li>
<p><strong>Performance &amp; Perceived Responsiveness</strong></p>
<ul>
<li><strong>What</strong>: Optimising server response time, perceptual speed tricks (skeleton screens, optimistic UI)</li>
<li><strong>Application</strong>: Features 1, 3 (pagination, search) with &lt;100ms response targets</li>
<li><strong>Reading</strong>: Nielsen (1993) "Response Times: The 3 Important Limits"</li>
</ul>
</li>
<li>
<p><strong>Progressive Web Apps (PWAs)</strong></p>
<ul>
<li><strong>What</strong>: Offline-first architecture, service workers, installable web apps</li>
<li><strong>Application</strong>: Feature 7 (offline mode) with background sync when network returns</li>
<li><strong>Reading</strong>: MDN Web Docs: Service Worker API; "Offline Cookbook" patterns</li>
</ul>
</li>
<li>
<p><strong>Inclusive AI &amp; Assistive Tech Integration</strong></p>
<ul>
<li><strong>What</strong>: Ensuring AI features work with screen readers, voice input, switch access</li>
<li><strong>Application</strong>: Feature 6 (AI suggestions) with ARIA announcements, feature 8 (a11y dashboard) accessible to all</li>
<li><strong>Reading</strong>: W3C (2024) "AI &amp; Accessibility Research Symposium"</li>
</ul>
</li>
<li>
<p><strong>Scaling to Production</strong></p>
<ul>
<li><strong>What</strong>: Database migration (CSV ‚Üí PostgreSQL), caching (Redis), deployment (Docker, Railway, Fly.io)</li>
<li><strong>Application</strong>: All features; moving from prototype to production-ready app</li>
<li><strong>Reading</strong>: Ktor docs on Database integration; Railway deployment guides</li>
</ul>
</li>
</ol>
<p><strong>Study path</strong>: If you're interested in <strong>research</strong>, focus on topics 1‚Äì2 (CSCW, AI ethics) and design a formal study. If you're interested in <strong>industry</strong>, focus on topics 3, 6 (performance, scaling) and build a production deployment. If you're interested in <strong>accessibility advocacy</strong>, focus on topics 5, 8 (inclusive AI, a11y tooling).</p>
<hr />
<h3 id="backlog-integration"><a class="header" href="#backlog-integration">Backlog Integration</a></h3>
<p>Your <strong>product backlog</strong> (from Activity 5, Step 3) should now include:</p>
<ol>
<li><strong>Incomplete Semester 1 items</strong> (e.g., backlog #8‚Äì12 from Activity 5 example)</li>
<li><strong>Peer feedback</strong> (from Week 11 Lab 1 studio crit)</li>
<li><strong>Semester 2 feature candidates</strong> (select 3‚Äì5 from table above)</li>
</ol>
<p><strong>Example integrated backlog</strong> (stored in <code>backlog.md</code> or issue tracker):</p>
<div class="table-wrapper"><table><thead><tr><th>ID</th><th>Description</th><th>Priority</th><th>Effort</th><th>Notes</th><th>Semester</th></tr></thead><tbody>
<tr><td>#1</td><td>‚úÖ CRUD operations (add, edit, delete tasks)</td><td>P1</td><td>8</td><td>Complete (Week 6)</td><td>S1</td></tr>
<tr><td>#2</td><td>‚úÖ HTMX dual-mode (JS-on vs no-JS)</td><td>P1</td><td>10</td><td>Complete (Week 6, 8)</td><td>S1</td></tr>
<tr><td>#3</td><td>‚úÖ Validation error alerts (WCAG 4.1.3)</td><td>P1</td><td>2</td><td>Complete (Week 10)</td><td>S1</td></tr>
<tr><td>#8</td><td>Add keyboard shortcut hints</td><td>P2</td><td>3</td><td>Peer feedback (Week 11)</td><td>S1</td></tr>
<tr><td>#9</td><td>Implement undo for task deletion</td><td>P2</td><td>4</td><td>Deferred from Week 10</td><td>S1</td></tr>
<tr><td>#12</td><td>Add automated a11y tests (axe-core CI/CD)</td><td>P1</td><td>6</td><td>High priority for S2; prevents regressions</td><td><strong>S2</strong></td></tr>
<tr><td>#13</td><td><strong>Pagination</strong> (10 tasks/page)</td><td>P2</td><td>5</td><td>Improves performance for 100+ tasks</td><td><strong>S2</strong></td></tr>
<tr><td>#14</td><td><strong>Tag system</strong> (filter by category)</td><td>P2</td><td>8</td><td>Requested in Week 6 needs-finding</td><td><strong>S2</strong></td></tr>
<tr><td>#15</td><td><strong>Search with autocomplete</strong></td><td>P3</td><td>6</td><td>Nice-to-have; low priority vs pagination</td><td><strong>S2</strong></td></tr>
<tr><td>#16</td><td><strong>AI task breakdown</strong> (LLM integration)</td><td>P4</td><td>10</td><td>Stretch goal; requires OpenAI API + ethics review</td><td><strong>S2</strong></td></tr>
</tbody></table>
</div>
<p><strong>Priority formula (from Week 10)</strong>: <code>(Impact + Inclusion) - Effort</code></p>
<p><strong>Action</strong>: Open your <code>backlog.md</code> (or create it in your repo root) and add Semester 2 features with priority scores.</p>
<hr />
<h3 id="skills-development-path"><a class="header" href="#skills-development-path">Skills Development Path</a></h3>
<p>To successfully implement Semester 2 features, you'll need to develop these skills progressively:</p>
<h4 id="path-1-full-stack-developer-features-15-7"><a class="header" href="#path-1-full-stack-developer-features-15-7">Path 1: Full-Stack Developer (Features 1‚Äì5, 7)</a></h4>
<p><strong>Goal</strong>: Build production-ready, scalable web app</p>
<div class="table-wrapper"><table><thead><tr><th>Skill</th><th>When to Learn</th><th>Resources</th><th>Application</th></tr></thead><tbody>
<tr><td><strong>SQL basics</strong> (PostgreSQL)</td><td>Week 1‚Äì2 (S2)</td><td>Ktor Database docs, PostgreSQL tutorial</td><td>Replace CSV with relational DB (features 1, 2, 4)</td></tr>
<tr><td><strong>Indexing &amp; query optimisation</strong></td><td>Week 3‚Äì4 (S2)</td><td>PostgreSQL EXPLAIN, indexing strategies</td><td>Feature 3 (search); ensure &lt;100ms response</td></tr>
<tr><td><strong>WebSockets (HTMX extension)</strong></td><td>Week 5‚Äì6 (S2)</td><td>hypermedia.systems Ch. 11; Ktor WebSocket plugin</td><td>Feature 5 (real-time updates)</td></tr>
<tr><td><strong>Service Workers &amp; PWA</strong></td><td>Week 7‚Äì8 (S2)</td><td>MDN Service Worker guide; Workbox library</td><td>Feature 7 (offline mode)</td></tr>
<tr><td><strong>Deployment (Docker, Railway)</strong></td><td>Week 9‚Äì10 (S2)</td><td>Railway docs; Ktor deployment guide</td><td>Production hosting</td></tr>
</tbody></table>
</div>
<h4 id="path-2-hci-researcher-features-6-8"><a class="header" href="#path-2-hci-researcher-features-6-8">Path 2: HCI Researcher (Features 6, 8)</a></h4>
<p><strong>Goal</strong>: Conduct formal usability studies; publish research</p>
<div class="table-wrapper"><table><thead><tr><th>Skill</th><th>When to Learn</th><th>Resources</th><th>Application</th></tr></thead><tbody>
<tr><td><strong>Formal study design</strong> (IRB, informed consent)</td><td>Week 1‚Äì2 (S2)</td><td>University ethics committee guidelines</td><td>Replicate Week 9 protocol with n=8+ participants</td></tr>
<tr><td><strong>Statistical analysis</strong> (t-tests, ANOVA)</td><td>Week 3‚Äì4 (S2)</td><td>R/Python (scipy.stats); "Statistics for HCI" course</td><td>Compare median task times across conditions (HTMX vs React)</td></tr>
<tr><td><strong>Qualitative coding</strong> (thematic analysis)</td><td>Week 5‚Äì6 (S2)</td><td>Braun &amp; Clarke (2006) thematic analysis guide</td><td>Analyse pilot quotes from Week 9</td></tr>
<tr><td><strong>AI transparency frameworks</strong></td><td>Week 7‚Äì8 (S2)</td><td>EU AI Act, Shneiderman (2020) Human-Centered AI</td><td>Feature 6 (AI suggestions) with user control</td></tr>
<tr><td><strong>Academic writing</strong> (CHI, ASSETS format)</td><td>Week 9‚Äì10 (S2)</td><td>CHI paper examples; ACM SIGCHI templates</td><td>Write 4-page paper on findings; submit to CHI LBW</td></tr>
</tbody></table>
</div>
<h4 id="path-3-accessibility-specialist-features-89"><a class="header" href="#path-3-accessibility-specialist-features-89">Path 3: Accessibility Specialist (Features 8‚Äì9)</a></h4>
<p><strong>Goal</strong>: Become expert in WCAG, audit tools, inclusive design</p>
<div class="table-wrapper"><table><thead><tr><th>Skill</th><th>When to Learn</th><th>Resources</th><th>Application</th></tr></thead><tbody>
<tr><td><strong>Automated testing</strong> (axe-core, Pa11y)</td><td>Week 1‚Äì2 (S2)</td><td>axe-core npm docs, Pa11y CI integration</td><td>Feature 8 (a11y dashboard); CI/CD pipeline</td></tr>
<tr><td><strong>Manual SR testing</strong> (NVDA, JAWS, VoiceOver)</td><td>Week 3‚Äì4 (S2)</td><td>WebAIM screen reader guides; NVDA user guide</td><td>Re-test all features with 3 SR users</td></tr>
<tr><td><strong>ARIA patterns</strong> (tabs, modals, tooltips)</td><td>Week 5‚Äì6 (S2)</td><td>W3C ARIA Authoring Practices Guide (APG)</td><td>Add modal dialogs, tooltips (with role=dialog, aria-labelledby)</td></tr>
<tr><td><strong>Colour contrast &amp; theming</strong></td><td>Week 7‚Äì8 (S2)</td><td>Colour Contrast Analyser, CSS custom properties</td><td>Feature 9 (dark mode); ensure 4.5:1 in all themes</td></tr>
<tr><td><strong>A11y advocacy &amp; training</strong></td><td>Week 9‚Äì10 (S2)</td><td>Write blog posts, give talks</td><td>Contribute to open-source projects; teach others</td></tr>
</tbody></table>
</div>
<p><strong>Choose your path</strong> based on career goals, then add relevant skills to your Semester 2 learning plan.</p>
<hr />
<h3 id="motivation-why-continue"><a class="header" href="#motivation-why-continue">Motivation: Why Continue?</a></h3>
<p>You've invested 6 weeks (Weeks 6‚Äì11) building a solid foundation. Here's why Semester 2 matters:</p>
<h4 id="1-portfolio-differentiation"><a class="header" href="#1-portfolio-differentiation">1. <strong>Portfolio Differentiation</strong></a></h4>
<p>Most CS students can build a CRUD app. Few can demonstrate:</p>
<ul>
<li><strong>Evidence-led iteration</strong> (pilot data ‚Üí prioritised fixes ‚Üí verification)</li>
<li><strong>WCAG 2.2 AA compliance</strong> (tested with real assistive tech)</li>
<li><strong>Privacy by design</strong> (UK GDPR, no PII, transparent data practices)</li>
<li><strong>Server-first architecture</strong> (progressive enhancement, no-JS parity)</li>
</ul>
<p>Semester 2 features (pagination, search, AI integration) add <strong>complexity</strong> while maintaining <strong>accessibility</strong>‚Äîa rare combination that employers and grad schools value.</p>
<h4 id="2-research-opportunities"><a class="header" href="#2-research-opportunities">2. <strong>Research Opportunities</strong></a></h4>
<p>Your Week 9 pilots produced <strong>publishable data</strong>. With a larger sample (n=8+, IRB approval), you could submit to:</p>
<ul>
<li><strong>CHI</strong> (ACM Conference on Human Factors in Computing Systems) - Late-Breaking Work track</li>
<li><strong>ASSETS</strong> (ACM SIGACCESS Conference on Computers and Accessibility)</li>
<li><strong>University undergraduate research conferences</strong> (Leeds Laidlaw, national showcases)</li>
</ul>
<p><strong>Example research question</strong> (from your Semester 1 work):</p>
<blockquote>
<p>"Do server-first architectures (HTMX) improve screen reader usability compared to client-side SPAs (React)? A comparative task-based study (n=16, between-subjects)."</p>
</blockquote>
<p>This extends your Week 9 methodology and could lead to co-authorship with module staff.</p>
<h4 id="3-industry-readiness"><a class="header" href="#3-industry-readiness">3. <strong>Industry Readiness</strong></a></h4>
<p>Employers look for:</p>
<ul>
<li><strong>End-to-end ownership</strong>: Requirements ‚Üí design ‚Üí implementation ‚Üí evaluation ‚Üí iteration</li>
<li><strong>Cross-functional skills</strong>: Code (Kotlin/Ktor), design (WCAG), research (pilots), writing (reflection)</li>
<li><strong>Trade-off reasoning</strong>: "I prioritised X over Y because [evidence]"</li>
</ul>
<p>Semester 2 features demonstrate <strong>production thinking</strong>:</p>
<ul>
<li>Feature 1 (pagination): "I scaled to 10,000 tasks with acceptable latency"</li>
<li>Feature 5 (real-time): "I implemented WebSockets while maintaining SR compatibility"</li>
<li>Feature 6 (AI): "I integrated LLMs with transparent disclaimers and user override"</li>
</ul>
<p>These are <strong>STAR interview stories</strong> (Situation, Task, Action, Result) that differentiate you from peers.</p>
<h4 id="4-personal-mastery"><a class="header" href="#4-personal-mastery">4. <strong>Personal Mastery</strong></a></h4>
<p>COMP2850 is hard. You've learned:</p>
<ul>
<li><strong>Server-first thinking</strong> (hypermedia as engine of state)</li>
<li><strong>Inclusive design</strong> (start with HTML, add ARIA only when needed)</li>
<li><strong>Evidence-based iteration</strong> (metrics &gt; intuition)</li>
</ul>
<p>Semester 2 is where you <strong>master</strong> these principles by applying them to harder problems (multi-user, real-time, AI). Mastery comes from deliberate practice, not from moving to a new topic.</p>
<hr />
<h3 id="concrete-next-steps-week-12"><a class="header" href="#concrete-next-steps-week-12">Concrete Next Steps (Week 12+)</a></h3>
<p><strong>Before Semester 2 starts</strong> (Winter break or Week 12):</p>
<ol>
<li>
<p><strong>Choose 3 features</strong> from the roadmap table (lines 911‚Äì920)</p>
<ul>
<li>Pick based on career interest (full-stack, research, or a11y specialist path)</li>
<li>Add to backlog with priority scores (Impact + Inclusion - Effort)</li>
</ul>
</li>
<li>
<p><strong>Learn 1 new skill</strong> from your chosen path</p>
<ul>
<li>Full-stack: Complete PostgreSQL tutorial (replace CSV in 1 feature)</li>
<li>Research: Read 3 CHI papers on accessibility evaluation methods</li>
<li>A11y: Master one ARIA pattern (modal dialog, tabs, or tooltips)</li>
</ul>
</li>
<li>
<p><strong>Refine your portfolio</strong></p>
<ul>
<li>Convert <code>README.md</code> to a static site (GitHub Pages, GitLab Pages)</li>
<li>Add "Semester 2 Roadmap" section citing your chosen features</li>
<li>Share with peers/mentors for feedback</li>
</ul>
</li>
<li>
<p><strong>Find a collaborator</strong> (optional)</p>
<ul>
<li>Pair with a peer who chose a complementary path</li>
<li>Example: You (full-stack) + peer (a11y specialist) = feature 5 (real-time) with SR testing</li>
</ul>
</li>
<li>
<p><strong>Set a measurable goal</strong></p>
<ul>
<li>Example: "By Week 8 (S2), I will deploy a production instance with 100 real users and collect SUS scores"</li>
<li>Example: "By Week 10 (S2), I will submit a 4-page paper to CHI LBW"</li>
</ul>
</li>
</ol>
<p><strong>During Semester 2</strong>:</p>
<ul>
<li><strong>Weeks 1‚Äì4</strong>: Implement features 1‚Äì2 (pagination + one stretch feature)</li>
<li><strong>Weeks 5‚Äì8</strong>: Implement feature 3 or 4 (search or multi-user)</li>
<li><strong>Weeks 9‚Äì10</strong>: Evaluate, iterate, and document (repeat Week 9‚Äì10 process)</li>
<li><strong>Week 11‚Äì12</strong>: Final portfolio assembly, research paper (if applicable), deployment</li>
</ul>
<p><strong>After Semester 2</strong>:</p>
<ul>
<li><strong>Showcase</strong>: Present at university research fair, publish blog post, submit to open-source conferences (FOSDEM, etc.)</li>
<li><strong>Job applications</strong>: Use portfolio as centerpiece of CV; link to live deployment</li>
<li><strong>Grad school</strong>: Use research paper as writing sample for HCI MSc/PhD applications</li>
</ul>
<hr />
<h3 id="resources"><a class="header" href="#resources">Resources</a></h3>
<p><strong>Backlog Management</strong></p>
<ul>
<li><strong>GitHub Issues/Projects</strong>: Free issue tracker with labels, milestones, priorities</li>
<li><strong>GitLab Issue Boards</strong>: Kanban-style backlog (drag-and-drop prioritisation)</li>
<li><strong>Notion/Trello</strong>: If you prefer visual boards over code-based trackers</li>
</ul>
<p><strong>Learning Paths</strong></p>
<ul>
<li><strong>Full-stack</strong>: <a href="https://ktor.io/">Ktor Docs</a>, <a href="https://www.postgresqltutorial.com/">PostgreSQL Tutorial</a>, <a href="https://docs.railway.app/">Railway Deploy Guide</a></li>
<li><strong>Research</strong>: <a href="https://chi2025.acm.org/">CHI 2025 Call for Papers</a>, <a href="https://assets25.sigaccess.org/">ASSETS 2025</a>, <a href="https://www.nngroup.com/articles/">UX Research Methods by NNGroup</a></li>
<li><strong>A11y</strong>: <a href="https://www.w3.org/WAI/ARIA/apg/">W3C ARIA Authoring Practices Guide</a>, <a href="https://www.npmjs.com/package/axe-core">axe-core npm</a>, <a href="https://dequeuniversity.com/">Deque University</a></li>
</ul>
<p><strong>Inspiration (Real-World Examples)</strong></p>
<ul>
<li><strong>Linear</strong> (task manager): Server-first with real-time (demonstrates feature 5)</li>
<li><strong>Basecamp</strong> (project management): No-JS baseline, progressive enhancement (demonstrates feature 2)</li>
<li><strong>GOV.UK Design System</strong>: WCAG AAA components, open-source (demonstrates feature 8‚Äì9)</li>
</ul>
<hr />
<p><strong>Semester 2 begins soon‚Äîyour foundation is strong. Choose your path, set measurable goals, and keep building with evidence and empathy.</strong></p>
<hr />
<h2 id="glossary-summary-9"><a class="header" href="#glossary-summary-9">Glossary Summary</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Term</th><th>Definition</th><th>Example/Context</th></tr></thead><tbody>
<tr><td><strong>Evidence chain</strong></td><td>Traceable path from raw data ‚Üí analysis ‚Üí fix ‚Üí verification</td><td>P3 pilot notes ‚Üí WCAG violation ‚Üí code commit ‚Üí retest</td></tr>
<tr><td><strong>Reflective writing</strong></td><td>Connecting theory to practice by answering What/Why/How/Learning</td><td>"I added role=alert (WCAG 4.1.3) because P3 didn't hear errors"</td></tr>
<tr><td><strong>Portfolio</strong></td><td>Organised collection of artefacts with accompanying reflection</td><td>Code repo + evidence/ + Task 1/2 packages + README</td></tr>
<tr><td><strong>Traceability</strong></td><td>Ability to link every claim to supporting evidence</td><td>"P3 took 127 s (see metrics.csv row 47)"</td></tr>
<tr><td><strong>Gradescope</strong></td><td>Submission platform with file size/format requirements</td><td>100 MB limit, PDF preferred, flat directory structure</td></tr>
<tr><td><strong>Commit hash</strong></td><td>Unique identifier for a Git commit</td><td><code>c8d1e4f</code> (first 7 chars of SHA-1)</td></tr>
<tr><td><strong>Regression testing</strong></td><td>Verifying fixes didn't break existing features</td><td>Keyboard, SR, no-JS paths all retested after validation fix</td></tr>
<tr><td><strong>Backlog</strong></td><td>Prioritised list of unfinished or future work</td><td>"Add undo feature" (P2, Effort: 4)</td></tr>
<tr><td><strong>WCAG compliance doc</strong></td><td>Mapping fixes to WCAG 2.2 success criteria</td><td>Fix 01 ‚Üí 4.1.3 Status Messages (AA)</td></tr>
<tr><td><strong>Compression</strong></td><td>Reducing file size (images, PDFs) to meet submission limits</td><td>PNG: 8 MB ‚Üí 2 MB via TinyPNG; PDF: 15 MB ‚Üí 5 MB via Ghostscript</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="reflection-questions-8"><a class="header" href="#reflection-questions-8">Reflection Questions</a></h2>
<ol>
<li>
<p><strong>Evidence chains</strong>: Choose one finding from your Week 9 analysis. Trace the complete evidence chain from raw data (pilot ID, task, metric) to fix (commit hash) to verification (retest result). Is any link in the chain missing or weak?</p>
</li>
<li>
<p><strong>Reflective writing quality</strong>: Reread your Task 1 and Task 2 reflections. For each, identify:</p>
<ul>
<li>One place where you cited theory (WCAG, privacy principle, academic source)</li>
<li>One place where you described a mistake and correction</li>
<li>One place where you connected learning to future practice</li>
</ul>
</li>
<li>
<p><strong>Portfolio organisation</strong>: Imagine you are a marker with 50 portfolios to grade. Open your <code>README.md</code> and <code>evidence/</code> directory. Can you find any specific artefact (e.g., "P3 retest screenshot") in &lt; 30 seconds? If not, what would improve navigation?</p>
</li>
<li>
<p><strong>Submission readiness</strong>: If Gradescope rejects your ZIP due to file size, which files would you compress first? Why?</p>
</li>
<li>
<p><strong>Semester 2 planning</strong>: Of the 3 goals you set in Activity 5, which excites you most? Which scares you most? Why?</p>
</li>
</ol>
<hr />
<h2 id="further-reading-3"><a class="header" href="#further-reading-3">Further Reading</a></h2>
<p><strong>Reflective practice</strong></p>
<ul>
<li>Moon, J. A. (2004). <em>A Handbook of Reflective and Experiential Learning: Theory and Practice</em>. Routledge.</li>
</ul>
<p><strong>Evidence-based design</strong></p>
<ul>
<li>Shneiderman, B., Plaisant, C., Cohen, M., Jacobs, S., Elmqvist, N., &amp; Diakopoulos, N. (2016). <em>Designing the User Interface: Strategies for Effective Human-Computer Interaction</em> (6th ed.). Pearson. (Ch. 4: Evaluation)</li>
</ul>
<p><strong>Portfolio assessment</strong></p>
<ul>
<li>Paulson, F. L., Paulson, P. R., &amp; Meyer, C. A. (1991). "What Makes a Portfolio a Portfolio?" <em>Educational Leadership</em>, 48(5), 60‚Äì63. <a href="https://www.ascd.org/el/articles/what-makes-a-portfolio-a-portfolio">https://www.ascd.org/el/articles/what-makes-a-portfolio-a-portfolio</a></li>
</ul>
<p><strong>Accessibility compliance</strong></p>
<ul>
<li>W3C (2024). <em>How to Meet WCAG (Quick Reference)</em>. <a href="https://www.w3.org/WAI/WCAG22/quickref/">https://www.w3.org/WAI/WCAG22/quickref/</a></li>
<li>GOV.UK (2024). <em>Making Your Service Accessible</em>. <a href="https://www.gov.uk/service-manual/helping-people-to-use-your-service/making-your-service-accessible-an-introduction">https://www.gov.uk/service-manual/helping-people-to-use-your-service/making-your-service-accessible-an-introduction</a></li>
</ul>
<p><strong>Server-first architecture</strong></p>
<ul>
<li>Gross, C., Stepinski, A., &amp; Ak≈üim≈üek, D. (2023). <em>Hypermedia Systems</em>. <a href="https://hypermedia.systems/">https://hypermedia.systems/</a> (Ch. 9: Practical Patterns; Ch. 11: Websockets)</li>
</ul>
<hr />
<h2 id="lab-checklist-3"><a class="header" href="#lab-checklist-3">Lab Checklist</a></h2>
<p>Before leaving lab, confirm:</p>
<ul>
<li><input disabled="" type="checkbox"/>
<strong>Task 1 polished</strong>: Critique feedback incorporated; evidence complete; reflection compiled to PDF</li>
<li><input disabled="" type="checkbox"/>
<strong>Task 2 assembled</strong>: Fix docs written; regression checklist completed; verification data organised; reflection compiled to PDF</li>
<li><input disabled="" type="checkbox"/>
<strong>Repository tidy</strong>: Commit history clean; <code>README.md</code> updated; <code>evidence/</code> organised by week</li>
<li><input disabled="" type="checkbox"/>
<strong>Submission ready</strong>: <code>task1-submission.zip</code> and <code>task2-submission.zip</code> created; file sizes &lt; 50 MB each; PDFs legible</li>
<li><input disabled="" type="checkbox"/>
<strong>Backlog updated</strong>: Peer feedback + Semester 2 goals added; priorities assigned</li>
<li><input disabled="" type="checkbox"/>
<strong>Final reflection written</strong>: 500-word summary of Weeks 6‚Äì11 journey (optional but recommended)</li>
<li><input disabled="" type="checkbox"/>
<strong>Backup created</strong>: Repository tagged (<code>v1.0-task1</code>, <code>v1.0-task2</code>); ZIPs backed up to cloud</li>
</ul>
<hr />
<h2 id="next-steps-3"><a class="header" href="#next-steps-3">Next Steps</a></h2>
<ol>
<li><strong>Gradescope submission</strong>: Upload <code>task1-submission.zip</code> and <code>task2-submission.zip</code> by the deadline (check Minerva for exact date/time).</li>
<li><strong>Peer review</strong> (if required): Some modules assign post-submission peer review; check Minerva announcements.</li>
<li><strong>Semester 2 prep</strong>: Review your backlog and Semester 2 goals; prioritise 1‚Äì2 items to start over break.</li>
<li><strong>Portfolio showcase</strong>: Consider converting your <code>README.md</code> to a static site (e.g., GitHub Pages) to show potential employers.</li>
<li><strong>Celebrate</strong>: You've completed a rigorous HCI project with evaluation, iteration, and evidence chains. Well done!</li>
</ol>
<hr />
<h2 id="acknowledgements-1"><a class="header" href="#acknowledgements-1">Acknowledgements</a></h2>
<p>This lab draws on:</p>
<ul>
<li><strong>GOV.UK Design System</strong> for accessible error handling patterns</li>
<li><strong>hypermedia.systems (Gross et al., 2023)</strong> for server-first architecture guidance</li>
<li><strong>WCAG 2.2</strong> for accessibility compliance mapping</li>
<li><strong>University of Leeds Academic Skills Centre</strong> for reflective writing frameworks</li>
</ul>
<hr />
<p><strong>Lab authored by</strong>: COMP2850 Teaching Team, University of Leeds
<strong>Last updated</strong>: 2025-01-14
<strong>Licence</strong>: Academic use only (not for redistribution)</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="code-resources-5"><a class="header" href="#code-resources-5">Code Resources</a></h1>
<div style="break-before: page; page-break-before: always;"></div><h1 id="assessment-overview"><a class="header" href="#assessment-overview">Assessment Overview</a></h1>
<p><img src="https://img.shields.io/badge/Assessment-Portfolio-orange" alt="Assessment" />
<img src="https://img.shields.io/badge/Weighting-See_Minerva-blue" alt="Weighting" /></p>
<hr />
<h2 id="introduction-5"><a class="header" href="#introduction-5">Introduction</a></h2>
<p>The HCI assessment evaluates your ability to <strong>design, evaluate, and improve accessible web interfaces</strong> using evidence-based methods. You'll demonstrate mastery of all <strong>13 HCI Learning Outcomes</strong> through two interconnected tasks.</p>
<p><strong>Assessment philosophy</strong>:</p>
<ul>
<li><strong>Evidence-based</strong>: Every claim backed by data (metrics, quotes, screenshots, WCAG audits)</li>
<li><strong>Iterative design</strong>: Task 1 findings inform Task 2 redesign</li>
<li><strong>Inclusive practice</strong>: WCAG 2.2 AA compliance, no-JS parity, screen reader testing</li>
<li><strong>Professional standards</strong>: Consent protocols, privacy-safe data, honest reporting</li>
</ul>
<hr />
<h2 id="timeline--deadlines"><a class="header" href="#timeline--deadlines">Timeline &amp; Deadlines</a></h2>
<h3 id="overview-weeks-6-11"><a class="header" href="#overview-weeks-6-11">Overview (Weeks 6-11)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Week</th><th>Activity</th><th>Assessment Milestone</th></tr></thead><tbody>
<tr><td><strong>6</strong></td><td>Server-first foundations, needs-finding</td><td>Build features, create backlog</td></tr>
<tr><td><strong>7</strong></td><td>Ethics, accessibility audit</td><td>Identify WCAG violations</td></tr>
<tr><td><strong>8</strong></td><td>Prototyping, no-JS parity</td><td><strong>üìã Task 1 launched</strong> (end of Lab 2)</td></tr>
<tr><td><strong>9</strong></td><td>Evaluation planning, instrumentation</td><td>Run pilots, <strong>üì§ Task 1 due</strong> (Lab 2 deadline)</td></tr>
<tr><td><strong>10</strong></td><td>Analysis, redesign</td><td><strong>üìã Task 2 launched</strong> (Lab 1), implement fixes</td></tr>
<tr><td><strong>11</strong></td><td>Studio crit, wrap-up</td><td><strong>üì§ Task 2 due</strong> (Lab 2 deadline)</td></tr>
</tbody></table>
</div>
<h3 id="evidence-journey"><a class="header" href="#evidence-journey">Evidence Journey</a></h3>
<pre class="mermaid">graph TD
  A[Needs-finding stories] --&gt; B[Inclusive backlog]
  B --&gt; C[WCAG &amp; heuristic audit]
  C --&gt; D[Pilots &amp; metrics]
  D --&gt; E[Analysis &amp; prioritisation]
  E --&gt; F[Inclusive redesign]
  F --&gt; G[Task 2 evidence pack]
  G --&gt; H[Studio crit &amp; wrap-up]
  H --&gt;|Carry forward| B
</pre>
<p><small>See <a href="assessment/../references/process-visuals.html#evidence-map">Process Visuals</a> for a text summary of each stage.</small></p>
<hr />
<h3 id="task-1-evaluation--findings-1"><a class="header" href="#task-1-evaluation--findings-1">Task 1: Evaluation &amp; Findings</a></h3>
<p><strong>Launch</strong>: Week 8 Lab 2 (end of session)
<strong>Work period</strong>: Weeks 8-9 (2 weeks)
<strong>Submission deadline</strong>: <strong>Week 9 Lab 2</strong> (Gradescope)</p>
<p><strong>What you'll do</strong>:</p>
<ul>
<li><strong>Week 8 Lab 2</strong>: Draft evaluation plan, define tasks, write protocol</li>
<li><strong>Week 9 Lab 1</strong>: Learn instrumentation, finalize protocol</li>
<li><strong>Week 9 Lab 2</strong>: Conduct 4+ peer pilots, analyse data, submit</li>
</ul>
<p><strong>Typical timeline</strong>:</p>
<ul>
<li>Week 8: 2-3 hours (planning)</li>
<li>Week 9 Lab 1: 2 hours (instrumentation setup)</li>
<li>Week 9 Lab 2: 2 hours (pilots + packaging)</li>
<li><strong>Total</strong>: ~6-7 hours across 2 weeks</li>
</ul>
<hr />
<h3 id="task-2-redesign--verification-1"><a class="header" href="#task-2-redesign--verification-1">Task 2: Redesign &amp; Verification</a></h3>
<p><strong>Launch</strong>: Week 10 Lab 1
<strong>Work period</strong>: Weeks 10-11 (2 weeks)
<strong>Submission deadline</strong>: <strong>Week 11 Lab 2</strong> (Gradescope)</p>
<p><strong>What you'll do</strong>:</p>
<ul>
<li><strong>Week 10 Lab 1</strong>: Analyse Task 1 data, prioritise fixes, write redesign brief</li>
<li><strong>Week 10 Lab 2</strong>: Implement fixes, regression testing, re-pilots</li>
<li><strong>Week 11 Lab 1</strong>: Present redesign in studio crit</li>
<li><strong>Week 11 Lab 2</strong>: Incorporate feedback, finalize documentation, submit</li>
</ul>
<p><strong>Typical timeline</strong>:</p>
<ul>
<li>Week 10 Lab 1: 2 hours (analysis + brief)</li>
<li>Week 10 Lab 2: 2 hours (implementation + verification)</li>
<li>Week 11 Lab 1: 2 hours (studio crit)</li>
<li>Week 11 Lab 2: 1-2 hours (final packaging)</li>
<li><strong>Total</strong>: ~7-8 hours across 2 weeks</li>
</ul>
<hr />
<h2 id="tasks-overview"><a class="header" href="#tasks-overview">Tasks Overview</a></h2>
<h3 id="task-1-evaluation--findings-week-9"><a class="header" href="#task-1-evaluation--findings-week-9">Task 1: Evaluation &amp; Findings (Week 9)</a></h3>
<p>Design and execute a <strong>task-based usability evaluation</strong> with peer pilots, collecting quantitative metrics and qualitative observations to identify accessibility and usability issues.</p>
<p><strong>Key deliverables</strong>:</p>
<ol>
<li>Evaluation plan (tasks, metrics, protocol)</li>
<li>Quantitative data (metrics.csv with time-on-task, errors, completion rates)</li>
<li>Findings document with evidence chains</li>
<li>Pilot notes and qualitative observations</li>
<li>Evidence artefacts (screenshots, no PII)</li>
</ol>
<p><strong>Learning Outcomes assessed</strong>: LO1, LO2, LO6, LO8, LO11, LO12, LO13</p>
<p><a href="assessment/task1.html">Full Task 1 details ‚Üí</a></p>
<hr />
<h3 id="task-2-redesign--verification-week-11"><a class="header" href="#task-2-redesign--verification-week-11">Task 2: Redesign &amp; Verification (Week 11)</a></h3>
<p>Implement <strong>inclusive redesign</strong> based on Task 1 findings, verify improvements through regression testing and re-pilots, and analyse societal impacts of design decisions.</p>
<p><strong>Key deliverables</strong>:</p>
<ol>
<li>Redesign brief with problem statement and measurable goals</li>
<li>Accessibility regression checklist (WCAG 2.2 AA, 30+ checks)</li>
<li>Before/after metrics summary</li>
<li>Key code/UX diffs (code snippets, templates, CSS changes)</li>
<li>Evidence artefacts (screenshots, screen reader transcripts, no PII)</li>
<li>Metrics data (pre/analysis.csv, post/postchange.csv)</li>
</ol>
<p><strong>Learning Outcomes assessed</strong>: LO3, LO4, LO5, LO6, LO7, LO9, LO10, LO12, LO13</p>
<p><a href="assessment/task2.html">Full Task 2 details ‚Üí</a></p>
<hr />
<h2 id="learning-outcomes-coverage"><a class="header" href="#learning-outcomes-coverage">Learning Outcomes Coverage</a></h2>
<p><strong>All 13 HCI Learning Outcomes</strong> are assessed across Tasks 1 &amp; 2:</p>
<div class="table-wrapper"><table><thead><tr><th>LO</th><th>Outcome</th><th>Task 1</th><th>Task 2</th></tr></thead><tbody>
<tr><td><strong>LO1</strong></td><td>Differentiate people-centred design and evaluation methodologies</td><td>‚úÖ</td><td></td></tr>
<tr><td><strong>LO2</strong></td><td>Design and conduct needs-finding activities</td><td>‚úÖ</td><td></td></tr>
<tr><td><strong>LO3</strong></td><td>Analyse ethical implications of design decisions</td><td></td><td>‚úÖ</td></tr>
<tr><td><strong>LO4</strong></td><td>Evaluate software interfaces for accessibility concerns</td><td></td><td>‚úÖ</td></tr>
<tr><td><strong>LO5</strong></td><td>Create interface prototypes using appropriate fidelity levels</td><td></td><td>‚úÖ</td></tr>
<tr><td><strong>LO6</strong></td><td>Apply iterative design processes</td><td>‚úÖ</td><td>‚úÖ</td></tr>
<tr><td><strong>LO7</strong></td><td>Analyse how design constraints affect interface decisions</td><td></td><td>‚úÖ</td></tr>
<tr><td><strong>LO8</strong></td><td>Design and execute appropriate evaluation methods</td><td>‚úÖ</td><td></td></tr>
<tr><td><strong>LO9</strong></td><td>Apply universal and inclusive design principles</td><td></td><td>‚úÖ</td></tr>
<tr><td><strong>LO10</strong></td><td>Critique potential impacts of designs on society</td><td></td><td>‚úÖ</td></tr>
<tr><td><strong>LO11</strong></td><td>Collaborate effectively in multidisciplinary teams</td><td>‚úÖ</td><td></td></tr>
<tr><td><strong>LO12</strong></td><td>Demonstrate professional dispositions</td><td>‚úÖ</td><td>‚úÖ</td></tr>
<tr><td><strong>LO13</strong></td><td>Integrate people-centred design with SE lifecycle</td><td>‚úÖ</td><td>‚úÖ</td></tr>
</tbody></table>
</div>
<p><strong>Coverage</strong>: Both tasks assess LO6, LO12, LO13. All other LOs assessed in one task.</p>
<p>See <a href="assessment/../references/learning-outcomes.html">Learning Outcomes Reference</a> for full definitions and week-by-week evidence locations.</p>
<hr />
<h2 id="weighting--grading"><a class="header" href="#weighting--grading">Weighting &amp; Grading</a></h2>
<p><strong>Module weighting</strong>: See Minerva for breakdown (Tasks 1 &amp; 2 contribute to overall COMP2850 grade)</p>
<p><strong>What markers look for</strong>:</p>
<h3 id="task-1-evaluation--findings-2"><a class="header" href="#task-1-evaluation--findings-2">Task 1 (Evaluation &amp; Findings)</a></h3>
<ul>
<li><strong>Evidence quality</strong> (30%): Complete data, traceable chains, no PII</li>
<li><strong>Method rigour</strong> (25%): Protocol design, consent, ethical practice</li>
<li><strong>Analysis depth</strong> (25%): Findings synthesis, WCAG references, inclusion impact</li>
<li><strong>Professional presentation</strong> (20%): Clear documentation, honest reporting</li>
</ul>
<h3 id="task-2-redesign--verification-2"><a class="header" href="#task-2-redesign--verification-2">Task 2 (Redesign &amp; Verification)</a></h3>
<ul>
<li><strong>Problem clarity</strong> (20%): Grounded in Task 1 data, specific, measurable</li>
<li><strong>Fix effectiveness</strong> (30%): WCAG compliance verified, measurable improvement</li>
<li><strong>Societal impact analysis</strong> (20%): Systemic barriers identified, beyond accommodation</li>
<li><strong>Evidence chains</strong> (20%): Before/after data, regression tests, re-pilot verification</li>
<li><strong>Professional presentation</strong> (10%): Clear diffs, complete documentation</li>
</ul>
<p><strong>Academic integrity</strong>: All work must be your own. Pilot data must be genuinely collected (not fabricated). Screenshots must be authentic. Plagiarism will be reported to Academic Integrity Office.</p>
<hr />
<h2 id="submission"><a class="header" href="#submission">Submission</a></h2>
<h3 id="platform-gradescope"><a class="header" href="#platform-gradescope">Platform: Gradescope</a></h3>
<p><strong>How to submit</strong>:</p>
<ol>
<li>Package your submission directory (Task 1: <code>wk09/lab-wk9/submission/task1-draft/</code>, Task 2: <code>wk10/gradescope/task2/</code>)</li>
<li>Upload to Gradescope before deadline</li>
<li>Verify all files uploaded correctly (check preview)</li>
</ol>
<p><strong>File requirements</strong>:</p>
<ul>
<li>‚úÖ Markdown files rendered correctly (<code>.md</code> not <code>.txt</code>)</li>
<li>‚úÖ CSV files have headers (<code>results.csv</code>, <code>regression-checklist.csv</code>)</li>
<li>‚úÖ Screenshots are PNG/JPG (not HEIC or proprietary formats)</li>
<li>‚úÖ No PII in any file (names, emails, student IDs scrubbed)</li>
<li>‚úÖ Directory structure matches specification</li>
</ul>
<p><strong>Late submissions</strong>: See Minerva for module policy on extensions and penalties.</p>
<hr />
<h2 id="common-mistakes-to-avoid"><a class="header" href="#common-mistakes-to-avoid">Common Mistakes to Avoid</a></h2>
<h3 id="task-1"><a class="header" href="#task-1">Task 1</a></h3>
<p>‚ùå <strong>Fabricated data</strong>: Markers can spot fake metrics (too perfect, unrealistic patterns)
‚ùå <strong>No evidence chains</strong>: Claims without data (e.g., "SR users struggled" with no pilot notes)
‚ùå <strong>PII leaks</strong>: Screenshots with names, session IDs that reveal identities
‚ùå <strong>Incomplete pilots</strong>: Only 2 participants instead of minimum 4
‚ùå <strong>Missing consent</strong>: No documentation of ethical protocol</p>
<h3 id="task-2"><a class="header" href="#task-2">Task 2</a></h3>
<p>‚ùå <strong>No before/after data</strong>: Can't prove improvement without metrics comparison
‚ùå <strong>Regression not tested</strong>: Fix broke something else but wasn't caught
‚ùå <strong>Superficial societal impact</strong>: Just saying "helps disabled people" without systemic analysis
‚ùå <strong>WCAG violations remain</strong>: Claimed compliance but axe DevTools still shows errors
‚ùå <strong>No-JS parity broken</strong>: Fix works with JS but breaks traditional path</p>
<hr />
<h2 id="tips-for-success"><a class="header" href="#tips-for-success">Tips for Success</a></h2>
<h3 id="general"><a class="header" href="#general">General</a></h3>
<p>‚úÖ <strong>Start early</strong>: Use the full 2-week window
‚úÖ <strong>Use templates</strong>: All templates provided in <code>wk09/</code> and <code>wk10/</code> directories
‚úÖ <strong>Link everything</strong>: Evidence chains must be traceable (file paths, line numbers, session IDs)
‚úÖ <strong>Test thoroughly</strong>: Keyboard, screen reader, no-JS, 200% zoom
‚úÖ <strong>Document honestly</strong>: Markers value honest reporting over perfect results</p>
<h3 id="task-1-specific"><a class="header" href="#task-1-specific">Task 1 Specific</a></h3>
<p>‚úÖ <strong>Pilot with diverse participants</strong>: At least 1 keyboard-only, 1 no-JS variant
‚úÖ <strong>Record immediately</strong>: Don't rely on memory‚Äîtake notes during pilots
‚úÖ <strong>Check metrics.csv</strong>: Verify data complete before leaving lab
‚úÖ <strong>Scrub screenshots</strong>: Crop/blur before including in submission</p>
<h3 id="task-2-specific"><a class="header" href="#task-2-specific">Task 2 Specific</a></h3>
<p>‚úÖ <strong>Prioritise ruthlessly</strong>: Can't fix everything‚Äîfocus on high inclusion impact
‚úÖ <strong>Test before re-pilots</strong>: Don't waste participants on broken fixes
‚úÖ <strong>Use Analyse.kt script</strong>: Automated stats more reliable than manual calculation
‚úÖ <strong>Compare like-with-like</strong>: Same tasks, same protocol for before/after</p>
<hr />
<h2 id="support-1"><a class="header" href="#support-1">Support</a></h2>
<p><strong>Lab sessions</strong>: Staff on hand for questions (Weeks 6-11, 2√ó2h per week)
<strong>Office hours</strong>: See Minerva for teaching team availability
<strong>Discussion board</strong>: Minerva forum for peer/staff questions
<strong>Technical issues</strong>: Email module lead or submit GitLab issue</p>
<p><strong>Emergency extensions</strong>: Contact module lead ASAP if unforeseen circumstances prevent submission.</p>
<hr />
<h2 id="faqs"><a class="header" href="#faqs">FAQs</a></h2>
<p><strong>Q: Can I work in a group?</strong>
A: No. Assessment is individual. You can pilot with peers but analysis/documentation must be your own.</p>
<p><strong>Q: What if I can't recruit 4 participants?</strong>
A: Minimum 4 required. Start recruiting early (Week 8). Use lab sessions to find peers.</p>
<p><strong>Q: Can I use my Week 6-7 work for Task 1?</strong>
A: Yes! Reference Week 6 job stories, Week 7 WCAG audit. That's the evidence trail.</p>
<p><strong>Q: Do I need to fix all issues found in Task 1?</strong>
A: No. Prioritise top 2-3 issues using (Impact + Inclusion) ‚Äì Effort. Quality over quantity.</p>
<p><strong>Q: What if my redesign doesn't improve metrics?</strong>
A: Document honestly. Analyse why (small n? wrong fix? need more iteration?). Shows LO12 (professionalism).</p>
<p><strong>Q: Can I submit early?</strong>
A: Yes, but you lose studio crit feedback (Week 11 Lab 1). Consider using full timeline.</p>
<p><strong>Q: What's the word limit?</strong>
A: No strict limit. Be concise. Findings doc typically 2000-3000 words, redesign brief 1500-2500.</p>
<hr />
<h2 id="quick-links"><a class="header" href="#quick-links">Quick Links</a></h2>
<ul>
<li><a href="assessment/task1.html">Task 1: Evaluation &amp; Findings</a></li>
<li><a href="assessment/task2.html">Task 2: Redesign &amp; Verification</a></li>
<li><a href="assessment/../references/learning-outcomes.html">Learning Outcomes Reference</a></li>
<li><a href="assessment/../references/glossary.html">Glossary</a></li>
<li><a href="https://www.w3.org/WAI/WCAG22/quickref/">WCAG 2.2 Quick Reference</a></li>
</ul>
<hr />
<p><strong>Remember</strong>: Assessment measures your ability to design inclusive, accessible interfaces using evidence-based methods. Focus on learning the process‚Äîgrades follow naturally.</p>
<p><strong>Good luck!</strong> üéì</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="task-1-evaluation--findings-3"><a class="header" href="#task-1-evaluation--findings-3">Task 1: Evaluation &amp; Findings</a></h1>
<p><img src="https://img.shields.io/badge/Task_1-Evaluation-blue" alt="Task 1" />
<img src="https://img.shields.io/badge/Due-Week_9_Lab_2-orange" alt="Week 9" />
<img src="https://img.shields.io/badge/LOs-7_assessed-green" alt="LOs" /></p>
<hr />
<h2 id="overview"><a class="header" href="#overview">Overview</a></h2>
<p>Design and execute a <strong>task-based usability evaluation</strong> with peer pilots (n=4 minimum), collecting quantitative metrics and qualitative observations to identify accessibility and usability issues in your HCI implementation.</p>
<p><strong>What you'll learn</strong>:</p>
<ul>
<li>How to design rigorous evaluation protocols</li>
<li>How to collect privacy-safe metrics using server-side instrumentation</li>
<li>How to synthesise findings from mixed-methods data</li>
<li>How to create evidence chains linking data to design decisions</li>
</ul>
<hr />
<h2 id="what-were-assessing"><a class="header" href="#what-were-assessing">What We're Assessing</a></h2>
<h3 id="-what-this-task-does-assess"><a class="header" href="#-what-this-task-does-assess">‚úÖ What This Task DOES Assess</a></h3>
<p><strong>HCI process competence</strong> (LO8):</p>
<ul>
<li>Can you design a rigorous evaluation protocol?</li>
<li>Can you execute ethical pilots (consent, privacy, right to withdraw)?</li>
<li>Can you collect valid quantitative data (metrics.csv complete, no fabrication)?</li>
<li>Can you synthesise findings from mixed-methods data?</li>
</ul>
<p><strong>Evidence-based thinking</strong> (LO1, LO6, LO12):</p>
<ul>
<li>Do you ground findings in data (evidence chains: data ‚Üí observation ‚Üí interpretation)?</li>
<li>Can you link evaluation to needs-finding (LO2: job stories ‚Üí task design)?</li>
<li>Do you report honestly (limitations acknowledged, unexpected results explained)?</li>
</ul>
<p><strong>Professional practice</strong> (LO11, LO12, LO13):</p>
<ul>
<li>Do you follow ethical protocols (consent, anonymity, no PII)?</li>
<li>Can you collaborate effectively (peer pilots, observer role)?</li>
<li>Can you integrate HCI methods with software engineering (server-side instrumentation)?</li>
</ul>
<h3 id="-what-this-task-does-not-assess"><a class="header" href="#-what-this-task-does-not-assess">‚ùå What This Task Does NOT Assess</a></h3>
<p><strong>Code quality</strong>: We're not grading your Week 6-8 implementation (that's already built). We assess your <strong>evaluation method</strong>, not your coding skills.</p>
<p><strong>Kotlin/Ktor proficiency</strong>: That's OOP (Weeks 1-5). We assess <strong>HCI methods</strong> (protocol design, pilots, analysis).</p>
<p><strong>Writing quality</strong>: Beyond basic clarity, we don't mark prose style. <strong>Tables, metrics, and evidence chains</strong> matter more than eloquent paragraphs.</p>
<p><strong>Feature completeness</strong>: We don't care if your app is "finished". We care if you can <strong>evaluate what exists</strong> using rigorous methods.</p>
<p><strong>Perfect results</strong>: We don't expect zero issues found. We expect <strong>honest reporting</strong> and <strong>traceable evidence</strong>.</p>
<hr />
<h2 id="timeline"><a class="header" href="#timeline">Timeline</a></h2>
<div class="table-wrapper"><table><thead><tr><th>When</th><th>Activity</th><th>Deliverable</th></tr></thead><tbody>
<tr><td><strong>Week 8 Lab 2</strong></td><td><strong>Task 1 launched</strong><br>Draft evaluation plan, define tasks, write protocol</td><td>Planning docs (not submitted yet)</td></tr>
<tr><td><strong>Week 9 Lab 1</strong></td><td>Learn server-side instrumentation (<code>Logger.kt</code>, timing)<br>Finalise protocol</td><td>Working instrumentation + consent protocol</td></tr>
<tr><td><strong>Week 9 Lab 2</strong></td><td>Conduct 4+ peer pilots<br>Synthesise findings<br><strong>Submit to Gradescope</strong></td><td>Complete Task 1 package (6 files + evidence)</td></tr>
</tbody></table>
</div>
<p><strong>Total time</strong>: 6-7 hours across 2 weeks</p>
<hr />
<h2 id="learning-outcomes-assessed"><a class="header" href="#learning-outcomes-assessed">Learning Outcomes Assessed</a></h2>
<p>This task assesses <strong>7 of 13 HCI Learning Outcomes</strong>:</p>
<div class="table-wrapper"><table><thead><tr><th>LO</th><th>Outcome</th><th>How Task 1 Assesses It</th></tr></thead><tbody>
<tr><td><strong>LO1</strong></td><td>Differentiate people-centred methodologies</td><td>Evaluation method selection and justification</td></tr>
<tr><td><strong>LO2</strong></td><td>Design and conduct needs-finding</td><td>Link evaluation tasks to Week 6 job stories</td></tr>
<tr><td><strong>LO6</strong></td><td>Apply iterative design</td><td>Pilot data ‚Üí findings synthesis ‚Üí redesign planning</td></tr>
<tr><td><strong>LO8</strong></td><td>Design and execute evaluation</td><td>Protocol design, 4+ pilots, metrics collection</td></tr>
<tr><td><strong>LO11</strong></td><td>Collaborate in teams</td><td>Peer pilot facilitation + observer role</td></tr>
<tr><td><strong>LO12</strong></td><td>Demonstrate professionalism</td><td>Consent adherence, honest reporting, evidence chains</td></tr>
<tr><td><strong>LO13</strong></td><td>Integrate HCI with SE</td><td>Server-side instrumentation (<code>Logger.kt</code>, timing wrappers)</td></tr>
</tbody></table>
</div>
<p>See <a href="assessment/../references/learning-outcomes.html">Learning Outcomes Reference</a> for full definitions.</p>
<hr />
<h2 id="what-youre-evaluating"><a class="header" href="#what-youre-evaluating">What You're Evaluating</a></h2>
<p><strong>Your own HCI implementation</strong> built during Weeks 6-8:</p>
<ul>
<li>Task management interface (CRUD operations)</li>
<li>Server-first architecture (Ktor + Pebble templates)</li>
<li>HTMX progressive enhancement</li>
<li>No-JS parity (all features work without JavaScript)</li>
<li>Accessibility features (ARIA, keyboard navigation, semantic HTML)</li>
</ul>
<p><strong>Focus</strong>: Evaluate <strong>actual implementation</strong>, not hypothetical design. Test what you built.</p>
<hr />
<h2 id="deliverables"><a class="header" href="#deliverables">Deliverables</a></h2>
<p>Submit <strong>6 files + evidence directory</strong> to Gradescope by <strong>Week 9 Lab 2 deadline</strong>:</p>
<h3 id="required-files"><a class="header" href="#required-files">Required Files</a></h3>
<h4 id="1-01-evaluation-planmd"><a class="header" href="#1-01-evaluation-planmd">1. <code>01-evaluation-plan.md</code></a></h4>
<p><strong>What it is</strong>: High-level plan explaining what you're evaluating, why, and how.</p>
<p><strong>Key sections</strong>:</p>
<ul>
<li>Evaluation objectives (design questions you need answered)</li>
<li><strong>Link to needs-finding</strong> (LO2): How Week 6 job stories informed task selection</li>
<li>Method selection (why task-based testing?)</li>
<li>Success criteria (quantitative targets + qualitative indicators)</li>
<li>Evaluation scope (features in/out of scope)</li>
<li>Risks &amp; mitigations</li>
<li>Ethical considerations</li>
<li>Timeline</li>
<li>Expected outcomes</li>
</ul>
<p><strong>Template</strong>: <a href="assessment/../../wk09/lab-wk9/submission/task1-draft/01-evaluation-plan.html">wk09/lab-wk9/submission/task1-draft/01-evaluation-plan.md</a></p>
<p><strong>Example connection to needs-finding</strong> (see <a href="assessment/task1.html#worked-example-linking-needs-finding-to-evaluation">Worked Example: Linking Needs-Finding to Evaluation</a> below):</p>
<blockquote>
<p>"Job story from Week 6: 'When I need to track coursework deadlines, I want to quickly add tasks, so I don't forget important dates' ‚Üí informed Task 3 (add task) with target time &lt;10 seconds."</p>
</blockquote>
<hr />
<h4 id="2-02-protocolmd"><a class="header" href="#2-02-protocolmd">2. <code>02-protocol.md</code></a></h4>
<p><strong>What it is</strong>: Step-by-step session flow for pilots (consent ‚Üí tasks ‚Üí debrief).</p>
<p><strong>Key sections</strong>:</p>
<ul>
<li>Consent process (script, participant rights)</li>
<li>Pre-session setup (instrumentation check, browser config)</li>
<li>Task instructions (read to participants verbatim)</li>
<li>Facilitator guidelines (neutral tone, no leading)</li>
<li>Observer notes template</li>
<li>Debrief questions (confidence ratings, open feedback)</li>
<li>Data handling (anonymisation, storage)</li>
</ul>
<p><strong>Template</strong>: Already exists at <a href="assessment/../../wk09/lab-wk9/research/protocol.html">wk09/lab-wk9/research/protocol.md</a></p>
<p><strong>Critical</strong>: Protocol must include consent confirmation and right to withdraw.</p>
<hr />
<h4 id="3-03-tasksmd"><a class="header" href="#3-03-tasksmd">3. <code>03-tasks.md</code></a></h4>
<p><strong>What it is</strong>: Specific evaluation tasks participants will perform.</p>
<p><strong>Structure for each task</strong>:</p>
<ul>
<li>Scenario (context for task)</li>
<li>Instructions (read to participant)</li>
<li>Success criteria (observable outcomes)</li>
<li>Expected duration (target time)</li>
<li>Known risks (potential issues)</li>
</ul>
<p><strong>Template</strong>: <a href="assessment/../../wk09/lab-wk9/submission/task1-draft/03-tasks.html">wk09/lab-wk9/submission/task1-draft/03-tasks.md</a></p>
<p><strong>Example task</strong>:</p>
<pre><code class="language-markdown">## Task 2 (T2): Edit Existing Task

### Scenario
You created a task with the wrong title. You need to edit it.

### Instructions
"Find the task titled 'Lab report' and change it to 'COMP2850 lab report'."

### Success Criteria
- Task title updated to 'COMP2850 lab report'
- No validation errors
- Task still visible in list

### Expected Duration
Target: &lt; 15 seconds

### Known Risks
- Inline edit focus management (keyboard users)
- Validation error not announced (SR users)
</code></pre>
<hr />
<h4 id="4-04-resultscsv--04-results-readmemd"><a class="header" href="#4-04-resultscsv--04-results-readmemd">4. <code>04-results.csv</code> + <code>04-results-README.md</code></a></h4>
<p><strong>What it is</strong>: Raw quantitative data from pilots (time-on-task, errors, completion).</p>
<p><strong>CSV schema</strong>:</p>
<pre><code class="language-csv">ts_iso,session_id,request_id,task_code,step,outcome,ms,http_status,js_mode
2025-10-15T14:18:23.456Z,P1_7a9f,r001,T3_add,success,,567,200,on
</code></pre>
<p><strong>Columns explained in README</strong>:</p>
<ul>
<li><code>ts_iso</code>: Event timestamp (ISO 8601 UTC)</li>
<li><code>session_id</code>: Anonymous participant ID (P1_xxxx, P2_xxxx)</li>
<li><code>task_code</code>: Task identifier (T1_filter, T2_edit, etc.)</li>
<li><code>step</code>: Event type (success, validation_error, fail)</li>
<li><code>outcome</code>: Specific error (blank_title, max_length, etc.)</li>
<li><code>ms</code>: Duration in milliseconds</li>
<li><code>http_status</code>: HTTP response code (200, 400, 500)</li>
<li><code>js_mode</code>: JavaScript availability (on, off)</li>
</ul>
<p><strong>Source</strong>: Captured via server-side <code>Logger.kt</code> (Week 9 Lab 1)</p>
<p><strong>Template</strong>: <a href="assessment/../../wk09/lab-wk9/submission/task1-draft/04-results.csv">wk09/lab-wk9/submission/task1-draft/04-results.csv</a></p>
<p><strong>Privacy</strong>: Session IDs must be anonymous (no names, emails, student IDs).</p>
<hr />
<h4 id="5-05-findingsmd"><a class="header" href="#5-05-findingsmd">5. <code>05-findings.md</code></a></h4>
<p><strong>What it is</strong>: Synthesised analysis with evidence chains linking data to findings.</p>
<p><strong>Key sections</strong>:</p>
<ol>
<li><strong>Executive summary</strong> (3-5 key findings)</li>
<li><strong>Quantitative results</strong> (completion rates, median times, error rates, JS-on vs JS-off)</li>
<li><strong>Qualitative findings</strong> (accessibility issues, usability issues, positive observations)</li>
<li><strong>Prioritisation</strong> (using Impact + Inclusion ‚Äì Effort matrix)</li>
<li><strong>Evidence chains</strong> (raw data ‚Üí observation ‚Üí interpretation ‚Üí backlog item)</li>
<li><strong>Limitations</strong> (sample size, diversity, study context)</li>
<li><strong>Conclusion</strong> (recommended fixes for Task 2)</li>
</ol>
<p><strong>Template</strong>: <a href="assessment/../../wk09/lab-wk9/submission/task1-draft/05-findings.html">wk09/lab-wk9/submission/task1-draft/05-findings.md</a></p>
<p><strong>Evidence chain example</strong>:</p>
<pre><code>04-results.csv line 127: P2_4d8e,T2_edit,validation_error,blank_title,0,400,on
    ‚Üì
06-evidence/pilot-notes/P2-notes.md line 12: "P2: 'I didn't hear any error message'"
    ‚Üì
Interpretation: SR users cannot detect validation errors (WCAG 4.1.3)
    ‚Üì
backlog/backlog.csv wk9-01: "Add role=alert to error messages"
    ‚Üì
Task 2 fix: Implement aria-live + aria-describedby + focus management
</code></pre>
<p><strong>Content</strong>: 600-800 words of prose + tables (quantitative stats) + evidence chains. Focus on analysis, not padding. Excludes tables, code snippets, and headings.</p>
<hr />
<h4 id="6-06-evidence"><a class="header" href="#6-06-evidence">6. <code>06-evidence/</code></a></h4>
<p><strong>What it is</strong>: Directory containing screenshots, pilot notes, and consent logs.</p>
<p><strong>Structure</strong>:</p>
<pre><code>06-evidence/
‚îú‚îÄ‚îÄ README.md                    # Privacy guidelines, annotation instructions
‚îú‚îÄ‚îÄ screenshots/
‚îÇ   ‚îú‚îÄ‚îÄ t2-validation-error.png  # Visual evidence of issues
‚îÇ   ‚îú‚îÄ‚îÄ t1-filter-results.png
‚îÇ   ‚îî‚îÄ‚îÄ annotations.md           # Alt text + context for all screenshots
‚îú‚îÄ‚îÄ pilot-notes/
‚îÇ   ‚îú‚îÄ‚îÄ P1-notes.md              # Qualitative observations per participant
‚îÇ   ‚îú‚îÄ‚îÄ P2-notes.md
‚îÇ   ‚îú‚îÄ‚îÄ P3-notes.md
‚îÇ   ‚îî‚îÄ‚îÄ P4-notes.md
‚îî‚îÄ‚îÄ consent-log.md               # Participant consent tracking (optional)
</code></pre>
<p><strong>Templates</strong>:</p>
<ul>
<li>README: <a href="assessment/../../wk09/lab-wk9/submission/task1-draft/06-evidence/README.html">wk09/lab-wk9/submission/task1-draft/06-evidence/README.md</a></li>
<li>Annotations: <a href="assessment/../../wk09/lab-wk9/submission/task1-draft/06-evidence/screenshots/annotations.html">wk09/lab-wk9/submission/task1-draft/06-evidence/screenshots/annotations.md</a></li>
</ul>
<p><strong>Privacy requirements</strong>:</p>
<ul>
<li>‚úÖ All screenshots cropped/blurred to remove PII</li>
<li>‚úÖ Pilot notes use codes (P1, P2) not names</li>
<li>‚úÖ Session IDs anonymous (P1_7a9f not recognisable)</li>
<li>‚úÖ No emails, student IDs, or personal data</li>
</ul>
<hr />
<h2 id="submission-structure"><a class="header" href="#submission-structure">Submission Structure</a></h2>
<p>Your <code>task1-draft/</code> directory should look like this:</p>
<pre><code>wk09/lab-wk9/submission/task1-draft/
‚îú‚îÄ‚îÄ 01-evaluation-plan.md
‚îú‚îÄ‚îÄ 02-protocol.md
‚îú‚îÄ‚îÄ 03-tasks.md
‚îú‚îÄ‚îÄ 04-results.csv
‚îú‚îÄ‚îÄ 04-results-README.md
‚îú‚îÄ‚îÄ 05-findings.md
‚îî‚îÄ‚îÄ 06-evidence/
    ‚îú‚îÄ‚îÄ README.md
    ‚îú‚îÄ‚îÄ screenshots/
    ‚îÇ   ‚îú‚îÄ‚îÄ t1-filter-results.png
    ‚îÇ   ‚îú‚îÄ‚îÄ t2-validation-error.png
    ‚îÇ   ‚îî‚îÄ‚îÄ annotations.md
    ‚îú‚îÄ‚îÄ pilot-notes/
    ‚îÇ   ‚îú‚îÄ‚îÄ P1-notes.md
    ‚îÇ   ‚îú‚îÄ‚îÄ P2-notes.md
    ‚îÇ   ‚îú‚îÄ‚îÄ P3-notes.md
    ‚îÇ   ‚îî‚îÄ‚îÄ P4-notes.md
    ‚îî‚îÄ‚îÄ consent-log.md
</code></pre>
<p><strong>Submission</strong>: Zip this directory and upload to Gradescope. (See <a href="assessment/task1.html#submission-instructions">Submission Instructions</a> below for details.)</p>
<hr />
<h2 id="minimum-requirements"><a class="header" href="#minimum-requirements">Minimum Requirements</a></h2>
<p><strong>Must have</strong>:</p>
<ul>
<li>‚úÖ <strong>Minimum 4 participants</strong> (n=4)</li>
<li>‚úÖ <strong>At least 3 variants tested</strong> (see <a href="assessment/task1.html#what-are-variants">What are variants?</a> below)</li>
<li>‚úÖ <strong>Quantitative data</strong> in <code>04-results.csv</code> (time, errors, completion)</li>
<li>‚úÖ <strong>Qualitative data</strong> in pilot notes (quotes, observations)</li>
<li>‚úÖ <strong>Evidence chains</strong> linking data ‚Üí findings ‚Üí backlog</li>
<li>‚úÖ <strong>Consent documented</strong> (protocol + participant confirmation)</li>
<li>‚úÖ <strong>No PII</strong> in any file</li>
</ul>
<p><strong>Nice to have</strong>:</p>
<ul>
<li>üåü Screen reader variant tested (NVDA, VoiceOver)</li>
<li>üåü More than 4 participants (stronger patterns)</li>
<li>üåü Statistical analysis (median, MAD calculated correctly)</li>
<li>üåü WCAG references in findings (specific criteria cited)</li>
</ul>
<hr />
<h2 id="what-are-variants"><a class="header" href="#what-are-variants">What are Variants?</a></h2>
<p><strong>Variants</strong> are different configurations or access methods used to test the interface. Testing multiple variants ensures your evaluation captures accessibility and progressive enhancement issues.</p>
<p><strong>Minimum requirement</strong>: Test at least <strong>3 different variants</strong> across your 4+ participants.</p>
<p><strong>Common variants</strong>:</p>
<div class="table-wrapper"><table><thead><tr><th>Variant</th><th>What it tests</th><th>Example participant</th></tr></thead><tbody>
<tr><td><strong>Standard (HTMX-on)</strong></td><td>Default enhanced experience</td><td>P1: Mouse + HTMX + JavaScript enabled</td></tr>
<tr><td><strong>Keyboard-only</strong></td><td>Keyboard navigation, focus management</td><td>P2: Tab/Enter only, no mouse, HTMX-on</td></tr>
<tr><td><strong>No-JS</strong></td><td>Baseline HTML forms, PRG pattern, full-page loads</td><td>P3: JavaScript disabled in browser</td></tr>
<tr><td><strong>Screen reader</strong></td><td>ARIA announcements, semantic HTML, labels</td><td>P4: NVDA/VoiceOver + keyboard</td></tr>
<tr><td><strong>Mobile</strong></td><td>Touch targets, viewport scaling, responsive layout</td><td>P5: Phone/tablet browser</td></tr>
</tbody></table>
</div>
<p><strong>Example distribution (n=5)</strong>:</p>
<ul>
<li>P1: Standard (mouse + HTMX)</li>
<li>P2: Keyboard-only (HTMX-on)</li>
<li>P3: No-JS (keyboard or mouse)</li>
<li>P4: Screen reader (NVDA + keyboard)</li>
<li>P5: Repeat of any variant for comparison</li>
</ul>
<p><strong>Why 3+ variants?</strong></p>
<ul>
<li>Catches progressive enhancement failures (HTMX vs no-JS)</li>
<li>Identifies keyboard traps, focus issues, unlabelled controls</li>
<li>Verifies ARIA live regions work (screen reader testing)</li>
<li>Demonstrates inclusive design competence (LO9)</li>
</ul>
<p><strong>Recording variants</strong>: Document in <code>js_mode</code> column of <code>04-results.csv</code> and participant notes.</p>
<hr />
<h2 id="common-mistakes-to-avoid-1"><a class="header" href="#common-mistakes-to-avoid-1">Common Mistakes to Avoid</a></h2>
<p>‚ùå <strong>Fabricated data</strong>: Markers can spot fake metrics (too perfect, unrealistic patterns)</p>
<p>‚ùå <strong>No evidence chains</strong>: Saying "SR users struggled" without pilot notes or screenshots</p>
<p>‚ùå <strong>PII leaks</strong>: Screenshots with names, session IDs that reveal identities</p>
<p>‚ùå <strong>Incomplete pilots</strong>: Only 2-3 participants instead of minimum 4</p>
<p>‚ùå <strong>Missing consent</strong>: No documentation of ethical protocol</p>
<p>‚ùå <strong>Vague findings</strong>: "Interface needs improvement" vs "Validation errors not announced (WCAG 4.1.3)"</p>
<p>‚ùå <strong>No link to needs-finding</strong>: Missing LO2 connection to Week 6 job stories</p>
<p>‚ùå <strong>Results.csv incomplete</strong>: Missing session IDs, timestamps, or task outcomes</p>
<hr />
<h2 id="worked-example-linking-needs-finding-to-evaluation"><a class="header" href="#worked-example-linking-needs-finding-to-evaluation">Worked Example: Linking Needs-Finding to Evaluation</a></h2>
<p><strong>Demonstrating LO2 competence</strong> requires showing how Week 6 job stories informed your Task 1 evaluation design.</p>
<h3 id="example-chain-job-story--task-design--success-criteria"><a class="header" href="#example-chain-job-story--task-design--success-criteria">Example Chain: Job Story ‚Üí Task Design ‚Üí Success Criteria</a></h3>
<h4 id="1-week-6-job-story-from-needs-finding"><a class="header" href="#1-week-6-job-story-from-needs-finding">1. Week 6 Job Story (from Needs-Finding)</a></h4>
<blockquote>
<p>"When I'm reviewing my weekly tasks on Sunday evening, I want to see incomplete items highlighted, so I can prioritize tomorrow's work, because I need to meet Friday's deadline."</p>
</blockquote>
<p><strong>Context</strong>: Participant prioritises coursework weekly; needs visual distinction between complete/incomplete tasks.</p>
<hr />
<h4 id="2-evaluation-task-design-task-1-week-9"><a class="header" href="#2-evaluation-task-design-task-1-week-9">2. Evaluation Task Design (Task 1, Week 9)</a></h4>
<p>From this job story, you designed <strong>Task 4 (T4): Filter incomplete tasks</strong></p>
<p><strong>Scenario</strong>: "You have 10 tasks in your list. 4 are complete, 6 are incomplete. You need to review only incomplete tasks."</p>
<p><strong>Instructions</strong>: "Use the filter to show only incomplete tasks."</p>
<p><strong>Success criteria</strong>:</p>
<ul>
<li>Filter applied successfully</li>
<li>Only incomplete tasks visible (n=6)</li>
<li>Screen reader announces result count ("Showing 6 of 10 tasks")</li>
</ul>
<p><strong>Expected duration</strong>: Target &lt; 8 seconds (job story context: "Sunday evening" = time-pressured)</p>
<hr />
<h4 id="3-link-in-evaluation-plan-01-evaluation-planmd"><a class="header" href="#3-link-in-evaluation-plan-01-evaluation-planmd">3. Link in Evaluation Plan (01-evaluation-plan.md)</a></h4>
<p>In your evaluation plan, Section 2 ("Link to Needs-Finding"), you write:</p>
<blockquote>
<p><strong>Job Story JS3</strong> (from Week 6 participant P2): "When I'm reviewing my weekly tasks on Sunday evening, I want to see incomplete items highlighted, so I can prioritize tomorrow's work, because I need to meet Friday's deadline."</p>
<p><strong>Informed design of Task 4 (Filter incomplete tasks)</strong>:</p>
<ul>
<li><strong>Time target</strong> (&lt; 8 seconds): Job story context indicates time pressure (Sunday evening review before Monday deadlines).</li>
<li><strong>Result count announcement</strong>: Job story participant mentioned needing to "see" distinction ‚Üí interpreted as need for both visual and auditory feedback (WCAG 1.3.1).</li>
<li><strong>Success metric</strong>: Completion rate &gt; 90%, median time &lt; 8s, screen reader result announcement verified.</li>
</ul>
</blockquote>
<hr />
<h4 id="4-evidence-in-findings-05-findingsmd"><a class="header" href="#4-evidence-in-findings-05-findingsmd">4. Evidence in Findings (05-findings.md)</a></h4>
<p>After running pilots, you analyse T4 data:</p>
<blockquote>
<p><strong>Finding F4</strong>: Filter feature (T4) achieved 100% completion rate (5/5 participants) with median time 6.2s (MAD: 1.1s), exceeding target (&lt; 8s). However, 1/2 screen reader participants reported confusion about result count format ("Showing 6 of 10" read as "Showing six of ten" without context). Links to <strong>JS3</strong> (Week 6): need for clear prioritisation feedback.</p>
</blockquote>
<hr />
<h3 id="what-this-demonstrates-lo2"><a class="header" href="#what-this-demonstrates-lo2">What This Demonstrates (LO2)</a></h3>
<p>‚úÖ <strong>Needs-finding informed task selection</strong>: Job story ‚Üí evaluation task
‚úÖ <strong>Measurable targets derived from context</strong>: "Sunday evening" time pressure ‚Üí &lt; 8s target
‚úÖ <strong>Accessibility considerations traced</strong>: "see highlighted" ‚Üí visual + auditory feedback
‚úÖ <strong>Evidence chain complete</strong>: Job story ‚Üí task design ‚Üí pilot data ‚Üí finding</p>
<h3 id="common-mistakes"><a class="header" href="#common-mistakes">Common Mistakes</a></h3>
<p>‚ùå <strong>Vague link</strong>: "Job stories informed my tasks" (no specifics)
‚ùå <strong>Post-hoc fabrication</strong>: Claiming link to job story that doesn't match task design
‚ùå <strong>Missing context</strong>: Citing job story without explaining <em>how</em> it shaped task parameters</p>
<hr />
<h2 id="tips-for-success-1"><a class="header" href="#tips-for-success-1">Tips for Success</a></h2>
<h3 id="planning-week-8-lab-2"><a class="header" href="#planning-week-8-lab-2">Planning (Week 8 Lab 2)</a></h3>
<p>‚úÖ <strong>Draft tasks early</strong>: Define 4-5 realistic tasks based on features you built</p>
<p>‚úÖ <strong>Set measurable targets</strong>: "&lt; 15 seconds" not "fast"</p>
<p>‚úÖ <strong>Link to Week 6</strong>: Show how job stories informed task design (LO2)</p>
<p>‚úÖ <strong>Test your protocol</strong>: Do a dry run before Week 9 pilots</p>
<hr />
<h3 id="execution-week-9-lab-1-2"><a class="header" href="#execution-week-9-lab-1-2">Execution (Week 9 Lab 1-2)</a></h3>
<p>‚úÖ <strong>Instrument carefully</strong>: Test <code>Logger.kt</code> before pilots‚Äîverify CSV writes correctly</p>
<p>‚úÖ <strong>Recruit early</strong>: Don't wait until Week 9 Lab 2 to find participants</p>
<p>‚úÖ <strong>Pilot diverse variants</strong>: At least 1 keyboard-only, 1 no-JS</p>
<p>‚úÖ <strong>Take notes immediately</strong>: Don't rely on memory‚Äîcapture quotes during session</p>
<p>‚úÖ <strong>Check data completeness</strong>: Before participants leave, verify <code>metrics.csv</code> has their data</p>
<hr />
<h3 id="analysis--documentation-week-9-lab-2"><a class="header" href="#analysis--documentation-week-9-lab-2">Analysis &amp; Documentation (Week 9 Lab 2)</a></h3>
<p>‚úÖ <strong>Scrub screenshots</strong>: Crop/blur PII before adding to <code>06-evidence/</code></p>
<p>‚úÖ <strong>Calculate stats correctly</strong>: Use median (not mean), calculate MAD for variability</p>
<p>‚úÖ <strong>Link everything</strong>: Every claim needs file path, line number, or session ID reference</p>
<p>‚úÖ <strong>Prioritise ruthlessly</strong>: Not all issues are equal‚Äîuse Impact + Inclusion ‚Äì Effort</p>
<p>‚úÖ <strong>Be honest</strong>: Markers value honest reporting over perfect results</p>
<hr />
<h2 id="faqs-1"><a class="header" href="#faqs-1">FAQs</a></h2>
<p><strong>Q: Can I use fewer than 4 participants?</strong>
A: No. Minimum 4 required for identifying patterns. Nielsen's 5-user rule suggests 5 find ~85% of issues.</p>
<p><strong>Q: What if participants don't give consent?</strong>
A: Don't proceed with the pilot. Find alternative participants. Consent is non-negotiable.</p>
<p><strong>Q: Can I fabricate data if I couldn't complete pilots?</strong>
A: Absolutely not. Academic integrity violation. Contact module lead immediately if you have issues.</p>
<p><strong>Q: What if my metrics.csv is empty?</strong>
A: Your instrumentation isn't working. Debug in Week 9 Lab 1 before running pilots.</p>
<p><strong>Q: Do I need to test with screen readers?</strong>
A: Not mandatory (keyboard-only is acceptable) but highly recommended for stronger evidence.</p>
<p><strong>Q: What if my findings show the interface has no problems?</strong>
A: Unlikely with n=4-5. Revisit pilot notes for subtle issues (confusion, hesitation, errors). Be honest if genuinely no issues, but check you're looking closely enough.</p>
<p><strong>Q: How do I link to Week 6 needs-finding?</strong>
A: In <code>01-evaluation-plan.md</code>, section 2 prompts you to reference 2-3 job stories and explain how they shaped your task selection.</p>
<p><strong>Q: Can I submit early?</strong>
A: Yes, but you miss Week 9 Lab 2 time for data verification. Use the full 2 weeks.</p>
<hr />
<h2 id="marking-criteria"><a class="header" href="#marking-criteria">Marking Criteria</a></h2>
<h3 id="evidence-quality-30"><a class="header" href="#evidence-quality-30">Evidence Quality (30%)</a></h3>
<ul>
<li>Complete quantitative data (<code>04-results.csv</code> with all required columns)</li>
<li>Rich qualitative data (pilot notes with quotes, timestamps, observations)</li>
<li>Traceable evidence chains (every claim links to data)</li>
<li>No PII in any file</li>
</ul>
<h3 id="method-rigour-25"><a class="header" href="#method-rigour-25">Method Rigour (25%)</a></h3>
<ul>
<li>Clear protocol with consent and ethical safeguards</li>
<li>Appropriate task design (realistic, measurable, independent)</li>
<li>Valid variants tested (keyboard, no-JS, etc.)</li>
<li>Minimum 4 participants recruited and tested</li>
</ul>
<h3 id="analysis-depth-25"><a class="header" href="#analysis-depth-25">Analysis Depth (25%)</a></h3>
<ul>
<li>Quantitative analysis correct (median, MAD, error rates)</li>
<li>Qualitative synthesis identifies patterns across participants</li>
<li>WCAG violations referenced with specific criteria</li>
<li>Inclusion impact articulated (who is excluded, how)</li>
<li>Link to needs-finding demonstrated (LO2)</li>
</ul>
<h3 id="professional-presentation-20"><a class="header" href="#professional-presentation-20">Professional Presentation (20%)</a></h3>
<ul>
<li>Clear, well-structured documentation</li>
<li>Honest reporting (doesn't hide limitations or unexpected results)</li>
<li>Complete submission (all 6 files + evidence)</li>
<li>UK spelling and grammar</li>
<li>Proper Markdown formatting</li>
</ul>
<hr />
<h2 id="resources-1"><a class="header" href="#resources-1">Resources</a></h2>
<h3 id="templates"><a class="header" href="#templates">Templates</a></h3>
<p>All templates available in <code>wk09/lab-wk9/submission/task1-draft/</code>:</p>
<ul>
<li><a href="assessment/../../wk09/lab-wk9/submission/task1-draft/01-evaluation-plan.html">01-evaluation-plan.md</a></li>
<li><a href="assessment/../../wk09/lab-wk9/research/protocol.html">02-protocol.md</a></li>
<li><a href="assessment/../../wk09/lab-wk9/submission/task1-draft/03-tasks.html">03-tasks.md</a></li>
<li><a href="assessment/../../wk09/lab-wk9/submission/task1-draft/04-results.csv">04-results.csv</a> + <a href="assessment/../../wk09/lab-wk9/submission/task1-draft/04-results-README.html">README</a></li>
<li><a href="assessment/../../wk09/lab-wk9/submission/task1-draft/05-findings.html">05-findings.md</a></li>
<li><a href="assessment/../../wk09/lab-wk9/submission/task1-draft/06-evidence/README.html">06-evidence/README.md</a></li>
</ul>
<h3 id="references-2"><a class="header" href="#references-2">References</a></h3>
<ul>
<li><a href="https://www.nngroup.com/articles/usability-testing-101/">Nielsen: Usability Testing 101</a></li>
<li><a href="https://www.nngroup.com/articles/why-you-only-need-to-test-with-5-users/">Nielsen: Why You Only Need 5 Users</a></li>
<li><a href="https://www.w3.org/WAI/test-evaluate/metrics/">W3C: Measuring Accessibility</a></li>
<li><a href="https://www.w3.org/WAI/WCAG22/quickref/">WCAG 2.2 Quick Reference</a></li>
<li><a href="assessment/../references/learning-outcomes.html">Learning Outcomes Reference</a></li>
<li><a href="assessment/../references/glossary.html">Glossary</a></li>
</ul>
<h3 id="week-9-lab-materials"><a class="header" href="#week-9-lab-materials">Week 9 Lab Materials</a></h3>
<ul>
<li><a href="assessment/../../wk09/wk9-lab1-eval-plan-instrumentation.html">Week 9 Lab 1: Evaluation Planning &amp; Instrumentation</a></li>
<li><a href="assessment/../../wk09/wk9-lab2-pilots-debrief-draft.html">Week 9 Lab 2: Peer Pilots, Debrief, and Task 1 Draft Pack</a></li>
</ul>
<hr />
<h2 id="quick-checklist"><a class="header" href="#quick-checklist">Quick Checklist</a></h2>
<p>Before submitting, verify:</p>
<ul>
<li><input disabled="" type="checkbox"/>
<strong>6 required files present</strong> (01-06 + evidence directory)</li>
<li><input disabled="" type="checkbox"/>
<strong>Minimum 4 participants</strong> (documented in results.csv + pilot notes)</li>
<li><input disabled="" type="checkbox"/>
<strong>Link to Week 6 needs-finding</strong> (LO2 addressed in evaluation plan)</li>
<li><input disabled="" type="checkbox"/>
<strong>Evidence chains complete</strong> (every finding links to data)</li>
<li><input disabled="" type="checkbox"/>
<strong>Consent documented</strong> (protocol includes consent script)</li>
<li><input disabled="" type="checkbox"/>
<strong>No PII in any file</strong> (screenshots cropped, session IDs anonymous)</li>
<li><input disabled="" type="checkbox"/>
<strong>WCAG references cited</strong> (specific criteria in findings)</li>
<li><input disabled="" type="checkbox"/>
<strong>Prioritisation documented</strong> (Impact + Inclusion ‚Äì Effort matrix)</li>
<li><input disabled="" type="checkbox"/>
<strong>Screenshots annotated</strong> (alt text + context in annotations.md)</li>
<li><input disabled="" type="checkbox"/>
<strong>Results.csv verified</strong> (all pilots have data, correct schema)</li>
</ul>
<hr />
<h2 id="submission-instructions"><a class="header" href="#submission-instructions">Submission Instructions</a></h2>
<p><strong>Gradescope submission details will be confirmed in Week 9 Lab 1.</strong></p>
<p>In the meantime, prepare your submission:</p>
<h3 id="packaging-requirements"><a class="header" href="#packaging-requirements">Packaging Requirements</a></h3>
<ul>
<li>Keep all files in the <code>task1-draft/</code> directory structure shown above</li>
<li>Ensure filenames match exactly (case-sensitive): <code>01-evaluation-plan.md</code>, <code>02-protocol.md</code>, etc.</li>
<li>Verify <strong>no PII</strong> in any file before packaging (screenshots cropped, session IDs anonymous)</li>
<li>Check all evidence chains are complete (file paths and line numbers accurate)</li>
</ul>
<h3 id="file-size-considerations"><a class="header" href="#file-size-considerations">File Size Considerations</a></h3>
<ul>
<li>Screenshots: Crop to relevant area, use PNG/JPG compression</li>
<li>CSV files: Text format, should be &lt; 1MB</li>
<li>Total package: Aim for &lt; 20MB (if larger, check for unnecessary files)</li>
</ul>
<h3 id="naming-conventions"><a class="header" href="#naming-conventions">Naming Conventions</a></h3>
<p><strong>To be confirmed</strong> ‚Äî watch for announcements in Week 9 Lab 1 about:</p>
<ul>
<li>Zip file naming (e.g., <code>studentID_task1.zip</code> vs <code>task1-draft.zip</code>)</li>
<li>Gradescope assignment name</li>
<li>Late submission policy</li>
</ul>
<h3 id="pre-submission-checklist"><a class="header" href="#pre-submission-checklist">Pre-Submission Checklist</a></h3>
<p>Use the <a href="assessment/task1.html#quick-checklist">Quick Checklist</a> below to verify all requirements met.</p>
<hr />
<p><a href="assessment/overview.html">‚Üê Back to Assessment Overview</a> | <a href="assessment/task2.html">Next: Task 2 ‚Üí</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="task-2-redesign--verification-3"><a class="header" href="#task-2-redesign--verification-3">Task 2: Redesign &amp; Verification</a></h1>
<p><img src="https://img.shields.io/badge/Task_2-Redesign-purple" alt="Task 2" />
<img src="https://img.shields.io/badge/Due-Week_11_Lab_2-orange" alt="Week 11" />
<img src="https://img.shields.io/badge/LOs-9_assessed-green" alt="LOs" /></p>
<hr />
<h2 id="overview-1"><a class="header" href="#overview-1">Overview</a></h2>
<p>Implement <strong>inclusive redesign</strong> based on Task 1 findings, verify improvements through regression testing and re-pilots (n=2 minimum), and analyse societal impacts of design decisions.</p>
<p><strong>What you'll learn</strong>:</p>
<ul>
<li>How to prioritise accessibility fixes using data</li>
<li>How to verify WCAG 2.2 AA compliance through regression testing</li>
<li>How to measure before/after improvement with metrics</li>
<li>How to analyse systemic barriers and societal impacts of design</li>
</ul>
<hr />
<h2 id="what-were-assessing-1"><a class="header" href="#what-were-assessing-1">What We're Assessing</a></h2>
<h3 id="-what-this-task-does-assess-1"><a class="header" href="#-what-this-task-does-assess-1">‚úÖ What This Task DOES Assess</a></h3>
<p><strong>Accessibility knowledge</strong> (LO4, LO9):</p>
<ul>
<li>Can you identify WCAG 2.2 AA violations using audits and testing?</li>
<li>Can you implement fixes that comply with accessibility standards?</li>
<li>Can you verify compliance through regression testing (30 checks)?</li>
<li>Can you test with assistive technologies (keyboard, screen reader, no-JS)?</li>
</ul>
<p><strong>Evidence-based design</strong> (LO5, LO6, LO7):</p>
<ul>
<li>Do you ground redesign in Task 1 data (findings ‚Üí prioritisation ‚Üí fixes)?</li>
<li>Can you measure improvement (before/after metrics comparison)?</li>
<li>Can you analyse design constraints and trade-offs (no-JS parity, server-first)?</li>
<li>Do you use iterative design (implement ‚Üí test ‚Üí verify ‚Üí refine)?</li>
</ul>
<p><strong>Critical analysis</strong> (LO3, LO10):</p>
<ul>
<li>Can you analyse systemic barriers (who is excluded, how, why)?</li>
<li>Can you critique societal impacts (beyond "helps disabled people")?</li>
<li>Can you consider ethical implications (privacy, autonomy, dignity)?</li>
<li>Can you distinguish universal design from accommodation?</li>
</ul>
<p><strong>Professional practice</strong> (LO12, LO13):</p>
<ul>
<li>Do you maintain evidence chains (Task 1 finding ‚Üí fix ‚Üí verification)?</li>
<li>Do you report honestly (if metrics don't improve, explain why)?</li>
<li>Can you integrate accessibility into engineering workflow (regression testing)?</li>
</ul>
<h3 id="-what-this-task-does-not-assess-1"><a class="header" href="#-what-this-task-does-not-assess-1">‚ùå What This Task Does NOT Assess</a></h3>
<p><strong>Code elegance</strong>: We're not grading software engineering quality. We assess <strong>accessibility compliance</strong> and <strong>evidence-based fixing</strong>, not elegant Kotlin.</p>
<p><strong>Feature scope</strong>: We don't care if you fix 1 issue or 10. We care about <strong>high-inclusion impact fixes</strong> (WCAG violations, SR/keyboard barriers) done thoroughly.</p>
<p><strong>Writing quality</strong>: <strong>Code diffs, regression checklists, and metrics tables</strong> matter more than prose. Societal impact needs critical analysis (not flowery language).</p>
<p><strong>Creative solutions</strong>: This isn't about innovation. It's about <strong>applying WCAG standards rigorously</strong> and <strong>verifying compliance methodically</strong>.</p>
<p><strong>Perfect metrics</strong>: We don't expect 100% improvement. We expect <strong>honest before/after comparison</strong> and <strong>analysis of results</strong> (even if modest).</p>
<hr />
<h2 id="timeline-1"><a class="header" href="#timeline-1">Timeline</a></h2>
<div class="table-wrapper"><table><thead><tr><th>When</th><th>Activity</th><th>Deliverable</th></tr></thead><tbody>
<tr><td><strong>Week 10 Lab 1</strong></td><td><strong>Task 2 launched</strong><br>Analyse Task 1 data<br>Prioritise fixes<br>Write redesign brief</td><td>Redesign brief with 2-3 priority fixes</td></tr>
<tr><td><strong>Week 10 Lab 2</strong></td><td>Implement fixes<br>Regression testing (30+ checks)<br>Re-pilots (n=2)</td><td>Working fixes + before/after metrics</td></tr>
<tr><td><strong>Week 11 Lab 1</strong></td><td>Present redesign in studio crit<br>Receive peer feedback</td><td>Feedback incorporated into documentation</td></tr>
<tr><td><strong>Week 11 Lab 2</strong></td><td>Finalise documentation<br><strong>Submit to Gradescope</strong></td><td>Complete Task 2 package (6 files + evidence + metrics)</td></tr>
</tbody></table>
</div>
<p><strong>Total time</strong>: 7-8 hours across 2 weeks</p>
<hr />
<h2 id="learning-outcomes-assessed-1"><a class="header" href="#learning-outcomes-assessed-1">Learning Outcomes Assessed</a></h2>
<p>This task assesses <strong>9 of 13 HCI Learning Outcomes</strong>:</p>
<div class="table-wrapper"><table><thead><tr><th>LO</th><th>Outcome</th><th>How Task 2 Assesses It</th></tr></thead><tbody>
<tr><td><strong>LO3</strong></td><td>Analyse ethical implications</td><td>Privacy audit, consent protocol, autonomy in error handling</td></tr>
<tr><td><strong>LO4</strong></td><td>Evaluate for accessibility</td><td>Regression testing (30+ checks), WCAG 2.2 AA verification</td></tr>
<tr><td><strong>LO5</strong></td><td>Create prototypes</td><td>Redesign implementation (templates, routes, CSS)</td></tr>
<tr><td><strong>LO6</strong></td><td>Apply iterative design</td><td>Task 1 findings ‚Üí redesign ‚Üí re-verification cycle</td></tr>
<tr><td><strong>LO7</strong></td><td>Analyse design constraints</td><td>No-JS parity, server-first constraints, trade-offs documentation</td></tr>
<tr><td><strong>LO9</strong></td><td>Apply inclusive design</td><td>WCAG-compliant fixes, universal design principles</td></tr>
<tr><td><strong>LO10</strong></td><td>Critique societal impacts</td><td>Systemic barriers analysis, exclusion patterns, long-term implications</td></tr>
<tr><td><strong>LO12</strong></td><td>Demonstrate professionalism</td><td>Evidence chains, honest reporting, complete regression testing</td></tr>
<tr><td><strong>LO13</strong></td><td>Integrate HCI with SE</td><td>Server-side fixes, template refactoring, routing patterns</td></tr>
</tbody></table>
</div>
<p>See <a href="assessment/../references/learning-outcomes.html">Learning Outcomes Reference</a> for full definitions.</p>
<hr />
<h2 id="what-youre-redesigning"><a class="header" href="#what-youre-redesigning">What You're Redesigning</a></h2>
<p><strong>Top 2-3 issues identified in Task 1</strong>, prioritised using <strong>(Impact + Inclusion) ‚Äì Effort</strong> (see <a href="assessment/task2.html#prioritisation-formula-explained">Prioritisation Formula</a> below):</p>
<p><strong>Focus on</strong>:</p>
<ul>
<li>WCAG 2.2 AA violations (especially Level A violations)</li>
<li>High inclusion impact (blocks access for screen reader, keyboard-only, or no-JS users)</li>
<li>Feasible within 2-week window (not architectural rewrites)</li>
</ul>
<p><strong>Not</strong>:</p>
<ul>
<li>Cosmetic improvements with low inclusion impact</li>
<li>Issues that require &gt;8 hours to fix</li>
<li>Nice-to-haves without evidence from Task 1</li>
</ul>
<hr />
<h2 id="deliverables-1"><a class="header" href="#deliverables-1">Deliverables</a></h2>
<p>Submit <strong>6 files + evidence + metrics directories</strong> to Gradescope by <strong>Week 11 Lab 2 deadline</strong>:</p>
<h3 id="required-files-1"><a class="header" href="#required-files-1">Required Files</a></h3>
<h4 id="1-01-redesign-briefmd"><a class="header" href="#1-01-redesign-briefmd">1. <code>01-redesign-brief.md</code></a></h4>
<p><strong>What it is</strong>: Design brief grounding fix in Task 1 data, with measurable goals.</p>
<p><strong>Key sections</strong>:</p>
<ul>
<li><strong>Problem</strong> (grounded in Task 1 analysis + audit, 1-2 sentences)</li>
<li><strong>Goal</strong> (measurable outcome targets: median time, error rate, completion rate, SR accessibility)</li>
<li><strong>Inclusion impact</strong> (who benefits, current vs after fix, impact level)</li>
<li><strong>Societal impact</strong> (LO10): Systemic barriers, exclusion analysis, ethical considerations</li>
<li><strong>Changes</strong> (server-first + no-JS parity): Code diffs for each fix</li>
<li><strong>Acceptance tests</strong> (keyboard, SR, no-JS, contrast, zoom, regression)</li>
<li><strong>Measurement plan</strong> (regression testing, re-pilots, before/after comparison)</li>
<li><strong>Timeline</strong> (implementation, testing, documentation breakdown)</li>
<li><strong>Risk assessment</strong> (what could go wrong, mitigations)</li>
<li><strong>Learning Outcomes addressed</strong></li>
</ul>
<p><strong>Template</strong>: <a href="assessment/../../wk10/gradescope/task2/01-redesign-brief.html">wk10/gradescope/task2/01-redesign-brief.md</a></p>
<p><strong>Example problem statement</strong>:</p>
<blockquote>
<p>"Validation errors on the task edit form (T2) are not announced to screen readers, causing a 33% error rate and blocking task completion for SR users (WCAG 4.1.3 violation). Week 9 pilots (n=5) showed 2/5 participants using keyboard-only mode could not detect or correct blank submission errors."</p>
</blockquote>
<p><strong>Societal impact section (LO10)</strong>:</p>
<ul>
<li>Who is excluded? (marginalised groups: disabled people in employment, education, civic participation)</li>
<li>Broader implications (systemic barriers, not individual inconvenience)</li>
<li>How fix addresses barriers (universal design vs accommodation)</li>
<li>Ethical considerations (privacy, autonomy, dignity)</li>
<li>Long-term impact (if pattern adopted widely)</li>
</ul>
<hr />
<h4 id="2-02-a11y-regression-checklistcsv"><a class="header" href="#2-02-a11y-regression-checklistcsv">2. <code>02-a11y-regression-checklist.csv</code></a></h4>
<p><strong>What it is</strong>: Comprehensive accessibility regression testing (30+ checks).</p>
<p><strong>CSV schema</strong>:</p>
<pre><code class="language-csv">check,item,pass,notes
Keyboard,All actions possible with keyboard only,PASS,Tab order verified
Keyboard,Focus order logical; no traps; visible focus,PASS,
Forms,Errors linked via aria-describedby (field &amp; summary),PASS,Added in fix
Dynamic,Status/messages announced via role="status",PASS,Tested with NVDA
No-JS,Full-page path equivalent to HTMX path,PASS,PRG pattern working
Visual,Contrast AA; 200% zoom ok,PASS,Colour Contrast Analyser 7.1:1
</code></pre>
<p><strong>Categories</strong> (30 checks total):</p>
<ul>
<li><strong>Keyboard</strong> (5 checks): Tab order, focus management, no traps</li>
<li><strong>Forms</strong> (3 checks): Labels, required fields, error association</li>
<li><strong>Dynamic</strong> (3 checks): Live regions, focus after updates</li>
<li><strong>No-JS</strong> (4 checks): Full-page parity, error visibility, confirmation</li>
<li><strong>Visual</strong> (5 checks): Contrast, zoom, resize, color independence</li>
<li><strong>Semantic</strong> (3 checks): Headings, landmarks, lists</li>
<li><strong>ARIA</strong> (3 checks): aria-label, aria-describedby, no unnecessary ARIA</li>
<li><strong>Images</strong> (2 checks): Alt text, decorative images</li>
<li><strong>Links</strong> (2 checks): Descriptive text, distinguishable</li>
</ul>
<p><strong>Template</strong>: <a href="assessment/../../wk10/gradescope/task2/02-a11y-regression-checklist.csv">wk10/gradescope/task2/02-a11y-regression-checklist.csv</a></p>
<p><strong>Critical</strong>: Every check must have PASS/FAIL + notes. No blanks.</p>
<hr />
<h4 id="3-03-before-after-summarymd"><a class="header" href="#3-03-before-after-summarymd">3. <code>03-before-after-summary.md</code></a></h4>
<p><strong>What it is</strong>: Quantitative comparison showing improvement from Task 1 baseline.</p>
<p><strong>Structure</strong>:</p>
<pre><code class="language-markdown"># Before vs After ‚Äî Summary

**Focus**: Task T2 (Edit task) ‚Äî primary target of redesign

| Metric | Pre (Week 9, n=5) | Post (Week 10, n=2) | Œî | Goal Met? | Notes |
|--------|------------------|---------------------|---|-----------|-------|
| Completion rate | 80% (4/5) | 100% (2/2) | +20pp | ‚úÖ Yes | All participants successful |
| Error rate | 33% (2/6) | 0% (0/2) | -33pp | ‚úÖ Yes | No validation errors triggered |
| Median time | 1400ms | 1150ms | -250ms | ‚úÖ Yes | 18% faster (goal: ‚â§1200ms) |
| SR accessibility | 0% (not announced) | 100% (announced) | +100pp | ‚úÖ Yes | WCAG 4.1.3 compliance |

**Overall**: ‚úÖ All goals met. T2 now fully accessible, faster, and error-free.
</code></pre>
<p><strong>Template</strong>: <a href="assessment/../../wk10/gradescope/task2/03-before-after-summary.html">wk10/gradescope/task2/03-before-after-summary.md</a></p>
<p><strong>Data sources</strong>:</p>
<ul>
<li><strong>Pre</strong>: <code>06-metrics/pre/analysis.csv</code> (Week 9 baseline from Task 1, generated via <code>Analyse.kt</code> script)</li>
<li><strong>Post</strong>: <code>06-metrics/post/postchange.csv</code> (Week 10 re-pilots, n=2 minimum)</li>
</ul>
<p><strong>Note</strong>: See <a href="assessment/task2.html#tools-analysekt-script">Tools: Analyse.kt Script</a> below for details on generating <code>pre/analysis.csv</code>.</p>
<hr />
<h4 id="4-04-key-diffsmd"><a class="header" href="#4-04-key-diffsmd">4. <code>04-key-diffs.md</code></a></h4>
<p><strong>What it is</strong>: Specific code/template/CSS changes with before/after snippets.</p>
<p><strong>Structure for each change</strong>:</p>
<ul>
<li><strong>Problem</strong> (1-2 sentences + evidence link to Task 1)</li>
<li><strong>Code changes</strong> (before/after snippets with issues/improvements annotated)</li>
<li><strong>UX impact</strong> (before/after user experience description)</li>
<li><strong>Screenshots</strong> (optional but recommended: before/after visual comparison)</li>
</ul>
<p><strong>Template</strong>: <a href="assessment/../../wk10/gradescope/task2/04-key-diffs.html">wk10/gradescope/task2/04-key-diffs.md</a></p>
<p><strong>Content</strong>: 400-600 words of prose + code snippets + tables. Societal impact section: 200-300 words (critical analysis, not description). Excludes code snippets, tables, and headings.</p>
<p><strong>Example</strong>:</p>
<pre><code class="language-markdown">### Change 1: Validation Error Accessibility

#### Problem
Validation errors not announced to screen readers (Task 1 Finding A1, 05-findings.md section 2.1).

#### Code Changes

**Before** (`templates/tasks/edit.peb`):
\`\`\`html
{% if error %}
  &lt;span class="error"&gt;{{ error }}&lt;/span&gt;  ‚Üê ‚ùå No role="alert"
{% endif %}
\`\`\`

**After** (`templates/tasks/edit.peb`):
\`\`\`html
{% if errors.title %}
  &lt;span id="title-error" class="error" role="alert"&gt;  ‚Üê ‚úÖ Added role="alert"
    {{ errors.title }}
  &lt;/span&gt;
{% endif %}

&lt;input aria-describedby="title-hint title-error"&gt;  ‚Üê ‚úÖ Added aria-describedby
\`\`\`

**WCAG compliance**: ‚úÖ 4.1.3 Status Messages (AA), ‚úÖ 3.3.1 Error Identification (A)

#### UX Impact
**Before**: SR users submit blank form ‚Üí hear nothing ‚Üí assume success ‚Üí task incomplete
**After**: SR users submit blank form ‚Üí hear "Alert. Title is required" ‚Üí correct error ‚Üí task complete
</code></pre>
<hr />
<h4 id="5-05-evidence"><a class="header" href="#5-05-evidence">5. <code>05-evidence/</code></a></h4>
<p><strong>What it is</strong>: Visual and qualitative evidence (screenshots, SR transcripts, code snippets).</p>
<p><strong>Structure</strong>:</p>
<pre><code>05-evidence/
‚îú‚îÄ‚îÄ README.md                          # Privacy guidelines, evidence chain instructions
‚îú‚îÄ‚îÄ screenshots/
‚îÇ   ‚îú‚îÄ‚îÄ before-validation-error.png    # Week 9 baseline (issue visible)
‚îÇ   ‚îú‚îÄ‚îÄ after-validation-error.png     # Week 10 fix (issue resolved)
‚îÇ   ‚îú‚îÄ‚îÄ contrast-before.png            # Colour Contrast Analyser (3.5:1 fail)
‚îÇ   ‚îú‚îÄ‚îÄ contrast-after.png             # Colour Contrast Analyser (7.1:1 pass AAA)
‚îÇ   ‚îî‚îÄ‚îÄ annotations.md                 # Alt text + context for all screenshots
‚îú‚îÄ‚îÄ screen-reader-transcripts/
‚îÇ   ‚îú‚îÄ‚îÄ before-nvda-validation.txt     # NVDA output before fix (no announcement)
‚îÇ   ‚îî‚îÄ‚îÄ after-nvda-validation.txt      # NVDA output after fix (error announced)
‚îî‚îÄ‚îÄ code-snippets/
    ‚îú‚îÄ‚îÄ routes-before.kt               # Relevant code before fix
    ‚îú‚îÄ‚îÄ routes-after.kt                # Relevant code after fix
    ‚îî‚îÄ‚îÄ template-diffs.md              # Template changes with annotations
</code></pre>
<p><strong>Templates</strong>:</p>
<ul>
<li><a href="assessment/../../wk10/gradescope/task2/05-evidence/README.html">05-evidence/README.md</a></li>
<li><a href="assessment/../../wk10/gradescope/task2/05-evidence/screenshots/annotations.html">05-evidence/screenshots/annotations.md</a></li>
</ul>
<p><strong>Privacy</strong>: No PII in screenshots or transcripts (crop/blur personal info).</p>
<hr />
<h4 id="6-06-metrics"><a class="header" href="#6-06-metrics">6. <code>06-metrics/</code></a></h4>
<p><strong>What it is</strong>: Before/after quantitative data for comparison.</p>
<p><strong>Structure</strong>:</p>
<pre><code>06-metrics/
‚îú‚îÄ‚îÄ README.md                      # Data sources, interpretation guidelines
‚îú‚îÄ‚îÄ pre/
‚îÇ   ‚îî‚îÄ‚îÄ analysis.csv               # Week 9 baseline (from Task 1, Week 10 Lab 1 Analyse.kt)
‚îî‚îÄ‚îÄ post/
    ‚îî‚îÄ‚îÄ postchange.csv             # Week 10 re-pilots (n=2, same format as pre/)
</code></pre>
<p><strong>CSV format</strong> (same for both pre/ and post/):</p>
<pre><code class="language-csv">task_code,js_mode,n_success,n_total,completion_rate,median_ms,mad_ms,errors_validation,error_rate
T2_edit,on,4,5,0.80,1400,234,2,0.33
</code></pre>
<p><strong>Template</strong>: <a href="assessment/../../wk10/gradescope/task2/06-metrics/README.html">06-metrics/README.md</a></p>
<p><strong>Data sources</strong>:</p>
<ul>
<li><strong>Pre</strong>: Week 9 <code>metrics.csv</code> ‚Üí Week 10 Lab 1 <code>Analyse.kt</code> script ‚Üí <code>pre/analysis.csv</code></li>
<li><strong>Post</strong>: Week 10 re-pilots (n=2) ‚Üí manual calculation or script ‚Üí <code>post/postchange.csv</code></li>
</ul>
<hr />
<h2 id="submission-structure-1"><a class="header" href="#submission-structure-1">Submission Structure</a></h2>
<p>Your <code>task2/</code> directory should look like this:</p>
<pre><code>wk10/gradescope/task2/
‚îú‚îÄ‚îÄ 01-redesign-brief.md
‚îú‚îÄ‚îÄ 02-a11y-regression-checklist.csv
‚îú‚îÄ‚îÄ 03-before-after-summary.md
‚îú‚îÄ‚îÄ 04-key-diffs.md
‚îú‚îÄ‚îÄ 05-evidence/
‚îÇ   ‚îú‚îÄ‚îÄ README.md
‚îÇ   ‚îú‚îÄ‚îÄ screenshots/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ before-validation-error.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ after-validation-error.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ contrast-before.png
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ contrast-after.png
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ annotations.md
‚îÇ   ‚îú‚îÄ‚îÄ screen-reader-transcripts/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ before-nvda-validation.txt
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ after-nvda-validation.txt
‚îÇ   ‚îî‚îÄ‚îÄ code-snippets/
‚îÇ       ‚îú‚îÄ‚îÄ routes-before.kt
‚îÇ       ‚îú‚îÄ‚îÄ routes-after.kt
‚îÇ       ‚îî‚îÄ‚îÄ template-diffs.md
‚îî‚îÄ‚îÄ 06-metrics/
    ‚îú‚îÄ‚îÄ README.md
    ‚îú‚îÄ‚îÄ pre/
    ‚îÇ   ‚îî‚îÄ‚îÄ analysis.csv
    ‚îî‚îÄ‚îÄ post/
        ‚îî‚îÄ‚îÄ postchange.csv
</code></pre>
<p><strong>Submission</strong>: Zip this directory and upload to Gradescope. (See <a href="assessment/task2.html#submission-instructions">Submission Instructions</a> below for details.)</p>
<hr />
<h2 id="minimum-requirements-1"><a class="header" href="#minimum-requirements-1">Minimum Requirements</a></h2>
<p><strong>Must have</strong>:</p>
<ul>
<li>‚úÖ <strong>Redesign brief</strong> grounded in Task 1 data (specific findings cited)</li>
<li>‚úÖ <strong>Regression checklist</strong> complete (all 30 checks with PASS/FAIL + notes, see <a href="assessment/task2.html#example-regression-checklist-excerpt">Example</a> below)</li>
<li>‚úÖ <strong>Before/after metrics</strong> (at least 1 task re-piloted, n=2 minimum, see <a href="assessment/task2.html#why-n2-re-pilots">Why n=2?</a> below)</li>
<li>‚úÖ <strong>Code diffs</strong> for all changes (before/after snippets)</li>
<li>‚úÖ <strong>Societal impact analysis</strong> (LO10 section in brief)</li>
<li>‚úÖ <strong>WCAG 2.2 AA compliance</strong> verified (regression tests + axe DevTools)</li>
<li>‚úÖ <strong>No-JS parity</strong> maintained (all features work without JS)</li>
<li>‚úÖ <strong>Evidence chains</strong> (every fix links to Task 1 finding)</li>
</ul>
<p><strong>Nice to have</strong>:</p>
<ul>
<li>üåü Screen reader transcripts (before/after comparison)</li>
<li>üåü More than 2 re-pilots (stronger post-fix data)</li>
<li>üåü Multiple fixes verified (2-3 changes, all tested)</li>
<li>üåü Studio crit feedback incorporated (Week 11 Lab 1 suggestions)</li>
</ul>
<hr />
<h2 id="why-n2-re-pilots"><a class="header" href="#why-n2-re-pilots">Why n=2 Re-Pilots?</a></h2>
<p><strong>Question</strong>: Task 1 required n=4 participants. Why does Task 2 only require n=2 for re-pilots?</p>
<p><strong>Answer</strong>: Task 2 re-pilots serve a <strong>different purpose</strong> than Task 1 evaluation:</p>
<div class="table-wrapper"><table><thead><tr><th>Aspect</th><th>Task 1 (n=4 minimum)</th><th>Task 2 (n=2 minimum)</th></tr></thead><tbody>
<tr><td><strong>Purpose</strong></td><td><strong>Summative evaluation</strong>: Identify unknown issues across diverse participants</td><td><strong>Formative verification</strong>: Confirm specific fixes work as intended</td></tr>
<tr><td><strong>Scope</strong></td><td>Broad: Test entire interface, discover patterns</td><td>Narrow: Re-test tasks affected by fixes (e.g., T2 edit errors)</td></tr>
<tr><td><strong>Analysis</strong></td><td>Statistical patterns (median, MAD, error rates across n=4-5)</td><td>Before/after comparison (did fix improve metrics?)</td></tr>
<tr><td><strong>Time</strong></td><td>2 weeks (Week 8-9)</td><td>1 week (Week 10 Lab 2)</td></tr>
</tbody></table>
</div>
<p><strong>Rationale for n=2</strong>:</p>
<ul>
<li>‚úÖ <strong>Feasibility</strong>: Limited time in Week 10 (7-8 hours total for implementation + testing + documentation)</li>
<li>‚úÖ <strong>Focused scope</strong>: Only re-testing tasks affected by fixes (not all tasks)</li>
<li>‚úÖ <strong>Verification goal</strong>: Checking fix didn't break things, not discovering new issues</li>
<li>‚úÖ <strong>Qualitative priority</strong>: 2 diverse variants (e.g., 1 keyboard-only, 1 screen reader) more valuable than 4 standard variants</li>
</ul>
<p><strong>What n=2 must demonstrate</strong>:</p>
<ol>
<li><strong>Fix effectiveness</strong>: Measurable improvement on target metric (completion rate, error rate, time, SR accessibility)</li>
<li><strong>No regressions</strong>: Regression checklist (30 checks) confirms fix didn't break other features</li>
<li><strong>Variant diversity</strong>: 2 participants using different access methods (e.g., P6 keyboard-only, P7 screen reader)</li>
</ol>
<p><strong>Example</strong>:</p>
<ul>
<li><strong>Task 1 baseline (n=5)</strong>: T2 (edit task) had 33% error rate, 1400ms median time, 0% SR accessibility</li>
<li><strong>Task 2 re-pilots (n=2)</strong>:
<ul>
<li>P6 (keyboard-only): 0% error rate, 1150ms time ‚Üí confirms fix works</li>
<li>P7 (screen reader + NVDA): Error announced correctly ‚Üí confirms WCAG 4.1.3 compliance</li>
</ul>
</li>
</ul>
<p><strong>If you have time</strong>: More than n=2 is encouraged (stronger evidence), but not required for pass/fail threshold.</p>
<hr />
<h2 id="prioritisation-formula-explained"><a class="header" href="#prioritisation-formula-explained">Prioritisation Formula Explained</a></h2>
<p><strong>Formula</strong>: <code>(Impact + Inclusion) ‚Äì Effort</code></p>
<p>Use this formula to prioritise which Task 1 findings to fix in Task 2.</p>
<h3 id="scoring-1-5-scale"><a class="header" href="#scoring-1-5-scale">Scoring (1-5 scale)</a></h3>
<h4 id="impact-1-5"><a class="header" href="#impact-1-5">Impact (1-5)</a></h4>
<p><strong>How severely does this issue affect task completion?</strong></p>
<div class="table-wrapper"><table><thead><tr><th>Score</th><th>Description</th><th>Example</th></tr></thead><tbody>
<tr><td><strong>5</strong></td><td>Complete blocker: task impossible</td><td>Validation error not announced ‚Üí SR user cannot complete task</td></tr>
<tr><td><strong>4</strong></td><td>Major hindrance: task very difficult</td><td>Keyboard trap ‚Üí user must use mouse or restart browser</td></tr>
<tr><td><strong>3</strong></td><td>Moderate issue: task slower/harder</td><td>Poor contrast ‚Üí low-vision user takes 3√ó longer</td></tr>
<tr><td><strong>2</strong></td><td>Minor annoyance: task doable but frustrating</td><td>Missing skip link ‚Üí keyboard user tabs through 20 nav items</td></tr>
<tr><td><strong>1</strong></td><td>Negligible: cosmetic or rare edge case</td><td>Button hover color slightly low contrast (4.4:1 instead of 4.5:1)</td></tr>
</tbody></table>
</div>
<hr />
<h4 id="inclusion-1-5"><a class="header" href="#inclusion-1-5">Inclusion (1-5)</a></h4>
<p><strong>How many people / which marginalised groups are excluded?</strong></p>
<div class="table-wrapper"><table><thead><tr><th>Score</th><th>Description</th><th>Example</th></tr></thead><tbody>
<tr><td><strong>5</strong></td><td>Excludes entire user group(s)</td><td>No keyboard support ‚Üí excludes all motor-impaired, SR, power users</td></tr>
<tr><td><strong>4</strong></td><td>Excludes large subset of users</td><td>No ARIA labels ‚Üí excludes all SR users (10-15% with disabilities)</td></tr>
<tr><td><strong>3</strong></td><td>Excludes specific scenario</td><td>No-JS path broken ‚Üí excludes users with JS disabled (security, privacy)</td></tr>
<tr><td><strong>2</strong></td><td>Affects accessibility preference</td><td>Missing focus indicators ‚Üí keyboard users struggle but not blocked</td></tr>
<tr><td><strong>1</strong></td><td>Affects narrow edge case</td><td>Mobile-only issue on rare screen size</td></tr>
</tbody></table>
</div>
<hr />
<h4 id="effort-1-5"><a class="header" href="#effort-1-5">Effort (1-5)</a></h4>
<p><strong>How much work to fix? (time, complexity, risk)</strong></p>
<div class="table-wrapper"><table><thead><tr><th>Score</th><th>Description</th><th>Example</th></tr></thead><tbody>
<tr><td><strong>5</strong></td><td>Architectural rewrite (&gt;8 hours)</td><td>Rebuild entire routing system for no-JS parity</td></tr>
<tr><td><strong>4</strong></td><td>Major refactor (4-8 hours)</td><td>Refactor all forms to use ARIA-describedby pattern</td></tr>
<tr><td><strong>3</strong></td><td>Moderate work (2-4 hours)</td><td>Add role="alert" to 5 error messages + test with NVDA</td></tr>
<tr><td><strong>2</strong></td><td>Minor fix (30min-2 hours)</td><td>Update CSS for focus indicators (outline: 3px solid)</td></tr>
<tr><td><strong>1</strong></td><td>Trivial (&lt;30min)</td><td>Add alt text to decorative image</td></tr>
</tbody></table>
</div>
<hr />
<h3 id="calculation-example"><a class="header" href="#calculation-example">Calculation Example</a></h3>
<p><strong>Finding A1</strong> (from Task 1): Validation errors not announced to screen readers</p>
<ul>
<li><strong>Impact</strong>: 5 (complete blocker for SR users‚Äîcannot detect or correct errors)</li>
<li><strong>Inclusion</strong>: 4 (excludes all SR users, ~10-15% of users with disabilities)</li>
<li><strong>Effort</strong>: 3 (add <code>role="alert"</code> + <code>aria-describedby</code> to 3 forms, test with NVDA)</li>
</ul>
<p><strong>Score</strong>: <code>(5 + 4) ‚Äì 3 = 6</code></p>
<hr />
<p><strong>Finding B2</strong> (from Task 1): Focus indicator contrast low (2.8:1)</p>
<ul>
<li><strong>Impact</strong>: 2 (keyboard users can still see focus, just harder)</li>
<li><strong>Inclusion</strong>: 2 (affects keyboard users with low vision, not blockers)</li>
<li><strong>Effort</strong>: 1 (update CSS <code>outline: 3px solid #0066A1</code>, 5-minute fix)</li>
</ul>
<p><strong>Score</strong>: <code>(2 + 2) ‚Äì 1 = 3</code></p>
<hr />
<p><strong>Finding C3</strong> (from Task 1): No mobile responsive layout</p>
<ul>
<li><strong>Impact</strong>: 3 (mobile users can zoom but layout breaks)</li>
<li><strong>Inclusion</strong>: 3 (affects mobile users, ~50% of web traffic)</li>
<li><strong>Effort</strong>: 5 (requires CSS grid refactor, viewport testing, 8+ hours)</li>
</ul>
<p><strong>Score</strong>: <code>(3 + 3) ‚Äì 5 = 1</code></p>
<hr />
<h3 id="prioritisation-decision"><a class="header" href="#prioritisation-decision">Prioritisation Decision</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Finding</th><th>Score</th><th>Priority</th><th>Rationale</th></tr></thead><tbody>
<tr><td><strong>A1</strong> (SR errors)</td><td><strong>6</strong></td><td>‚úÖ <strong>High</strong></td><td>WCAG Level A violation, high impact+inclusion, feasible effort</td></tr>
<tr><td><strong>B2</strong> (Focus contrast)</td><td><strong>3</strong></td><td>‚öôÔ∏è <strong>Medium</strong></td><td>Quick win but lower impact (not a blocker)</td></tr>
<tr><td><strong>C3</strong> (Mobile layout)</td><td><strong>1</strong></td><td>‚ùå <strong>Low</strong></td><td>High effort, not an accessibility blocker (zoom works)</td></tr>
</tbody></table>
</div>
<p><strong>Task 2 plan</strong>: Fix A1 + B2 (total ~4 hours), skip C3 (not feasible in 2 weeks).</p>
<hr />
<h3 id="tips-for-using-the-formula"><a class="header" href="#tips-for-using-the-formula">Tips for Using the Formula</a></h3>
<p>‚úÖ <strong>Be honest</strong>: Don't inflate Impact/Inclusion to justify pet features
‚úÖ <strong>Evidence-based</strong>: Use Task 1 data (error rates, pilot quotes, WCAG refs) to score
‚úÖ <strong>Focus on inclusion</strong>: High Inclusion score = prioritise (module theme)
‚úÖ <strong>Document</strong>: Show calculation in <code>01-redesign-brief.md</code> for transparency</p>
<hr />
<h2 id="example-regression-checklist-excerpt"><a class="header" href="#example-regression-checklist-excerpt">Example Regression Checklist Excerpt</a></h2>
<p><strong>What "complete with PASS/FAIL + notes" looks like</strong> (from <code>02-a11y-regression-checklist.csv</code>):</p>
<pre><code class="language-csv">check,item,pass,notes
Keyboard,All interactive elements reachable via Tab,PASS,Verified all buttons/links/inputs reachable
Keyboard,Tab order logical (matches visual flow),PASS,Tested with Tab key only; no jumps
Keyboard,No keyboard traps (can Tab out of all components),PASS,Tested filter form + edit dialogs
Keyboard,Focus visible on all interactive elements,PASS,Blue 3px outline on all :focus (WCAG 2.4.7)
Keyboard,Skip link present and functional,PASS,Tab reveals skip link; Enter jumps to #main
Forms,Labels associated with inputs (for/id or aria-label),PASS,All inputs have explicit &lt;label&gt; with matching id
Forms,Required fields indicated (aria-required or required),PASS,Title field has required attribute + aria-required="true"
Forms,Error messages linked via aria-describedby,PASS,Added in Task 2 fix; tested with NVDA
Dynamic,Status messages announced (role="status" or role="alert"),PASS,Validation errors use role="alert"; task added uses role="status"
Dynamic,Live region updates detected by SR,PASS,NVDA announces "Task added successfully" after submit
Dynamic,Focus managed after dynamic updates,PASS,Focus returns to add button after task added (WCAG 2.4.3)
No-JS,All features work with JavaScript disabled,PASS,Tested add/edit/delete/filter with JS off; PRG pattern working
No-JS,Form submissions use POST + 303 redirect,PASS,All forms POST to server; 303 redirect to GET
No-JS,Error messages visible without JS,PASS,Server renders errors in full-page reload
No-JS,Confirmation messages visible without JS,PASS,"Task added" message appears in full page after redirect
Visual,Text contrast ‚â•4.5:1 (AA),PASS,Colour Contrast Analyser: body text 7.1:1
Visual,Focus indicator contrast ‚â•3:1,PASS,Blue outline on white: 8.2:1 (fixed in Task 2)
Visual,200% zoom: no horizontal scroll,PASS,Tested in Chrome at 200%; layout responsive
Visual,Text resizes without loss of functionality,PASS,Tested at 150%/200%; no text overlap or clipping
Visual,Color not sole indicator of info,PASS,Error messages use icon + text + color
Semantic,Headings nested correctly (h1 &gt; h2 &gt; h3),PASS,Page title h1; sections h2; tasks h3
Semantic,Landmarks used (&lt;nav&gt; &lt;main&gt; &lt;footer&gt;),PASS,nav/main/footer elements present; tested with NVDA
Semantic,Lists use &lt;ul&gt;/&lt;ol&gt; (not &lt;div&gt;),PASS,Task list uses &lt;ul&gt;; pagination uses &lt;nav&gt;&lt;ul&gt;
ARIA,aria-label used only when needed,PASS,Used for delete buttons ("Delete task: Buy milk")
ARIA,aria-describedby links errors to inputs,PASS,Title input has aria-describedby="title-hint title-error"
ARIA,No unnecessary ARIA (prefer semantic HTML),PASS,Buttons use &lt;button&gt; not &lt;div role="button"&gt;
Images,All images have alt text or role="presentation",PASS,Logo has alt="COMP2850 Task Manager"; decorative SVGs role="presentation"
Images,Alt text describes content (not "image of..."),PASS,Logo alt describes branding; icons describe action
Links,Link text descriptive (not "click here"),PASS,All links describe destination ("View task details")
Links,Links distinguishable (not color-only),PASS,Links underlined + color
</code></pre>
<p><strong>Key observations</strong>:</p>
<ul>
<li>‚úÖ Every check has <strong>PASS</strong> or <strong>FAIL</strong> (no blanks, no "N/A")</li>
<li>‚úÖ Notes explain <strong>what was tested</strong> or <strong>how compliance was verified</strong></li>
<li>‚úÖ Specific details given (e.g., "7.1:1" contrast, "NVDA" screen reader)</li>
<li>‚úÖ Task 2 fixes referenced where relevant ("Added in Task 2 fix")</li>
</ul>
<p><strong>Common mistakes</strong>:</p>
<ul>
<li>‚ùå Leaving notes blank (write what you tested!)</li>
<li>‚ùå Using "N/A" instead of PASS/FAIL (all checks apply to all apps)</li>
<li>‚ùå Vague notes: "Focus works" ‚Üí ‚ùå Better: "Blue 3px outline on all :focus (WCAG 2.4.7)"</li>
</ul>
<hr />
<h2 id="common-mistakes-to-avoid-2"><a class="header" href="#common-mistakes-to-avoid-2">Common Mistakes to Avoid</a></h2>
<p>‚ùå <strong>No before/after data</strong>: Can't prove improvement without metrics comparison</p>
<p>‚ùå <strong>Regression not tested</strong>: Fix broke something else but wasn't caught</p>
<p>‚ùå <strong>Superficial societal impact</strong>: "Helps disabled people" without systemic analysis</p>
<p>‚ùå <strong>WCAG violations remain</strong>: Claimed compliance but axe DevTools still shows errors</p>
<p>‚ùå <strong>No-JS parity broken</strong>: Fix works with JS but traditional path fails</p>
<p>‚ùå <strong>Not grounded in Task 1</strong>: Fixes random issues instead of Task 1 findings</p>
<p>‚ùå <strong>Incomplete regression checklist</strong>: Blanks or "N/A" instead of PASS/FAIL</p>
<p>‚ùå <strong>No code diffs</strong>: Claims code changed but no snippets shown</p>
<hr />
<h2 id="tips-for-success-2"><a class="header" href="#tips-for-success-2">Tips for Success</a></h2>
<h3 id="prioritisation-week-10-lab-1"><a class="header" href="#prioritisation-week-10-lab-1">Prioritisation (Week 10 Lab 1)</a></h3>
<p>‚úÖ <strong>Use Task 1 data</strong>: Prioritise findings with evidence (metrics, quotes, WCAG refs)</p>
<p>‚úÖ <strong>Focus on inclusion impact</strong>: WCAG violations affecting SR/keyboard users &gt; cosmetic fixes</p>
<p>‚úÖ <strong>Be realistic</strong>: 2-3 fixes maximum in 2 weeks. Quality over quantity.</p>
<p>‚úÖ <strong>Use the formula</strong>: (Impact + Inclusion) ‚Äì Effort (both Impact and Inclusion 1-5, Effort 1-5)</p>
<hr />
<h3 id="implementation-week-10-lab-2"><a class="header" href="#implementation-week-10-lab-2">Implementation (Week 10 Lab 2)</a></h3>
<p>‚úÖ <strong>Test before re-pilots</strong>: Verify fixes work manually (keyboard, NVDA, no-JS) before recruiting participants</p>
<p>‚úÖ <strong>Regression test early</strong>: Run 30-check checklist after each fix, not at the end</p>
<p>‚úÖ <strong>Maintain no-JS parity</strong>: Test traditional path (JS disabled) for every change</p>
<p>‚úÖ <strong>Use axe DevTools</strong>: Automated scan catches regressions you might miss</p>
<p>‚úÖ <strong>Keep Task 1 protocol</strong>: Re-pilots use same tasks + same method for comparability</p>
<hr />
<h3 id="documentation-week-11-lab-2"><a class="header" href="#documentation-week-11-lab-2">Documentation (Week 11 Lab 2)</a></h3>
<p>‚úÖ <strong>Scrub screenshots</strong>: Crop/blur PII before adding to <code>05-evidence/</code></p>
<p>‚úÖ <strong>Link everything</strong>: Every fix ‚Üí Task 1 finding (file + section reference)</p>
<p>‚úÖ <strong>Complete checklists</strong>: No blanks‚Äîevery check needs PASS/FAIL + note</p>
<p>‚úÖ <strong>Honest reporting</strong>: If metrics didn't improve, analyse why (LO12 professionalism)</p>
<p>‚úÖ <strong>Incorporate crit feedback</strong>: Week 11 Lab 1 suggestions in final docs</p>
<hr />
<h2 id="tools-analysekt-script"><a class="header" href="#tools-analysekt-script">Tools: Analyse.kt Script</a></h2>
<p><strong>What it is</strong>: A Kotlin script provided in Week 10 Lab 1 that processes your Task 1 <code>metrics.csv</code> file and generates <code>pre/analysis.csv</code> for before/after comparison.</p>
<p><strong>Location</strong>: <code>wk10/lab-wk10/analysis/Analyse.kt</code></p>
<p><strong>Purpose</strong>: Automates calculation of:</p>
<ul>
<li>Completion rates per task (successful / total attempts)</li>
<li>Median time-on-task (ms)</li>
<li>MAD (Median Absolute Deviation) for time variability</li>
<li>Error rates (validation errors / total attempts)</li>
<li>Breakdowns by <code>js_mode</code> (on vs off)</li>
</ul>
<p><strong>Input</strong>: <code>wk09/lab-wk9/submission/task1-draft/04-results.csv</code> (from Task 1)</p>
<p><strong>Output</strong>: <code>wk10/gradescope/task2/06-metrics/pre/analysis.csv</code></p>
<p><strong>Output schema</strong>:</p>
<pre><code class="language-csv">task_code,js_mode,n_success,n_total,completion_rate,median_ms,mad_ms,errors_validation,error_rate
T2_edit,on,4,5,0.80,1400,234,2,0.33
T2_edit,off,3,3,1.00,1650,180,0,0.00
</code></pre>
<p><strong>Usage</strong> (Week 10 Lab 1):</p>
<ol>
<li>Ensure Task 1 <code>04-results.csv</code> is complete and in correct location</li>
<li>Run script: <code>./gradlew run -PmainClass=AnalyseKt</code> (or IDE run configuration)</li>
<li>Script reads <code>metrics.csv</code>, calculates stats, writes <code>pre/analysis.csv</code></li>
<li>Review <code>pre/analysis.csv</code> to confirm data looks correct</li>
<li>Use <code>pre/analysis.csv</code> as baseline for Task 2 comparisons</li>
</ol>
<p><strong>Why use a script?</strong></p>
<ul>
<li>‚úÖ <strong>Consistency</strong>: Same calculation method for all students (prevents errors in manual median/MAD calculation)</li>
<li>‚úÖ <strong>Speed</strong>: Processes 50+ data points in seconds</li>
<li>‚úÖ <strong>Accuracy</strong>: Handles edge cases (odd/even n, missing data)</li>
<li>‚úÖ <strong>Evidence</strong>: Script is provided code (not student-written), ensuring fair comparison</li>
</ul>
<p><strong>Can you modify the script?</strong></p>
<ul>
<li>‚ùå <strong>No</strong>: Use provided script as-is to ensure consistency across cohort</li>
<li>‚úÖ <strong>Yes, if needed</strong>: Can adapt for different CSV format (e.g., if you added custom columns in Task 1)</li>
<li><strong>Ask staff first</strong>: If you think script has a bug or need to modify, contact module lead</li>
</ul>
<p><strong>What if script doesn't work?</strong></p>
<ol>
<li>Check <code>04-results.csv</code> format matches expected schema (see Task 1 deliverable 4)</li>
<li>Verify file path is correct (<code>wk09/lab-wk9/submission/task1-draft/04-results.csv</code>)</li>
<li>Check for data issues (missing session IDs, invalid timestamps, blank task codes)</li>
<li>Consult Week 10 Lab 1 troubleshooting section</li>
<li>Contact module staff if still blocked (don't fabricate <code>pre/analysis.csv</code> manually)</li>
</ol>
<p><strong>Alternative (if script unavailable)</strong>:
If script not provided by Week 10 Lab 1, manually calculate:</p>
<ul>
<li><strong>Median time</strong>: Sort times for each task, pick middle value (or average of middle 2 if even n)</li>
<li><strong>MAD</strong>: For each time, calculate <code>|time - median|</code>, then take median of those deviations</li>
<li><strong>Completion rate</strong>: <code>n_success / n_total</code></li>
<li><strong>Error rate</strong>: <code>errors_validation / n_total</code></li>
</ul>
<hr />
<h2 id="submission-instructions-1"><a class="header" href="#submission-instructions-1">Submission Instructions</a></h2>
<p><strong>Gradescope submission details will be confirmed in Week 11 Lab 1.</strong></p>
<p>In the meantime, prepare your submission:</p>
<h3 id="packaging-requirements-1"><a class="header" href="#packaging-requirements-1">Packaging Requirements</a></h3>
<ul>
<li>Keep all files in the <code>task2/</code> directory structure shown above</li>
<li>Ensure filenames match exactly (case-sensitive): <code>01-redesign-brief.md</code>, <code>02-a11y-regression-checklist.csv</code>, etc.</li>
<li>Verify <strong>no PII</strong> in any file before packaging (screenshots cropped, transcripts anonymised)</li>
<li>Check all evidence chains are complete (file paths and line numbers accurate)</li>
</ul>
<h3 id="file-size-considerations-1"><a class="header" href="#file-size-considerations-1">File Size Considerations</a></h3>
<ul>
<li>Screenshots: Crop to relevant area, use PNG/JPG compression</li>
<li>CSV files: Text format, should be &lt; 500KB</li>
<li>Code snippets: Keep to relevant sections only (not entire files)</li>
<li>Total package: Aim for &lt; 25MB (if larger, check for unnecessary files)</li>
</ul>
<h3 id="naming-conventions-1"><a class="header" href="#naming-conventions-1">Naming Conventions</a></h3>
<p><strong>To be confirmed</strong> ‚Äî watch for announcements in Week 11 Lab 1 about:</p>
<ul>
<li>Zip file naming (e.g., <code>studentID_task2.zip</code> vs <code>task2.zip</code>)</li>
<li>Gradescope assignment name</li>
<li>Late submission policy</li>
</ul>
<h3 id="pre-submission-checklist-1"><a class="header" href="#pre-submission-checklist-1">Pre-Submission Checklist</a></h3>
<p>Use the <a href="assessment/task2.html#quick-checklist">Quick Checklist</a> below to verify all requirements met.</p>
<hr />
<h2 id="faqs-2"><a class="header" href="#faqs-2">FAQs</a></h2>
<p><strong>Q: How many fixes should I implement?</strong>
A: 2-3 fixes maximum. Focus on high inclusion impact (WCAG AA violations, SR/keyboard barriers).</p>
<p><strong>Q: What if my re-pilots show no improvement?</strong>
A: Document honestly. Analyse why (wrong fix? small n? need more iteration?). Shows LO12 professionalism.</p>
<p><strong>Q: Do I need to re-pilot all tasks?</strong>
A: No. Re-pilot tasks affected by your fixes (e.g., if you fixed T2 edit errors, re-pilot T2).</p>
<p><strong>Q: Can I use Week 10 Lab 1 Analyse.kt for before data?</strong>
A: Yes, that's the recommended approach. It generates <code>analysis.csv</code> from Task 1 <code>metrics.csv</code>.</p>
<p><strong>Q: What if regression testing finds new issues?</strong>
A: Fix them before re-pilots. That's why regression testing exists‚Äîcatch regressions early.</p>
<p><strong>Q: How detailed should societal impact analysis be?</strong>
A: 300-500 words. Beyond "helps disabled people"‚Äîanalyse systemic barriers, exclusion patterns, long-term implications. See template examples.</p>
<p><strong>Q: Can I fix issues not in Task 1?</strong>
A: Not recommended. Assessment requires evidence chain (Task 1 finding ‚Üí fix ‚Üí verification). New issues lack baseline data.</p>
<p><strong>Q: What if I can't recruit 2 re-pilots?</strong>
A: Minimum 2 required. Start recruiting early (Week 10). Use lab sessions to find peers.</p>
<hr />
<h2 id="marking-criteria-1"><a class="header" href="#marking-criteria-1">Marking Criteria</a></h2>
<h3 id="problem-clarity-20"><a class="header" href="#problem-clarity-20">Problem Clarity (20%)</a></h3>
<ul>
<li>Problem statement grounded in Task 1 data (specific findings cited)</li>
<li>Measurable goals with targets (completion rate, error rate, median time, SR accessibility)</li>
<li>WCAG violations referenced with specific criteria</li>
</ul>
<h3 id="fix-effectiveness-30"><a class="header" href="#fix-effectiveness-30">Fix Effectiveness (30%)</a></h3>
<ul>
<li>WCAG 2.2 AA compliance verified (regression checklist complete, axe DevTools clean)</li>
<li>Measurable improvement demonstrated (before/after metrics)</li>
<li>No-JS parity maintained (traditional path works)</li>
<li>No regressions introduced (30-check checklist all PASS)</li>
</ul>
<h3 id="societal-impact-analysis-20"><a class="header" href="#societal-impact-analysis-20">Societal Impact Analysis (20%)</a></h3>
<ul>
<li>Systemic barriers identified (beyond individual inconvenience)</li>
<li>Exclusion patterns analysed (who is excluded, how, why)</li>
<li>Universal design principles applied (accommodation vs. inclusive design)</li>
<li>Ethical considerations addressed (privacy, autonomy, dignity)</li>
<li>Long-term implications discussed (if pattern adopted widely)</li>
</ul>
<h3 id="evidence-chains-20"><a class="header" href="#evidence-chains-20">Evidence Chains (20%)</a></h3>
<ul>
<li>Every fix links to Task 1 finding (file + section reference)</li>
<li>Before/after metrics comparison (pre/analysis.csv vs post/postchange.csv)</li>
<li>Code diffs complete (before/after snippets with annotations)</li>
<li>Screenshots annotated (alt text + context)</li>
<li>Regression tests documented (30 checks complete)</li>
</ul>
<h3 id="professional-presentation-10"><a class="header" href="#professional-presentation-10">Professional Presentation (10%)</a></h3>
<ul>
<li>Clear, well-structured documentation</li>
<li>Honest reporting (doesn't hide limitations or unexpected results)</li>
<li>Complete submission (6 files + evidence + metrics)</li>
<li>UK spelling and grammar</li>
<li>Proper Markdown formatting</li>
</ul>
<hr />
<h2 id="resources-2"><a class="header" href="#resources-2">Resources</a></h2>
<h3 id="templates-1"><a class="header" href="#templates-1">Templates</a></h3>
<p>All templates available in <code>wk10/gradescope/task2/</code>:</p>
<ul>
<li><a href="assessment/../../wk10/gradescope/task2/01-redesign-brief.html">01-redesign-brief.md</a></li>
<li><a href="assessment/../../wk10/gradescope/task2/02-a11y-regression-checklist.csv">02-a11y-regression-checklist.csv</a></li>
<li><a href="assessment/../../wk10/gradescope/task2/03-before-after-summary.html">03-before-after-summary.md</a></li>
<li><a href="assessment/../../wk10/gradescope/task2/04-key-diffs.html">04-key-diffs.md</a></li>
<li><a href="assessment/../../wk10/gradescope/task2/05-evidence/README.html">05-evidence/README.md</a></li>
<li><a href="assessment/../../wk10/gradescope/task2/06-metrics/README.html">06-metrics/README.md</a></li>
</ul>
<h3 id="references-3"><a class="header" href="#references-3">References</a></h3>
<ul>
<li><a href="https://www.w3.org/WAI/WCAG22/quickref/">WCAG 2.2 Quick Reference</a></li>
<li><a href="https://webaim.org/techniques/forms/">WebAIM: Creating Accessible Forms</a></li>
<li><a href="https://design-system.service.gov.uk/components/error-message/">GOV.UK: Error Message Patterns</a></li>
<li><a href="https://www.gov.uk/guidance/equality-act-2010-guidance">GOV.UK: Accessibility and Equality</a></li>
<li><a href="assessment/../references/learning-outcomes.html">Learning Outcomes Reference</a></li>
<li><a href="assessment/../references/glossary.html">Glossary</a></li>
</ul>
<h3 id="week-10-11-lab-materials"><a class="header" href="#week-10-11-lab-materials">Week 10-11 Lab Materials</a></h3>
<ul>
<li><a href="assessment/../../wk10/wk10-lab1-analysis-prioritisation.html">Week 10 Lab 1: Analysis &amp; Prioritisation</a></li>
<li><a href="assessment/../../wk10/wk10-lab2-redesign-reverify-package.html">Week 10 Lab 2: Redesign, Re-verification, Package</a></li>
<li><a href="assessment/../../wk11/wk11-lab1-studio-crit.html">Week 11 Lab 1: Studio Critique</a></li>
<li><a href="assessment/../../wk11/wk11-lab2-wrapup-portfolio.html">Week 11 Lab 2: Wrap-up &amp; Portfolio</a></li>
</ul>
<hr />
<h2 id="quick-checklist-1"><a class="header" href="#quick-checklist-1">Quick Checklist</a></h2>
<p>Before submitting, verify:</p>
<ul>
<li><input disabled="" type="checkbox"/>
<strong>6 required files present</strong> (01-06 + evidence + metrics directories)</li>
<li><input disabled="" type="checkbox"/>
<strong>Redesign brief grounded in Task 1</strong> (specific findings cited with file references)</li>
<li><input disabled="" type="checkbox"/>
<strong>Societal impact analysis complete</strong> (LO10 section in brief, 300-500 words)</li>
<li><input disabled="" type="checkbox"/>
<strong>Regression checklist complete</strong> (all 30 checks PASS/FAIL + notes, no blanks)</li>
<li><input disabled="" type="checkbox"/>
<strong>Before/after metrics comparison</strong> (pre/analysis.csv vs post/postchange.csv)</li>
<li><input disabled="" type="checkbox"/>
<strong>Minimum 2 re-pilots conducted</strong> (documented in post/postchange.csv)</li>
<li><input disabled="" type="checkbox"/>
<strong>Code diffs documented</strong> (before/after snippets for all changes)</li>
<li><input disabled="" type="checkbox"/>
<strong>WCAG 2.2 AA compliance verified</strong> (axe DevTools clean, regression tests PASS)</li>
<li><input disabled="" type="checkbox"/>
<strong>No-JS parity maintained</strong> (tested traditional path after fixes)</li>
<li><input disabled="" type="checkbox"/>
<strong>Screenshots annotated</strong> (alt text + context in annotations.md)</li>
<li><input disabled="" type="checkbox"/>
<strong>No PII in any file</strong> (screenshots cropped, transcripts anonymised)</li>
<li><input disabled="" type="checkbox"/>
<strong>Evidence chains complete</strong> (every fix ‚Üí Task 1 finding)</li>
</ul>
<hr />
<p><a href="assessment/task1.html">‚Üê Back to Task 1</a> | <a href="assessment/overview.html">‚Üê Back to Assessment Overview</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="marking-rubric"><a class="header" href="#marking-rubric">Marking Rubric</a></h1>
<p><img src="https://img.shields.io/badge/Rubric-Transparent-blue" alt="Rubric" />
<img src="https://img.shields.io/badge/Standards-Evidence_Based-green" alt="Standards" /></p>
<hr />
<h2 id="introduction-6"><a class="header" href="#introduction-6">Introduction</a></h2>
<p>This rubric shows <strong>exactly how tasks are marked</strong>. We assess <strong>HCI process competence</strong>, not code quality or writing style.</p>
<p><strong>Key principles</strong>:</p>
<ul>
<li><strong>Evidence over eloquence</strong>: Tables, metrics, and code diffs matter more than prose</li>
<li><strong>Process over product</strong>: We mark your method (protocol, testing, analysis), not your app</li>
<li><strong>Honesty over perfection</strong>: Reporting limitations honestly scores higher than hiding problems</li>
<li><strong>Rigour over scope</strong>: One fix done thoroughly beats three fixes done poorly</li>
</ul>
<hr />
<h2 id="grading-bands"><a class="header" href="#grading-bands">Grading Bands</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Band</th><th>Descriptor</th><th>Typical %range</th></tr></thead><tbody>
<tr><td><strong>Excellent</strong></td><td>Exceeds expectations</td><td>70-100%</td></tr>
<tr><td><strong>Good</strong></td><td>Meets expectations with minor gaps</td><td>60-69%</td></tr>
<tr><td><strong>Satisfactory</strong></td><td>Meets minimum requirements</td><td>50-59%</td></tr>
<tr><td><strong>Needs Work</strong></td><td>Significant gaps, incomplete</td><td>40-49%</td></tr>
<tr><td><strong>Fail</strong></td><td>Critical failures, academic integrity issues</td><td>0-39%</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="task-1-evaluation--findings-4"><a class="header" href="#task-1-evaluation--findings-4">Task 1: Evaluation &amp; Findings</a></h2>
<p><strong>Total</strong>: 100 marks (see Minerva for weighting within overall COMP2850 grade)</p>
<h3 id="evidence-quality-30-marks"><a class="header" href="#evidence-quality-30-marks">Evidence Quality (30 marks)</a></h3>
<h4 id="excellent-21-30-marks"><a class="header" href="#excellent-21-30-marks">Excellent (21-30 marks)</a></h4>
<ul>
<li>‚úÖ Complete quantitative data (<code>04-results.csv</code> with all columns, n‚â•4 participants)</li>
<li>‚úÖ Rich qualitative data (pilot notes with timestamps, direct quotes, specific observations)</li>
<li>‚úÖ Traceable evidence chains (every finding links to data: file path, line number, session ID)</li>
<li>‚úÖ No PII in any file (screenshots cropped, session IDs anonymous)</li>
<li>‚úÖ Multiple data sources converge (metrics + quotes + screenshots all tell same story)</li>
</ul>
<h4 id="good-18-20-marks"><a class="header" href="#good-18-20-marks">Good (18-20 marks)</a></h4>
<ul>
<li>‚úÖ Complete quantitative data (n=4, all columns present)</li>
<li>‚úÖ Adequate qualitative data (pilot notes present, some quotes)</li>
<li>‚úÖ Most findings have evidence chains (1-2 minor gaps)</li>
<li>‚úÖ No PII violations</li>
<li>‚ö†Ô∏è Evidence chains occasionally vague ("some participants struggled" without specifics)</li>
</ul>
<h4 id="satisfactory-15-17-marks"><a class="header" href="#satisfactory-15-17-marks">Satisfactory (15-17 marks)</a></h4>
<ul>
<li>‚úÖ Quantitative data present (n=4 minimum met)</li>
<li>‚ö†Ô∏è Thin qualitative data (pilot notes brief, few quotes)</li>
<li>‚ö†Ô∏è Evidence chains incomplete (findings asserted without clear data links)</li>
<li>‚úÖ No PII violations</li>
<li>‚ö†Ô∏è Data sources sometimes contradict (metrics say 100% completion, notes say "struggled")</li>
</ul>
<h4 id="needs-work-12-14-marks"><a class="header" href="#needs-work-12-14-marks">Needs Work (12-14 marks)</a></h4>
<ul>
<li>‚ö†Ô∏è Incomplete quantitative data (missing sessions, columns incomplete)</li>
<li>‚ö†Ô∏è Minimal qualitative data (pilot notes cursory or missing)</li>
<li>‚ùå Evidence chains absent (claims without data)</li>
<li>‚ö†Ô∏è Minor PII issues (session IDs identifiable, screenshots not scrubbed)</li>
</ul>
<h4 id="fail-0-11-marks"><a class="header" href="#fail-0-11-marks">Fail (0-11 marks)</a></h4>
<ul>
<li>‚ùå Fabricated data (markers can detect unrealistic patterns)</li>
<li>‚ùå n&lt;4 participants (minimum not met)</li>
<li>‚ùå Major PII violations (names, emails visible)</li>
<li>‚ùå No evidence chains (entire findings section unsupported)</li>
</ul>
<hr />
<h3 id="method-rigour-25-marks"><a class="header" href="#method-rigour-25-marks">Method Rigour (25 marks)</a></h3>
<h4 id="excellent-18-25-marks"><a class="header" href="#excellent-18-25-marks">Excellent (18-25 marks)</a></h4>
<ul>
<li>‚úÖ Protocol includes consent script, right to withdraw, ethical safeguards</li>
<li>‚úÖ Tasks realistic, measurable, independent (clear success criteria)</li>
<li>‚úÖ Appropriate variants tested (keyboard, no-JS, screen reader)</li>
<li>‚úÖ Link to Week 6 needs-finding demonstrated (LO2: job stories ‚Üí task design)</li>
<li>‚úÖ Pilot execution follows protocol (facilitator neutral, observer notes structured)</li>
</ul>
<h4 id="good-15-17-marks"><a class="header" href="#good-15-17-marks">Good (15-17 marks)</a></h4>
<ul>
<li>‚úÖ Protocol includes consent and ethical safeguards</li>
<li>‚úÖ Tasks measurable and realistic</li>
<li>‚úÖ Minimum 3 variants tested</li>
<li>‚ö†Ô∏è Needs-finding link present but superficial (brief mention, not integrated)</li>
<li>‚úÖ Protocol mostly followed</li>
</ul>
<h4 id="satisfactory-13-14-marks"><a class="header" href="#satisfactory-13-14-marks">Satisfactory (13-14 marks)</a></h4>
<ul>
<li>‚úÖ Basic protocol present (consent mentioned)</li>
<li>‚ö†Ô∏è Tasks vague (success criteria unclear)</li>
<li>‚úÖ 2-3 variants tested (minimum met)</li>
<li>‚ö†Ô∏è Needs-finding link weak or missing</li>
<li>‚ö†Ô∏è Protocol execution inconsistent (some pilots rushed)</li>
</ul>
<h4 id="needs-work-10-12-marks"><a class="header" href="#needs-work-10-12-marks">Needs Work (10-12 marks)</a></h4>
<ul>
<li>‚ö†Ô∏è Protocol incomplete (consent unclear, no right to withdraw)</li>
<li>‚ùå Tasks poorly designed (not measurable or independent)</li>
<li>‚ö†Ô∏è Limited variants (only standard, no keyboard/no-JS)</li>
<li>‚ùå No link to needs-finding (LO2 not addressed)</li>
</ul>
<h4 id="fail-0-9-marks"><a class="header" href="#fail-0-9-marks">Fail (0-9 marks)</a></h4>
<ul>
<li>‚ùå No consent protocol (ethical violation)</li>
<li>‚ùå Tasks not suitable for evaluation</li>
<li>‚ùå Only 1-2 pilots conducted</li>
<li>‚ùå Protocol not followed (leading questions, no observer notes)</li>
</ul>
<hr />
<h3 id="analysis-depth-25-marks"><a class="header" href="#analysis-depth-25-marks">Analysis Depth (25 marks)</a></h3>
<h4 id="excellent-18-25-marks-1"><a class="header" href="#excellent-18-25-marks-1">Excellent (18-25 marks)</a></h4>
<ul>
<li>‚úÖ Quantitative analysis correct (median/MAD calculated, error rates accurate)</li>
<li>‚úÖ Qualitative synthesis identifies patterns across participants</li>
<li>‚úÖ WCAG violations cited with specific criteria (4.1.3, 3.3.1, etc.)</li>
<li>‚úÖ Inclusion impact articulated (who is excluded, how, why)</li>
<li>‚úÖ Prioritisation uses formula: (Impact + Inclusion) ‚Äì Effort with justification</li>
<li>‚úÖ Limitations acknowledged (sample size, diversity, context)</li>
</ul>
<h4 id="good-15-17-marks-1"><a class="header" href="#good-15-17-marks-1">Good (15-17 marks)</a></h4>
<ul>
<li>‚úÖ Quantitative analysis mostly correct (minor calculation errors)</li>
<li>‚úÖ Qualitative synthesis present, some patterns identified</li>
<li>‚úÖ WCAG violations cited (may lack specific criteria numbers)</li>
<li>‚úÖ Inclusion impact mentioned (SR users, keyboard users)</li>
<li>‚ö†Ô∏è Prioritisation present but formula not applied consistently</li>
<li>‚ö†Ô∏è Limitations briefly mentioned</li>
</ul>
<h4 id="satisfactory-13-14-marks-1"><a class="header" href="#satisfactory-13-14-marks-1">Satisfactory (13-14 marks)</a></h4>
<ul>
<li>‚ö†Ô∏è Quantitative analysis basic (completion rates calculated, but no MAD/median)</li>
<li>‚ö†Ô∏è Qualitative synthesis superficial (lists issues without patterns)</li>
<li>‚ö†Ô∏è WCAG references generic ("accessibility issues" not specific criteria)</li>
<li>‚ö†Ô∏è Inclusion impact vague ("helps disabled people")</li>
<li>‚ö†Ô∏è Prioritisation arbitrary (no formula, unclear rationale)</li>
<li>‚ùå Limitations not discussed</li>
</ul>
<h4 id="needs-work-10-12-marks-1"><a class="header" href="#needs-work-10-12-marks-1">Needs Work (10-12 marks)</a></h4>
<ul>
<li>‚ùå Quantitative analysis incorrect or missing</li>
<li>‚ùå Qualitative synthesis absent (just lists observations)</li>
<li>‚ùå No WCAG references</li>
<li>‚ùå Inclusion impact not discussed</li>
<li>‚ùå No prioritisation</li>
</ul>
<h4 id="fail-0-9-marks-1"><a class="header" href="#fail-0-9-marks-1">Fail (0-9 marks)</a></h4>
<ul>
<li>‚ùå No analysis (raw data dumped without interpretation)</li>
<li>‚ùå Findings fabricated or unsupported</li>
<li>‚ùå No evidence of understanding WCAG or accessibility concepts</li>
</ul>
<hr />
<h3 id="professional-presentation-20-marks"><a class="header" href="#professional-presentation-20-marks">Professional Presentation (20 marks)</a></h3>
<h4 id="excellent-15-20-marks"><a class="header" href="#excellent-15-20-marks">Excellent (15-20 marks)</a></h4>
<ul>
<li>‚úÖ Clear, well-structured documentation (all 6 files present, organised)</li>
<li>‚úÖ Honest reporting (limitations acknowledged, unexpected results explained)</li>
<li>‚úÖ Complete submission (directory structure matches specification)</li>
<li>‚úÖ UK spelling and grammar throughout</li>
<li>‚úÖ Proper Markdown formatting (tables render, headings hierarchical)</li>
<li>‚úÖ Evidence organised (screenshots annotated, pilot notes templated)</li>
</ul>
<h4 id="good-12-14-marks"><a class="header" href="#good-12-14-marks">Good (12-14 marks)</a></h4>
<ul>
<li>‚úÖ Documentation clear and complete</li>
<li>‚úÖ Honest reporting</li>
<li>‚úÖ Submission complete</li>
<li>‚ö†Ô∏è Minor spelling/grammar issues (1-2 Americanisms)</li>
<li>‚ö†Ô∏è Formatting mostly correct (1-2 tables malformed)</li>
<li>‚úÖ Evidence organised</li>
</ul>
<h4 id="satisfactory-10-11-marks"><a class="header" href="#satisfactory-10-11-marks">Satisfactory (10-11 marks)</a></h4>
<ul>
<li>‚ö†Ô∏è Documentation adequate but could be clearer</li>
<li>‚úÖ Reporting mostly honest</li>
<li>‚ö†Ô∏è 1 file missing or incomplete</li>
<li>‚ö†Ô∏è Spelling/grammar errors present</li>
<li>‚ö†Ô∏è Formatting issues (some tables don't render)</li>
<li>‚ö†Ô∏è Evidence somewhat disorganised</li>
</ul>
<h4 id="needs-work-8-9-marks"><a class="header" href="#needs-work-8-9-marks">Needs Work (8-9 marks)</a></h4>
<ul>
<li>‚ùå Documentation unclear or disorganised</li>
<li>‚ö†Ô∏è Reporting hides problems (only positive results shown)</li>
<li>‚ùå 2+ files missing</li>
<li>‚ùå Poor spelling/grammar</li>
<li>‚ùå Formatting broken (Markdown errors)</li>
</ul>
<h4 id="fail-0-7-marks"><a class="header" href="#fail-0-7-marks">Fail (0-7 marks)</a></h4>
<ul>
<li>‚ùå Submission incomplete (half the files missing)</li>
<li>‚ùå Dishonest reporting (fabricates data, hides failures)</li>
<li>‚ùå Plagiarism or academic integrity violation</li>
</ul>
<hr />
<h2 id="task-2-redesign--verification-4"><a class="header" href="#task-2-redesign--verification-4">Task 2: Redesign &amp; Verification</a></h2>
<p><strong>Total</strong>: 100 marks (see Minerva for weighting within overall COMP2850 grade)</p>
<h3 id="problem-clarity-20-marks"><a class="header" href="#problem-clarity-20-marks">Problem Clarity (20 marks)</a></h3>
<h4 id="excellent-15-20-marks-1"><a class="header" href="#excellent-15-20-marks-1">Excellent (15-20 marks)</a></h4>
<ul>
<li>‚úÖ Problem statement grounded in Task 1 data (specific findings cited: file + section)</li>
<li>‚úÖ Measurable goals with targets (completion rate, error rate, median time, SR accessibility)</li>
<li>‚úÖ WCAG violations referenced with specific criteria (4.1.3, 3.3.1, etc.)</li>
<li>‚úÖ Prioritisation justified using (Impact + Inclusion) ‚Äì Effort formula</li>
</ul>
<h4 id="good-12-14-marks-1"><a class="header" href="#good-12-14-marks-1">Good (12-14 marks)</a></h4>
<ul>
<li>‚úÖ Problem grounded in Task 1 (findings cited)</li>
<li>‚úÖ Goals measurable</li>
<li>‚ö†Ô∏è WCAG references generic (criteria numbers missing)</li>
<li>‚ö†Ô∏è Prioritisation mentioned but formula not applied</li>
</ul>
<h4 id="satisfactory-10-11-marks-1"><a class="header" href="#satisfactory-10-11-marks-1">Satisfactory (10-11 marks)</a></h4>
<ul>
<li>‚ö†Ô∏è Problem references Task 1 (vague link)</li>
<li>‚ö†Ô∏è Goals present but not fully measurable</li>
<li>‚ùå No WCAG references</li>
<li>‚ùå Prioritisation arbitrary</li>
</ul>
<h4 id="needs-work--fail-0-9-marks"><a class="header" href="#needs-work--fail-0-9-marks">Needs Work / Fail (0-9 marks)</a></h4>
<ul>
<li>‚ùå Problem not grounded in Task 1</li>
<li>‚ùå Goals missing or unmeasurable</li>
<li>‚ùå No prioritisation</li>
</ul>
<hr />
<h3 id="fix-effectiveness-30-marks"><a class="header" href="#fix-effectiveness-30-marks">Fix Effectiveness (30 marks)</a></h3>
<h4 id="excellent-22-30-marks"><a class="header" href="#excellent-22-30-marks">Excellent (22-30 marks)</a></h4>
<ul>
<li>‚úÖ WCAG 2.2 AA compliance verified (regression checklist complete, axe DevTools clean)</li>
<li>‚úÖ Measurable improvement demonstrated (before/after metrics show gains)</li>
<li>‚úÖ No-JS parity maintained (traditional path tested, works identically)</li>
<li>‚úÖ No regressions introduced (30-check checklist all PASS)</li>
<li>‚úÖ Fixes target high inclusion impact (WCAG violations, SR/keyboard barriers)</li>
</ul>
<h4 id="good-18-21-marks"><a class="header" href="#good-18-21-marks">Good (18-21 marks)</a></h4>
<ul>
<li>‚úÖ WCAG AA compliance verified (1-2 minor issues remain)</li>
<li>‚úÖ Improvement demonstrated</li>
<li>‚úÖ No-JS parity maintained</li>
<li>‚ö†Ô∏è 1-2 minor regressions (documented and explained)</li>
<li>‚úÖ Fixes target inclusion</li>
</ul>
<h4 id="satisfactory-15-17-marks-1"><a class="header" href="#satisfactory-15-17-marks-1">Satisfactory (15-17 marks)</a></h4>
<ul>
<li>‚ö†Ô∏è WCAG AA mostly compliant (some gaps)</li>
<li>‚ö†Ô∏è Modest improvement (metrics improve slightly)</li>
<li>‚ö†Ô∏è No-JS parity mostly maintained (1 minor break)</li>
<li>‚ö†Ô∏è Some regressions not caught</li>
<li>‚ö†Ô∏è Fixes address some accessibility issues</li>
</ul>
<h4 id="needs-work-12-14-marks-1"><a class="header" href="#needs-work-12-14-marks-1">Needs Work (12-14 marks)</a></h4>
<ul>
<li>‚ùå WCAG violations remain (regression checklist incomplete)</li>
<li>‚ùå No measurable improvement (metrics unchanged or worse)</li>
<li>‚ùå No-JS parity broken</li>
<li>‚ùå Multiple regressions introduced</li>
</ul>
<h4 id="fail-0-11-marks-1"><a class="header" href="#fail-0-11-marks-1">Fail (0-11 marks)</a></h4>
<ul>
<li>‚ùå Fixes don't work or introduce major accessibility issues</li>
<li>‚ùå No regression testing performed</li>
<li>‚ùå No-JS completely broken</li>
<li>‚ùå Academic integrity issues (fixes copied without understanding)</li>
</ul>
<hr />
<h3 id="societal-impact-analysis-lo10-20-marks"><a class="header" href="#societal-impact-analysis-lo10-20-marks">Societal Impact Analysis (LO10) (20 marks)</a></h3>
<h4 id="excellent-15-20-marks-2"><a class="header" href="#excellent-15-20-marks-2">Excellent (15-20 marks)</a></h4>
<ul>
<li>‚úÖ Systemic barriers identified (beyond individual inconvenience: employment, education, civic participation)</li>
<li>‚úÖ Exclusion patterns analysed (who is excluded, how, why‚Äînot just "disabled people")</li>
<li>‚úÖ Universal design distinguished from accommodation (fix benefits all users, not just workaround)</li>
<li>‚úÖ Ethical considerations addressed (privacy, autonomy, dignity)</li>
<li>‚úÖ Long-term implications discussed (if pattern adopted widely, societal change)</li>
<li>‚úÖ Critical depth: 300-500 words of analysis (not description)</li>
</ul>
<h4 id="good-12-14-marks-2"><a class="header" href="#good-12-14-marks-2">Good (12-14 marks)</a></h4>
<ul>
<li>‚úÖ Systemic barriers mentioned (some analysis beyond individual)</li>
<li>‚úÖ Exclusion patterns identified (specific groups)</li>
<li>‚ö†Ô∏è Universal design vs accommodation touched on (not deeply explored)</li>
<li>‚ö†Ô∏è Ethical considerations brief</li>
<li>‚ö†Ô∏è Long-term implications mentioned (not analysed)</li>
<li>‚ö†Ô∏è 200-300 words</li>
</ul>
<h4 id="satisfactory-10-11-marks-2"><a class="header" href="#satisfactory-10-11-marks-2">Satisfactory (10-11 marks)</a></h4>
<ul>
<li>‚ö†Ô∏è Barriers mentioned but not systemic (individual inconvenience)</li>
<li>‚ö†Ô∏è Exclusion generic ("disabled people" without specifics)</li>
<li>‚ùå No distinction between universal design and accommodation</li>
<li>‚ùå Ethics not discussed</li>
<li>‚ùå No long-term analysis</li>
<li>‚ö†Ô∏è 150-250 words</li>
</ul>
<h4 id="needs-work-8-9-marks-1"><a class="header" href="#needs-work-8-9-marks-1">Needs Work (8-9 marks)</a></h4>
<ul>
<li>‚ùå Superficial ("helps disabled people" without analysis)</li>
<li>‚ùå No systemic thinking</li>
<li>‚ùå &lt;150 words or missing</li>
</ul>
<h4 id="fail-0-7-marks-1"><a class="header" href="#fail-0-7-marks-1">Fail (0-7 marks)</a></h4>
<ul>
<li>‚ùå Section missing or completely inadequate</li>
<li>‚ùå Shows no understanding of LO10</li>
</ul>
<hr />
<h3 id="evidence-chains-20-marks"><a class="header" href="#evidence-chains-20-marks">Evidence Chains (20 marks)</a></h3>
<h4 id="excellent-15-20-marks-3"><a class="header" href="#excellent-15-20-marks-3">Excellent (15-20 marks)</a></h4>
<ul>
<li>‚úÖ Every fix links to Task 1 finding (file + section reference)</li>
<li>‚úÖ Before/after metrics comparison complete (pre/analysis.csv vs post/postchange.csv)</li>
<li>‚úÖ Code diffs complete for all changes (before/after snippets with annotations)</li>
<li>‚úÖ Screenshots annotated (alt text + context)</li>
<li>‚úÖ Regression tests documented (30 checks complete, notes for each)</li>
</ul>
<h4 id="good-12-14-marks-3"><a class="header" href="#good-12-14-marks-3">Good (12-14 marks)</a></h4>
<ul>
<li>‚úÖ Most fixes link to Task 1 (1-2 minor gaps)</li>
<li>‚úÖ Metrics comparison complete</li>
<li>‚ö†Ô∏è Code diffs mostly complete (1-2 changes lack snippets)</li>
<li>‚ö†Ô∏è Screenshots present (annotations brief)</li>
<li>‚úÖ Regression tests complete</li>
</ul>
<h4 id="satisfactory-10-11-marks-3"><a class="header" href="#satisfactory-10-11-marks-3">Satisfactory (10-11 marks)</a></h4>
<ul>
<li>‚ö†Ô∏è Some fixes link to Task 1 (gaps present)</li>
<li>‚ö†Ô∏è Metrics comparison incomplete (only 1-2 metrics compared)</li>
<li>‚ö†Ô∏è Code diffs superficial (claims changed but minimal evidence)</li>
<li>‚ö†Ô∏è Screenshots present but not annotated</li>
<li>‚ö†Ô∏è Regression checklist incomplete (blanks, N/As)</li>
</ul>
<h4 id="needs-work--fail-0-9-marks-1"><a class="header" href="#needs-work--fail-0-9-marks-1">Needs Work / Fail (0-9 marks)</a></h4>
<ul>
<li>‚ùå No link to Task 1</li>
<li>‚ùå No before/after comparison</li>
<li>‚ùå No code diffs</li>
<li>‚ùå Regression checklist absent or mostly blank</li>
</ul>
<hr />
<h3 id="professional-presentation-10-marks"><a class="header" href="#professional-presentation-10-marks">Professional Presentation (10 marks)</a></h3>
<h4 id="excellent-8-10-marks"><a class="header" href="#excellent-8-10-marks">Excellent (8-10 marks)</a></h4>
<ul>
<li>‚úÖ Clear, well-structured documentation (all 6 files + directories)</li>
<li>‚úÖ Honest reporting (if metrics didn't improve, explains why)</li>
<li>‚úÖ Complete submission (matches specification exactly)</li>
<li>‚úÖ UK spelling and grammar</li>
<li>‚úÖ Proper Markdown formatting</li>
</ul>
<h4 id="good-6-7-marks"><a class="header" href="#good-6-7-marks">Good (6-7 marks)</a></h4>
<ul>
<li>‚úÖ Documentation clear</li>
<li>‚úÖ Honest reporting</li>
<li>‚ö†Ô∏è 1 minor file/directory missing</li>
<li>‚ö†Ô∏è Minor spelling/grammar issues</li>
<li>‚ö†Ô∏è Minor formatting issues</li>
</ul>
<h4 id="satisfactory--needs-work-4-5-marks"><a class="header" href="#satisfactory--needs-work-4-5-marks">Satisfactory / Needs Work (4-5 marks)</a></h4>
<ul>
<li>‚ö†Ô∏è Documentation adequate</li>
<li>‚ö†Ô∏è Reporting hides some issues</li>
<li>‚ùå 2+ files missing</li>
<li>‚ùå Spelling/grammar errors</li>
</ul>
<h4 id="fail-0-3-marks"><a class="header" href="#fail-0-3-marks">Fail (0-3 marks)</a></h4>
<ul>
<li>‚ùå Submission incomplete</li>
<li>‚ùå Dishonest reporting</li>
<li>‚ùå Plagiarism or academic integrity violation</li>
</ul>
<hr />
<h2 id="academic-integrity"><a class="header" href="#academic-integrity">Academic Integrity</a></h2>
<h3 id="automatic-fail-triggers"><a class="header" href="#automatic-fail-triggers">Automatic Fail Triggers</a></h3>
<p>The following result in <strong>immediate zero marks</strong> and referral to Academic Integrity Office:</p>
<p>‚ùå <strong>Fabricated pilot data</strong> (markers can detect unrealistic patterns: too perfect, identical times, no variation)</p>
<p>‚ùå <strong>Plagiarism</strong> (code/analysis copied from peers or internet without attribution)</p>
<p>‚ùå <strong>Contract cheating</strong> (someone else did the work)</p>
<p>‚ùå <strong>Falsified evidence</strong> (screenshots doctored, metrics invented, consent not obtained)</p>
<p>‚ùå <strong>No actual pilots conducted</strong> (claims 4 pilots but only did 1-2, or none)</p>
<h3 id="serious-penalties"><a class="header" href="#serious-penalties">Serious Penalties</a></h3>
<p>The following result in <strong>major mark deductions</strong> (30-50% penalty):</p>
<p>‚ö†Ô∏è <strong>Major PII violations</strong> (participant names/emails visible, identifiable session IDs)</p>
<p>‚ö†Ô∏è <strong>No consent obtained</strong> (pilots conducted without ethical protocol)</p>
<p>‚ö†Ô∏è <strong>Significant plagiarism</strong> (substantial sections copied, inadequate attribution)</p>
<hr />
<h2 id="common-misconceptions"><a class="header" href="#common-misconceptions">Common Misconceptions</a></h2>
<h3 id="-i-need-perfect-code-to-get-high-marks"><a class="header" href="#-i-need-perfect-code-to-get-high-marks">‚ùå "I need perfect code to get high marks"</a></h3>
<p><strong>No</strong>. We don't mark code quality. We mark <strong>HCI process</strong>. You can have bugs in your app and still get Excellent if your evaluation/redesign method is rigorous.</p>
<h3 id="-i-need-to-write-3000-words-to-get-good-marks"><a class="header" href="#-i-need-to-write-3000-words-to-get-good-marks">‚ùå "I need to write 3000 words to get good marks"</a></h3>
<p><strong>No</strong>. We prefer <strong>concise tables and metrics over verbose prose</strong>. A 1200-word findings doc with strong evidence beats a 3000-word essay with weak data.</p>
<h3 id="-if-my-redesign-doesnt-improve-metrics-ill-fail"><a class="header" href="#-if-my-redesign-doesnt-improve-metrics-ill-fail">‚ùå "If my redesign doesn't improve metrics, I'll fail"</a></h3>
<p><strong>No</strong>. We mark <strong>honest analysis</strong>. If metrics don't improve, explain why (small n? wrong fix? need more iteration?). Shows LO12 (professionalism).</p>
<h3 id="-i-need-to-fix-all-issues-found-in-task-1"><a class="header" href="#-i-need-to-fix-all-issues-found-in-task-1">‚ùå "I need to fix all issues found in Task 1"</a></h3>
<p><strong>No</strong>. We mark <strong>prioritisation and thoroughness</strong>. 2 fixes done rigorously (WCAG verified, regression tested, re-piloted) beats 10 fixes done superficially.</p>
<h3 id="-i-cant-get-excellent-if-i-find-problems-in-my-work"><a class="header" href="#-i-cant-get-excellent-if-i-find-problems-in-my-work">‚ùå "I can't get Excellent if I find problems in my work"</a></h3>
<p><strong>No</strong>. <strong>Reporting limitations honestly</strong> is a mark of professionalism (LO12). Hiding problems loses marks; acknowledging them gains marks.</p>
<hr />
<h2 id="how-to-self-assess-before-submission"><a class="header" href="#how-to-self-assess-before-submission">How to Self-Assess Before Submission</a></h2>
<h3 id="task-1-checklist"><a class="header" href="#task-1-checklist">Task 1 Checklist</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
<strong>Evidence</strong>: Every finding has file path, line number, or session ID reference?</li>
<li><input disabled="" type="checkbox"/>
<strong>n=4 minimum</strong>: At least 4 participants piloted?</li>
<li><input disabled="" type="checkbox"/>
<strong>Variants</strong>: At least 3 variants tested (standard, keyboard, no-JS)?</li>
<li><input disabled="" type="checkbox"/>
<strong>Needs-finding link</strong>: Connected evaluation to Week 6 job stories (LO2)?</li>
<li><input disabled="" type="checkbox"/>
<strong>Consent</strong>: Protocol includes consent script and right to withdraw?</li>
<li><input disabled="" type="checkbox"/>
<strong>No PII</strong>: All screenshots cropped, session IDs anonymous?</li>
<li><input disabled="" type="checkbox"/>
<strong>WCAG</strong>: Specific criteria cited (4.1.3, 3.3.1, etc.)?</li>
<li><input disabled="" type="checkbox"/>
<strong>Honest</strong>: Limitations acknowledged, unexpected results explained?</li>
</ul>
<h3 id="task-2-checklist"><a class="header" href="#task-2-checklist">Task 2 Checklist</a></h3>
<ul>
<li><input disabled="" type="checkbox"/>
<strong>Grounded</strong>: Problem links to specific Task 1 findings (file + section)?</li>
<li><input disabled="" type="checkbox"/>
<strong>WCAG AA</strong>: Regression checklist complete (all 30 checks PASS)?</li>
<li><input disabled="" type="checkbox"/>
<strong>Before/after</strong>: Metrics comparison shows improvement?</li>
<li><input disabled="" type="checkbox"/>
<strong>No-JS parity</strong>: Traditional path tested and works?</li>
<li><input disabled="" type="checkbox"/>
<strong>Societal impact</strong>: 300-500 words analysing systemic barriers (LO10)?</li>
<li><input disabled="" type="checkbox"/>
<strong>Code diffs</strong>: Before/after snippets for all changes?</li>
<li><input disabled="" type="checkbox"/>
<strong>Re-pilots</strong>: n‚â•2 conducted using same protocol as Task 1?</li>
<li><input disabled="" type="checkbox"/>
<strong>Honest</strong>: If metrics didn't improve, explained why?</li>
</ul>
<hr />
<h2 id="faqs-3"><a class="header" href="#faqs-3">FAQs</a></h2>
<p><strong>Q: What if I can only recruit 3 participants?</strong>
A: Minimum 4 required. Start earlier, use lab sessions to find peers. n=3 loses marks in Evidence Quality.</p>
<p><strong>Q: Can I use mean instead of median?</strong>
A: Median is more robust (less affected by outliers). Using mean is acceptable but justify why.</p>
<p><strong>Q: What if my regression testing finds new issues?</strong>
A: Fix them before re-pilots. That's why regression testing exists. Document in notes.</p>
<p><strong>Q: Do I need to implement screen reader fixes?</strong>
A: Not mandatory, but WCAG violations affecting SR users are high inclusion impact (prioritise these).</p>
<p><strong>Q: What if my fix breaks no-JS parity?</strong>
A: That's a fail in Fix Effectiveness. Test traditional path after every change.</p>
<p><strong>Q: Can I get Excellent without Task 1‚ÜíTask 2 evidence chains?</strong>
A: No. Evidence chains are core to Evidence Chains criterion (20 marks). Every fix must link to Task 1 finding.</p>
<p><strong>Q: How detailed should code diffs be?</strong>
A: Show enough to understand the change (5-15 lines before/after). Full files not needed.</p>
<p><strong>Q: What if I find no WCAG violations in Task 1?</strong>
A: Unlikely if you tested with axe DevTools + keyboard + SR. Revisit Week 7 audit. If genuinely compliant, document that honestly.</p>
<hr />
<h2 id="summary-what-gets-high-marks"><a class="header" href="#summary-what-gets-high-marks">Summary: What Gets High Marks?</a></h2>
<p>‚úÖ <strong>Evidence trails</strong>: Every claim traceable to data
‚úÖ <strong>Method rigour</strong>: Consent, variants, systematic testing
‚úÖ <strong>WCAG knowledge</strong>: Specific criteria cited, compliance verified
‚úÖ <strong>Critical thinking</strong>: Systemic barriers analysed, not just "helps disabled people"
‚úÖ <strong>Honest reporting</strong>: Limitations acknowledged, problems not hidden
‚úÖ <strong>Process over product</strong>: Evaluation/redesign method matters, not code elegance</p>
<p><strong>Focus on demonstrating HCI competence, not software engineering mastery.</strong></p>
<hr />
<p><a href="assessment/overview.html">‚Üê Back to Assessment Overview</a> | <a href="assessment/task1.html">Task 1 Details ‚Üí</a> | <a href="assessment/task2.html">Task 2 Details ‚Üí</a></p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="glossary"><a class="header" href="#glossary">Glossary</a></h1>
<p>Quick reference for technical terms, acronyms, and HCI concepts used throughout COMP2850.</p>
<p><strong>Categories</strong>: <img src="https://img.shields.io/badge/Accessibility-a11y-purple" alt="Accessibility" /> <img src="https://img.shields.io/badge/Architecture-Design-blue" alt="Architecture" /> <img src="https://img.shields.io/badge/HCI-UX-orange" alt="HCI" /> <img src="https://img.shields.io/badge/HTTP-Protocol-red" alt="HTTP" /> <img src="https://img.shields.io/badge/HTMX-Hypermedia-green" alt="HTMX" /> <img src="https://img.shields.io/badge/Module-COMP2850-darkblue" alt="Module" /> <img src="https://img.shields.io/badge/Tools-Tech-grey" alt="Tools" /> <img src="https://img.shields.io/badge/Web_Tech-HTML%2FCSS%2FJS-yellow" alt="Web Tech" /></p>
<p><strong><a href="references/glossary.html#acronyms-quick-reference">Jump to Acronyms Quick Reference ‚Üì</a></strong></p>
<hr />
<h3 id="accessibility"><a class="header" href="#accessibility">Accessibility (a11y)</a></h3>
<p><img src="https://img.shields.io/badge/Accessibility-a11y-purple" alt="Accessibility" /></p>
<p><strong>Definition</strong>: Practice of designing products usable by people with disabilities (visual, auditory, motor, cognitive). "a11y" is numeronym (a + 11 letters + y).</p>
<p><strong>Core principles (POUR)</strong>:</p>
<ul>
<li><strong>Perceivable</strong> - Can see/hear content (alt text, captions, contrast)</li>
<li><strong>Operable</strong> - Can use keyboard/mouse/voice (keyboard nav, focus indicators)</li>
<li><strong>Understandable</strong> - Clear language, predictable behaviour, error messages</li>
<li><strong>Robust</strong> - Works with assistive technologies (semantic HTML, ARIA)</li>
</ul>
<p><strong>Used in COMP2850</strong>: WCAG 2.2 AA compliance is mandatory from Week 6.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#wcag">WCAG</a>, <a href="references/glossary.html#aria">ARIA</a>, <a href="references/glossary.html#semantic-html">Semantic HTML</a></p>
<hr />
<h3 id="ajax"><a class="header" href="#ajax">AJAX</a></h3>
<p><img src="https://img.shields.io/badge/Web_Tech-HTML%2FCSS%2FJS-yellow" alt="Web Tech" /></p>
<p><strong>Full name</strong>: Asynchronous JavaScript and XML</p>
<p><strong>Definition</strong>: Technique for updating parts of a web page without a full reload. The browser sends a request in the background (via JavaScript), receives a response, and updates the DOM.</p>
<p><strong>History</strong>: Name comes from early 2000s when XML was common. Modern AJAX typically uses JSON or HTML.</p>
<p><strong>Used in COMP2850</strong>: HTMX uses AJAX under the hood, but you write HTML attributes instead of JavaScript <code>XMLHttpRequest</code> or <code>fetch()</code> code.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#htmx">HTMX</a>, <a href="references/glossary.html#dom">DOM</a></p>
<hr />
<h3 id="aria"><a class="header" href="#aria">ARIA</a></h3>
<p><img src="https://img.shields.io/badge/Accessibility-a11y-purple" alt="Accessibility" /></p>
<p><strong>Full name</strong>: Accessible Rich Internet Applications</p>
<p><strong>Definition</strong>: Set of HTML attributes that provide semantic information to assistive technologies (screen readers, voice control). Includes roles (<code>role="alert"</code>), properties (<code>aria-label</code>), and states (<code>aria-expanded</code>).</p>
<p><strong>When to use</strong>: Only when semantic HTML isn't sufficient. <strong>First rule of ARIA</strong>: Don't use ARIA if you can use semantic HTML instead.</p>
<p><strong>Used in COMP2850</strong>: <code>role="status"</code>, <code>aria-live="polite"</code>, <code>aria-label</code> for context-specific buttons.</p>
<p><strong>Reference</strong>: <a href="https://www.w3.org/WAI/ARIA/apg/">WAI-ARIA Authoring Practices</a></p>
<p><strong>See also</strong>: <a href="references/glossary.html#aria-live-region">ARIA Live Region</a>, <a href="references/glossary.html#semantic-html">Semantic HTML</a></p>
<hr />
<h3 id="aria-live-region"><a class="header" href="#aria-live-region">ARIA Live Region</a></h3>
<p><img src="https://img.shields.io/badge/Accessibility-a11y-purple" alt="Accessibility" /></p>
<p><strong>Definition</strong>: Element that screen readers monitor for changes and announce automatically, without moving focus.</p>
<p><strong>Why it matters</strong>: HTMX updates the page dynamically. Without live regions, screen reader users don't know anything changed.</p>
<p><strong>Attributes</strong>:</p>
<ul>
<li><code>role="status"</code> or <code>role="alert"</code> - What type of announcement</li>
<li><code>aria-live="polite"</code> - Wait for user to pause before announcing</li>
<li><code>aria-live="assertive"</code> - Interrupt immediately (errors only)</li>
</ul>
<p><strong>Example</strong>:</p>
<pre><code class="language-html">&lt;div id="status" role="status" aria-live="polite" class="visually-hidden"&gt;
  Task added successfully
&lt;/div&gt;
</code></pre>
<p><strong>Used in COMP2850</strong>: Every HTMX action must update a live region via OOB swap.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#oob-swap">OOB Swap</a>, <a href="references/glossary.html#screen-reader">Screen Reader</a></p>
<hr />
<h3 id="css"><a class="header" href="#css">CSS</a></h3>
<p><img src="https://img.shields.io/badge/Web_Tech-HTML%2FCSS%2FJS-yellow" alt="Web Tech" /></p>
<p><strong>Full name</strong>: Cascading Style Sheets</p>
<p><strong>Definition</strong>: Language for styling HTML (colors, fonts, layout, animations, etc.).</p>
<p><strong>Used in COMP2850</strong>: Pico CSS framework for baseline styles, custom CSS for accessibility (skip links, focus indicators).</p>
<hr />
<h3 id="dom"><a class="header" href="#dom">DOM</a></h3>
<p><img src="https://img.shields.io/badge/Web_Tech-HTML%2FCSS%2FJS-yellow" alt="Web Tech" /></p>
<p><strong>Full name</strong>: Document Object Model</p>
<p><strong>Definition</strong>: Tree-like representation of an HTML document in memory. The browser parses HTML into the DOM, which JavaScript can then read and manipulate.</p>
<p><strong>Key concepts</strong>:</p>
<ul>
<li><strong>Nodes</strong>: Each element, attribute, and piece of text is a node in the tree</li>
<li><strong>Manipulation</strong>: JavaScript can add, remove, or change nodes (e.g., <code>document.getElementById()</code>)</li>
<li><strong>HTMX updates</strong>: HTMX modifies the DOM by swapping HTML fragments without full page reload</li>
</ul>
<p><strong>Example</strong>: <code>&lt;ul id="tasks"&gt;&lt;li&gt;Task 1&lt;/li&gt;&lt;/ul&gt;</code> becomes a tree: <code>ul</code> (parent) ‚Üí <code>li</code> (child) ‚Üí text node "Task 1"</p>
<p><strong>Why it matters</strong>: Understanding the DOM helps debug HTMX swaps and accessibility issues (screen readers navigate the DOM tree).</p>
<p><strong>See also</strong>: <a href="references/glossary.html#htmx">HTMX</a>, <a href="references/glossary.html#ajax">AJAX</a>, <a href="references/glossary.html#html">HTML</a></p>
<hr />
<h3 id="evaluation"><a class="header" href="#evaluation">Evaluation</a></h3>
<p><img src="https://img.shields.io/badge/HCI-UX-orange" alt="HCI" /></p>
<p><strong>Definition</strong>: Process of measuring how well an interface meets user needs and usability goals.</p>
<p><strong>Types</strong>:</p>
<ul>
<li><strong>Formative</strong> - During design/development to guide iteration</li>
<li><strong>Summative</strong> - After release to measure success</li>
</ul>
<p><strong>Metrics (COMP2850)</strong>:</p>
<ul>
<li><strong>Utility</strong> - Does it solve the problem?</li>
<li><strong>Efficiency</strong> - How quickly can people complete tasks?</li>
<li><strong>Learnability</strong> - How quickly can new users learn it?</li>
<li><strong>Satisfaction</strong> - How pleasant is it to use?</li>
<li><strong>Affect</strong> - Emotional response (confidence, frustration)</li>
</ul>
<p><strong>Used in COMP2850</strong>: Week 9 peer pilots, Week 10 analysis.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#task-based-evaluation">Task-Based Evaluation</a></p>
<hr />
<h3 id="focus-indicator"><a class="header" href="#focus-indicator">Focus Indicator</a></h3>
<p><img src="https://img.shields.io/badge/Accessibility-a11y-purple" alt="Accessibility" /></p>
<p><strong>Definition</strong>: Visual outline or highlight that shows which element currently has keyboard focus.</p>
<p><strong>Why it matters</strong>: WCAG 2.4.7 (Focus Visible). Keyboard users need to see where they are on the page.</p>
<p><strong>Requirements</strong>: Minimum 3:1 contrast ratio against background, 2px minimum thickness (WCAG 2.2).</p>
<p><strong>Example</strong>: Browser default blue outline, or custom CSS <code>outline: 3px solid #0066A1;</code>.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#accessibility">Accessibility</a>, <a href="references/glossary.html#wcag">WCAG</a></p>
<hr />
<h3 id="fragment"><a class="header" href="#fragment">Fragment</a></h3>
<p><img src="https://img.shields.io/badge/HTMX-Hypermedia-green" alt="HTMX" /></p>
<p><strong>Definition</strong>: A partial HTML snippet (e.g., <code>&lt;li&gt;New item&lt;/li&gt;</code> or <code>&lt;div&gt;...&lt;/div&gt;</code>) returned by the server, rather than a complete page with <code>&lt;html&gt;</code>, <code>&lt;head&gt;</code>, <code>&lt;body&gt;</code>.</p>
<p><strong>Used in COMP2850</strong>: When HTMX makes a request, the server detects <code>HX-Request: true</code> header and returns a fragment instead of the full page.</p>
<p><strong>Example</strong>: Server renders <code>tasks/_item.peb</code> (just the <code>&lt;li&gt;</code>) instead of <code>tasks/index.peb</code> (full page).</p>
<p><strong>See also</strong>: <a href="references/glossary.html#htmx">HTMX</a>, <a href="references/glossary.html#template-factoring">Template Factoring</a>, <a href="references/glossary.html#partial">Partial</a></p>
<hr />
<h3 id="hateoas"><a class="header" href="#hateoas">HATEOAS</a></h3>
<p><img src="https://img.shields.io/badge/Architecture-Design-blue" alt="Architecture" /></p>
<p><strong>Full name</strong>: Hypermedia As The Engine Of Application State</p>
<p><strong>Definition</strong>: REST principle where the server's responses include hyperlinks/forms that tell the client what actions are possible next. The client doesn't need hardcoded URLs.</p>
<p><strong>Example</strong>: Task list HTML includes <code>&lt;form action="/tasks" method="post"&gt;</code> (server tells client "you can add tasks here").</p>
<p><strong>See also</strong>: <a href="references/glossary.html#hypermedia">Hypermedia</a></p>
<hr />
<h3 id="heuristics"><a class="header" href="#heuristics">Heuristics</a></h3>
<p><img src="https://img.shields.io/badge/HCI-UX-orange" alt="HCI" /></p>
<p><strong>Definition</strong>: General rules or principles for evaluating interface usability, not strict guidelines.</p>
<p><strong>Examples</strong>:</p>
<ul>
<li><strong>Nielsen's 10 Usability Heuristics</strong> (visibility of status, user control, consistency, error prevention, etc.)</li>
<li><strong>Shneiderman's 8 Golden Rules</strong> (consistency, shortcuts, feedback, closure, error handling, etc.)</li>
</ul>
<p><strong>Used in COMP2850</strong>: Week 7 accessibility audit uses heuristics + WCAG.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#wcag">WCAG</a>, <a href="references/glossary.html#accessibility">Accessibility</a></p>
<hr />
<h3 id="html"><a class="header" href="#html">HTML</a></h3>
<p><img src="https://img.shields.io/badge/Web_Tech-HTML%2FCSS%2FJS-yellow" alt="Web Tech" /></p>
<p><strong>Full name</strong>: HyperText Markup Language</p>
<p><strong>Definition</strong>: Standard markup language for web pages. Defines structure and semantics (headings, paragraphs, forms, links, etc.).</p>
<p><strong>Why it matters</strong>: Semantic HTML (using correct tags like <code>&lt;nav&gt;</code>, <code>&lt;main&gt;</code>, <code>&lt;button&gt;</code>) is essential for accessibility.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#semantic-html">Semantic HTML</a></p>
<hr />
<h3 id="htmx"><a class="header" href="#htmx">HTMX</a></h3>
<p><img src="https://img.shields.io/badge/HTMX-Hypermedia-green" alt="HTMX" /></p>
<p><strong>Definition</strong>: JavaScript library that extends HTML with attributes (<code>hx-get</code>, <code>hx-post</code>, <code>hx-target</code>, <code>hx-swap</code>) to enable AJAX requests and DOM updates without writing JavaScript.</p>
<p><strong>Key idea</strong>: Server sends HTML fragments (not JSON), HTMX swaps them into the page.</p>
<p><strong>Example</strong>: <code>&lt;button hx-get="/tasks/123" hx-target="#content"&gt;Load&lt;/button&gt;</code> ‚Üí Click ‚Üí AJAX GET ‚Üí Server returns HTML ‚Üí HTMX replaces <code>#content</code>.</p>
<p><strong>Why it matters</strong>: Simpler than React/Vue, accessible by default, progressive enhancement friendly.</p>
<p><strong>Documentation</strong>: <a href="https://htmx.org/">htmx.org</a> | <a href="https://hypermedia.systems/">hypermedia.systems</a></p>
<p><strong>See also</strong>: <a href="references/glossary.html#ajax">AJAX</a>, <a href="references/glossary.html#oob-swap">OOB Swap</a>, <a href="references/glossary.html#progressive-enhancement">Progressive Enhancement</a></p>
<hr />
<h3 id="http-methods"><a class="header" href="#http-methods">HTTP Methods</a></h3>
<p><img src="https://img.shields.io/badge/HTTP-Protocol-red" alt="HTTP" /></p>
<p><strong>Definition</strong>: Verbs that indicate the type of request being made to the server.</p>
<p><strong>Common methods</strong>:</p>
<ul>
<li><strong>GET</strong> - Retrieve data (safe, idempotent, cacheable)</li>
<li><strong>POST</strong> - Create new resource or submit data</li>
<li><strong>PUT</strong> - Update/replace entire resource</li>
<li><strong>PATCH</strong> - Partial update</li>
<li><strong>DELETE</strong> - Remove resource</li>
</ul>
<p><strong>Used in COMP2850</strong>: GET for viewing, POST for forms (add/edit/delete). HTMX supports all methods.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#prg">PRG</a></p>
<hr />
<h3 id="http-status-codes"><a class="header" href="#http-status-codes">HTTP Status Codes</a></h3>
<p><img src="https://img.shields.io/badge/HTTP-Protocol-red" alt="HTTP" /></p>
<p><strong>Definition</strong>: 3-digit codes indicating the result of an HTTP request.</p>
<p><strong>Common codes</strong>:</p>
<ul>
<li><strong>200 OK</strong> - Success</li>
<li><strong>201 Created</strong> - Resource created successfully</li>
<li><strong>303 See Other</strong> - Redirect after POST (PRG pattern)</li>
<li><strong>400 Bad Request</strong> - Client error (validation failed)</li>
<li><strong>404 Not Found</strong> - Resource doesn't exist</li>
<li><strong>500 Internal Server Error</strong> - Server error</li>
</ul>
<p><strong>Used in COMP2850</strong>: 303 for PRG redirects, 201 for successful creation, 400 for validation errors.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#prg">PRG</a></p>
<hr />
<h3 id="hx-swap"><a class="header" href="#hx-swap">hx-swap</a></h3>
<p><img src="https://img.shields.io/badge/HTMX-Hypermedia-green" alt="HTMX" /></p>
<p><strong>Definition</strong>: HTMX attribute specifying <strong>how</strong> to insert the server's response into the target.</p>
<p><strong>Common values</strong>:</p>
<ul>
<li><code>innerHTML</code> (default) - Replace target's contents</li>
<li><code>outerHTML</code> - Replace target itself</li>
<li><code>beforeend</code> - Append to target (inside, at end)</li>
<li><code>afterend</code> - Insert after target (outside)</li>
<li><code>beforebegin</code> - Insert before target (outside)</li>
</ul>
<p><strong>Example</strong>: <code>hx-swap="beforeend"</code> ‚Üí append new task to list.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#hx-target">hx-target</a>, <a href="references/glossary.html#htmx">HTMX</a></p>
<hr />
<h3 id="hx-target"><a class="header" href="#hx-target">hx-target</a></h3>
<p><img src="https://img.shields.io/badge/HTMX-Hypermedia-green" alt="HTMX" /></p>
<p><strong>Definition</strong>: HTMX attribute specifying which element to update with the server's response. Uses CSS selector syntax.</p>
<p><strong>Example</strong>: <code>hx-target="#task-list"</code> ‚Üí response goes into element with <code>id="task-list"</code>.</p>
<p><strong>Default</strong>: If not specified, targets the element that triggered the request.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#hx-swap">hx-swap</a>, <a href="references/glossary.html#htmx">HTMX</a></p>
<hr />
<h3 id="hx-trigger"><a class="header" href="#hx-trigger">hx-trigger</a></h3>
<p><img src="https://img.shields.io/badge/HTMX-Hypermedia-green" alt="HTMX" /></p>
<p><strong>Definition</strong>: HTMX attribute specifying what event triggers the AJAX request.</p>
<p><strong>Examples</strong>:</p>
<ul>
<li><code>hx-trigger="click"</code> (default for buttons)</li>
<li><code>hx-trigger="submit"</code> (default for forms)</li>
<li><code>hx-trigger="keyup changed delay:300ms"</code> (debounced search)</li>
<li><code>hx-trigger="revealed"</code> (lazy load when scrolled into view)</li>
</ul>
<p><strong>See also</strong>: <a href="references/glossary.html#htmx">HTMX</a></p>
<hr />
<h3 id="hypermedia"><a class="header" href="#hypermedia">Hypermedia</a></h3>
<p><img src="https://img.shields.io/badge/Architecture-Design-blue" alt="Architecture" /></p>
<p><strong>Definition</strong>: Media (HTML) that contains hyperlinks and forms as controls for navigating and manipulating application state. The server tells the client what actions are available via links (<code>&lt;a&gt;</code>) and forms (<code>&lt;form&gt;</code>).</p>
<p><strong>Why it matters</strong>: Follows REST/HATEOAS principles. The UI is the API. No separate JSON API needed.</p>
<p><strong>Used in COMP2850</strong>: We build hypermedia systems following <a href="https://hypermedia.systems/">hypermedia.systems</a>.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#htmx">HTMX</a>, <a href="references/glossary.html#rest">REST</a>, <a href="references/glossary.html#hateoas">HATEOAS</a></p>
<hr />
<h3 id="javascript"><a class="header" href="#javascript">JavaScript</a></h3>
<p><img src="https://img.shields.io/badge/Web_Tech-HTML%2FCSS%2FJS-yellow" alt="Web Tech" /></p>
<p><strong>Definition</strong>: Programming language that runs in the browser to add interactivity.</p>
<p><strong>Used in COMP2850</strong>: Minimal JavaScript via HTMX library. All features must work without JavaScript (progressive enhancement).</p>
<p><strong>See also</strong>: <a href="references/glossary.html#progressive-enhancement">Progressive Enhancement</a>, <a href="references/glossary.html#htmx">HTMX</a></p>
<hr />
<h3 id="job-stories"><a class="header" href="#job-stories">Job Stories</a></h3>
<p><img src="https://img.shields.io/badge/HCI-UX-orange" alt="HCI" /></p>
<p><strong>Definition</strong>: Format for capturing user needs based on context, motivation, and outcome. Structure: <strong>"When [situation], I want [motivation], so I can [outcome], because [reasoning]."</strong></p>
<p><strong>Example</strong>: "When I'm reviewing my weekly tasks on Sunday evening, I want to see incomplete items highlighted, so I can prioritize tomorrow's work, because I need to meet Friday's deadline."</p>
<p><strong>Why not user stories</strong>: User stories ("As a user, I want...") focus on demographics. Job stories focus on context and causality.</p>
<p><strong>Used in COMP2850</strong>: Week 6 Lab 2.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#needs-finding">Needs-Finding</a></p>
<hr />
<h3 id="json"><a class="header" href="#json">JSON</a></h3>
<p><img src="https://img.shields.io/badge/Web_Tech-HTML%2FCSS%2FJS-yellow" alt="Web Tech" /></p>
<p><strong>Full name</strong>: JavaScript Object Notation</p>
<p><strong>Definition</strong>: Lightweight data format for exchanging data between server and client. Common in REST APIs.</p>
<p><strong>Used in COMP2850</strong>: We <strong>do not</strong> use JSON APIs. Server sends HTML fragments, not JSON.</p>
<p><strong>Why</strong>: Hypermedia approach. HTML is the data format.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#hypermedia">Hypermedia</a></p>
<hr />
<h3 id="kotlin"><a class="header" href="#kotlin">Kotlin</a></h3>
<p><img src="https://img.shields.io/badge/Tools-Tech-grey" alt="Tools" /></p>
<p><strong>Definition</strong>: Modern programming language for JVM (Java Virtual Machine). Statically typed, null-safe, concise syntax.</p>
<p><strong>Used in COMP2850</strong>: Server-side code (routes, data models, storage).</p>
<p><strong>See also</strong>: <a href="references/glossary.html#ktor">Ktor</a></p>
<hr />
<h3 id="ktor"><a class="header" href="#ktor">Ktor</a></h3>
<p><img src="https://img.shields.io/badge/Tools-Tech-grey" alt="Tools" /></p>
<p><strong>Definition</strong>: Kotlin web framework for building server applications. Lightweight, asynchronous, uses coroutines.</p>
<p><strong>Used in COMP2850</strong>: HTTP server, routing, template rendering (via Pebble plugin).</p>
<p><strong>Documentation</strong>: <a href="https://ktor.io/">ktor.io</a></p>
<p><strong>See also</strong>: <a href="references/glossary.html#kotlin">Kotlin</a>, <a href="references/glossary.html#pebble">Pebble</a></p>
<hr />
<h3 id="needs-finding"><a class="header" href="#needs-finding">Needs-Finding</a></h3>
<p><img src="https://img.shields.io/badge/HCI-UX-orange" alt="HCI" /></p>
<p><strong>Definition</strong>: Research method to understand what people actually need (not what they say they want). Uses observation, interviews, job stories, contextual inquiry.</p>
<p><strong>Why not "requirements gathering"</strong>: Implies people know what they need and can articulate it. Needs-finding acknowledges we must discover unstated needs.</p>
<p><strong>Used in COMP2850</strong>: Week 6 Lab 2 - conduct peer interviews, write job stories.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#job-stories">Job Stories</a>, <a href="references/glossary.html#people-centred-language">People-Centred Language</a></p>
<hr />
<h3 id="no-js-parity"><a class="header" href="#no-js-parity">No-JS Parity</a></h3>
<p><img src="https://img.shields.io/badge/Architecture-Design-blue" alt="Architecture" /></p>
<p><strong>Definition</strong>: Requirement that every feature must work identically with JavaScript disabled. The user experience may differ (page reload vs. instant swap), but functionality must be identical.</p>
<p><strong>Why it matters</strong>: Accessibility, resilience, progressive enhancement compliance.</p>
<p><strong>Example</strong>: Add task button works via form POST ‚Üí redirect (no-JS) OR HTMX AJAX ‚Üí fragment swap (JS-enabled).</p>
<p><strong>See also</strong>: <a href="references/glossary.html#progressive-enhancement">Progressive Enhancement</a></p>
<hr />
<h3 id="oob-swap"><a class="header" href="#oob-swap">OOB Swap (Out-of-Band Swap)</a></h3>
<p><img src="https://img.shields.io/badge/HTMX-Hypermedia-green" alt="HTMX" /></p>
<p><strong>Full name</strong>: Out-of-Band Swap</p>
<p><strong>Definition</strong>: HTMX feature that updates an element <strong>outside</strong> the main target. The server includes <code>hx-swap-oob="true"</code> on an element, and HTMX updates it based on its <code>id</code>, even if it's not the primary target.</p>
<p><strong>Why it matters</strong>: Lets you update multiple parts of the page from one response (e.g., update task list + update status message).</p>
<p><strong>Example</strong>:</p>
<pre><code class="language-html">&lt;!-- Main target --&gt;
&lt;li id="task-3"&gt;Updated task&lt;/li&gt;

&lt;!-- OOB swap (updates #status even though target is #task-list) --&gt;
&lt;div id="status" hx-swap-oob="true"&gt;Task added!&lt;/div&gt;
</code></pre>
<p><strong>See also</strong>: <a href="references/glossary.html#htmx">HTMX</a>, <a href="references/glossary.html#aria-live-region">ARIA Live Region</a></p>
<hr />
<h3 id="partial"><a class="header" href="#partial">Partial</a></h3>
<p><img src="https://img.shields.io/badge/HTMX-Hypermedia-green" alt="HTMX" /></p>
<p><strong>Definition</strong>: A reusable template file (e.g., <code>_item.peb</code>, <code>_list.peb</code>, <code>_header.peb</code>) designed to be included in other templates or rendered independently as a fragment.</p>
<p><strong>Naming convention</strong>: Prefixed with underscore (<code>_</code>) to distinguish from full-page templates.</p>
<p><strong>Example</strong>:</p>
<ul>
<li><code>templates/tasks/_list.peb</code> - Partial template (source code)</li>
<li><code>templates/tasks/index.peb</code> - Full page template (includes partials)</li>
</ul>
<p><strong>How it works</strong>: The server renders a partial template to produce a <a href="references/glossary.html#fragment">fragment</a> of HTML that can be:</p>
<ul>
<li>Included in a full page via <code>{% include "tasks/_list.peb" %}</code></li>
<li>Returned directly for HTMX requests: <code>GET /tasks/fragment</code> renders <code>_list.peb</code> ‚Üí HTML fragment</li>
</ul>
<p><strong>Why it matters</strong>: Partials eliminate duplication‚Äîaccessibility fixes, ARIA attributes, and markup stay in one source file, ensuring consistency across full-page and HTMX-enhanced flows.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#fragment">Fragment</a>, <a href="references/glossary.html#template-factoring">Template Factoring</a></p>
<hr />
<h3 id="participant"><a class="header" href="#participant">Participant</a></h3>
<p><img src="https://img.shields.io/badge/Module-COMP2850-darkblue" alt="Module" /></p>
<p><strong>Definition</strong>: Person taking part in research (pilots, interviews, usability tests). Preferred term over "user" or "subject."</p>
<p><strong>Why</strong>: More respectful, acknowledges agency, aligns with ethics protocols.</p>
<p><strong>Used in COMP2850</strong>: Module-wide standard term.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#people-centred-language">People-Centred Language</a></p>
<hr />
<h3 id="pebble"><a class="header" href="#pebble">Pebble</a></h3>
<p><img src="https://img.shields.io/badge/Tools-Tech-grey" alt="Tools" /></p>
<p><strong>Definition</strong>: Template engine for Java/Kotlin. Similar to Jinja2 (Python) or Twig (PHP). Renders HTML with dynamic data.</p>
<p><strong>Syntax</strong>:</p>
<ul>
<li><code>{{ variable }}</code> - Output</li>
<li><code>{% for item in list %}...{% endfor %}</code> - Logic</li>
<li><code>{% extends "base.peb" %}</code> - Inheritance</li>
</ul>
<p><strong>Used in COMP2850</strong>: Server-side HTML rendering.</p>
<p><strong>Documentation</strong>: <a href="https://pebbletemplates.io/">pebbletemplates.io</a></p>
<p><strong>See also</strong>: <a href="references/glossary.html#ktor">Ktor</a>, <a href="references/glossary.html#template-factoring">Template Factoring</a></p>
<hr />
<h3 id="people-centred-language"><a class="header" href="#people-centred-language">People-Centred Language</a></h3>
<p><img src="https://img.shields.io/badge/HCI-UX-orange" alt="HCI" /></p>
<p><strong>Definition</strong>: Putting the person first, not the disability or technology. Avoids deficit-based terms.</p>
<p><strong>Examples</strong>:</p>
<ul>
<li>‚úÖ "Person using a screen reader" (not "blind user")</li>
<li>‚úÖ "Keyboard user" (not "disabled person")</li>
<li>‚úÖ "Person with low vision" (not "visually impaired user")</li>
</ul>
<p><strong>Why it matters</strong>: Disability arises from environmental barriers (bad design), not individual impairment. Language shapes how we think about accessibility.</p>
<p><strong>Used in COMP2850</strong>: Module-wide terminology standard.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#accessibility">Accessibility</a></p>
<hr />
<h3 id="pii"><a class="header" href="#pii">PII (Personally Identifiable Information)</a></h3>
<p><img src="https://img.shields.io/badge/Module-COMP2850-darkblue" alt="Module" /></p>
<p><strong>Full name</strong>: Personally Identifiable Information</p>
<p><strong>Definition</strong>: Data that can identify a specific individual (name, email, photo, student ID, IP address).</p>
<p><strong>Used in COMP2850</strong>: We collect <strong>no PII</strong>. Only anonymous session IDs and timestamps. UK GDPR compliant.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#privacy-by-design">Privacy by Design</a></p>
<hr />
<h3 id="pico-css"><a class="header" href="#pico-css">Pico CSS</a></h3>
<p><img src="https://img.shields.io/badge/Tools-Tech-grey" alt="Tools" /></p>
<p><strong>Definition</strong>: Minimal CSS framework with semantic styling. Classless (styles semantic HTML tags) + optional utility classes.</p>
<p><strong>Why Pico</strong>: Accessibility-first, no-JS, works with semantic HTML, lightweight (~10KB).</p>
<p><strong>Used in COMP2850</strong>: Baseline styling for student web apps.</p>
<p><strong>Documentation</strong>: <a href="https://picocss.com/">picocss.com</a></p>
<p><strong>See also</strong>: <a href="references/glossary.html#css">CSS</a>, <a href="references/glossary.html#semantic-html">Semantic HTML</a></p>
<hr />
<h3 id="prg"><a class="header" href="#prg">PRG (Post-Redirect-Get)</a></h3>
<p><img src="https://img.shields.io/badge/Architecture-Design-blue" alt="Architecture" /></p>
<p><strong>Full name</strong>: Post-Redirect-Get pattern</p>
<p><strong>Definition</strong>: After processing a POST request (form submission), the server returns an HTTP 303 redirect to a GET URL instead of rendering a page directly. This prevents duplicate submissions if the user refreshes.</p>
<p><strong>How it works</strong>:</p>
<ol>
<li>User submits form ‚Üí POST <code>/tasks</code> (create task)</li>
<li>Server validates, saves to database</li>
<li>Server returns HTTP 303 redirect to GET <code>/tasks</code></li>
<li>Browser follows redirect ‚Üí GET <code>/tasks</code> (displays updated list)</li>
<li>User refreshes ‚Üí safe GET request (no duplicate)</li>
</ol>
<p><strong>Used in COMP2850</strong>: Every form POST must use PRG for the no-JS path.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#http-methods">HTTP Methods</a></p>
<hr />
<h3 id="privacy-by-design"><a class="header" href="#privacy-by-design">Privacy by Design</a></h3>
<p><img src="https://img.shields.io/badge/Module-COMP2850-darkblue" alt="Module" /></p>
<p><strong>Definition</strong>: Approach to system design where privacy protections are built in from the start, not added later.</p>
<p><strong>Principles</strong>:</p>
<ol>
<li>Proactive (prevent, don't react)</li>
<li>Privacy as default setting</li>
<li>Privacy embedded in design</li>
<li>Full functionality (positive-sum, not zero-sum)</li>
<li>End-to-end security</li>
<li>Visibility and transparency</li>
<li>Respect for user privacy</li>
</ol>
<p><strong>Used in COMP2850</strong>: No PII collection, anonymous instrumentation, module-wide blanket consent.</p>
<p><strong>Reference</strong>: <code>references/privacy-by-design.md</code></p>
<p><strong>See also</strong>: <a href="references/glossary.html#pii">PII</a></p>
<hr />
<h3 id="progressive-enhancement"><a class="header" href="#progressive-enhancement">Progressive Enhancement</a></h3>
<p><img src="https://img.shields.io/badge/Architecture-Design-blue" alt="Architecture" /></p>
<p><strong>Definition</strong>: Design philosophy where you build a baseline experience that works for everyone (HTML), then add optional layers (CSS for styling, JavaScript for interactivity) that enhance the experience when available.</p>
<p><strong>Why it matters</strong>: If JavaScript fails to load (network error, corporate firewall, assistive tech incompatibility), users still get full functionality.</p>
<p><strong>Example</strong>: Form submits via POST/redirect (no-JS baseline) + HTMX intercepts and does AJAX swap (enhanced).</p>
<p><strong>See also</strong>: <a href="references/glossary.html#server-first">Server-First</a>, <a href="references/glossary.html#no-js-parity">No-JS Parity</a></p>
<hr />
<h3 id="request-headers"><a class="header" href="#request-headers">Request Headers</a></h3>
<p><img src="https://img.shields.io/badge/HTTP-Protocol-red" alt="HTTP" /></p>
<p><strong>Definition</strong>: Key-value pairs sent by the browser with each HTTP request, providing metadata about the request.</p>
<p><strong>Examples</strong>:</p>
<ul>
<li><code>User-Agent: Mozilla/5.0...</code> (browser identity)</li>
<li><code>Accept: text/html</code> (what content types browser accepts)</li>
<li><code>HX-Request: true</code> (HTMX adds this to identify AJAX requests)</li>
<li><code>Content-Type: application/x-www-form-urlencoded</code> (form data format)</li>
</ul>
<p><strong>Used in COMP2850</strong>: Server checks <code>HX-Request</code> header to decide whether to return full page or fragment.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#htmx">HTMX</a>, <a href="references/glossary.html#fragment">Fragment</a></p>
<hr />
<h3 id="rest"><a class="header" href="#rest">REST</a></h3>
<p><img src="https://img.shields.io/badge/Architecture-Design-blue" alt="Architecture" /></p>
<p><strong>Full name</strong>: Representational State Transfer</p>
<p><strong>Definition</strong>: Architectural style for web services that uses standard HTTP methods (GET, POST, PUT, DELETE) to operate on resources identified by URLs. Key principles include stateless communication, resource-based URLs, and hypermedia as the engine of application state.</p>
<p><strong>HTTP methods</strong>:</p>
<ul>
<li><strong>GET</strong> <code>/tasks</code> - Retrieve resources (safe, idempotent)</li>
<li><strong>POST</strong> <code>/tasks</code> - Create new resource</li>
<li><strong>PUT</strong> <code>/tasks/123</code> - Update entire resource</li>
<li><strong>DELETE</strong> <code>/tasks/123</code> - Remove resource</li>
</ul>
<p><strong>Why it matters</strong>: REST principles guide our route design. We use hypermedia (HTML) instead of JSON APIs, following the original REST vision.</p>
<p><strong>Used in COMP2850</strong>: All routes follow RESTful conventions. GET for reading, POST for creating, DELETE for removing.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#hateoas">HATEOAS</a>, <a href="references/glossary.html#http-methods">HTTP Methods</a>, <a href="references/glossary.html#hypermedia">Hypermedia</a></p>
<hr />
<h3 id="screen-reader"><a class="header" href="#screen-reader">Screen Reader</a></h3>
<p><img src="https://img.shields.io/badge/Accessibility-a11y-purple" alt="Accessibility" /></p>
<p><strong>Definition</strong>: Assistive technology that converts on-screen text and UI elements into synthesized speech or braille. Used by people who are blind or have low vision.</p>
<p><strong>Examples</strong>:</p>
<ul>
<li><strong>NVDA</strong> (Windows, free)</li>
<li><strong>JAWS</strong> (Windows, commercial)</li>
<li><strong>VoiceOver</strong> (macOS/iOS, built-in)</li>
<li><strong>Orca</strong> (Linux, built-in)</li>
</ul>
<p><strong>Used in COMP2850</strong>: All features must be tested with NVDA or VoiceOver to verify labels, announcements, and keyboard navigation.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#aria-live-region">ARIA Live Region</a>, <a href="references/glossary.html#accessibility">Accessibility</a></p>
<hr />
<h3 id="semantic-html"><a class="header" href="#semantic-html">Semantic HTML</a></h3>
<p><img src="https://img.shields.io/badge/Accessibility-a11y-purple" alt="Accessibility" /></p>
<p><strong>Definition</strong>: Using HTML elements that convey <strong>meaning</strong> (semantics), not just structure or appearance.</p>
<p><strong>Examples</strong>:</p>
<ul>
<li>‚úÖ Good: <code>&lt;button type="submit"&gt;Add&lt;/button&gt;</code></li>
<li>‚ùå Bad: <code>&lt;div onclick="submit()"&gt;Add&lt;/div&gt;</code></li>
<li>‚úÖ Good: <code>&lt;nav&gt;</code>, <code>&lt;main&gt;</code>, <code>&lt;article&gt;</code>, <code>&lt;section&gt;</code></li>
<li>‚ùå Bad: <code>&lt;div class="nav"&gt;</code>, <code>&lt;div class="main"&gt;</code></li>
</ul>
<p><strong>Why it matters</strong>: Assistive technologies (screen readers, voice control) rely on semantic elements to understand page structure and functionality.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#html">HTML</a>, <a href="references/glossary.html#accessibility">Accessibility</a></p>
<hr />
<h3 id="server-first"><a class="header" href="#server-first">Server-First Architecture</a></h3>
<p><img src="https://img.shields.io/badge/Architecture-Design-blue" alt="Architecture" /></p>
<p><strong>Definition</strong>: Architecture where the server generates complete HTML pages and sends them to the browser, rather than sending JavaScript that builds the page client-side.</p>
<p><strong>Why it matters</strong>: Pages load faster, work without JavaScript, and are accessible by default because the server controls the semantic HTML structure.</p>
<p><strong>Example</strong>: Ktor renders a Pebble template ‚Üí sends complete HTML ‚Üí browser displays immediately.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#progressive-enhancement">Progressive Enhancement</a>, <a href="references/glossary.html#ssr">SSR</a></p>
<hr />
<h3 id="skip-link"><a class="header" href="#skip-link">Skip Link</a></h3>
<p><img src="https://img.shields.io/badge/Accessibility-a11y-purple" alt="Accessibility" /></p>
<p><strong>Definition</strong>: Link at the top of a page that lets keyboard users jump directly to main content, bypassing repeated navigation.</p>
<p><strong>Why it matters</strong>: WCAG 2.4.1 (Bypass Blocks). Users shouldn't have to tab through 50 nav links on every page.</p>
<p><strong>Implementation</strong>:</p>
<pre><code class="language-html">&lt;a href="#main" class="skip-link"&gt;Skip to main content&lt;/a&gt;
&lt;!-- ... nav ... --&gt;
&lt;main id="main" tabindex="-1"&gt;Content here&lt;/main&gt;
</code></pre>
<p><strong>Styling</strong>: Hidden visually until keyboard-focused (<code>:focus</code>).</p>
<p><strong>See also</strong>: <a href="references/glossary.html#accessibility">Accessibility</a>, <a href="references/glossary.html#wcag">WCAG</a></p>
<hr />
<h3 id="ssr"><a class="header" href="#ssr">SSR (Server-Side Rendering)</a></h3>
<p><img src="https://img.shields.io/badge/Architecture-Design-blue" alt="Architecture" /></p>
<p><strong>Full name</strong>: Server-Side Rendering</p>
<p><strong>Definition</strong>: The server generates the final HTML and sends it to the browser. The browser receives complete markup, not an empty shell that JavaScript fills in.</p>
<p><strong>Contrast with CSR</strong>: Client-side rendering (CSR) sends minimal HTML + JavaScript bundle ‚Üí browser runs JS ‚Üí JS fetches data ‚Üí JS builds DOM. Slower, accessibility-unfriendly.</p>
<p><strong>Used in COMP2850</strong>: Ktor + Pebble templates = SSR.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#server-first">Server-First</a></p>
<hr />
<h3 id="task-based-evaluation"><a class="header" href="#task-based-evaluation">Task-Based Evaluation</a></h3>
<p><img src="https://img.shields.io/badge/HCI-UX-orange" alt="HCI" /></p>
<p><strong>Definition</strong>: Usability testing where participants attempt realistic tasks while you measure performance (time, errors, completion rate) and gather qualitative observations.</p>
<p><strong>Example</strong>: "Add a task called 'Buy milk', mark it complete, then delete it" (measures core CRUD functionality).</p>
<p><strong>Used in COMP2850</strong>: Week 9 Lab 2 - 4-person peer pilots with 4 tasks.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#evaluation">Evaluation</a></p>
<hr />
<h3 id="template-factoring"><a class="header" href="#template-factoring">Template Factoring</a></h3>
<p><img src="https://img.shields.io/badge/HTMX-Hypermedia-green" alt="HTMX" /></p>
<p><strong>Definition</strong>: Breaking templates into reusable partials so the server can render full pages OR just fragments for HTMX.</p>
<p><strong>Example</strong>:</p>
<ul>
<li><code>base.peb</code> - Full page layout</li>
<li><code>tasks/index.peb</code> - Full page (extends base)</li>
<li><code>tasks/_list.peb</code> - Partial (just the <code>&lt;ul&gt;</code>)</li>
<li><code>tasks/_item.peb</code> - Partial (just one <code>&lt;li&gt;</code>)</li>
</ul>
<p><strong>Why it matters</strong>: Server returns <code>_list.peb</code> for HTMX requests, <code>index.peb</code> for full page loads.</p>
<p><strong>See also</strong>: <a href="references/glossary.html#partial">Partial</a>, <a href="references/glossary.html#fragment">Fragment</a>, <a href="references/glossary.html#htmx">HTMX</a></p>
<hr />
<h3 id="uk-gdpr"><a class="header" href="#uk-gdpr">UK GDPR</a></h3>
<p><img src="https://img.shields.io/badge/Module-COMP2850-darkblue" alt="Module" /></p>
<p><strong>Full name</strong>: UK General Data Protection Regulation (Data Protection Act 2018)</p>
<p><strong>Definition</strong>: UK law governing personal data collection, storage, and processing.</p>
<p><strong>Key principles</strong>: Lawfulness, fairness, transparency, purpose limitation, data minimization, accuracy, storage limitation, integrity/confidentiality, accountability.</p>
<p><strong>Used in COMP2850</strong>: All instrumentation must be GDPR-compliant (no PII, verbal consent, opt-out supported).</p>
<p><strong>See also</strong>: <a href="references/glossary.html#privacy-by-design">Privacy by Design</a>, <a href="references/glossary.html#pii">PII</a></p>
<hr />
<h3 id="wcag"><a class="header" href="#wcag">WCAG</a></h3>
<p><img src="https://img.shields.io/badge/Accessibility-a11y-purple" alt="Accessibility" /></p>
<p><strong>Full name</strong>: Web Content Accessibility Guidelines</p>
<p><strong>Definition</strong>: International standard for web accessibility published by W3C. Defines success criteria at 3 levels: A (minimum), AA (target), AAA (enhanced).</p>
<p><strong>Used in COMP2850</strong>: We target <strong>WCAG 2.2 Level AA</strong> compliance for all features.</p>
<p><strong>Reference</strong>: <a href="https://www.w3.org/WAI/WCAG22/quickref/">W3C WCAG 2.2 Quick Reference</a></p>
<p><strong>See also</strong>: <a href="references/glossary.html#accessibility">Accessibility</a></p>
<hr />
<h2 id="acronyms-quick-reference"><a class="header" href="#acronyms-quick-reference">Acronyms Quick Reference</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Acronym</th><th>Full Name</th><th>Link</th></tr></thead><tbody>
<tr><td><strong>a11y</strong></td><td>Accessibility (a + 11 letters + y)</td><td><a href="references/glossary.html#accessibility">‚Üë</a></td></tr>
<tr><td><strong>AJAX</strong></td><td>Asynchronous JavaScript and XML</td><td><a href="references/glossary.html#ajax">‚Üë</a></td></tr>
<tr><td><strong>ARIA</strong></td><td>Accessible Rich Internet Applications</td><td><a href="references/glossary.html#aria">‚Üë</a></td></tr>
<tr><td><strong>CSS</strong></td><td>Cascading Style Sheets</td><td><a href="references/glossary.html#css">‚Üë</a></td></tr>
<tr><td><strong>CSR</strong></td><td>Client-Side Rendering</td><td><a href="references/glossary.html#ssr">‚Üë</a></td></tr>
<tr><td><strong>GDPR</strong></td><td>General Data Protection Regulation</td><td><a href="references/glossary.html#uk-gdpr">‚Üë</a></td></tr>
<tr><td><strong>HATEOAS</strong></td><td>Hypermedia As The Engine Of Application State</td><td><a href="references/glossary.html#hateoas">‚Üë</a></td></tr>
<tr><td><strong>HTML</strong></td><td>HyperText Markup Language</td><td><a href="references/glossary.html#html">‚Üë</a></td></tr>
<tr><td><strong>HTTP</strong></td><td>HyperText Transfer Protocol</td><td><a href="references/glossary.html#http-methods">‚Üë</a></td></tr>
<tr><td><strong>JSON</strong></td><td>JavaScript Object Notation</td><td><a href="references/glossary.html#json">‚Üë</a></td></tr>
<tr><td><strong>OOB</strong></td><td>Out-of-Band (swap)</td><td><a href="references/glossary.html#oob-swap">‚Üë</a></td></tr>
<tr><td><strong>PII</strong></td><td>Personally Identifiable Information</td><td><a href="references/glossary.html#pii">‚Üë</a></td></tr>
<tr><td><strong>PRG</strong></td><td>Post-Redirect-Get</td><td><a href="references/glossary.html#prg">‚Üë</a></td></tr>
<tr><td><strong>SSR</strong></td><td>Server-Side Rendering</td><td><a href="references/glossary.html#ssr">‚Üë</a></td></tr>
<tr><td><strong>WCAG</strong></td><td>Web Content Accessibility Guidelines</td><td><a href="references/glossary.html#wcag">‚Üë</a></td></tr>
</tbody></table>
</div>
<hr />
<p><strong>Version</strong>: 0.2
<strong>Last updated</strong>: 2025-01-07
<strong>Module</strong>: COMP2850 HCI, University of Leeds</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="learning-outcomes-reference"><a class="header" href="#learning-outcomes-reference">Learning Outcomes Reference</a></h1>
<blockquote>
<p><strong>Purpose</strong> This document is the <strong>definitive reference</strong> for all Learning Outcomes in COMP2850 HCI. It clarifies terminology, maps outcomes to weeks/labs, and ensures consistency across all teaching materials.</p>
</blockquote>
<hr />
<h2 id="understanding-the-hierarchy"><a class="header" href="#understanding-the-hierarchy">Understanding the Hierarchy</a></h2>
<p>There are <strong>three levels</strong> of learning specifications in this module:</p>
<div class="table-wrapper"><table><thead><tr><th>Level</th><th>Scope</th><th>Purpose</th><th>Where Used</th></tr></thead><tbody>
<tr><td><strong>Module Aims</strong></td><td>Broad, aspirational statements about overall module goals</td><td>High-level intentions; what the module sets out to achieve</td><td>Homepage, module outline</td></tr>
<tr><td><strong>Learning Outcomes (LOs)</strong></td><td>Specific, measurable competencies students will demonstrate</td><td>Assessment criteria; aligned to accreditation standards (ACM CS2023)</td><td>Week/lab mappings, assessment rubrics, portfolio</td></tr>
<tr><td><strong>Lab Objectives</strong></td><td>Session-specific tasks and activities</td><td>What students will do in this lab to work toward LOs</td><td>Individual lab pages</td></tr>
</tbody></table>
</div>
<p><strong>Key distinction</strong>:</p>
<ul>
<li><strong>Aims</strong> are broad intentions ("enable students to...")</li>
<li><strong>Outcomes</strong> are measurable achievements ("students will be able to...")</li>
<li><strong>Objectives</strong> are specific activities ("implement a consent form", "run 4 pilots")</li>
</ul>
<hr />
<h2 id="module-wide-learning-outcomes-comp2850"><a class="header" href="#module-wide-learning-outcomes-comp2850">Module-Wide Learning Outcomes (COMP2850)</a></h2>
<p>These <strong>10 outcomes</strong> apply to the <strong>entire COMP2850 module</strong> (Weeks 1-11, covering OOP + HCI). The HCI component (Weeks 6-11) contributes to these outcomes alongside the OOP component (Weeks 1-5).</p>
<p>On successful completion of COMP2850, students will have demonstrated the ability to:</p>
<ol>
<li>
<p><strong>Apply subject specific knowledge and engineering design principles</strong> to design and implement software artefacts which satisfy complex real-world requirements, considering accessibility and inclusive design principles <em>(C1, M1, C2, M2, C5, M5, C6, M6, C11, M11)</em></p>
</li>
<li>
<p><strong>Select and interpret sources of information</strong> to solve complex real-world problems <em>(C4, M4)</em></p>
</li>
<li>
<p><strong>Use appropriately selected tools and processes</strong> to design, test, analyse and evaluate computer systems and identify limitations <em>(C12, M12, C13, M13)</em></p>
</li>
<li>
<p><strong>Identify and analyse ethical and sustainability concerns</strong> when designing and implementing software and make reasoned decisions informed by ethical frameworks and codes of conduct to minimise adverse impacts <em>(C7, M7, C8, M8)</em></p>
</li>
<li>
<p><strong>Identify and interpret risk</strong> assessing the potential impact and plan mitigation approaches <em>(C9, M9, C10, M10)</em></p>
</li>
<li>
<p><strong>Apply and discuss the principles of quality management</strong> in software engineering and systems design <em>(C14, M14)</em></p>
</li>
<li>
<p><strong>Operate effectively as a member of a team</strong> in various roles <em>(C16, M16)</em></p>
</li>
<li>
<p><strong>Apply and discuss engineering management principles</strong> demonstrating awareness of commercial context, project and change management, and relevant legal matters <em>(C15, M15)</em></p>
</li>
<li>
<p><strong>Communicate effectively complex topics</strong> related to programming and software engineering to technical and non-technical audiences <em>(C17, M17)</em></p>
</li>
<li>
<p><strong>Reflect on their level of mastery</strong> of subject knowledge and skills and plan for personal development <em>(C18, M18)</em></p>
</li>
</ol>
<p><strong>HCI contribution</strong>: Weeks 6-11 primarily contribute to outcomes <strong>1, 2, 3, 4, 7, 9, and 10</strong>.</p>
<hr />
<h2 id="hci-specific-learning-outcomes-weeks-6-11"><a class="header" href="#hci-specific-learning-outcomes-weeks-6-11">HCI-Specific Learning Outcomes (Weeks 6-11)</a></h2>
<p>These <strong>13 outcomes</strong> are specific to the <strong>HCI component</strong> (Weeks 6-11). They elaborate on how the module-wide outcomes are achieved through HCI activities. They are numbered <strong>LO1 through LO13</strong> and should be referenced consistently across all lab materials.</p>
<p><strong>Source</strong>: <code>learning-outcomes-condensed.md</code></p>
<h3 id="lo1-differentiate-people-centred-design-and-evaluation-methodologies"><a class="header" href="#lo1-differentiate-people-centred-design-and-evaluation-methodologies">LO1: Differentiate people-centred design and evaluation methodologies</a></h3>
<p><strong>Description</strong>: Distinguish between design methodologies (e.g., participatory design, user-centred design) and evaluation methods (e.g., heuristic evaluation, task-based testing, A/B testing).</p>
<p><strong>Evidenced in</strong>: Week 6 Lab 2 (needs-finding, job stories), Week 9 Lab 1 (evaluation planning, method selection)</p>
<p><strong>ACM strands</strong>: Understanding People (UP/1-3), HCI-Evaluation (HC/5)</p>
<hr />
<h3 id="lo2-design-and-conduct-needs-finding-activities"><a class="header" href="#lo2-design-and-conduct-needs-finding-activities">LO2: Design and conduct needs-finding activities</a></h3>
<p><strong>Description</strong>: Plan and run structured needs-finding sessions (interviews, observation, job story extraction) following ethical protocols including informed consent.</p>
<p><strong>Evidenced in</strong>: Week 6 Lab 2 (job stories, consent forms), Week 7 Lab 1 (user scenarios)</p>
<p><strong>ACM strands</strong>: Understanding People (UP/1-2), Requirements Engineering</p>
<hr />
<h3 id="lo3-analyse-ethical-implications-of-design-decisions"><a class="header" href="#lo3-analyse-ethical-implications-of-design-decisions">LO3: Analyse ethical implications of design decisions</a></h3>
<p><strong>Description</strong>: Identify ethical concerns (privacy, consent, data retention, bias) in interface designs and propose mitigation strategies informed by frameworks like UK GDPR, BCS Code of Conduct.</p>
<p><strong>Evidenced in</strong>: Week 7 Lab 1 (consent modal, privacy by design), Week 6 Lab 2 (data handling), Week 10 Lab 2 (inclusive redesign)</p>
<p><strong>ACM strands</strong>: Social and Professional Issues (SP/1-2), Privacy &amp; Security</p>
<hr />
<h3 id="lo4-evaluate-software-interfaces-for-accessibility-concerns"><a class="header" href="#lo4-evaluate-software-interfaces-for-accessibility-concerns">LO4: Evaluate software interfaces for accessibility concerns</a></h3>
<p><strong>Description</strong>: Conduct accessibility audits using automated tools (axe DevTools) and manual testing (keyboard navigation, screen readers) against WCAG 2.2 AA standards.</p>
<p><strong>Evidenced in</strong>: Week 7 Lab 2 (accessibility audit, WCAG mapping), Week 8 Lab 2 (no-JS verification), Week 10 Lab 2 (regression testing)</p>
<p><strong>ACM strands</strong>: Designing Interaction (HC/2), Accessibility (WCAG 2.2 AA)</p>
<hr />
<h3 id="lo5-create-interface-prototypes-using-appropriate-fidelity-levels"><a class="header" href="#lo5-create-interface-prototypes-using-appropriate-fidelity-levels">LO5: Create interface prototypes using appropriate fidelity levels</a></h3>
<p><strong>Description</strong>: Build prototypes ranging from paper sketches to functional HTML/HTMX implementations, selecting fidelity appropriate to the design question.</p>
<p><strong>Evidenced in</strong>: Week 8 Lab 1 (HTMX prototypes, partials), Week 10 Lab 2 (redesign implementation)</p>
<p><strong>ACM strands</strong>: Prototyping Techniques (HC/3)</p>
<hr />
<h3 id="lo6-apply-iterative-design-processes"><a class="header" href="#lo6-apply-iterative-design-processes">LO6: Apply iterative design processes</a></h3>
<p><strong>Description</strong>: Execute design-test-refine cycles, incorporating evaluation findings into redesigns and documenting rationale with evidence.</p>
<p><strong>Evidenced in</strong>: Week 9 Lab 2 (pilots, debrief), Week 10 Lab 1 (analysis, prioritisation), Week 10 Lab 2 (redesign, re-verification)</p>
<p><strong>ACM strands</strong>: Iterative Design (HC/4)</p>
<hr />
<h3 id="lo7-analyse-how-design-constraints-affect-interface-decisions"><a class="header" href="#lo7-analyse-how-design-constraints-affect-interface-decisions">LO7: Analyse how design constraints affect interface decisions</a></h3>
<p><strong>Description</strong>: Identify technical, accessibility, and no-JS constraints; explain trade-offs in design decisions (e.g., progressive enhancement vs SPA, server-first vs client-first).</p>
<p><strong>Evidenced in</strong>: Week 8 Lab 1 (pagination, filtering constraints), Week 8 Lab 2 (no-JS parity, routing trade-offs)</p>
<p><strong>ACM strands</strong>: Design Constraints (HC/4), Software Architecture</p>
<hr />
<h3 id="lo8-design-and-execute-appropriate-evaluation-methods"><a class="header" href="#lo8-design-and-execute-appropriate-evaluation-methods">LO8: Design and execute appropriate evaluation methods</a></h3>
<p><strong>Description</strong>: Develop task-based evaluation protocols, define metrics (time-on-task, errors, SUS), run pilots with n=4 participants, and analyse quantitative/qualitative data.</p>
<p><strong>Evidenced in</strong>: Week 9 Lab 1 (evaluation plan, metrics, instrumentation), Week 9 Lab 2 (pilots, observer notes), Week 10 Lab 1 (data analysis)</p>
<p><strong>ACM strands</strong>: HCI-Evaluation (HC/5), Empirical Methods</p>
<hr />
<h3 id="lo9-apply-universal-and-inclusive-design-principles"><a class="header" href="#lo9-apply-universal-and-inclusive-design-principles">LO9: Apply universal and inclusive design principles</a></h3>
<p><strong>Description</strong>: Design interfaces that work for diverse users (keyboard-only, screen reader, low vision, cognitive differences) using techniques like semantic HTML, ARIA, focus management.</p>
<p><strong>Evidenced in</strong>: Week 7 Lab 2 (inclusive fix), Week 8 Lab 2 (no-JS parity), Week 10 Lab 2 (inclusive redesign)</p>
<p><strong>ACM strands</strong>: Accessibility (HC/2), Universal Design (UP/3)</p>
<hr />
<h3 id="lo10-critique-potential-impacts-of-designs-on-society"><a class="header" href="#lo10-critique-potential-impacts-of-designs-on-society">LO10: Critique potential impacts of designs on society</a></h3>
<p><strong>Description</strong>: Analyse societal implications of design choices (surveillance, exclusion, environmental cost) and propose alternatives that reduce harm.</p>
<p><strong>Evidenced in</strong>: Week 7 Lab 1 (ethics analysis), Week 6 Lab 2 (privacy considerations)</p>
<p><strong>ACM strands</strong>: Social and Professional Issues (SP/1-2), Ethics</p>
<hr />
<h3 id="lo11-collaborate-effectively-in-multidisciplinary-teams"><a class="header" href="#lo11-collaborate-effectively-in-multidisciplinary-teams">LO11: Collaborate effectively in multidisciplinary teams</a></h3>
<p><strong>Description</strong>: Work in teams using version control (Git), code review, and shared documentation; communicate design rationale to technical and non-technical peers.</p>
<p><strong>Evidenced in</strong>: Week 9 Lab 2 (peer pilots, observer role), Week 11 Lab 1 (studio crit, peer feedback)</p>
<p><strong>ACM strands</strong>: Teamwork (Professional Skills)</p>
<hr />
<h3 id="lo12-demonstrate-professional-dispositions"><a class="header" href="#lo12-demonstrate-professional-dispositions">LO12: Demonstrate professional dispositions</a></h3>
<p><strong>Description</strong>: Show responsibility (meet deadlines, follow protocols), integrity (cite sources, report honestly), and respect (use people-centred language, honour consent).</p>
<p><strong>Evidenced in</strong>: All labs (consent adherence, evidence-based claims, inclusive language)</p>
<p><strong>ACM strands</strong>: Professional Skills, Ethics</p>
<hr />
<h3 id="lo13-integrate-people-centred-design-with-se-lifecycle"><a class="header" href="#lo13-integrate-people-centred-design-with-se-lifecycle">LO13: Integrate people-centred design with SE lifecycle</a></h3>
<p><strong>Description</strong>: Embed HCI practices (needs-finding, evaluation, iteration) within software engineering workflows (version control, testing, deployment).</p>
<p><strong>Evidenced in</strong>: Week 8 Lab 1 (server-first patterns), Week 9 Lab 1 (instrumentation in code), Week 10 Lab 2 (regression testing)</p>
<p><strong>ACM strands</strong>: Software Engineering Processes, Requirements Engineering</p>
<hr />
<h2 id="cross-reference-los-to-weeks--activities"><a class="header" href="#cross-reference-los-to-weeks--activities">Cross-Reference: LOs to Weeks &amp; Activities</a></h2>
<p>This table maps each HCI Learning Outcome to specific weeks, labs, and deliverables. Use this for curriculum planning, assessment design, and student progress tracking.</p>
<div class="table-wrapper"><table><thead><tr><th>LO</th><th>Outcome (condensed)</th><th>Primary Evidence</th><th>Secondary Evidence</th><th>Assessment Task</th><th>ACM Strands</th></tr></thead><tbody>
<tr><td><strong>LO1</strong></td><td>Differentiate people-centred methods</td><td>W6 L2 (needs-finding, job stories)</td><td>W9 L1 (evaluation methods)</td><td>Task 1: Evaluation plan</td><td>UP/1-3, HC/5</td></tr>
<tr><td><strong>LO2</strong></td><td>Design and conduct needs-finding</td><td>W6 L2 (job stories, consent)</td><td>W7 L1 (scenarios)</td><td>Backlog (user needs)</td><td>UP/1-2</td></tr>
<tr><td><strong>LO3</strong></td><td>Analyse ethical implications</td><td>W7 L1 (consent modal, GDPR)</td><td>W6 L2 (privacy), W10 L2 (bias)</td><td>Task 2: Privacy audit</td><td>SP/1-2</td></tr>
<tr><td><strong>LO4</strong></td><td>Evaluate for accessibility</td><td>W7 L2 (audit, WCAG map)</td><td>W8 L2 (no-JS), W10 L2 (regression)</td><td>Task 2: Accessibility fixes</td><td>HC/2, WCAG 2.2 AA</td></tr>
<tr><td><strong>LO5</strong></td><td>Create prototypes</td><td>W8 L1 (HTMX partials)</td><td>W10 L2 (redesign)</td><td>Code submissions</td><td>HC/3</td></tr>
<tr><td><strong>LO6</strong></td><td>Apply iterative design</td><td>W9 L2 (pilots), W10 (analysis + redesign)</td><td>W11 L1 (critique)</td><td>Tasks 1 &amp; 2: Full cycle</td><td>HC/4</td></tr>
<tr><td><strong>LO7</strong></td><td>Analyse design constraints</td><td>W8 L1 (pagination, filtering)</td><td>W8 L2 (no-JS trade-offs)</td><td>Task 2: Trade-offs doc</td><td>HC/4</td></tr>
<tr><td><strong>LO8</strong></td><td>Design and execute evaluation</td><td>W9 L1 (plan, metrics), W9 L2 (pilots)</td><td>W10 L1 (analysis)</td><td>Task 1: Pilots &amp; findings</td><td>HC/5</td></tr>
<tr><td><strong>LO9</strong></td><td>Apply inclusive design</td><td>W7 L2 (inclusive fix)</td><td>W8 L2 (no-JS), W10 L2 (redesign)</td><td>Task 2: WCAG compliance</td><td>HC/2, UP/3</td></tr>
<tr><td><strong>LO10</strong></td><td>Critique societal impacts</td><td>W7 L1 (ethics overlay)</td><td>W6 L2 (privacy)</td><td>Reflections</td><td>SP/1-2</td></tr>
<tr><td><strong>LO11</strong></td><td>Collaborate in teams</td><td>W9 L2 (peer pilots)</td><td>W11 L1 (studio crit)</td><td>Peer feedback forms</td><td>Professional Skills</td></tr>
<tr><td><strong>LO12</strong></td><td>Demonstrate professionalism</td><td>All labs (consent, citations)</td><td>Portfolio (integrity)</td><td>All submissions</td><td>Professional Skills</td></tr>
<tr><td><strong>LO13</strong></td><td>Integrate HCI with SE</td><td>W8 L1 (server patterns), W9 L1 (instrumentation)</td><td>W10 L2 (regression)</td><td>Codebase quality</td><td>SE Processes</td></tr>
</tbody></table>
</div>
<p><strong>How to use this table</strong>:</p>
<ul>
<li><strong>Curriculum planning</strong>: Ensure each LO has sufficient coverage across weeks</li>
<li><strong>Student progress</strong>: Track which LOs are being addressed in each lab</li>
<li><strong>Assessment design</strong>: Align rubrics to LOs</li>
<li><strong>Accreditation</strong>: Map LOs to ACM/BCS requirements</li>
</ul>
<hr />
<h2 id="module-aims-not-learning-outcomes"><a class="header" href="#module-aims-not-learning-outcomes">Module Aims (Not Learning Outcomes)</a></h2>
<p>These <strong>four aims</strong> appear on the homepage.<br />
They are <strong>broad aspirational statements</strong> about what the module
enables you to do. They are <strong>not</strong> the same as Learning Outcomes (which are specific and measurable).</p>
<ol>
<li>Apply HCI principles to design inclusive interfaces</li>
<li>Evaluate accessibility and ethics in interactive systems</li>
<li>Implement server-first architecture with progressive enhancement</li>
<li>Communicate design decisions with evidence</li>
</ol>
<hr />
<h2 id="terminology-clarification"><a class="header" href="#terminology-clarification">Terminology Clarification</a></h2>
<h3 id="module-aims-1"><a class="header" href="#module-aims-1">Module Aims</a></h3>
<p><strong>Definition</strong>: Broad, aspirational statements about what the module sets out to achieve.</p>
<p><strong>Characteristics</strong>:</p>
<ul>
<li>High-level, conceptual</li>
<li>Focus on "enabling" or "equipping" students</li>
<li>Not directly assessed (but outcomes derived from aims are assessed)</li>
</ul>
<p><strong>Example</strong>: "This module aims to enable students to design accessible web interfaces."</p>
<h3 id="learning-outcomes-los"><a class="header" href="#learning-outcomes-los">Learning Outcomes (LOs)</a></h3>
<p><strong>Definition</strong>: Specific, measurable competencies that students will demonstrate by the end of the module.</p>
<p><strong>Characteristics</strong>:</p>
<ul>
<li>Use action verbs (apply, analyse, design, evaluate)</li>
<li>Aligned to Bloom's Taxonomy</li>
<li>Directly assessed</li>
<li>Mapped to accreditation standards (ACM, BCS)</li>
</ul>
<p><strong>Example</strong>: "LO4: Evaluate software interfaces for accessibility concerns using WCAG 2.2 AA standards."</p>
<h3 id="lab-objectives-12"><a class="header" href="#lab-objectives-12">Lab Objectives</a></h3>
<p><strong>Definition</strong>: Session-specific tasks and activities that contribute to achieving Learning Outcomes.</p>
<p><strong>Characteristics</strong>:</p>
<ul>
<li>Concrete, actionable</li>
<li>Time-bound (this lab session)</li>
<li>Contribute to one or more LOs</li>
</ul>
<p><strong>Example</strong>: "Run an axe DevTools audit and document 5+ WCAG violations" (contributes to LO4).</p>
<hr />
<h2 id="acm-cs2023-mapping"><a class="header" href="#acm-cs2023-mapping">ACM CS2023 Mapping</a></h2>
<p>The 13 HCI Learning Outcomes map to the following ACM Computer Science 2023 curriculum standards:</p>
<h3 id="human-computer-interaction-hc"><a class="header" href="#human-computer-interaction-hc">Human-Computer Interaction (HC)</a></h3>
<ul>
<li><strong>HC/2</strong>: Designing Interaction (LO4, LO9)</li>
<li><strong>HC/3</strong>: Prototyping Techniques (LO5)</li>
<li><strong>HC/4</strong>: Iterative Design (LO6, LO7)</li>
<li><strong>HC/5</strong>: Evaluation (LO1, LO8)</li>
</ul>
<h3 id="understanding-people-up"><a class="header" href="#understanding-people-up">Understanding People (UP)</a></h3>
<ul>
<li><strong>UP/1</strong>: User Research (LO1, LO2)</li>
<li><strong>UP/2</strong>: Needs Finding (LO2)</li>
<li><strong>UP/3</strong>: Accessibility &amp; Universal Design (LO9)</li>
</ul>
<h3 id="social-and-professional-issues-sp"><a class="header" href="#social-and-professional-issues-sp">Social and Professional Issues (SP)</a></h3>
<ul>
<li><strong>SP/1</strong>: Ethics in Computing (LO3, LO10)</li>
<li><strong>SP/2</strong>: Privacy &amp; Security (LO3)</li>
<li><strong>SP/Professional Skills</strong>: Teamwork, Communication (LO11, LO12)</li>
</ul>
<h3 id="software-engineering-processes-sep"><a class="header" href="#software-engineering-processes-sep">Software Engineering Processes (SEP)</a></h3>
<ul>
<li><strong>SEP/2</strong>: Requirements Engineering (LO2, LO13)</li>
<li><strong>SEP/3</strong>: Design Patterns &amp; Architecture (LO7, LO13)</li>
</ul>
<h3 id="web--mobile-systems"><a class="header" href="#web--mobile-systems">Web &amp; Mobile Systems</a></h3>
<ul>
<li><strong>Server-first patterns</strong> (LO5, LO7, LO13)</li>
<li><strong>Progressive enhancement</strong> (LO7, LO9)</li>
</ul>
<hr />
<h2 id="wcag-22-mapping"><a class="header" href="#wcag-22-mapping">WCAG 2.2 Mapping</a></h2>
<p>Learning Outcomes with direct WCAG 2.2 AA compliance requirements:</p>
<div class="table-wrapper"><table><thead><tr><th>LO</th><th>WCAG Principles</th><th>Key Success Criteria</th></tr></thead><tbody>
<tr><td><strong>LO4</strong></td><td>All (Perceivable, Operable, Understandable, Robust)</td><td>1.3.1 Info &amp; Relationships, 1.4.3 Contrast, 2.1.1 Keyboard, 2.4.7 Focus Visible, 4.1.2 Name/Role/Value</td></tr>
<tr><td><strong>LO9</strong></td><td>Operable, Understandable</td><td>2.1.1 Keyboard, 2.4.1 Skip Links, 2.4.3 Focus Order, 3.3.2 Labels, 4.1.3 Status Messages</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="for-students-self-assessment"><a class="header" href="#for-students-self-assessment">For Students: Self-Assessment</a></h2>
<p>Use this checklist to track your progress across the 13 HCI Learning Outcomes:</p>
<div class="table-wrapper"><table><thead><tr><th>LO</th><th>Outcome</th><th>Confidence (1‚Äì5)</th><th>Evidence Location</th></tr></thead><tbody>
<tr><td>LO1</td><td>Differentiate people-centred methods</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W6 L2 job stories, W9 L1 eval plan</td></tr>
<tr><td>LO2</td><td>Design and conduct needs-finding</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W6 L2 consent protocol</td></tr>
<tr><td>LO3</td><td>Analyse ethical implications</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W7 L1 consent modal, privacy audit</td></tr>
<tr><td>LO4</td><td>Evaluate for accessibility</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W7 L2 axe audit, WCAG map</td></tr>
<tr><td>LO5</td><td>Create prototypes</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W8 L1 HTMX features</td></tr>
<tr><td>LO6</td><td>Apply iterative design</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W9 L2 pilots ‚Üí W10 L2 redesign</td></tr>
<tr><td>LO7</td><td>Analyse design constraints</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W8 L2 no-JS trade-offs doc</td></tr>
<tr><td>LO8</td><td>Design and execute evaluation</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W9 L1 metrics + W9 L2 pilots</td></tr>
<tr><td>LO9</td><td>Apply inclusive design</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W7 L2 fix, W10 L2 redesign</td></tr>
<tr><td>LO10</td><td>Critique societal impacts</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W7 L1 ethics reflection</td></tr>
<tr><td>LO11</td><td>Collaborate in teams</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W9 L2 peer pilots, W11 L1 crit</td></tr>
<tr><td>LO12</td><td>Demonstrate professionalism</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>All labs: consent, citations</td></tr>
<tr><td>LO13</td><td>Integrate HCI with SE</td><td>‚òê‚òê‚òê‚òê‚òê</td><td>W8 L1 Ktor patterns, W9 L1 instrumentation</td></tr>
</tbody></table>
</div>
<p><strong>Confidence scale</strong>: 1 = Not confident, 3 = Moderately confident, 5 = Very confident</p>
<hr />
<h2 id="for-teaching-staff-using-this-reference"><a class="header" href="#for-teaching-staff-using-this-reference">For Teaching Staff: Using This Reference</a></h2>
<h3 id="curriculum-design"><a class="header" href="#curriculum-design">Curriculum Design</a></h3>
<ul>
<li>Ensure each LO has ‚â•2 touchpoints across weeks</li>
<li>Balance formative (practice) and summative (assessed) evidence</li>
<li>Check ACM/WCAG coverage for accreditation</li>
</ul>
<h3 id="assessment-design"><a class="header" href="#assessment-design">Assessment Design</a></h3>
<ul>
<li>Tasks 1 &amp; 2 should collectively assess all 13 LOs</li>
<li>Use cross-reference table to verify coverage</li>
<li>Map rubric criteria to specific LOs</li>
</ul>
<h3 id="student-support"><a class="header" href="#student-support">Student Support</a></h3>
<ul>
<li>Link to this reference in feedback ("see LO4 for accessibility criteria")</li>
<li>Use self-assessment checklist in tutorials</li>
<li>Explain aims vs outcomes vs objectives in Week 6</li>
</ul>
<h3 id="quality-assurance"><a class="header" href="#quality-assurance">Quality Assurance</a></h3>
<ul>
<li>Annual review: verify LO mappings still accurate</li>
<li>External examiner reports: reference this document</li>
<li>Student feedback: check if LO structure is clear</li>
</ul>
<hr />
<h2 id="version-history"><a class="header" href="#version-history">Version History</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Version</th><th>Date</th><th>Changes</th></tr></thead><tbody>
<tr><td>0.2</td><td>2025-11-07</td><td>Initial definitive reference created; standardised terminology; mapped 13 HCI LOs + 10 module LOs</td></tr>
<tr><td>0.1</td><td>2025-10-29</td><td>Initial draft created; added learning outcomes, aims, and cross-reference table</td></tr>
</tbody></table>
</div>
<hr />
<p><strong>Questions?</strong> See <a href="references/glossary.html">Glossary</a> for term definitions or contact module teaching staff.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="serverfirst-a-practical-guide-for-comp2850-hci"><a class="header" href="#serverfirst-a-practical-guide-for-comp2850-hci">Server‚ÄëFirst: A Practical Guide for COMP2850 (HCI)</a></h1>
<blockquote>
<p><strong>TL;DR</strong>: Render HTML on the <strong>server</strong> by default. Add interactivity as <strong><a href="references/glossary.html#progressive-enhancement">progressive enhancement</a></strong> using <a href="references/glossary.html#htmx">HTMX</a>. If JavaScript is off, everything still works. Use <strong><a href="references/glossary.html#prg">PRG (Post/Redirect/Get)</a></strong> for forms, return <strong><a href="references/glossary.html#fragment">fragments</a></strong> to HTMX when it asks, and make <strong><a href="references/glossary.html#accessibility">accessibility</a></strong> non‚Äënegotiable.</p>
</blockquote>
<p><strong>New to these terms?</strong> See the <strong><a href="references/glossary.html">Glossary</a></strong> for full definitions.</p>
<hr />
<h2 id="why-serverfirst"><a class="header" href="#why-serverfirst">Why "server‚Äëfirst"?</a></h2>
<ul>
<li><strong>Reliability</strong>: No dependency on client frameworks to show a page or submit a form.</li>
<li><strong>Simplicity</strong>: Routing, validation, and business logic live on the server (<a href="references/glossary.html#ktor">Ktor</a>). You avoid duplicating logic in the browser.</li>
<li><strong>Performance</strong>: Initial loads are fast (HTML streams quickly); interactivity is layered as needed.</li>
<li><strong><a href="references/glossary.html#accessibility">Accessibility</a></strong>: <a href="references/glossary.html#semantic-html">Semantic HTML</a>, sensible focus order, and <a href="references/glossary.html#aria">ARIA</a> work from the start.</li>
</ul>
<hr />
<h2 id="core-principles"><a class="header" href="#core-principles">Core principles</a></h2>
<ol>
<li><strong>Server renders the UI</strong> (full pages + partials).</li>
<li><strong><a href="references/glossary.html#progressive-enhancement">Progressive enhancement</a></strong> with <a href="references/glossary.html#htmx">HTMX</a> (or plain forms and links).</li>
<li><strong><a href="references/glossary.html#no-js-parity">No‚ÄëJS parity</a></strong> is mandatory‚Äîevery action has a full-page path.</li>
<li><strong><a href="references/glossary.html#prg">PRG pattern</a></strong> for all forms (avoid resubmits; clean URLs).</li>
<li><strong>One source of truth</strong>: validation and business rules on the server.</li>
<li><strong><a href="references/glossary.html#accessibility">Accessibility</a> by default</strong>: structure, labels, keyboard paths, and <a href="references/glossary.html#aria-live-region">live updates</a>.</li>
</ol>
<hr />
<h2 id="quickstart-checklist"><a class="header" href="#quickstart-checklist">Quick‚Äëstart checklist</a></h2>
<ul>
<li><input disabled="" type="checkbox"/>
<strong>Routes</strong> return full pages by default; fragments when <code>HX-Request: true</code> is present.</li>
<li><input disabled="" type="checkbox"/>
<strong>Forms</strong> use PRG: <code>POST /thing</code> ‚Üí validate ‚Üí save ‚Üí <code>redirect("/things")</code>.</li>
<li><input disabled="" type="checkbox"/>
<strong>HTMX</strong> requests hit the <em>same</em> routes; server returns only the fragment (no layout).</li>
<li><input disabled="" type="checkbox"/>
<strong>Validation</strong> errors re-render the form (full page or fragment) with error messages bound to fields.</li>
<li><input disabled="" type="checkbox"/>
<strong>Announcements</strong> use <code>aria-live="polite"</code> and/or <code>hx-swap-oob</code> for status banners.</li>
<li><input disabled="" type="checkbox"/>
<strong>No client-only state machines</strong>. Server owns state.</li>
<li><input disabled="" type="checkbox"/>
<strong>Links still work</strong> with normal navigation (use <code>hx-boost="true"</code> as a <a href="https://hypermedia.systems/htmx-patterns/">sprinkle</a> only).</li>
<li><input disabled="" type="checkbox"/>
<strong>Keyboard &amp; screen reader</strong> flows are tested (Tab order, headings, labels).</li>
<li><input disabled="" type="checkbox"/>
<strong>JS disabled</strong> tests pass (you can complete tasks end-to-end).</li>
</ul>
<hr />
<h2 id="minimal-reference-implementation"><a class="header" href="#minimal-reference-implementation">Minimal reference implementation</a></h2>
<h3 id="1-routing-in-ktor-kotlin"><a class="header" href="#1-routing-in-ktor-kotlin">1) Routing in Ktor (Kotlin)</a></h3>
<p>Use a helper to detect HTMX and return the right view.</p>
<pre><code class="language-kotlin">fun Application.module() {
    routing {
        // List
        get("/tasks") {
            val tasks = taskRepo.all()
            if (call.request.headers["HX-Request"] == "true") {
                call.respond(renderPartial("_tasks_table.peb", mapOf("tasks" to tasks)))
            } else {
                call.respond(renderPage("tasks.peb", mapOf("tasks" to tasks)))
            }
        }

        // Create (PRG)
        post("/tasks") {
            val params = call.receiveParameters()
            val title = params["title"]?.trim().orEmpty()

            val errors = mutableMapOf&lt;String, String&gt;()
            if (title.isBlank()) errors["title"] = "Title is required."

            if (errors.isNotEmpty()) {
                val model = mapOf("errors" to errors, "values" to params)
                if (call.request.headers["HX-Request"] == "true") {
                    // return just the form fragment with errors
                    call.respond(HttpStatusCode.UnprocessableEntity, renderPartial("_task_form.peb", model))
                } else {
                    call.respond(renderPage("task_new.peb", model))
                }
                return@post
            }

            taskRepo.add(title)
            // PRG: after success, redirect for full-page; or return fragment for HTMX
            if (call.request.headers["HX-Request"] == "true") {
                val tasks = taskRepo.all()
                call.respond(renderPartial("_tasks_table.peb", mapOf("tasks" to tasks, "flash" to "Task added")))
            } else {
                call.respondRedirect("/tasks?flash=Task+added")
            }
        }
    }
}
</code></pre>
<blockquote>
<p><strong>Notes</strong></p>
<ul>
<li><code>renderPage(template, model)</code> returns the <strong>full</strong> layout (header/footer + body).</li>
<li><code>renderPartial(template, model)</code> returns a <strong>fragment</strong> only (no Chrome).</li>
<li>HTMX sets <code>HX-Request: true</code> automatically‚Äîuse it to branch responses.</li>
<li>On error, send <strong>422 Unprocessable Entity</strong> for HTMX (helps debugging).</li>
</ul>
</blockquote>
<h3 id="2-templates-pebblefreemarkeretc"><a class="header" href="#2-templates-pebblefreemarkeretc">2) Templates (Pebble/FreeMarker/etc.)</a></h3>
<p><strong><code>tasks.peb</code></strong> (full page)</p>
<pre><code class="language-html">&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
  &lt;meta charset="utf-8" /&gt;
  &lt;title&gt;Tasks&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
  &lt;main&gt;
    &lt;h1&gt;Tasks&lt;/h1&gt;

    &lt;div id="alerts" aria-live="polite"&gt;
      {% if flash %}&lt;div class="alert"&gt;{{ flash }}&lt;/div&gt;{% endif %}
    &lt;/div&gt;

    &lt;section&gt;
      {% include "_task_form.peb" %}
    &lt;/section&gt;

    &lt;section id="tasks-table"&gt;
      {% include "_tasks_table.peb" %}
    &lt;/section&gt;
  &lt;/main&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<p><strong><code>_task_form.peb</code></strong> (fragment)</p>
<pre><code class="language-html">&lt;form action="/tasks" method="post"
      hx-post="/tasks" hx-target="#tasks-table" hx-swap="innerHTML"&gt;
  &lt;label for="title"&gt;Title&lt;/label&gt;
  &lt;input id="title" name="title" value="{{ values.title | default('') }}"
         aria-invalid="{{ errors.title ? 'true' : 'false' }}"
         aria-describedby="{{ errors.title ? 'title-error' : '' }}"&gt;

  {% if errors.title %}
    &lt;div id="title-error" class="error"&gt;{{ errors.title }}&lt;/div&gt;
  {% endif %}

  &lt;button type="submit"&gt;Add&lt;/button&gt;
&lt;/form&gt;
</code></pre>
<p><strong><code>_tasks_table.peb</code></strong> (fragment)</p>
<pre><code class="language-html">&lt;table role="table"&gt;
  &lt;thead&gt;
    &lt;tr&gt;&lt;th&gt;Title&lt;/th&gt;&lt;th&gt;Actions&lt;/th&gt;&lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
  {% for t in tasks %}
    &lt;tr&gt;
      &lt;td&gt;{{ t.title }}&lt;/td&gt;
      &lt;td&gt;
        &lt;button hx-delete="/tasks/{{ t.id }}"
                hx-target="#tasks-table"
                hx-swap="innerHTML"&gt;Delete&lt;/button&gt;
      &lt;/td&gt;
    &lt;/tr&gt;
  {% endfor %}
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;!-- Optional OOB flash update --&gt;
&lt;div id="alerts" hx-swap-oob="true" aria-live="polite"&gt;
  {% if flash %}&lt;div class="alert"&gt;{{ flash }}&lt;/div&gt;{% endif %}
&lt;/div&gt;
</code></pre>
<blockquote>
<p><strong>Why this works</strong></p>
<ul>
<li>Full page render for normal navigation.</li>
<li>HTMX swaps only <code>#tasks-table</code> (fast, minimal HTML over the wire).</li>
<li>Same URLs &amp; same controllers for both full and partial flows.</li>
<li><code>hx-swap-oob</code> lets us update the flash area <em>outside</em> the target region.</li>
</ul>
</blockquote>
<hr />
<h2 id="prg-postredirectget-done-right"><a class="header" href="#prg-postredirectget-done-right">PRG (Post/Redirect/Get) done right</a></h2>
<ul>
<li><strong>Full page</strong>: <code>POST /tasks</code> ‚Üí validate ‚Üí save ‚Üí <code>302 Location: /tasks</code> ‚Üí browser GETs ‚Üí shows ‚ÄúTask added‚Äù.</li>
<li><strong>HTMX</strong>: <code>POST /tasks</code> ‚Üí validate ‚Üí save ‚Üí return <strong>updated fragment</strong> (or send header <code>HX-Redirect: /tasks</code> if you want HTMX to follow a redirect).</li>
<li><strong>Avoid</strong> returning ‚Äúsuccess pages‚Äù to a POST. They break refresh/back and risk duplicate submissions.</li>
</ul>
<hr />
<h2 id="validation--errors"><a class="header" href="#validation--errors">Validation &amp; errors</a></h2>
<ul>
<li>Use server-side validators; <strong>never</strong> rely solely on client hints.</li>
<li>Return <strong>422</strong> with the form fragment and inline errors for HTMX.</li>
<li>For full pages, re-render the page with the form and errors bound.</li>
<li>Keep focus management in mind‚Äîon error, focus the first invalid field.</li>
</ul>
<hr />
<h2 id="accessibility-essentials-baked-in"><a class="header" href="#accessibility-essentials-baked-in">Accessibility essentials (baked in)</a></h2>
<ul>
<li>Semantic HTML: headings, lists, labels, landmark regions (<code>&lt;main&gt;</code>, <code>&lt;nav&gt;</code>).</li>
<li><strong>Labels</strong> bound to inputs; <strong>error text</strong> bound with <code>aria-describedby</code>.</li>
<li>Buttons are real <code>&lt;button&gt;</code> elements; links are <code>&lt;a&gt;</code> elements (not divs).</li>
<li><strong>Focus states</strong> visible; Tab order logical.</li>
<li>Live updates (<code>aria-live="polite"</code>) for flash/status messages.</li>
<li>Test with keyboard only and with a screen reader (e.g., Orca/NVDA/VoiceOver).</li>
</ul>
<hr />
<h2 id="progressive-enhancement-patterns"><a class="header" href="#progressive-enhancement-patterns">Progressive enhancement patterns</a></h2>
<h3 id="a-boost-links--forms-optional"><a class="header" href="#a-boost-links--forms-optional">A) Boost links &amp; forms (optional)</a></h3>
<pre><code class="language-html">&lt;body hx-boost="true"&gt;
  &lt;!-- Links and forms become HTMX requests automatically.
       Turn off if it confuses the flow for beginners. --&gt;
&lt;/body&gt;
</code></pre>
<h3 id="b-keep-urls-tidy-on-partial-swaps"><a class="header" href="#b-keep-urls-tidy-on-partial-swaps">B) Keep URLs tidy on partial swaps</a></h3>
<p>If a swap represents a ‚Äúreal‚Äù navigation, add <code>hx-push-url="true"</code> so the back button works as expected.</p>
<h3 id="c-small-composable-fragments"><a class="header" href="#c-small-composable-fragments">C) Small, composable fragments</a></h3>
<p>Prefer <code>_task_row.peb</code> included by <code>_tasks_table.peb</code> so you can swap a single row on update, e.g. <code>hx-target="#task-{{id}}"</code>.</p>
<hr />
<h2 id="debugging--testing"><a class="header" href="#debugging--testing">Debugging &amp; testing</a></h2>
<ul>
<li><strong>No‚ÄëJS test</strong>: Disable JS and complete every critical flow (create, list, delete).</li>
<li><strong>HTMX visibility</strong>: In the browser console, run <code>htmx.logAll()</code> to see events.</li>
<li><strong>Headers</strong>: Confirm <code>HX-Request: true</code> in devtools for HTMX requests.</li>
<li><strong>Status codes</strong>: Use 200/302 for success; 422 for validation errors.</li>
<li><strong>cURL</strong>: Simulate HTMX:
<pre><code class="language-bash">curl -H "HX-Request: true" http://localhost:8080/tasks
</code></pre>
</li>
</ul>
<hr />
<h2 id="security-notes"><a class="header" href="#security-notes">Security notes</a></h2>
<ul>
<li><strong>CSRF</strong>: Include a CSRF token in all forms (double-submit cookie or server session token). HTMX will submit it like any other field.</li>
<li><strong>Method safety</strong>: Use proper HTTP verbs (GET is read‚Äëonly; POST/PUT/PATCH/DELETE mutate).</li>
<li><strong>Validation &amp; encoding</strong>: Validate inputs; encode all dynamic output in templates.</li>
</ul>
<hr />
<h2 id="performance-tips"><a class="header" href="#performance-tips">Performance tips</a></h2>
<ul>
<li>Keep fragments <strong>small</strong> and <strong>cacheable</strong> where appropriate.</li>
<li>Avoid sending large JSON blobs. Send just the HTML you need.</li>
<li>Consider <strong>ETags/Last‚ÄëModified</strong> for GET endpoints with expensive renders.</li>
</ul>
<hr />
<h2 id="common-antipatterns-avoid"><a class="header" href="#common-antipatterns-avoid">Common anti‚Äëpatterns (avoid)</a></h2>
<ul>
<li>‚ùå Two separate apps (SPA + API) for simple CRUD‚Äîoverkill here.</li>
<li>‚ùå Client‚Äëside validation only‚Äîexcludes customers and risks bad data.</li>
<li>‚ùå Hidden, fragile UI state that the server doesn‚Äôt know about.</li>
<li>‚ùå POST responses that render success pages without redirects (breaks back/refresh).</li>
</ul>
<hr />
<h2 id="make-it-real-checklist-for-your-lab"><a class="header" href="#make-it-real-checklist-for-your-lab">‚ÄúMake it real‚Äù checklist for your lab</a></h2>
<ol>
<li>Build the <strong>list</strong> + <strong>create</strong> flows using the patterns above.</li>
<li>Add <strong>inline validation</strong> and a <strong>flash</strong> region.</li>
<li>Prove <strong>no‚ÄëJS parity</strong> by completing the flow with JS turned off.</li>
<li>Add one <strong>OOB update</strong> (e.g., flash, count badge).</li>
<li>Write a <strong>one‚Äëpage test plan</strong>: steps, expected results, and screenshots.</li>
</ol>
<hr />
<h2 id="appendix-tiny-helper-ktor"><a class="header" href="#appendix-tiny-helper-ktor">Appendix: tiny helper (Ktor)</a></h2>
<pre><code class="language-kotlin">fun ApplicationCall.isHtmx() = request.headers["HX-Request"] == "true"
</code></pre>
<p>Use <code>if (call.isHtmx()) renderPartial(...) else renderPage(...)</code> to keep controllers tidy.</p>
<hr />
<h3 id="final-thought"><a class="header" href="#final-thought">Final thought</a></h3>
<p><strong>Server‚Äëfirst ‚â† anti‚ÄëJavaScript.</strong> It's about choosing HTML as the reliable baseline, then layering interaction where it genuinely improves the experience. You'll build features faster, with fewer bugs, and everyone‚Äîincluding people navigating with assistive tech‚Äîbenefits.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="serverfirst-in-github-codespaces-ktor--htmx"><a class="header" href="#serverfirst-in-github-codespaces-ktor--htmx">Server‚ÄëFirst in GitHub Codespaces (Ktor + HTMX)</a></h1>
<p>This guide shows how to run the <strong>server‚Äëfirst</strong> pattern in <strong>GitHub Codespaces</strong> with <strong>Ktor</strong> and <strong>HTMX</strong>. It includes a minimal devcontainer, project skeleton, and common fixes.</p>
<hr />
<h2 id="what-youll-get"><a class="header" href="#what-youll-get">What you‚Äôll get</a></h2>
<ul>
<li>One‚Äëclick Codespaces environment (JDK 21 + Gradle).</li>
<li>Ktor server bound to <code>0.0.0.0</code>, using <code>$PORT</code> or <code>8080</code>.</li>
<li>FreeMarker templating (official Ktor support) with HTMX for progressive enhancement.</li>
<li>Works with JavaScript <strong>off</strong> (no‚ÄëJS parity).</li>
</ul>
<hr />
<h2 id="1-devcontainerdevcontainerjson"><a class="header" href="#1-devcontainerdevcontainerjson">1) <code>.devcontainer/devcontainer.json</code></a></h2>
<pre><code class="language-json">{
  "name": "COMP2850 Ktor (server-first)",
  "build": { "dockerfile": "Dockerfile" },
  "forwardPorts": [8080],
  "portsAttributes": {
    "8080": { "label": "Ktor app", "onAutoForward": "openPreview" }
  },
  "postCreateCommand": "chmod +x ./gradlew || true",
  "customizations": {
    "vscode": {
      "extensions": [
        "vscjava.vscode-java-pack",
        "fwcd.kotlin",
        "redhat.vscode-yaml",
        "editorconfig.editorconfig"
      ]
    }
  }
}
</code></pre>
<h2 id="2-devcontainerdockerfile"><a class="header" href="#2-devcontainerdockerfile">2) <code>.devcontainer/Dockerfile</code></a></h2>
<pre><code class="language-dockerfile">FROM mcr.microsoft.com/devcontainers/java:1-21-bullseye

# Optional: Gradle cache to speed up builds
ENV GRADLE_USER_HOME=/workspace/.gradle
</code></pre>
<h2 id="3-buildgradlekts-essentials"><a class="header" href="#3-buildgradlekts-essentials">3) <code>build.gradle.kts</code> (essentials)</a></h2>
<p>Uses <strong>Ktor 2.x + Netty + FreeMarker</strong> for smooth Codespaces support.</p>
<pre><code class="language-kotlin">plugins {
    application
    kotlin("jvm") version "2.0.0"
    id("io.ktor.plugin") version "2.3.11"
}

repositories { mavenCentral() }

val ktorVersion = "2.3.11"

dependencies {
    implementation("io.ktor:ktor-server-core-jvm:$ktorVersion")
    implementation("io.ktor:ktor-server-netty-jvm:$ktorVersion")
    implementation("io.ktor:ktor-server-freemarker-jvm:$ktorVersion")
    implementation("ch.qos.logback:logback-classic:1.4.14")

    testImplementation(kotlin("test"))
    testImplementation("io.ktor:ktor-server-tests-jvm:$ktorVersion")
}

application {
    mainClass.set("MainKt")
}

tasks.withType&lt;JavaExec&gt; {
    systemProperty("io.ktor.development", "true")
}
</code></pre>
<h2 id="4-srcmainkotlinmainkt"><a class="header" href="#4-srcmainkotlinmainkt">4) <code>src/main/kotlin/Main.kt</code></a></h2>
<pre><code class="language-kotlin">import io.ktor.server.application.*
import io.ktor.server.engine.*
import io.ktor.server.netty.*
import io.ktor.server.response.*
import io.ktor.server.request.*
import io.ktor.server.routing.*
import io.ktor.server.freemarker.*
import io.ktor.server.plugins.contentnegotiation.*
import io.ktor.http.*
import freemarker.cache.ClassTemplateLoader

fun main() {
    val port = System.getenv("PORT")?.toIntOrNull() ?: 8080
    embeddedServer(Netty, port = port, host = "0.0.0.0") {
        module()
    }.start(wait = true)
}

fun Application.module() {
    install(FreeMarker) {
        templateLoader = ClassTemplateLoader(this::class.java.classLoader, "templates")
    }
    install(ContentNegotiation)

    routing {
        get("/") {
            // Full-page render (server-first)
            call.respond(FreeMarkerContent("tasks.ftl", mapOf("tasks" to listOf("Example task"))))
        }

        post("/tasks") {
            val params = call.receiveParameters()
            val title = params["title"]?.trim().orEmpty()
            if (title.isBlank()) {
                // 422 for HTMX validation errors; full page flow would re-render with errors
                call.respond(HttpStatusCode.UnprocessableEntity, "Title is required")
                return@post
            }
            // PRG for full-page; for HTMX you can return a fragment or tell HTMX to redirect
            call.response.headers.append("HX-Redirect", "/")
            call.respond(HttpStatusCode.OK)
        }
    }
}
</code></pre>
<h2 id="5-srcmainresourcestemplatestasksftl-full-page--htmx"><a class="header" href="#5-srcmainresourcestemplatestasksftl-full-page--htmx">5) <code>src/main/resources/templates/tasks.ftl</code> (full page + HTMX)</a></h2>
<pre><code class="language-html">&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
  &lt;meta charset="utf-8"&gt;
  &lt;title&gt;Tasks&lt;/title&gt;
  &lt;script src="https://unpkg.com/htmx.org@1.9.10"&gt;&lt;/script&gt;
&lt;/head&gt;
&lt;body&gt;
  &lt;main&gt;
    &lt;h1&gt;Tasks&lt;/h1&gt;

    &lt;section aria-live="polite" id="alerts"&gt;&lt;/section&gt;

    &lt;form action="/tasks" method="post"
          hx-post="/tasks"
          hx-target="#alerts"
          hx-swap="innerHTML"&gt;
      &lt;label for="title"&gt;Title&lt;/label&gt;
      &lt;input id="title" name="title" required&gt;
      &lt;button type="submit"&gt;Add&lt;/button&gt;
    &lt;/form&gt;

    &lt;ul&gt;
      &lt;#list tasks as t&gt;
        &lt;li&gt;${t}&lt;/li&gt;
      &lt;/#list&gt;
    &lt;/ul&gt;
  &lt;/main&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<hr />
<h2 id="6-how-to-run-in-codespaces"><a class="header" href="#6-how-to-run-in-codespaces">6) How to run in Codespaces</a></h2>
<ol>
<li>Open the repo in Codespaces (with the <code>.devcontainer</code> files present).</li>
<li>In the terminal, run:
<pre><code class="language-bash">./gradlew run
</code></pre>
</li>
<li>Codespaces will auto‚Äëforward <strong>port 8080</strong> and open a preview. If not, open the <strong>Ports</strong> tab and make port 8080 <strong>Public</strong> or click the forwarded URL.</li>
</ol>
<hr />
<h2 id="7-common-gotchas-fix-quickly"><a class="header" href="#7-common-gotchas-fix-quickly">7) Common gotchas (fix quickly)</a></h2>
<ul>
<li><strong>Bind host</strong> to <code>0.0.0.0</code> (not <code>localhost</code>), or Codespaces can‚Äôt reach it.</li>
<li><strong>Use <code>$PORT</code></strong> if Codespaces provides one; default to 8080 otherwise.</li>
<li><strong>Official templates</strong>: stick to FreeMarker/Thymeleaf/Mustache/Velocity to reduce surprises.</li>
<li><strong>Fragments vs pages</strong>: HTMX sends <code>HX-Request: true</code>; branch accordingly if you add fragment routes.</li>
<li><strong>Live reload</strong>: <code>-Dio.ktor.development=true</code> is enabled via Gradle task config.</li>
</ul>
<hr />
<h2 id="8-optional-enhancements"><a class="header" href="#8-optional-enhancements">8) Optional enhancements</a></h2>
<ul>
<li><strong><code>hx-boost="true"</code></strong> to progressively enhance links/forms without changing routes.</li>
<li><strong>OOB updates</strong> (<code>hx-swap-oob</code>) for global banners like flash messages.</li>
<li><strong>Accessibility checks</strong>: keyboard‚Äëonly test, visible focus, labelled inputs, <code>aria-live</code> for status.</li>
<li><strong>cURL HTMX</strong>:
<pre><code class="language-bash">curl -H "HX-Request: true" http://localhost:8080/
</code></pre>
</li>
</ul>
<hr />
<h2 id="9-suggested-repo-structure"><a class="header" href="#9-suggested-repo-structure">9) Suggested repo structure</a></h2>
<pre><code>.
‚îú‚îÄ .devcontainer/
‚îÇ  ‚îú‚îÄ Dockerfile
‚îÇ  ‚îî‚îÄ devcontainer.json
‚îú‚îÄ src/
‚îÇ  ‚îú‚îÄ main/
‚îÇ  ‚îÇ  ‚îú‚îÄ kotlin/
‚îÇ  ‚îÇ  ‚îÇ  ‚îî‚îÄ Main.kt
‚îÇ  ‚îÇ  ‚îî‚îÄ resources/
‚îÇ  ‚îÇ     ‚îî‚îÄ templates/
‚îÇ  ‚îÇ        ‚îî‚îÄ tasks.ftl
‚îú‚îÄ build.gradle.kts
‚îî‚îÄ settings.gradle.kts
</code></pre>
<hr />
<div style="break-before: page; page-break-before: always;"></div><h1 id="pebble-templates-in-comp2850"><a class="header" href="#pebble-templates-in-comp2850">Pebble templates in COMP2850</a></h1>
<h2 id="what-is-pebble"><a class="header" href="#what-is-pebble">What is Pebble?</a></h2>
<p>Pebble is a lightweight HTML templating engine for the JVM. It takes plain text files (usually HTML) and replaces expressions, loops, and conditionals using the data you pass from Kotlin. Pebble renders on the server, so the browser receives fully formed HTML that works even when JavaScript is disabled.</p>
<h2 id="why-we-use-pebble"><a class="header" href="#why-we-use-pebble">Why we use Pebble</a></h2>
<ul>
<li>Server-first philosophy: we can build complete, accessible HTML before any enhancement.</li>
<li>Safe by default: output is escaped unless you explicitly mark it as safe, which reduces XSS risks.</li>
<li>Familiar syntax: Jinja- or Twig-style blocks (<code>{% %}</code>) and expressions (<code>{{ }}</code>) keep the learning curve gentle.</li>
<li>Layouts and partials: <code>extends</code>, <code>block</code>, and <code>include</code> let us reuse structure and enforce consistency.</li>
<li>No build tooling required: templates are plain files in <code>resources/templates/</code> so they work on RHEL lab machines and Codespaces without extra setup.</li>
</ul>
<h2 id="mental-model"><a class="header" href="#mental-model">Mental model</a></h2>
<ol>
<li>Ktor gathers or builds the data (for example <code>tasks: List&lt;Task&gt;</code>).</li>
<li>We call <code>PebbleRender.render("tasks/index.peb", model)</code> to render HTML as a string.</li>
<li>Ktor sends that HTML to the browser. HTMX can then request fragments of the same templates.</li>
</ol>
<p>Because rendering is server-side, keyboard-only usage, screen readers, and automated auditing tools get identical
content to the HTMX-enhanced version.</p>
<h2 id="syntax-common-examples"><a class="header" href="#syntax-common-examples">Syntax common examples</a></h2>
<pre><code class="language-pebble">{% extends "base.peb" %}
{% block content %}
  &lt;h1&gt;{{ title }}&lt;/h1&gt;
  &lt;ul&gt;
    {% for task in tasks %}
      &lt;li&gt;{{ task.title }}&lt;/li&gt;
    {% endfor %}
  &lt;/ul&gt;
{% endblock %}
</code></pre>
<ul>
<li><code>{% ... %}</code>: control structures (extends, block, if, for).</li>
<li><code>{{ ... }}</code>: output an expression; values are HTML-escaped automatically.</li>
<li><code>{# ... #}</code>: comments; they do not appear in the rendered output.</li>
</ul>
<h2 id="layouts-and-includes"><a class="header" href="#layouts-and-includes">Layouts and includes</a></h2>
<ul>
<li>Define shared chrome in <code>base.peb</code> and expose replaceable sections with <code>{% block %}</code>.</li>
<li>Pull reusable fragments into separate files and include them:
<pre><code class="language-pebble">{% include "tasks/item.peb" with task=task %}
</code></pre>
</li>
<li>Because includes are just files, we can create patterns like <code>_list.peb</code>, <code>_status.peb</code>, and <code>_pager.peb</code> once and reuse them across weeks.</li>
</ul>
<h2 id="passing-data-from-ktor"><a class="header" href="#passing-data-from-ktor">Passing data from Ktor</a></h2>
<pre><code class="language-kotlin">val model = mapOf(
    "title" to "Tasks",
    "tasks" to repo.all()
)
call.respondHtml(PebbleRender.render("tasks/index.peb", model))
</code></pre>
<p>Pebble sees the keys of the model map as variables in the template. Use descriptive names and prefer simple DTOs or immutable data to keep templates readable.</p>
<h2 id="friendliness-with-htmx-and-accessibility"><a class="header" href="#friendliness-with-htmx-and-accessibility">Friendliness with HTMX and accessibility</a></h2>
<ul>
<li>HTMX requests hit the same templates; we often render a partial (for example the <code>&lt;li&gt;</code> fragment) and return it.</li>
<li>Live regions (<code>role="status"</code>) live in <code>base.peb</code>, so every page automatically announces status updates.</li>
<li>Because Pebble renders semantic HTML, WCAG checks and screen readers work irrespective of JavaScript state.</li>
</ul>
<h2 id="debug-tips"><a class="header" href="#debug-tips">Debug tips</a></h2>
<ul>
<li>Pebble line numbers appear in stack traces. If you see <code>Line 24, Column 10</code>, open that template and check the expression.</li>
<li>When nothing renders, confirm the template path matches the file name and that you passed the expected keys in the model map.</li>
<li>To inspect the final HTML, view source in the browser or log the rendered string locally.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="pebble-template-engine-cheatsheet"><a class="header" href="#pebble-template-engine-cheatsheet">Pebble Template Engine Cheatsheet</a></h1>
<p><strong>Quick reference for COMP2850 HCI students</strong></p>
<hr />
<h2 id="1-basic-syntax"><a class="header" href="#1-basic-syntax">1. Basic Syntax</a></h2>
<h3 id="three-types-of-delimiters"><a class="header" href="#three-types-of-delimiters">Three Types of Delimiters</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Delimiter</th><th>Purpose</th><th>Example</th></tr></thead><tbody>
<tr><td><code>{{ }}</code></td><td><strong>Output</strong> - Print expressions</td><td><code>{{ task.title }}</code></td></tr>
<tr><td><code>{% %}</code></td><td><strong>Tags/Logic</strong> - Control flow</td><td><code>{% if completed %}...{% endif %}</code></td></tr>
<tr><td><code>{# #}</code></td><td><strong>Comments</strong> - Not rendered</td><td><code>{# TODO: Add pagination #}</code></td></tr>
</tbody></table>
</div>
<hr />
<h2 id="2-variables--output"><a class="header" href="#2-variables--output">2. Variables &amp; Output</a></h2>
<h3 id="simple-variables"><a class="header" href="#simple-variables">Simple Variables</a></h3>
<pre><code class="language-pebble">{{ taskTitle }}           {# Outputs: "Buy Groceries" #}
{{ taskCount }}           {# Outputs: 5 #}
{{ isCompleted }}         {# Outputs: true or false #}
</code></pre>
<h3 id="object-properties-dot-notation"><a class="header" href="#object-properties-dot-notation">Object Properties (Dot Notation)</a></h3>
<pre><code class="language-pebble">{{ task.id }}             {# Accesses task object's id property #}
{{ task.title }}          {# Accesses task object's title property #}
{{ task.createdAt }}      {# Accesses task object's createdAt property #}
</code></pre>
<h3 id="accessing-maps-from-kotlin"><a class="header" href="#accessing-maps-from-kotlin">Accessing Maps (from Kotlin)</a></h3>
<pre><code class="language-kotlin">// In Kotlin route:
mapOf("task" to task.toPebbleContext())

// In Pebble template:
{{ task.id }}             {# Accesses map key "id" #}
{{ task.completed }}      {# Accesses map key "completed" #}
</code></pre>
<hr />
<h2 id="3-filters-pipe-syntax"><a class="header" href="#3-filters-pipe-syntax">3. Filters (Pipe Syntax)</a></h2>
<p>Filters transform output values using the pipe <code>|</code> operator.</p>
<h3 id="common-filters"><a class="header" href="#common-filters">Common Filters</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Filter</th><th>Purpose</th><th>Example</th><th>Output</th></tr></thead><tbody>
<tr><td><code>length</code></td><td>Get collection size</td><td><code>{{ tasks | length }}</code></td><td><code>5</code></td></tr>
<tr><td><code>upper</code></td><td>Uppercase</td><td><code>{{ title | upper }}</code></td><td><code>"BUY GROCERIES"</code></td></tr>
<tr><td><code>lower</code></td><td>Lowercase</td><td><code>{{ title | lower }}</code></td><td><code>"buy groceries"</code></td></tr>
<tr><td><code>capitalise</code></td><td>Capitalise first letter</td><td><code>{{ status | capitalize }}</code></td><td><code>"Complete"</code></td></tr>
<tr><td><code>escape</code></td><td>HTML escape (auto in Pebble)</td><td><code>{{ userInput | escape }}</code></td><td><code>&amp;lt;script&amp;gt;</code></td></tr>
<tr><td><code>default</code></td><td>Fallback if null/empty</td><td><code>{{ title | default("Untitled") }}</code></td><td><code>"Untitled"</code> if title is null</td></tr>
<tr><td><code>date</code></td><td>Format date</td><td><code>{{ createdAt | date("yyyy-MM-dd") }}</code></td><td><code>"2025-10-14"</code></td></tr>
<tr><td><code>trim</code></td><td>Remove whitespace</td><td><code>{{ title | trim }}</code></td><td><code>"Buy groceries"</code> (no spaces)</td></tr>
</tbody></table>
</div>
<h3 id="chaining-filters"><a class="header" href="#chaining-filters">Chaining Filters</a></h3>
<pre><code class="language-pebble">{{ task.title | lower | capitalize }}
{# "buy groceries" ‚Üí "Buy groceries" #}

{{ tasks | length | default(0) }}
{# If tasks is null, output 0 #}
</code></pre>
<hr />
<h2 id="4-control-flow"><a class="header" href="#4-control-flow">4. Control Flow</a></h2>
<h3 id="if--else"><a class="header" href="#if--else">If / Else</a></h3>
<pre><code class="language-pebble">{% if task.completed %}
  &lt;span class="completed"&gt;‚úì Done&lt;/span&gt;
{% else %}
  &lt;span class="pending"&gt;Pending&lt;/span&gt;
{% endif %}
</code></pre>
<h3 id="if--elseif--else"><a class="header" href="#if--elseif--else">If / ElseIf / Else</a></h3>
<pre><code class="language-pebble">{% if taskCount == 0 %}
  &lt;p&gt;No tasks yet.&lt;/p&gt;
{% elseif taskCount == 1 %}
  &lt;p&gt;You have 1 task.&lt;/p&gt;
{% else %}
  &lt;p&gt;You have {{ taskCount }} tasks.&lt;/p&gt;
{% endif %}
</code></pre>
<h3 id="comparison-operators"><a class="header" href="#comparison-operators">Comparison Operators</a></h3>
<pre><code class="language-pebble">{% if count &gt; 5 %}          {# Greater than #}
{% if count &gt;= 5 %}         {# Greater than or equal #}
{% if count &lt; 5 %}          {# Less than #}
{% if count &lt;= 5 %}         {# Less than or equal #}
{% if count == 5 %}         {# Equal (use ==, not =) #}
{% if count != 5 %}         {# Not equal #}
</code></pre>
<h3 id="logical-operators"><a class="header" href="#logical-operators">Logical Operators</a></h3>
<pre><code class="language-pebble">{% if completed and visible %}           {# AND #}
{% if completed or visible %}            {# OR #}
{% if not completed %}                   {# NOT #}
{% if (a or b) and (c or d) %}          {# Grouping with () #}
</code></pre>
<h3 id="checking-for-nullempty"><a class="header" href="#checking-for-nullempty">Checking for Null/Empty</a></h3>
<pre><code class="language-pebble">{% if tasks is null %}                   {# Is null #}
{% if tasks is not null %}               {# Is not null #}
{% if tasks is empty %}                  {# Is null or empty collection #}
{% if title is defined %}                {# Variable exists #}
</code></pre>
<hr />
<h2 id="5-loops-for"><a class="header" href="#5-loops-for">5. Loops (For)</a></h2>
<h3 id="basic-for-loop"><a class="header" href="#basic-for-loop">Basic For Loop</a></h3>
<pre><code class="language-pebble">&lt;ul&gt;
  {% for task in tasks %}
    &lt;li&gt;{{ task.title }}&lt;/li&gt;
  {% endfor %}
&lt;/ul&gt;
</code></pre>
<h3 id="for-loop-with-empty-fallback"><a class="header" href="#for-loop-with-empty-fallback">For Loop with Empty Fallback</a></h3>
<pre><code class="language-pebble">&lt;ul&gt;
  {% for task in tasks %}
    &lt;li&gt;{{ task.title }}&lt;/li&gt;
  {% empty %}
    &lt;li&gt;No tasks to display.&lt;/li&gt;
  {% endfor %}
&lt;/ul&gt;
</code></pre>
<h3 id="loop-variables-special-properties"><a class="header" href="#loop-variables-special-properties">Loop Variables (Special Properties)</a></h3>
<p>Inside a <code>{% for %}</code> loop, you have access to special <code>loop</code> variables:</p>
<div class="table-wrapper"><table><thead><tr><th>Variable</th><th>Description</th><th>Example Value</th></tr></thead><tbody>
<tr><td><code>loop.index</code></td><td>Current iteration (1-based)</td><td><code>1, 2, 3, ...</code></td></tr>
<tr><td><code>loop.index0</code></td><td>Current iteration (0-based)</td><td><code>0, 1, 2, ...</code></td></tr>
<tr><td><code>loop.revindex</code></td><td>Iterations remaining (1-based)</td><td><code>5, 4, 3, ...</code></td></tr>
<tr><td><code>loop.revindex0</code></td><td>Iterations remaining (0-based)</td><td><code>4, 3, 2, ...</code></td></tr>
<tr><td><code>loop.first</code></td><td>True if first iteration</td><td><code>true</code> or <code>false</code></td></tr>
<tr><td><code>loop.last</code></td><td>True if last iteration</td><td><code>true</code> or <code>false</code></td></tr>
<tr><td><code>loop.length</code></td><td>Total number of items</td><td><code>5</code></td></tr>
</tbody></table>
</div>
<p><strong>Example</strong>:</p>
<pre><code class="language-pebble">{% for task in tasks %}
  &lt;li class="{% if loop.first %}first{% endif %} {% if loop.last %}last{% endif %}"&gt;
    {{ loop.index }}. {{ task.title }}
  &lt;/li&gt;
{% endfor %}
</code></pre>
<p>Output:</p>
<pre><code class="language-html">&lt;li class="first"&gt;1. Buy groceries&lt;/li&gt;
&lt;li&gt;2. Pay bills&lt;/li&gt;
&lt;li class="last"&gt;3. Call dentist&lt;/li&gt;
</code></pre>
<hr />
<h2 id="6-template-inheritance"><a class="header" href="#6-template-inheritance">6. Template Inheritance</a></h2>
<h3 id="base-template-_layoutbasepeb"><a class="header" href="#base-template-_layoutbasepeb">Base Template (<code>_layout/base.peb</code>)</a></h3>
<pre><code class="language-pebble">&lt;!DOCTYPE html&gt;
&lt;html lang="en"&gt;
&lt;head&gt;
  &lt;title&gt;{% block title %}Default Title{% endblock %}&lt;/title&gt;
&lt;/head&gt;
&lt;body&gt;
  &lt;header&gt;
    &lt;h1&gt;Task Manager&lt;/h1&gt;
  &lt;/header&gt;

  &lt;main&gt;
    {% block content %}
      {# Default content if child doesn't override #}
    {% endblock %}
  &lt;/main&gt;

  &lt;footer&gt;
    {% block footer %}
      &lt;p&gt;&amp;copy; 2025 COMP2850&lt;/p&gt;
    {% endblock %}
  &lt;/footer&gt;
&lt;/body&gt;
&lt;/html&gt;
</code></pre>
<h3 id="child-template-tasksindexpeb"><a class="header" href="#child-template-tasksindexpeb">Child Template (<code>tasks/index.peb</code>)</a></h3>
<pre><code class="language-pebble">{% extends "_layout/base.peb" %}

{% block title %}Task List{% endblock %}

{% block content %}
  &lt;h2&gt;Your Tasks&lt;/h2&gt;
  &lt;ul&gt;
    {% for task in tasks %}
      &lt;li&gt;{{ task.title }}&lt;/li&gt;
    {% endfor %}
  &lt;/ul&gt;
{% endblock %}
</code></pre>
<p><strong>Result</strong>: Child template inherits base layout, overrides <code>title</code> and <code>content</code> blocks.</p>
<hr />
<h2 id="7-including-partials"><a class="header" href="#7-including-partials">7. Including Partials</a></h2>
<h3 id="include-without-parameters"><a class="header" href="#include-without-parameters">Include Without Parameters</a></h3>
<pre><code class="language-pebble">{% include "tasks/_item.peb" %}
</code></pre>
<h3 id="include-with-parameters"><a class="header" href="#include-with-parameters">Include With Parameters</a></h3>
<pre><code class="language-pebble">{% for task in tasks %}
  {% include "tasks/_item.peb" with {"task": task} %}
{% endfor %}
</code></pre>
<h3 id="include-with-override-pass-specific-variables"><a class="header" href="#include-with-override-pass-specific-variables">Include With Override (Pass Specific Variables)</a></h3>
<pre><code class="language-pebble">{% include "tasks/_list.peb" with {"tasks": completedTasks, "heading": "Completed Tasks"} %}
</code></pre>
<p><strong>Note</strong>: <code>with</code> creates a new scope. Only variables explicitly passed are available in the included template.</p>
<hr />
<h2 id="8-comp2850-specific-patterns"><a class="header" href="#8-comp2850-specific-patterns">8. COMP2850-Specific Patterns</a></h2>
<h3 id="dual-mode-htmx-pattern"><a class="header" href="#dual-mode-htmx-pattern">Dual-Mode HTMX Pattern</a></h3>
<pre><code class="language-pebble">{# Full page vs partial detection #}
{% if isHtmx %}
  {# Return fragment only (no layout) #}
  {% include "tasks/_list.peb" %}
{% else %}
  {# Return full page (extends base) #}
  {% extends "_layout/base.peb" %}
  {% block content %}
    {% include "tasks/_list.peb" %}
  {% endblock %}
{% endif %}
</code></pre>
<h3 id="aria-live-region-status-announcements"><a class="header" href="#aria-live-region-status-announcements">ARIA Live Region (Status Announcements)</a></h3>
<pre><code class="language-pebble">&lt;div id="status" role="status" aria-live="polite" aria-atomic="true"&gt;
  {% if statusMessage %}
    {{ statusMessage }}
  {% endif %}
&lt;/div&gt;
</code></pre>
<h3 id="out-of-band-oob-updates"><a class="header" href="#out-of-band-oob-updates">Out-of-Band (OOB) Updates</a></h3>
<pre><code class="language-pebble">{# Update status region separately from main content #}
&lt;div id="status" hx-swap-oob="true" role="alert"&gt;
  Task "{{ task.title }}" added successfully!
&lt;/div&gt;

{# Main content also returned in same response #}
&lt;li id="task-{{ task.id }}"&gt;
  {{ task.title }}
&lt;/li&gt;
</code></pre>
<h3 id="task-list-with-accessibility"><a class="header" href="#task-list-with-accessibility">Task List with Accessibility</a></h3>
<pre><code class="language-pebble">&lt;ul id="task-list" aria-describedby="task-count"&gt;
  {% for task in tasks %}
    &lt;li id="task-{{ task.id }}"&gt;
      &lt;span&gt;{{ task.title }}&lt;/span&gt;
      &lt;form action="/tasks/{{ task.id }}/delete" method="post" style="display:inline;"&gt;
        &lt;button type="submit" aria-label="Delete task: {{ task.title }}"&gt;Delete&lt;/button&gt;
      &lt;/form&gt;
    &lt;/li&gt;
  {% empty %}
    &lt;li&gt;No tasks yet. Add one above!&lt;/li&gt;
  {% endfor %}
&lt;/ul&gt;
&lt;p id="task-count" class="visually-hidden"&gt;
  Showing {{ tasks | length }} tasks.
&lt;/p&gt;
</code></pre>
<hr />
<h2 id="9-common-mistakes--solutions"><a class="header" href="#9-common-mistakes--solutions">9. Common Mistakes &amp; Solutions</a></h2>
<h3 id="-wrong-using--for-comparison"><a class="header" href="#-wrong-using--for-comparison">‚ùå Wrong: Using <code>=</code> for Comparison</a></h3>
<pre><code class="language-pebble">{% if count = 5 %}  {# WRONG: Use == #}
</code></pre>
<h3 id="-right-use-"><a class="header" href="#-right-use-">‚úÖ Right: Use <code>==</code></a></h3>
<pre><code class="language-pebble">{% if count == 5 %}  {# CORRECT #}
</code></pre>
<hr />
<h3 id="-wrong-missing-quotes-in-strings"><a class="header" href="#-wrong-missing-quotes-in-strings">‚ùå Wrong: Missing Quotes in Strings</a></h3>
<pre><code class="language-pebble">{% if status == completed %}  {# WRONG: 'completed' is a variable #}
</code></pre>
<h3 id="-right-quote-string-literals"><a class="header" href="#-right-quote-string-literals">‚úÖ Right: Quote String Literals</a></h3>
<pre><code class="language-pebble">{% if status == "completed" %}  {# CORRECT: String literal #}
</code></pre>
<hr />
<h3 id="-wrong-accessing-undefined-variables"><a class="header" href="#-wrong-accessing-undefined-variables">‚ùå Wrong: Accessing Undefined Variables</a></h3>
<pre><code class="language-pebble">{{ user.name }}  {# ERROR if user is null #}
</code></pre>
<h3 id="-right-use-default-filter"><a class="header" href="#-right-use-default-filter">‚úÖ Right: Use Default Filter</a></h3>
<pre><code class="language-pebble">{{ user.name | default("Guest") }}  {# Safe: Returns "Guest" if null #}
</code></pre>
<hr />
<h3 id="-wrong-forgetting-endfor--endif"><a class="header" href="#-wrong-forgetting-endfor--endif">‚ùå Wrong: Forgetting <code>endfor</code> / <code>endif</code></a></h3>
<pre><code class="language-pebble">{% for task in tasks %}
  &lt;li&gt;{{ task.title }}&lt;/li&gt;
{# WRONG: Missing {% endfor %} #}
</code></pre>
<h3 id="-right-always-close-tags"><a class="header" href="#-right-always-close-tags">‚úÖ Right: Always Close Tags</a></h3>
<pre><code class="language-pebble">{% for task in tasks %}
  &lt;li&gt;{{ task.title }}&lt;/li&gt;
{% endfor %}  {# CORRECT #}
</code></pre>
<hr />
<h3 id="-wrong-using---for-output"><a class="header" href="#-wrong-using---for-output">‚ùå Wrong: Using <code>{% %}</code> for Output</a></h3>
<pre><code class="language-pebble">{% task.title %}  {# WRONG: Use {{ }} for output #}
</code></pre>
<h3 id="-right-use--"><a class="header" href="#-right-use--">‚úÖ Right: Use <code>{{ }}</code></a></h3>
<pre><code class="language-pebble">{{ task.title }}  {# CORRECT #}
</code></pre>
<hr />
<h2 id="10-debugging-tips"><a class="header" href="#10-debugging-tips">10. Debugging Tips</a></h2>
<h3 id="check-variable-type"><a class="header" href="#check-variable-type">Check Variable Type</a></h3>
<pre><code class="language-pebble">{# Temporarily output variable to see what it contains #}
&lt;pre&gt;{{ task }}&lt;/pre&gt;
</code></pre>
<h3 id="check-if-variable-exists"><a class="header" href="#check-if-variable-exists">Check If Variable Exists</a></h3>
<pre><code class="language-pebble">{% if task is defined %}
  Task exists: {{ task.title }}
{% else %}
  Task is undefined!
{% endif %}
</code></pre>
<h3 id="view-loop-variables"><a class="header" href="#view-loop-variables">View Loop Variables</a></h3>
<pre><code class="language-pebble">{% for task in tasks %}
  &lt;p&gt;Index: {{ loop.index }}, First: {{ loop.first }}, Last: {{ loop.last }}&lt;/p&gt;
{% endfor %}
</code></pre>
<h3 id="escape-html-to-see-raw-output"><a class="header" href="#escape-html-to-see-raw-output">Escape HTML to See Raw Output</a></h3>
<pre><code class="language-pebble">&lt;pre&gt;{{ task.title | escape }}&lt;/pre&gt;
</code></pre>
<hr />
<h2 id="11-pebble-vs-other-template-engines"><a class="header" href="#11-pebble-vs-other-template-engines">11. Pebble vs Other Template Engines</a></h2>
<p>If you've used other template engines, here's a quick comparison:</p>
<div class="table-wrapper"><table><thead><tr><th>Feature</th><th>Pebble</th><th>Thymeleaf</th><th>FreeMarker</th></tr></thead><tbody>
<tr><td>Variables</td><td><code>{{ var }}</code></td><td><code>${var}</code></td><td><code>${var}</code></td></tr>
<tr><td>If statement</td><td><code>{% if %}</code></td><td><code>th:if</code></td><td><code>&lt;#if&gt;</code></td></tr>
<tr><td>For loop</td><td><code>{% for %}</code></td><td><code>th:each</code></td><td><code>&lt;#list&gt;</code></td></tr>
<tr><td>Comments</td><td><code>{# #}</code></td><td><code>&lt;!--/* */--&gt;</code></td><td><code>&lt;#-- --&gt;</code></td></tr>
<tr><td>Inheritance</td><td><code>{% extends %}</code></td><td><code>th:replace</code></td><td><code>&lt;#include&gt;</code></td></tr>
</tbody></table>
</div>
<hr />
<h2 id="12-resources"><a class="header" href="#12-resources">12. Resources</a></h2>
<h3 id="official-documentation"><a class="header" href="#official-documentation">Official Documentation</a></h3>
<ul>
<li><strong>Pebble Docs</strong>: https://pebbletemplates.io/</li>
<li><strong>Syntax Guide</strong>: https://pebbletemplates.io/wiki/guide/basic-usage/</li>
<li><strong>Filters Reference</strong>: https://pebbletemplates.io/wiki/filter/abs/</li>
</ul>
<h3 id="comp2850-specific"><a class="header" href="#comp2850-specific">COMP2850-Specific</a></h3>
<ul>
<li>Week 6 Lab 1: Pebble syntax primer (inline)</li>
<li><code>pebble-intro.md</code>: Longer introduction to Pebble</li>
</ul>
<h3 id="getting-help"><a class="header" href="#getting-help">Getting Help</a></h3>
<ul>
<li><strong>Syntax errors</strong>: Check matching tags (<code>{% if %}</code> needs <code>{% endif %}</code>)</li>
<li><strong>Variable undefined</strong>: Use <code>| default()</code> filter or check spelling</li>
<li><strong>Unexpected output</strong>: Use <code>&lt;pre&gt;{{ var }}&lt;/pre&gt;</code> to inspect variable</li>
</ul>
<hr />
<p><strong>Cheatsheet Version</strong>: 1.0
<strong>Last Updated</strong>: 2025-10-14
<strong>Module</strong>: COMP2850 HCI</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="htmx-patterns--progressive-enhancement"><a class="header" href="#htmx-patterns--progressive-enhancement">HTMX Patterns &amp; Progressive Enhancement</a></h1>
<h2 id="what-is-htmx"><a class="header" href="#what-is-htmx">What is HTMX?</a></h2>
<p><strong>HTMX</strong> is a JavaScript library that lets you build <strong>dynamic web interfaces</strong> using <strong>HTML attributes</strong> instead of writing JavaScript code. It extends HTML with attributes like <code>hx-get</code>, <code>hx-post</code>, <code>hx-target</code>, and <code>hx-swap</code> that trigger <a href="references/glossary.html#ajax">AJAX</a> requests and update parts of the page.</p>
<p><strong>Key idea</strong>: The server sends <strong><a href="references/glossary.html#fragment">HTML fragments</a></strong> (not <a href="references/glossary.html#json">JSON</a>), and HTMX swaps them into the page. You write normal HTML forms and links, add a few <code>hx-*</code> attributes, and suddenly they work dynamically without page reloads.</p>
<p><strong>Core text</strong>: <a href="https://hypermedia.systems/">Hypermedia Systems</a> by Carson Gross, Adam Stepinski, and Deniz Ak≈üim≈üek (2023) - read Chapters 1-6 for foundations.</p>
<h2 id="why-htmx-for-hci"><a class="header" href="#why-htmx-for-hci">Why HTMX for HCI?</a></h2>
<ol>
<li><strong><a href="references/glossary.html#accessibility">Accessibility</a> by default</strong> - Server controls HTML structure, ensuring <a href="references/glossary.html#semantic-html">semantic markup</a>, <a href="references/glossary.html#aria">ARIA</a> roles, and <a href="references/glossary.html#screen-reader">screen reader</a> compatibility</li>
<li><strong><a href="references/glossary.html#progressive-enhancement">Progressive enhancement</a></strong> - Everything works without JavaScript; HTMX enhances the experience when available</li>
<li><strong>Simplicity</strong> - No build tools, no client-side state management, no framework complexity</li>
<li><strong><a href="references/glossary.html#hypermedia">Hypermedia</a>-driven</strong> - Follows <a href="references/glossary.html#rest">REST</a>/<a href="references/glossary.html#hateoas">HATEOAS</a> principles - the server tells the client what to display (HTML) and what actions are available (links/forms)</li>
</ol>
<h2 id="how-it-works"><a class="header" href="#how-it-works">How it works</a></h2>
<ol>
<li><strong>Human interaction</strong> - Click a button, submit a form, type in a search box</li>
<li><strong>HTMX sends AJAX request</strong> - Adds <code>HX-Request: true</code> <a href="references/glossary.html#request-headers">header</a> so server knows it's AJAX</li>
<li><strong>Server responds with HTML</strong> - Returns a <a href="references/glossary.html#fragment">fragment</a> (e.g., <code>&lt;li&gt;New item&lt;/li&gt;</code>) not a full page</li>
<li><strong>HTMX swaps the fragment</strong> - Updates the target element (append, replace, etc.)</li>
<li><strong>Screen readers announce</strong> - <a href="references/glossary.html#aria-live-region">ARIA live regions</a> announce changes automatically</li>
</ol>
<p><strong>Example</strong>:</p>
<pre><code class="language-html">&lt;button hx-get="/tasks/123" hx-target="#content"&gt;Load Task&lt;/button&gt;
</code></pre>
<ul>
<li>Click ‚Üí AJAX GET to <code>/tasks/123</code></li>
<li>Server returns HTML: <code>&lt;div&gt;Task details...&lt;/div&gt;</code></li>
<li>HTMX replaces <code>#content</code> with the response</li>
<li>No page reload, no JavaScript written by you</li>
</ul>
<h2 id="core-attributes"><a class="header" href="#core-attributes">Core Attributes</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Attribute</th><th>Purpose</th><th>Example</th></tr></thead><tbody>
<tr><td><code>hx-get</code></td><td>HTTP GET request</td><td><code>&lt;button hx-get="/tasks"&gt;</code></td></tr>
<tr><td><code>hx-post</code></td><td>HTTP POST request</td><td><code>&lt;form hx-post="/tasks"&gt;</code></td></tr>
<tr><td><code>hx-target</code></td><td>Where to insert response</td><td><code>hx-target="#task-list"</code></td></tr>
<tr><td><code>hx-swap</code></td><td>How to insert (replace/append/etc.)</td><td><code>hx-swap="beforeend"</code></td></tr>
<tr><td><code>hx-trigger</code></td><td>What event triggers request</td><td><code>hx-trigger="keyup changed delay:300ms"</code></td></tr>
<tr><td><code>hx-swap-oob</code></td><td>Update element outside target</td><td><code>&lt;div id="status" hx-swap-oob="true"&gt;</code></td></tr>
</tbody></table>
</div>
<h2 id="progressive-enhancement-pattern"><a class="header" href="#progressive-enhancement-pattern">Progressive Enhancement Pattern</a></h2>
<p>Every HTMX feature must have a <strong><a href="references/glossary.html#no-js-parity">no-JS fallback</a></strong>:</p>
<pre><code class="language-html">&lt;!-- Works WITHOUT JavaScript (full page POST-Redirect-GET) --&gt;
&lt;!-- Works WITH JavaScript (HTMX AJAX, fragment swap) --&gt;
&lt;form action="/tasks" method="post"
      hx-post="/tasks"
      hx-target="#task-list"
      hx-swap="beforeend"&gt;
  &lt;input name="title" required&gt;
  &lt;button type="submit"&gt;Add Task&lt;/button&gt;
&lt;/form&gt;
</code></pre>
<p><strong>Server detects HTMX</strong>:</p>
<pre><code class="language-kotlin">if (call.request.headers["HX-Request"] == "true") {
    // Return fragment for HTMX
    call.respondText("&lt;li&gt;New task&lt;/li&gt;", ContentType.Text.Html)
} else {
    // Return full page or redirect for no-JS
    call.respondRedirect("/tasks")
}
</code></pre>
<hr />
<h2 id="common-patterns"><a class="header" href="#common-patterns">Common Patterns</a></h2>
<p>Use these canonical patterns repeatedly across Weeks 6‚Äì10. Each snippet assumes the server exposes matching routes and keeps the no-JS fallback intact.</p>
<h2 id="1-active-search--filter"><a class="header" href="#1-active-search--filter">1. Active Search / Filter</a></h2>
<p><strong>üìñ Reference</strong>: <a href="https://hypermedia.systems/more-htmx-patterns/#_active_search">Hypermedia Systems, Ch. 6: More HTMX Patterns</a></p>
<p>Filter results as people type, with history support and a live status update.</p>
<pre><code class="language-html">&lt;form action="/tasks" method="get"
      hx-get="/tasks/fragment"
      hx-target="#task-area"
      hx-trigger="keyup changed delay:300ms, submit from:closest(form)"
      hx-push-url="true"&gt;
  &lt;label for="q"&gt;Filter tasks&lt;/label&gt;
  &lt;input id="q" name="q" type="search" aria-describedby="q-hint"&gt;
  &lt;small id="q-hint"&gt;Type to filter. Works without JavaScript.&lt;/small&gt;
  &lt;button type="submit"&gt;Apply&lt;/button&gt;
&lt;/form&gt;

&lt;div id="task-area" hx-indicator="#loading"&gt;
  &lt;progress id="loading" class="visually-hidden" aria-hidden="true"&gt;&lt;/progress&gt;
  {% include "tasks/_list.peb" %}
  {% include "tasks/_pager.peb" %}
&lt;/div&gt;
</code></pre>
<p>Server path (return list + pager + status when HX request):</p>
<pre><code class="language-kotlin">get("/tasks/fragment") {
    val q = call.request.queryParameters["q"].orEmpty()
    val page = call.request.queryParameters["page"]?.toIntOrNull() ?: 1
    val data = repo.search(q, page)
    val list = PebbleRender.render("tasks/_list.peb", mapOf("page" to data, "q" to q))
    val pager = PebbleRender.render("tasks/_pager.peb", mapOf("page" to data, "q" to q))
    val status = """&lt;div id="status" hx-swap-oob="true"&gt;Found ${data.total} tasks.&lt;/div&gt;"""
    call.respondText(list + pager + status, ContentType.Text.Html)
}
</code></pre>
<h2 id="2-oob-out-of-band-status-messages"><a class="header" href="#2-oob-out-of-band-status-messages">2. OOB (Out-of-Band) Status Messages</a></h2>
<p><strong>üìñ Reference</strong>: <a href="https://htmx.org/attributes/hx-swap-oob/">HTMX Docs: hx-swap-oob</a> | <a href="https://hypermedia.systems/hypermedia-on-the-web/#_practical_patterns">Hypermedia Systems, Ch. 9</a></p>
<p>Announce changes without touching focus.</p>
<pre><code class="language-html">&lt;p id="status" role="status" aria-live="polite" class="visually-hidden"&gt;&lt;/p&gt;
</code></pre>
<pre><code class="language-kotlin">val status = """&lt;div id="status" hx-swap-oob="true"&gt;Added "${task.title}".&lt;/div&gt;"""
call.respondText(fragment + status, ContentType.Text.Html)
</code></pre>
<h2 id="3-inline-edit-click-to-edit"><a class="header" href="#3-inline-edit-click-to-edit">3. Inline Edit (Click to Edit)</a></h2>
<p><strong>üìñ Reference</strong>: <a href="https://hypermedia.systems/htmx-patterns/#_click_to_edit">Hypermedia Systems, Ch. 5: HTMX Patterns</a></p>
<p>Swap a container after a PATCH-like request (inline editing).</p>
<pre><code class="language-html">&lt;form action="/tasks/{{ task.id }}/edit" method="post"
      hx-post="/tasks/{{ task.id }}/edit"
      hx-target="#task-{{ task.id }}"
      hx-swap="outerHTML"&gt;
  &lt;!-- label + input + button --&gt;
&lt;/form&gt;
</code></pre>
<h2 id="4-deferred-swap-after-swap-delay"><a class="header" href="#4-deferred-swap-after-swap-delay">4. Deferred Swap (after swap delay)</a></h2>
<p>Useful for optimistic UI (e.g. show success, then clear form).</p>
<pre><code class="language-html">&lt;div hx-target="this"
     hx-swap="outerHTML settle:1s"&gt;
  &lt;p class="success"&gt;Saved!&lt;/p&gt;
&lt;/div&gt;
</code></pre>
<h2 id="5-multi-target-updates"><a class="header" href="#5-multi-target-updates">5. Multi-target updates</a></h2>
<p>Use <code>hx-swap-oob</code> to update multiple DOM nodes from one response.</p>
<pre><code class="language-html">&lt;div id="summary" hx-swap-oob="true"&gt;‚Ä¶&lt;/div&gt;
&lt;li id="task-3"&gt;‚Ä¶&lt;/li&gt;
</code></pre>
<h2 id="6-indicators--disabled-states"><a class="header" href="#6-indicators--disabled-states">6. Indicators &amp; Disabled States</a></h2>
<pre><code class="language-html">&lt;form hx-post="/tasks" hx-target="#task-list" hx-disabled-elt="[data-disable]"&gt;
  &lt;button data-disable&gt;Save&lt;/button&gt;
  &lt;div class="spinner" hx-indicator&gt;&lt;/div&gt;
&lt;/form&gt;
</code></pre>
<h2 id="7-confirmcancel-actions"><a class="header" href="#7-confirmcancel-actions">7. Confirm/Cancel Actions</a></h2>
<pre><code class="language-html">&lt;button hx-delete="/tasks/{{ task.id }}"
        hx-target="#task-{{ task.id }}"
        hx-swap="outerHTML"
        hx-confirm="Delete this task?"&gt;
  Delete
&lt;/button&gt;
</code></pre>
<h2 id="8-lazy-loading"><a class="header" href="#8-lazy-loading">8. Lazy Loading</a></h2>
<p><strong>üìñ Reference</strong>: <a href="https://hypermedia.systems/more-htmx-patterns/#_lazy_loading">Hypermedia Systems, Ch. 6: More HTMX Patterns</a></p>
<p>Lazy load content</p>
<pre><code class="language-html">&lt;div hx-get="/tasks/details/{{ task.id }}"
     hx-trigger="revealed"&gt;
  Loading‚Ä¶
&lt;/div&gt;
</code></pre>
<p>Keep parity: every pattern must have a server-rendered fallback so the same request works without HTMX attributes present.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="worked-example--accessible-inline-edit-week-7-lab-2"><a class="header" href="#worked-example--accessible-inline-edit-week-7-lab-2">Worked Example ‚Äî Accessible Inline Edit (Week 7 Lab 2)</a></h1>
<h2 id="scenario"><a class="header" href="#scenario">Scenario</a></h2>
<p>Inline edit form for updating a task title.
Original implementation failed accessibility checks:</p>
<ul>
<li>No label tied to the input generated for editing</li>
<li>Error message appended visually but not announced</li>
<li>Focus jumped unexpectedly after save</li>
</ul>
<h2 id="before-problematic-code"><a class="header" href="#before-problematic-code">Before (problematic code)</a></h2>
<pre><code class="language-pebble">&lt;li id="task-{{ task.id }}"&gt;
  &lt;span&gt;{{ task.title }}&lt;/span&gt;
  &lt;form action="/tasks/{{ task.id }}/edit" method="post"
        hx-post="/tasks/{{ task.id }}/edit"
        hx-target="#task-{{ task.id }}"&gt;
    &lt;input name="title" value="{{ task.title }}"&gt;
    &lt;button type="submit"&gt;Save&lt;/button&gt;
  &lt;/form&gt;
&lt;/li&gt;
</code></pre>
<p>Issues found in audit:</p>
<ul>
<li>Missing <code>&lt;label&gt;</code> and <code>id</code> ‚Üí fails WCAG 1.3.1 (A)</li>
<li>No error summary or field-level association</li>
<li>Screen readers received no confirmation message</li>
</ul>
<h2 id="after-fixed-version"><a class="header" href="#after-fixed-version">After (fixed version)</a></h2>
<pre><code class="language-pebble">&lt;li id="task-{{ task.id }}"&gt;
  &lt;form action="/tasks/{{ task.id }}/edit" method="post"
        hx-post="/tasks/{{ task.id }}/edit"
        hx-target="#task-{{ task.id }}"
        hx-swap="outerHTML"&gt;
    &lt;label class="visually-hidden" for="title-{{ task.id }}"&gt;
      Edit title for {{ task.title }}
    &lt;/label&gt;
    &lt;input id="title-{{ task.id }}" name="title" value="{{ task.title }}"
           aria-describedby="hint-{{ task.id }}"&gt;
    &lt;small id="hint-{{ task.id }}" class="visually-hidden"&gt;
      Keep titles concise; changes announce in status area.
    &lt;/small&gt;
    &lt;button type="submit"&gt;Save&lt;/button&gt;
  &lt;/form&gt;
&lt;/li&gt;
</code></pre>
<p>Server route (Ktor) now logs validation errors and returns OOB status updates:</p>
<pre><code class="language-kotlin">post("/tasks/{id}/edit") {
    val id = call.parameters["id"]?.toIntOrNull() ?: return@post call.respond(HttpStatusCode.BadRequest)
    val title = call.receiveParameters()["title"].orEmpty().trim()
    if (title.isBlank()) {
        val fragment = PebbleRender.render("tasks/edit-error.peb", mapOf("task" to repo.get(id)))
        val status = """&lt;div id="status" hx-swap-oob="true"&gt;Title is required.&lt;/div&gt;"""
        // Logger implementation covered in Week 9; shown here for completeness
        Logger.write(session = sid(call), req = reqId(call), task = "T2_edit", step = "validation_error", outcome = "blank_title", ms = 0, status = 400, js = jsMode(call))
        return@post call.respondText(fragment + status, ContentType.Text.Html)
    }

    repo.update(id, title)
    val fragment = PebbleRender.render("tasks/item.peb", mapOf("task" to repo.get(id)))
    val status = """&lt;div id="status" hx-swap-oob="true"&gt;Updated "$title".&lt;/div&gt;"""
    call.respondText(fragment + status, ContentType.Text.Html)
}
</code></pre>
<p>Checklist we ticked off:</p>
<ul>
<li>‚úÖ Field has a label (visually hidden) and <code>aria-describedby</code></li>
<li>‚úÖ Error path returns fragment with inline message + status update</li>
<li>‚úÖ Success path announces change via live region (<code>status</code> element in base template)</li>
<li>‚úÖ Focus management: HTMX attempts to restore focus to the matching <code>id="title-{{ task.id }}"</code> after swap; test with keyboard navigation to verify behaviour</li>
<li>‚úÖ Logger records validation errors for metrics analysis (Week 9 addition)</li>
</ul>
<h2 id="evidence-to-capture-for-task-1"><a class="header" href="#evidence-to-capture-for-task-1">Evidence to capture (for Task 1)</a></h2>
<ul>
<li>Screenshot of before/after (with annotations on label / status)</li>
<li>Screen reader transcript (NVDA) confirming: ‚ÄúUpdated "Submit report".‚Äù</li>
<li>Backlog entry referencing WCAG 1.3.1 and 4.1.3</li>
</ul>
<p>Use this pattern as a blueprint: the key is tying markup + server response + evidence together.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="assistive-technology-testing-checklist-week-6--week-11"><a class="header" href="#assistive-technology-testing-checklist-week-6--week-11">Assistive Technology Testing Checklist (Week 6 ‚Üí Week 11)</a></h1>
<h2 id="what-is-accessibility-first-design"><a class="header" href="#what-is-accessibility-first-design">What is Accessibility-First Design?</a></h2>
<p><strong>Accessibility-first design</strong> means building interfaces that work for everyone from the start‚Äînot retrofitting accessible features after the fact. In this module, we prioritise:</p>
<ul>
<li><strong><a href="references/glossary.html#wcag">WCAG</a> 2.2 AA compliance</strong> as the minimum standard for all features</li>
<li><strong><a href="references/glossary.html#screen-reader">Screen reader</a> compatibility</strong> verified through NVDA/Orca testing in every lab</li>
<li><strong>Keyboard navigation</strong> ensuring all interactions work without a mouse</li>
<li><strong><a href="references/glossary.html#no-js-parity">No-JS parity</a></strong> so core functionality remains available when JavaScript fails or is unavailable</li>
<li><strong>Inclusive design</strong> informed by people-centred language and real customer needs</li>
</ul>
<p>Unlike "accessibility as an audit" (checking compliance at the end), accessibility-first means every design decision‚Äîfrom route structure to <a href="references/glossary.html#aria">ARIA</a> attributes to colour contrast‚Äîis evaluated for inclusion before implementation. This approach reduces technical debt, improves usability for all users, and ensures legal compliance with the Equality Act 2010 and UK GDPR.</p>
<h2 id="testing-checklist"><a class="header" href="#testing-checklist">Testing Checklist</a></h2>
<p>Use this mini-check at the end of every lab to capture evidence quickly. Print it or keep it in your repo (<code>testing/checklist.md</code>).</p>
<div class="table-wrapper"><table><thead><tr><th>Area</th><th>Steps</th><th>Evidence to capture</th></tr></thead><tbody>
<tr><td>Keyboard-only</td><td>Tab through the entire flow: skip link ‚Üí forms ‚Üí buttons. Ensure visible focus.</td><td>Screenshot or short note confirming order + any issues.</td></tr>
<tr><td>No-JS parity</td><td>Disable JS (DevTools) and repeat the task. Watch network panel to confirm only full-page requests.</td><td>Browser screenshot + note. If broken, log backlog item.</td></tr>
<tr><td>Screen reader (SR)</td><td>NVDA (Windows) or Orca (RHEL): navigate headings (<code>H</code>), forms (<code>F</code>), run the interaction, listen for live status.</td><td>Transcript snippet or notes of announcements.</td></tr>
<tr><td>Zoom &amp; reflow</td><td>Zoom to 200%; ensure layout doesn‚Äôt break and no horizontal scroll on desktop widths.</td><td>Screenshot at 200% zoom.</td></tr>
<tr><td>Colour/contrast</td><td>Use built-in contrast checker or extension (e.g. Chrome DevTools ‚Üí CSS overview).</td><td>Contrast report or note with values.</td></tr>
<tr><td>Error messaging</td><td>Trigger validation errors; confirm focus stays in context and SR announces the message.</td><td>Screenshot of error + note on announcement.</td></tr>
<tr><td>Metrics logging (when added)</td><td>Confirm <code>data/metrics.csv</code> records success + validation_error rows.</td><td>Copy of latest rows or summary in notes.</td></tr>
</tbody></table>
</div>
<h2 id="tips"><a class="header" href="#tips">Tips</a></h2>
<ul>
<li>Pair up: one person drives, another logs issues in <code>backlog/backlog.csv</code>.</li>
<li>If a check fails, capture it immediately‚Äîauditors and Week 7-10 labs rely on real evidence.</li>
<li>Create an <code>evidence/</code> directory in your repo and store artefacts per week (e.g., <code>evidence/wk6/</code>, <code>evidence/wk7/</code>) to keep things tidy.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="assistive-technology-testing-checklist-week-6--week-11-1"><a class="header" href="#assistive-technology-testing-checklist-week-6--week-11-1">Assistive Technology Testing Checklist (Week 6 ‚Üí Week 11)</a></h1>
<p>Use this mini-check at the end of every lab to capture evidence quickly. Print it or keep it in your repo (<code>testing/checklist.md</code>).</p>
<div class="table-wrapper"><table><thead><tr><th>Area</th><th>Steps</th><th>Evidence to capture</th></tr></thead><tbody>
<tr><td>Keyboard-only</td><td>Tab through the entire flow: skip link ‚Üí forms ‚Üí buttons. Ensure visible focus.</td><td>Screenshot or short note confirming order + any issues.</td></tr>
<tr><td>No-JS parity</td><td>Disable JS (DevTools) and repeat the task. Watch network panel to confirm only full-page requests.</td><td>Browser screenshot + note. If broken, log backlog item.</td></tr>
<tr><td>Screen reader (SR)</td><td><strong>NVDA</strong> (Windows, free), <strong>VoiceOver</strong> (macOS, built-in), or <strong>Orca</strong> (Linux/RHEL, built-in but can be clunky‚Äîsee <a href="references/assistive-testing-checklist.html#orca-linux">setup notes</a>). Navigate headings (<code>H</code>), forms (<code>F</code>), run the interaction, listen for live status.</td><td>Transcript snippet or notes of announcements.</td></tr>
<tr><td>Zoom &amp; reflow</td><td>Zoom to 200%; ensure layout doesn't break and no horizontal scroll on desktop widths.</td><td>Screenshot at 200% zoom.</td></tr>
<tr><td>Colour/contrast</td><td>Use built-in contrast checker or extension (e.g. Chrome DevTools ‚Üí CSS overview).</td><td>Contrast report or note with values.</td></tr>
<tr><td>Error messaging</td><td>Trigger validation errors; confirm focus stays in context and SR announces the message.</td><td>Screenshot of error + note on announcement.</td></tr>
<tr><td>Metrics logging (when added)</td><td>Confirm <code>data/metrics.csv</code> records success + validation_error rows.</td><td>Copy of latest rows or summary in notes.</td></tr>
</tbody></table>
</div>
<h2 id="tips-1"><a class="header" href="#tips-1">Tips</a></h2>
<ul>
<li>Pair up: one person drives, another logs issues in <code>backlog/backlog.csv</code>.</li>
<li>If a check fails, capture it immediately‚Äîauditors and Week 7-10 labs rely on real evidence.</li>
<li>Create an <code>evidence/</code> directory in your repo and store artefacts per week (e.g., <code>evidence/wk6/</code>, <code>evidence/wk7/</code>) to keep things tidy.</li>
</ul>
<h2 id="orca-linux"><a class="header" href="#orca-linux">Orca (Linux)</a></h2>
<p><strong>Orca</strong> is the built-in screen reader for GNOME (RHEL/Fedora/Ubuntu). It's functional but can be clunky compared to NVDA (Windows) or VoiceOver (macOS).</p>
<h3 id="starting-orca"><a class="header" href="#starting-orca">Starting Orca</a></h3>
<ul>
<li><strong>Terminal</strong>: <code>orca</code> (use this if keyboard shortcuts don't work)</li>
<li><strong>Shortcut</strong>: <code>Super + Alt + S</code> (Super = Windows key on laptops)</li>
<li><strong>Stop Orca</strong>: Press <code>Super + Alt + S</code> again, or <code>Insert + Q</code></li>
</ul>
<p><strong>Note</strong>: You may see warnings when starting from terminal. Orca should still work, but if speech doesn't activate,
check your system's accessibility settings.</p>
<h3 id="resources-3"><a class="header" href="#resources-3">Resources</a></h3>
<ul>
<li><strong>Official guide</strong>: <a href="https://help.gnome.org/users/orca/stable/">GNOME Orca Help</a></li>
</ul>
<h3 id="basic-navigation"><a class="header" href="#basic-navigation">Basic Navigation</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Key</th><th>Action</th></tr></thead><tbody>
<tr><td><code>Insert + Space</code></td><td>Toggle browse/focus mode</td></tr>
<tr><td><code>H</code></td><td>Next heading (in browse mode)</td></tr>
<tr><td><code>F</code></td><td>Next form field</td></tr>
<tr><td><code>Insert + Down Arrow</code></td><td>Read current line</td></tr>
<tr><td><code>Insert + ;</code></td><td>Read entire page</td></tr>
</tbody></table>
</div><div style="break-before: page; page-break-before: always;"></div><h1 id="privacy-by-design"><a class="header" href="#privacy-by-design">Privacy by Design</a></h1>
<h2 id="what-is-privacy-by-design"><a class="header" href="#what-is-privacy-by-design">What is Privacy by Design?</a></h2>
<p><strong>Privacy by Design</strong> is an approach to system development that embeds privacy and data protection into the entire lifecycle of technologies, from the earliest design stages through to deployment and beyond. Rather than treating privacy as an afterthought or compliance checkbox, it becomes a core design principle that shapes every decision.</p>
<p>The concept was developed by <a href="https://iapp.org/media/pdf/resource_center/pbd_implement_7found_principles.pdf">Dr Ann Cavoukian</a> in the 1990s and has since become a foundational principle in data protection legislation, including GDPR (General Data Protection Regulation).</p>
<h2 id="core-principles-1"><a class="header" href="#core-principles-1">Core Principles</a></h2>
<h3 id="1-proactive-not-reactive-preventative-not-remedial"><a class="header" href="#1-proactive-not-reactive-preventative-not-remedial">1. Proactive not Reactive; Preventative not Remedial</a></h3>
<ul>
<li>Anticipate and prevent privacy risks before they occur</li>
<li>Don't wait for privacy breaches to happen before taking action</li>
<li>Design systems that cannot easily leak or misuse personal data</li>
</ul>
<h3 id="2-privacy-as-the-default-setting"><a class="header" href="#2-privacy-as-the-default-setting">2. Privacy as the Default Setting</a></h3>
<ul>
<li>Participants' privacy should be protected automatically</li>
<li>No action required from the participant to protect their privacy</li>
<li>Systems should work with minimal data collection by default</li>
</ul>
<h3 id="3-privacy-embedded-into-design"><a class="header" href="#3-privacy-embedded-into-design">3. Privacy Embedded into Design</a></h3>
<ul>
<li>Privacy is integral to the system, not a bolt-on feature</li>
<li>Not an add-on, not an afterthought</li>
<li>Becomes a core functional requirement</li>
</ul>
<h3 id="4-full-functionality--positive-sum-not-zero-sum"><a class="header" href="#4-full-functionality--positive-sum-not-zero-sum">4. Full Functionality ‚Äì Positive-Sum, not Zero-Sum</a></h3>
<ul>
<li>Privacy doesn't require trade-offs with functionality</li>
<li>Both privacy and functionality can be achieved</li>
<li>False dichotomy between "usable" and "private"</li>
</ul>
<h3 id="5-end-to-end-security--full-lifecycle-protection"><a class="header" href="#5-end-to-end-security--full-lifecycle-protection">5. End-to-End Security ‚Äì Full Lifecycle Protection</a></h3>
<ul>
<li>Strong security measures from data collection to destruction</li>
<li>Data minimisation at every stage</li>
<li>Secure deletion when data is no longer needed</li>
</ul>
<h3 id="6-visibility-and-transparency"><a class="header" href="#6-visibility-and-transparency">6. Visibility and Transparency</a></h3>
<ul>
<li>Keep systems open and accountable</li>
<li>Operations remain visible to participants and stakeholders</li>
<li>Trust but verify approach</li>
</ul>
<h3 id="7-respect-for-participant-privacy"><a class="header" href="#7-respect-for-participant-privacy">7. Respect for Participant Privacy</a></h3>
<ul>
<li>Keep person-centred focus</li>
<li>Give participants control over their data</li>
<li>Make privacy the default, but allow informed choices</li>
</ul>
<h2 id="why-privacy-by-design-matters"><a class="header" href="#why-privacy-by-design-matters">Why Privacy by Design Matters</a></h2>
<h3 id="1-legal-compliance"><a class="header" href="#1-legal-compliance">1. <strong>Legal Compliance</strong></a></h3>
<ul>
<li>GDPR requires Privacy by Design (Article 25)</li>
<li>UK Data Protection Act 2018 codifies these principles</li>
<li>Non-compliance can result in significant fines (up to 4% of global turnover or ‚Ç¨20 million)</li>
<li>Better to build it in than retrofit later</li>
</ul>
<h3 id="2-ethical-responsibility"><a class="header" href="#2-ethical-responsibility">2. <strong>Ethical Responsibility</strong></a></h3>
<ul>
<li>As software engineers, we have power over people's data</li>
<li>With that power comes responsibility to protect it</li>
<li>People have a right to privacy, autonomy, and dignity</li>
<li>Our systems should respect those rights by default</li>
</ul>
<h3 id="3-trust-and-reputation"><a class="header" href="#3-trust-and-reputation">3. <strong>Trust and Reputation</strong></a></h3>
<ul>
<li>Privacy breaches destroy trust</li>
<li>Trust takes years to build, seconds to lose</li>
<li>Privacy-respecting systems build confidence</li>
<li>Competitive advantage in privacy-conscious markets</li>
</ul>
<h3 id="4-security-benefits"><a class="header" href="#4-security-benefits">4. <strong>Security Benefits</strong></a></h3>
<ul>
<li>Less data collected = smaller attack surface</li>
<li>Fewer high-value targets for attackers</li>
<li>Reduced impact if a breach does occur</li>
<li>Minimises risk exposure for both participants and organisation</li>
</ul>
<h3 id="5-cost-efficiency"><a class="header" href="#5-cost-efficiency">5. <strong>Cost Efficiency</strong></a></h3>
<ul>
<li>Cheaper to build privacy in from the start</li>
<li>Retrofitting privacy is expensive and often incomplete</li>
<li>Reduces storage and processing costs (less data to manage)</li>
<li>Avoids costly breach responses and legal fees</li>
</ul>
<h3 id="6-participant-empowerment"><a class="header" href="#6-participant-empowerment">6. <strong>Participant Empowerment</strong></a></h3>
<ul>
<li>People should control their own data</li>
<li>Informed consent requires clear, simple choices</li>
<li>Privacy by Design enables genuine agency</li>
<li>Respects human autonomy and dignity</li>
</ul>
<h2 id="privacy-by-design-in-comp2850-hci"><a class="header" href="#privacy-by-design-in-comp2850-hci">Privacy by Design in COMP2850 HCI</a></h2>
<p>In this module, we practise Privacy by Design through several concrete patterns:</p>
<h3 id="data-minimisation"><a class="header" href="#data-minimisation">Data Minimisation</a></h3>
<p><strong>What we do:</strong></p>
<ul>
<li>Collect only anonymous session IDs (6-8 characters)</li>
<li>Use random request IDs instead of personally identifiable information</li>
<li>No names, emails, IP addresses, or other PII (Personally Identifiable Information) in logs</li>
<li>No accounts, authentication, or persistent profiles</li>
</ul>
<p><strong>Why:</strong></p>
<pre><code class="language-csv"># Our logs look like this:
ts_iso,session_id,request_id,task_code,step,outcome,ms,http_status,js_mode
2024-10-13T14:23:01Z,abc123xy,req-8f7g,T1_filter,start,success,234,200,true

# NOT like this (bad example):
ts_iso,user_email,user_name,ip_address,task_code,outcome,ms
2024-10-13T14:23:01Z,alice@email.com,Alice Smith,192.168.1.42,T1_filter,success,234
</code></pre>
<p>We can still measure usability metrics (completion time, error rates) without knowing <em>who</em> the person is.</p>
<h3 id="local-storage-only"><a class="header" href="#local-storage-only">Local Storage Only</a></h3>
<p><strong>What we do:</strong></p>
<ul>
<li>All metrics stored in local CSV files on University of Leeds OneDrive (covered by institutional ethical consent)</li>
<li>No cloud services, no external analytics</li>
<li>No third-party tracking scripts</li>
<li>Data stays within UoL-controlled infrastructure</li>
</ul>
<p><strong>Why:</strong></p>
<ul>
<li>Reduces risk of data exposure through third parties</li>
<li>No terms-of-service surprises from external vendors</li>
<li>Clear data lifecycle (we control retention and deletion)</li>
<li>Compliance is simpler when data doesn't leave our infrastructure</li>
<li>UoL OneDrive provides secure, GDPR-compliant storage with appropriate access controls</li>
</ul>
<h3 id="peer-only-testing-protocol"><a class="header" href="#peer-only-testing-protocol">Peer-Only Testing Protocol</a></h3>
<p><strong>What we do:</strong></p>
<ul>
<li>Usability testing only with course peers</li>
<li>Module-wide blanket consent (everyone knows they may be observed)</li>
<li>No external participants who might not understand context</li>
<li>No recordings (video/audio)</li>
</ul>
<p><strong>Why:</strong></p>
<ul>
<li>Creates safe learning environment</li>
<li>Everyone understands the educational purpose</li>
<li>Reduces power imbalance (peers, not vulnerable populations)</li>
<li>Minimal risk because everyone is consenting participant</li>
</ul>
<h3 id="evidence-without-pii"><a class="header" href="#evidence-without-pii">Evidence Without PII</a></h3>
<p><strong>What we do:</strong></p>
<ul>
<li>Screenshots must be cropped to show only interface</li>
<li>Personal information scrubbed from any evidence</li>
<li>No images of people</li>
<li>Alt text required for accessibility, but no identifying details</li>
<li>Use pseudoanonymisation (e.g., "Participant A", "Session 1") when reporting qualitative data from interviews, recordings, or transcription</li>
</ul>
<p><strong>Why:</strong></p>
<ul>
<li>Evidence is about interface design, not people</li>
<li>Respects dignity and consent of participants</li>
<li>Prevents accidental identification years later</li>
<li>Forces focus on the system, not the person using it</li>
<li><strong>Note</strong>: Full anonymisation is often impossible for qualitative research; pseudoanonymisation (removing direct identifiers while retaining links for analysis) is typically the best achievable practice for interviews, recordings, transcription, and quantitative analysis</li>
</ul>
<h3 id="transparent-research-protocol"><a class="header" href="#transparent-research-protocol">Transparent Research Protocol</a></h3>
<p><strong>What we do:</strong></p>
<ul>
<li>Clear written protocol explaining what data is collected</li>
<li>Explicit task descriptions and measures</li>
<li>Right to withdraw at any time</li>
<li>Minimal task time caps (3 minutes max to avoid frustration)</li>
</ul>
<p><strong>Why:</strong></p>
<ul>
<li>Informed consent requires transparency</li>
<li>People can only consent to what they understand</li>
<li>Respects participant autonomy</li>
<li>Builds trust in research process</li>
</ul>
<h3 id="no-feature-creep"><a class="header" href="#no-feature-creep">No Feature Creep</a></h3>
<p><strong>What we do:</strong></p>
<ul>
<li>Don't add "helpful" tracking features</li>
<li>Resist temptation to add "just one more field"</li>
<li>Question every data point: is this necessary?</li>
<li>Start with minimal data, expand only if justified</li>
</ul>
<p><strong>Why:</strong></p>
<ul>
<li>Scope creep applies to data collection too</li>
<li>Each new field is a new privacy risk</li>
<li>"We might need it someday" is not justification</li>
<li>Constraints breed creativity (work within limits)</li>
</ul>
<h2 id="practical-examples-from-our-labs"><a class="header" href="#practical-examples-from-our-labs">Practical Examples from Our Labs</a></h2>
<h3 id="week-9-server-side-instrumentation"><a class="header" href="#week-9-server-side-instrumentation">Week 9: Server-Side Instrumentation</a></h3>
<p><strong>Privacy-Respecting Approach:</strong></p>
<pre><code class="language-kotlin">// Log only what's needed for metrics
Logger.log(
    sessionId = "abc123xy",      // Anonymous cookie
    requestId = "req-8f7g",       // Random per-task
    taskCode = "T1_filter",       // Which task
    step = "start",               // What happened
    outcome = "success",          // Result
    ms = 234L,                    // Duration
    httpStatus = 200,             // HTTP response
    jsMode = "true"               // JS enabled/disabled
)
</code></pre>
<p><strong>What we DON'T log:</strong></p>
<ul>
<li>Browser user agent strings (can fingerprint devices)</li>
<li>Full URLs (might contain personal data in query params)</li>
<li>Form input values (might be personal information)</li>
<li>Mouse movements or keystroke timings (surveillance-like)</li>
<li>IP addresses (can identify individuals)</li>
</ul>
<h3 id="week-10-analysis--evidence"><a class="header" href="#week-10-analysis--evidence">Week 10: Analysis &amp; Evidence</a></h3>
<p><strong>Privacy-Respecting Analysis:</strong></p>
<pre><code class="language-kotlin">// Aggregate data, analyse patterns, no individuals
data class TaskStats(
    val taskCode: String,
    val medianMs: Double,
    val completionRate: Double,
    val errorRate: Double
)
</code></pre>
<p>We report: "Task T1 had a median completion time of 8.2 seconds with a 90% completion rate."</p>
<p>We DON'T report: "Session abc123xy took 15 seconds and made 3 errors."</p>
<p><strong>Why:</strong> The goal is to improve the interface, not judge individuals.</p>
<h3 id="week-11-portfolio--submission"><a class="header" href="#week-11-portfolio--submission">Week 11: Portfolio &amp; Submission</a></h3>
<p><strong>Privacy-Respecting Evidence:</strong></p>
<ul>
<li>Screenshots cropped to show only UI elements</li>
<li>No usernames visible in interface</li>
<li>No timestamps that could identify sessions</li>
<li>Generic task data ("rename task A to task B")</li>
</ul>
<p><strong>Privacy-Violating Evidence (Don't do this):</strong></p>
<ul>
<li>Full-screen screenshots showing participant's desktop</li>
<li>Visible personal calendar events or email notifications</li>
<li>Identifiable profiles in test data</li>
<li>Timestamped evidence linking to specific people</li>
</ul>
<h2 id="common-myths-about-privacy"><a class="header" href="#common-myths-about-privacy">Common Myths About Privacy</a></h2>
<h3 id="myth-1-were-not-collecting-sensitive-data-so-privacy-doesnt-matter"><a class="header" href="#myth-1-were-not-collecting-sensitive-data-so-privacy-doesnt-matter">Myth 1: "We're not collecting sensitive data, so privacy doesn't matter"</a></h3>
<p><strong>Reality:</strong> What seems innocuous can become sensitive in aggregate or context. Session patterns, timing data, and behavioural metrics can reveal sensitive information. Privacy by Design applies to all data.</p>
<h3 id="myth-2-privacy-and-usability-are-in-conflict"><a class="header" href="#myth-2-privacy-and-usability-are-in-conflict">Myth 2: "Privacy and usability are in conflict"</a></h3>
<p><strong>Reality:</strong> Privacy by Design is about smart design choices, not removing features. Anonymous session IDs work just as well as personal accounts for our use case. Good UX respects participants' privacy.</p>
<h3 id="myth-3-we-can-just-anonymise-data-later"><a class="header" href="#myth-3-we-can-just-anonymise-data-later">Myth 3: "We can just anonymise data later"</a></h3>
<p><strong>Reality:</strong> Anonymisation is hard and often fails. Re-identification attacks are common. Better to never collect identifying data in the first place. True anonymity requires design from the start.</p>
<h3 id="myth-4-people-dont-care-about-privacy-anyway"><a class="header" href="#myth-4-people-dont-care-about-privacy-anyway">Myth 4: "People don't care about privacy anyway"</a></h3>
<p><strong>Reality:</strong> People care deeply when they understand the implications. Surveys show privacy is a top concern. More importantly, privacy is a right, not a popularity contest.</p>
<h3 id="myth-5-we-need-data-to-improve-the-product"><a class="header" href="#myth-5-we-need-data-to-improve-the-product">Myth 5: "We need data to improve the product"</a></h3>
<p><strong>Reality:</strong> We need <em>insights</em>, not personal data. Aggregate metrics, task success rates, and usability findings don't require knowing who anyone is. Data minimisation often leads to better focus.</p>
<h2 id="questions-to-ask"><a class="header" href="#questions-to-ask">Questions to Ask</a></h2>
<p>When designing any system that collects data, ask:</p>
<ol>
<li>
<p><strong>Do we need this data at all?</strong></p>
<ul>
<li>What decision does it inform?</li>
<li>What happens if we don't collect it?</li>
<li>Is there a less invasive alternative?</li>
</ul>
</li>
<li>
<p><strong>Can we use anonymous or pseudonymous data?</strong></p>
<ul>
<li>Random session IDs instead of accounts?</li>
<li>Request IDs instead of tracking individuals?</li>
<li>Aggregate statistics instead of individual records?</li>
</ul>
</li>
<li>
<p><strong>How long do we need to keep it?</strong></p>
<ul>
<li>Set retention policies upfront</li>
<li>Delete data when no longer needed</li>
<li>Question perpetual storage defaults</li>
</ul>
</li>
<li>
<p><strong>Who has access?</strong></p>
<ul>
<li>Minimise access to those who need it</li>
<li>Log access to sensitive data</li>
<li>Audit regularly</li>
</ul>
</li>
<li>
<p><strong>What could go wrong?</strong></p>
<ul>
<li>Threat model: what attacks are possible?</li>
<li>Data breach: what's the impact?</li>
<li>Misuse: could this data harm people?</li>
</ul>
</li>
<li>
<p><strong>Can people control their data?</strong></p>
<ul>
<li>Export their data?</li>
<li>Delete their data?</li>
<li>Correct inaccuracies?</li>
</ul>
</li>
<li>
<p><strong>Is collection transparent?</strong></p>
<ul>
<li>Do people know what's collected?</li>
<li>Do they understand why?</li>
<li>Can they make informed choices?</li>
</ul>
</li>
</ol>
<h2 id="resources--further-reading"><a class="header" href="#resources--further-reading">Resources &amp; Further Reading</a></h2>
<h3 id="foundational-documents"><a class="header" href="#foundational-documents">Foundational Documents</a></h3>
<ul>
<li><a href="https://iapp.org/media/pdf/resource_center/pbd_implement_7found_principles.pdf">Privacy by Design: The 7 Foundational Principles</a> (Ann Cavoukian)</li>
<li><a href="https://gdpr-info.eu/art-25-gdpr/">GDPR Article 25: Data Protection by Design and by Default</a></li>
</ul>
<h3 id="uk-context"><a class="header" href="#uk-context">UK Context</a></h3>
<ul>
<li><a href="https://ico.org.uk/for-organisations/guide-to-data-protection/guide-to-the-general-data-protection-regulation-gdpr/accountability-and-governance/data-protection-by-design-and-default/">ICO Guide to Privacy by Design</a></li>
<li><a href="https://www.legislation.gov.uk/ukpga/2018/12/contents/enacted">UK Data Protection Act 2018</a></li>
</ul>
<h3 id="practical-guides"><a class="header" href="#practical-guides">Practical Guides</a></h3>
<ul>
<li><a href="https://cheatsheetseries.owasp.org/cheatsheets/Privacy_Cheat_Sheet.html">OWASP Privacy Cheat Sheet</a></li>
<li><a href="https://privacypatterns.org/">Privacy Patterns (design patterns for privacy)</a></li>
<li></li>
</ul>
<h2 id="summary-why-this-matters-for-hci--ux"><a class="header" href="#summary-why-this-matters-for-hci--ux">Summary: Why This Matters for HCI &amp; UX</a></h2>
<p>As HCI practitioners, we design the interfaces, systems and UX that mediate people's digital lives.<br />
Every interaction we design, every feature we implement, has privacy implications.</p>
<p><strong>Privacy by Design is good HCI &amp; UX because:</strong></p>
<ol>
<li><strong>Respects human dignity</strong> - People are not data points</li>
<li><strong>Builds trust</strong> - Essential for meaningful human-computer interaction</li>
<li><strong>Reduces cognitive burden</strong> - People shouldn't need law degrees to protect themselves</li>
<li><strong>Enables inclusion</strong> - Privacy concerns disproportionately affect marginalised groups</li>
<li><strong>Future-proofs systems</strong> - Privacy-respecting design ages better</li>
<li><strong>Aligns with ethics</strong> - Core ACM Code of Ethics principle (1.6: Respect privacy)</li>
</ol>
<p>In COMP2850, we practise Privacy by Design not because it's required for coursework, but because it's required for <strong>responsible software engineering</strong>. The habits you form now shape the systems you'll build throughout your career.</p>
<p><strong>The question is not "How much data can we collect?"</strong></p>
<p><strong>The question is "How little data do we need to achieve our goals?"</strong></p>
<p>Privacy by Design starts with that question.</p>
<h3 id="academic-perspectives"><a class="header" href="#academic-perspectives">Academic Perspectives</a></h3>
<ul>
<li>
<p>Shirlei Aparecida de Chaves and Fabiane Benitti. 2025. User-Centred Privacy and Data Protection: An Overview of Current Research Trends and Challenges for the Human‚ÄìComputer Interaction Field. ACM Comput. Surv. 57, 7, Article 176 (February 2025), 36 pages. https://doi.org/10.1145/3715903</p>
</li>
<li>
<p>Giovanni Iachello and Jason Hong. 2007. End-User Privacy in Human-Computer Interaction. Found. Trends Hum.‚ÄìComput. Interact. 1, 1 (January 2007), 1‚Äì137. https://www.cs.cmu.edu/~jasonh/publications/fnt-end-user-privacy-in-human-computer-interaction-final.pdf</p>
</li>
<li>
<p>Jaap-Henk Hoepman. 2014. Privacy Design Strategies. In ICT Systems Security and Privacy Protection, Nora Cuppens-Boulahia, Fr√©d√©ric Cuppens, Sushil Jajodia, Anas Abou El Kalam, and Thierry Sans (Eds.). Springer, Berlin, Heidelberg, 446‚Äì459. https://doi.org/10.1007/978-3-642-55415-5_38</p>
</li>
<li>
<p>George Danezis, Josep Domingo-Ferrer, Marit Hansen, Jaap-Henk Hoepman, Daniel Le M√©tayer, Rodica Tirtea, and Stefan Schiffner. 2014. Privacy and Data Protection by Design ‚Äì from policy to engineering. ENISA, European Union Agency for Network and Information Security. https://arxiv.org/abs/1501.03726</p>
</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="consent-pii-and-low-risk-research-faq-weeks-67"><a class="header" href="#consent-pii-and-low-risk-research-faq-weeks-67">Consent, PII, and Low-Risk Research FAQ (Weeks 6‚Äì7)</a></h1>
<h2 id="why-this-matters-6"><a class="header" href="#why-this-matters-6">Why this matters</a></h2>
<p>Even with peer-to-peer studies in lab, we must follow university guidance and treat peers‚Äô data respectfully. This FAQ clarifies what‚Äôs in scope for our blanket low-risk consent protocol.</p>
<hr />
<h2 id="quick-definitions"><a class="header" href="#quick-definitions">Quick definitions</a></h2>
<ul>
<li><strong>PII (Personally Identifiable Information)</strong>: Anything that can identify a person. In our labs it includes full names, student IDs, email addresses, recorded voices, facial images, device IDs.</li>
<li><strong>De-identified notes</strong>: Observations or timings that cannot point to a specific person (e.g., ‚ÄúParticipant A took 48s to complete T2, mis-clicked once‚Äù).</li>
<li><strong>Low-risk study</strong>: Peer pairs, no external participants, no vulnerable groups, no sensitive topics, no recordings.</li>
</ul>
<hr />
<h2 id="whats-allowed-in-week-67-labs"><a class="header" href="#whats-allowed-in-week-67-labs">What‚Äôs allowed in Week 6‚Äì7 labs?</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Activity</th><th>Allowed?</th><th>Notes</th></tr></thead><tbody>
<tr><td>Peer needs-finding interviews (with consent script)</td><td>‚úÖ</td><td>Keep to lab partners, no recording. Use initials or pseudonyms in notes.</td></tr>
<tr><td>Timing tasks during pilots (Stopwatch / server logs)</td><td>‚úÖ</td><td>Store in <code>data/metrics.csv</code> without names.</td></tr>
<tr><td>Collecting demographic data</td><td>‚ùå</td><td>Out of scope; introduces unnecessary sensitivity.</td></tr>
<tr><td>Screenshots of peers</td><td>‚ùå</td><td>Do not capture faces. Crop to interface only.</td></tr>
<tr><td>Recording audio/video</td><td>‚ùå</td><td>Not covered by low-risk blanket approval.</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="consent-protocol-essentials"><a class="header" href="#consent-protocol-essentials">Consent protocol essentials</a></h2>
<ol>
<li><strong>Introduce</strong> the activity and remind peers participation is voluntary.</li>
<li><strong>Clarify</strong> data collected (timings, errors, notes) and how it will be stored (local repo, private).</li>
<li><strong>Offer opt-out</strong>: they can stop at any time, no penalty.</li>
<li><strong>Confirm no PII</strong> is stored; use pseudonyms or IDs like <code>P1</code>, <code>P2</code>.</li>
<li><strong>Record consent</strong> in <code>research/consent_protocol.md</code> (date, activity, initials if needed).</li>
</ol>
<p>Sample script (use in Week 6 Lab 2):</p>
<blockquote>
<p>‚ÄúWe‚Äôre running a quick needs-finding chat about the task list app. I‚Äôll take notes under <code>P1</code>, no names, and we won‚Äôt record. You can stop whenever you like. Okay to proceed?‚Äù</p>
</blockquote>
<hr />
<h2 id="storing-notes-safely"><a class="header" href="#storing-notes-safely">Storing notes safely</a></h2>
<ul>
<li>Keep notes in the repo under <code>research/</code> with pseudonyms.</li>
<li>Do not sync to public forks. Push only to private module repos or upload via Minerva if required.</li>
<li>If you accidentally capture PII, remove it immediately and note the correction in your reflection.</li>
</ul>
<hr />
<h2 id="handling-data-after-the-lab"><a class="header" href="#handling-data-after-the-lab">Handling data after the lab</a></h2>
<ul>
<li>Delete raw notes/screenshots containing identifying details once you‚Äôve transcribed anonymised versions.</li>
<li>For Gradescope submissions, ensure evidence folders contain cropped UI screenshots, no participant info.</li>
</ul>
<hr />
<h2 id="common-mistakes-to-avoid-3"><a class="header" href="#common-mistakes-to-avoid-3">Common mistakes to avoid</a></h2>
<ul>
<li>Writing ‚ÄúSpoke to Sam, she struggled with focus order‚Äù ‚Üí instead use ‚ÄúParticipant A‚Ä¶‚Äù</li>
<li>Storing Google Form responses with email addresses ‚Üí don‚Äôt collect emails (use plain Markdown tables).</li>
<li>Sharing repo publicly before removing <code>research/</code> folder ‚Üí keep private until evidence is sanitised.</li>
</ul>
<hr />
<h2 id="who-to-ask-if-unsure"><a class="header" href="#who-to-ask-if-unsure">Who to ask if unsure?</a></h2>
<ul>
<li>Lab teaching staff during sessions.</li>
<li>Lecturers for edge cases (e.g., wanting to test with someone outside the cohort).</li>
</ul>
<p>Document any unusual situations in your self-reflection so we can show due diligence.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="evaluation-metrics-quick-reference-week-910"><a class="header" href="#evaluation-metrics-quick-reference-week-910">Evaluation Metrics Quick Reference (Week 9‚Äì10)</a></h1>
<h2 id="what-are-evaluation-metrics"><a class="header" href="#what-are-evaluation-metrics">What are Evaluation Metrics?</a></h2>
<p><strong>Evaluation metrics</strong> are quantitative measures that help us assess the usability and effectiveness of interactive systems. Rather than relying on assumptions or opinions about whether an interface works well, metrics provide <strong>evidence-based data</strong> to identify problems, track improvements, and justify design decisions.</p>
<p>In HCI, we distinguish between:</p>
<ul>
<li><strong>Objective metrics</strong> - Measurable performance data (time, error rates, completion rates) captured through instrumentation</li>
<li><strong>Subjective metrics</strong> - Self-reported experiences (confidence, satisfaction, perceived difficulty) captured through questionnaires</li>
</ul>
<p>For COMP2850, we focus on <strong>task-based evaluation</strong>: participants attempt specific tasks (e.g., "filter tasks by status") while we measure completion time, success rates, and errors. This approach reveals usability issues that might not surface through inspection methods alone.</p>
<p><strong>Why metrics matter:</strong></p>
<ul>
<li><strong>Data-driven redesign</strong> - Identify which tasks cause the most friction</li>
<li><strong>Accessibility verification</strong> - Compare JS-on vs JS-off performance to ensure <a href="references/glossary.html#no-js-parity">no-JS parity</a></li>
<li><strong>Prioritisation</strong> - Use error rates and completion times to rank backlog fixes by impact</li>
<li><strong>Evidence chains</strong> - Support claims in Task 1 and Task 2 submissions with concrete data, not guesswork</li>
</ul>
<p>All metrics must respect <a href="references/privacy-by-design.html">privacy by design</a> principles: we log anonymous session IDs and task codes, never personal identifiers.</p>
<hr />
<h2 id="why-task-based-evaluation"><a class="header" href="#why-task-based-evaluation">Why Task-Based Evaluation?</a></h2>
<h3 id="theoretical-foundation"><a class="header" href="#theoretical-foundation">Theoretical Foundation</a></h3>
<p><strong>Task-based usability evaluation</strong> has its roots in cognitive psychology and human factors research from the 1980s-90s. Rather than measuring abstract performance (e.g., reaction time, motor precision), task-based methods assess how well people can accomplish <strong>realistic goals</strong> with a system.</p>
<p><strong>Key foundations:</strong></p>
<ul>
<li><strong>ISO 9241-11 (2018)</strong>: Defines usability as "the extent to which a system can be used by specified users to achieve specified goals with effectiveness, efficiency and satisfaction in a specified context of use"</li>
<li><strong>Nielsen &amp; Landauer (1993)</strong>: Established the "5-user rule" - testing with 5 participants identifies ~85% of usability issues</li>
<li><strong>Dumas &amp; Redish (1993)</strong>: <em>A Practical Guide to Usability Testing</em> - formalized task-based protocols for industry</li>
<li><strong>Lewis (1982, 2014)</strong>: Developed task-based metrics (completion rate, time-on-task, subjective ratings) still used today</li>
</ul>
<p><strong>Why task-based over alternatives?</strong></p>
<div class="table-wrapper"><table><thead><tr><th>Method</th><th>What it measures</th><th>When to use</th><th>Why we don't use it here</th></tr></thead><tbody>
<tr><td><strong>Fitts' Law / ISO 9241-9</strong></td><td>Motor performance (pointing, clicking speed)</td><td>Low-level widget design (button size, target distance)</td><td>Too low-level; doesn't capture real workflow issues</td></tr>
<tr><td><strong>GOMS / KLM</strong></td><td>Expert performance (keystroke-level model)</td><td>Predict expert task time for routine operations</td><td>Assumes error-free performance; misses novice struggles</td></tr>
<tr><td><strong>Reaction time tests</strong></td><td>Perceptual-motor speed (stimulus ‚Üí response)</td><td>Attention research, cognitive load studies</td><td>Doesn't reflect real task complexity</td></tr>
<tr><td><strong>Task-based evaluation</strong></td><td>Effectiveness, efficiency, satisfaction on realistic tasks</td><td>Formative evaluation, iterative design, accessibility testing</td><td>‚úÖ Matches our goal: find usability + accessibility issues in real workflows</td></tr>
</tbody></table>
</div>
<h3 id="ecological-validity"><a class="header" href="#ecological-validity">Ecological Validity</a></h3>
<p>Task-based evaluation prioritizes <strong>ecological validity</strong> - the extent to which findings generalize to real-world use. By asking participants to complete realistic scenarios ("add a task with a deadline"), we uncover issues that matter in practice:</p>
<ul>
<li>Form validation errors that block task completion</li>
<li>Missing labels that confuse screen reader navigation</li>
<li>Keyboard traps that prevent no-mouse workflows</li>
<li>Performance differences between JS-on and JS-off conditions</li>
</ul>
<p>These issues don't surface in abstract performance tests but critically affect real users.</p>
<h3 id="our-approach-in-comp2850"><a class="header" href="#our-approach-in-comp2850">Our Approach in COMP2850</a></h3>
<p>We use <strong>lightweight task-based testing</strong> inspired by:</p>
<ul>
<li><strong>Nielsen's discount usability engineering</strong>: Small samples (n=4-5), qualitative + quantitative data, rapid iteration</li>
<li><strong>Lewis's task-based metrics</strong>: Completion rate, time-on-task, error rate, confidence ratings</li>
<li><strong>WCAG evaluation methodology</strong>: Test with assistive technology variants (keyboard, screen reader, no-JS)</li>
</ul>
<p><strong>What we test:</strong></p>
<ul>
<li>Representative tasks from Week 6 needs-finding (job stories ‚Üí evaluation tasks)</li>
<li>Multiple interaction modes: mouse + keyboard, JS-on + JS-off, visual + screen reader</li>
<li>Both <strong>effectiveness</strong> (Can people complete the task?) and <strong>efficiency</strong> (How quickly?)</li>
</ul>
<p><strong>What makes our approach academically rigorous:</strong></p>
<ul>
<li><strong>Privacy-safe instrumentation</strong>: Server-side logging (not surveillance)</li>
<li><strong>Mixed methods</strong>: Quantitative metrics + qualitative observations</li>
<li><strong>Evidence chains</strong>: Every claim traceable to data</li>
<li><strong>Ethical protocols</strong>: Informed consent, right to withdraw, no PII</li>
</ul>
<p>For detailed task descriptions and assessment criteria, see <a href="references/../assessment/task1.html">Task 1: Evaluation &amp; Findings</a>.</p>
<hr />
<h2 id="core-metrics"><a class="header" href="#core-metrics">Core Metrics</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Metric</th><th>How to calculate</th><th>Why we use it</th><th>Notes</th></tr></thead><tbody>
<tr><td>Median time (<code>median_ms</code>)</td><td>Sort successful task durations; pick middle value (or average middle two)</td><td>Resistant to outliers; tells us typical completion time</td><td>Use Kotlin helper in <code>Analyse.kt</code> or spreadsheet <code>MEDIAN</code>.</td></tr>
<tr><td>Median absolute deviation (<code>mad_ms</code>)</td><td>Median of `</td><td>value - median</td><td>` for each duration</td></tr>
<tr><td>Completion rate</td><td><code>success / (success + fail)</code></td><td>Shows task feasibility; &lt;1 means people are stuck</td><td>Track separately for JS-on vs JS-off.</td></tr>
<tr><td>Validation error count</td><td>Number of <code>validation_error</code> rows per task</td><td>Flags form issues (copy errors, missing labels)</td><td>Relates directly to accessibility backlog items.</td></tr>
<tr><td>Error rate</td><td><code>validation_error / (success + validation_error)</code></td><td>Highlights forms that confuse or block people</td><td>Pair with qualitative notes to prioritise fixes.</td></tr>
<tr><td>Confidence score</td><td>Average of 1‚Äì5 scale reported post-task</td><td>Taps into affective feedback (HCI evaluation requirement)</td><td>Capture in <code>metrics.csv</code> or a parallel sheet.</td></tr>
</tbody></table>
</div>
<h2 id="workflow-reminder"><a class="header" href="#workflow-reminder">Workflow reminder</a></h2>
<ol>
<li>Append raw pilot data to <code>data/metrics.csv</code> (server logs + manual entries).</li>
<li>Run <code>./gradlew runAnalyse</code> (or <code>Analyse.kt</code>) to regenerate <code>analysis/analysis.csv</code>.</li>
<li>Copy summary rows into <code>analysis/summary.md</code> with narrative interpretation.</li>
<li>Use the numbers to populate <code>analysis/prioritisation.csv</code> (impact/inclusion/effort scores).</li>
</ol>
<p>Keep this reference handy during Weeks 9‚Äì10 labs so you don‚Äôt have to re-derive the formulas under time pressure.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="screenshot-guide-for-evidence-collection"><a class="header" href="#screenshot-guide-for-evidence-collection">Screenshot Guide for Evidence Collection</a></h1>
<p><strong>COMP2850 HCI - Privacy-Safe Screenshot Practices</strong></p>
<hr />
<h2 id="why-screenshots-matter"><a class="header" href="#why-screenshots-matter">Why Screenshots Matter</a></h2>
<p>For Task 1 (Week 9) and Task 2 (Week 10-11) submissions, you'll include <strong>screenshot evidence</strong> showing:</p>
<ul>
<li>Interface states (before/after redesign)</li>
<li>Accessibility features (ARIA live regions, focus indicators)</li>
<li>Browser DevTools inspections (HTML structure, network timing)</li>
<li>Screen reader output (NVDA/VoiceOver speech viewer)</li>
</ul>
<p>Screenshots must be <strong>privacy-safe</strong> (no PII) and <strong>readable</strong> (clear, well-cropped).</p>
<hr />
<h2 id="1-recommended-tools"><a class="header" href="#1-recommended-tools">1. Recommended Tools</a></h2>
<h3 id="windows"><a class="header" href="#windows">Windows</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Tool</th><th>Use Case</th><th>How to Access</th></tr></thead><tbody>
<tr><td><strong>Snipping Tool</strong></td><td>Quick screenshots, built-in</td><td><code>Win + Shift + S</code></td></tr>
<tr><td><strong>Windows Snip &amp; Sketch</strong></td><td>Annotate after capture</td><td>Windows Search ‚Üí "Snip &amp; Sketch"</td></tr>
<tr><td><strong>ShareX</strong> (free)</td><td>Advanced (regions, scrolling pages)</td><td>Download: https://getsharex.com/</td></tr>
<tr><td><strong>Greenshot</strong> (free)</td><td>Annotate, auto-save to folders</td><td>Download: https://getgreenshot.org/</td></tr>
</tbody></table>
</div>
<h3 id="macos"><a class="header" href="#macos">macOS</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Tool</th><th>Use Case</th><th>How to Access</th></tr></thead><tbody>
<tr><td><strong>Screenshot</strong> (built-in)</td><td>Full screen, window, region</td><td><code>Cmd + Shift + 3/4/5</code></td></tr>
<tr><td><strong>CleanShot X</strong> (paid)</td><td>Professional annotations</td><td>App Store</td></tr>
<tr><td><strong>Skitch</strong> (free)</td><td>Annotate after capture</td><td>App Store</td></tr>
</tbody></table>
</div>
<h3 id="linux"><a class="header" href="#linux">Linux</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Tool</th><th>Use Case</th><th>How to Access</th></tr></thead><tbody>
<tr><td><strong>Spectacle</strong> (KDE)</td><td>Full screen, window, region</td><td>Install via package manager</td></tr>
<tr><td><strong>GNOME Screenshot</strong></td><td>Built-in for GNOME desktop</td><td><code>PrtScn</code> key</td></tr>
<tr><td><strong>Flameshot</strong> (free)</td><td>Annotate, draw arrows</td><td>Install: <code>sudo apt install flameshot</code></td></tr>
</tbody></table>
</div>
<h3 id="browser-extensions-cross-platform"><a class="header" href="#browser-extensions-cross-platform">Browser Extensions (Cross-Platform)</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Extension</th><th>Use Case</th><th>Install</th></tr></thead><tbody>
<tr><td><strong>Awesome Screenshot</strong></td><td>Full page, scrolling captures</td><td>Chrome/Firefox Web Store</td></tr>
<tr><td><strong>Nimbus Screenshot</strong></td><td>Annotate, blur sensitive areas</td><td>Chrome/Firefox Web Store</td></tr>
<tr><td><strong>Full Page Screen Capture</strong></td><td>Long pages (useful for task lists)</td><td>Chrome Web Store</td></tr>
</tbody></table>
</div>
<hr />
<h2 id="2-what-to-crop-out-privacy-scrubbing"><a class="header" href="#2-what-to-crop-out-privacy-scrubbing">2. What to Crop Out (Privacy Scrubbing)</a></h2>
<h3 id="-remove-these-piisensitive-data"><a class="header" href="#-remove-these-piisensitive-data">‚ùå Remove These (PII/Sensitive Data)</a></h3>
<ul>
<li><strong>Usernames/Real Names</strong>: In browser tabs, bookmarks, login forms</li>
<li><strong>Email Addresses</strong>: In bookmarks, open Gmail tabs, login screens</li>
<li><strong>Profile Pictures</strong>: In browser toolbar, Google account icons</li>
<li><strong>Bookmark Bar Content</strong>: May reveal personal sites, work projects</li>
<li><strong>Browser History</strong>: If visible in search suggestions</li>
<li><strong>File Paths with Usernames</strong>: <code>C:\Users\JohnSmith\...</code> ‚Üí <code>C:\Users\[redacted]\...</code></li>
<li><strong>IP Addresses</strong>: In DevTools Network tab (if showing server IPs)</li>
<li><strong>Session Tokens</strong>: In DevTools Application ‚Üí Cookies</li>
<li><strong>Real Task Data</strong>: If using personal tasks instead of test data</li>
</ul>
<h3 id="-keep-these-useful-evidence"><a class="header" href="#-keep-these-useful-evidence">‚úÖ Keep These (Useful Evidence)</a></h3>
<ul>
<li><strong>Browser Name/Version</strong>: "Chrome 120.0" (shows compatibility)</li>
<li><strong>Window Title</strong>: "Task Manager - localhost:8080" (shows page context)</li>
<li><strong>DevTools Panel</strong>: HTML inspector, Console, Network tab</li>
<li><strong>Code Line Numbers</strong>: In DevTools Elements panel</li>
<li><strong>ARIA Attributes</strong>: <code>role="status"</code>, <code>aria-label="..."</code></li>
<li><strong>Network Request Timing</strong>: Duration, status codes (200, 400)</li>
<li><strong>Screen Reader Output</strong>: NVDA/VoiceOver speech viewer text</li>
</ul>
<hr />
<h2 id="3-screenshot-checklist-before-saving"><a class="header" href="#3-screenshot-checklist-before-saving">3. Screenshot Checklist (Before Saving)</a></h2>
<p>Before saving each screenshot, check:</p>
<ul>
<li><input disabled="" type="checkbox"/>
<strong>No real names</strong> in browser tabs, bookmarks, or login forms</li>
<li><input disabled="" type="checkbox"/>
<strong>No email addresses</strong> visible</li>
<li><input disabled="" type="checkbox"/>
<strong>No personal task titles</strong> (use test data: "Buy milk", "Pay bills")</li>
<li><input disabled="" type="checkbox"/>
<strong>No usernames in file paths</strong> (crop or blur <code>C:\Users\YourName\</code>)</li>
<li><input disabled="" type="checkbox"/>
<strong>Bookmark bar hidden or cropped</strong></li>
<li><input disabled="" type="checkbox"/>
<strong>Screenshot is readable</strong> (text legible, not too small)</li>
<li><input disabled="" type="checkbox"/>
<strong>Relevant content in focus</strong> (crop to show only what's needed)</li>
<li><input disabled="" type="checkbox"/>
<strong>Annotations added</strong> (if needed: arrows, boxes, labels)</li>
</ul>
<hr />
<h2 id="4-optimal-dimensions--file-formats"><a class="header" href="#4-optimal-dimensions--file-formats">4. Optimal Dimensions &amp; File Formats</a></h2>
<h3 id="dimensions"><a class="header" href="#dimensions">Dimensions</a></h3>
<p><strong>For web interfaces</strong>:</p>
<ul>
<li><strong>Full screenshot</strong>: 1920√ó1080 (or your screen resolution)</li>
<li><strong>Cropped to browser content</strong>: 1280√ó720 (readable in PDFs)</li>
<li><strong>Close-up (DevTools, code)</strong>: 800√ó600 minimum (text must be legible)</li>
</ul>
<p><strong>General rule</strong>: Text should be <strong>14pt or larger</strong> when viewed at 100% zoom in PDF.</p>
<h3 id="file-formats"><a class="header" href="#file-formats">File Formats</a></h3>
<div class="table-wrapper"><table><thead><tr><th>Format</th><th>When to Use</th><th>Pros</th><th>Cons</th></tr></thead><tbody>
<tr><td><strong>PNG</strong></td><td>Screenshots with text, UI elements</td><td>Lossless, sharp text</td><td>Larger file size</td></tr>
<tr><td><strong>JPG</strong></td><td>Photos, complex images (not UI)</td><td>Smaller file size</td><td>Lossy compression, blurry text</td></tr>
<tr><td><strong>WebP</strong></td><td>Modern alternative to PNG/JPG</td><td>Smaller + lossless</td><td>Not all viewers support it</td></tr>
</tbody></table>
</div>
<p><strong>Recommendation</strong>: Use <strong>PNG</strong> for all UI/code screenshots. Use <strong>JPG</strong> only for photos (if applicable).</p>
<hr />
<h2 id="5-how-to-crop-effectively"><a class="header" href="#5-how-to-crop-effectively">5. How to Crop Effectively</a></h2>
<h3 id="tool-specific-instructions"><a class="header" href="#tool-specific-instructions">Tool-Specific Instructions</a></h3>
<h4 id="windows-snipping-tool"><a class="header" href="#windows-snipping-tool">Windows Snipping Tool</a></h4>
<ol>
<li>Press <code>Win + Shift + S</code></li>
<li>Drag rectangle around <strong>relevant area only</strong> (not entire screen)</li>
<li>Click notification ‚Üí Opens Snip &amp; Sketch</li>
<li><strong>Before saving</strong>: Use pen tool to blur usernames/emails</li>
<li>Save as PNG to <code>wk09/evidence/screenshots/</code></li>
</ol>
<h4 id="macos-screenshot"><a class="header" href="#macos-screenshot">macOS Screenshot</a></h4>
<ol>
<li>Press <code>Cmd + Shift + 4</code></li>
<li>Drag crosshair around relevant area</li>
<li>Screenshot saves to Desktop (default)</li>
<li>Open in Preview ‚Üí Tools ‚Üí Annotate ‚Üí Blur sensitive areas</li>
<li>Export as PNG to <code>wk09/evidence/screenshots/</code></li>
</ol>
<h4 id="linux-flameshot"><a class="header" href="#linux-flameshot">Linux (Flameshot)</a></h4>
<ol>
<li>Run <code>flameshot gui</code></li>
<li>Drag rectangle around relevant area</li>
<li>Use blur tool (icon) to redact sensitive info</li>
<li>Click Save icon ‚Üí Save as PNG</li>
</ol>
<hr />
<h2 id="6-common-screenshot-types--best-practices"><a class="header" href="#6-common-screenshot-types--best-practices">6. Common Screenshot Types &amp; Best Practices</a></h2>
<h3 id="a-interface-screenshots-full-page"><a class="header" href="#a-interface-screenshots-full-page">A. Interface Screenshots (Full Page)</a></h3>
<p><strong>Purpose</strong>: Show complete UI state (e.g., task list before/after redesign)</p>
<p><strong>Best Practices</strong>:</p>
<ul>
<li>Hide bookmark bar (<code>Ctrl + Shift + B</code> in most browsers)</li>
<li>Close unnecessary tabs (only keep relevant tab open)</li>
<li>Zoom browser to 100% (not 125% or 67%)</li>
<li>Ensure URL bar shows <code>localhost:8080</code> or Codespaces URL</li>
<li>Crop to show browser content area + minimal chrome</li>
</ul>
<p><strong>Example Filename</strong>: <code>task-list-before-redesign.png</code></p>
<hr />
<h3 id="b-devtools-screenshots-html-structure"><a class="header" href="#b-devtools-screenshots-html-structure">B. DevTools Screenshots (HTML Structure)</a></h3>
<p><strong>Purpose</strong>: Show ARIA attributes, semantic HTML, live regions</p>
<p><strong>Best Practices</strong>:</p>
<ul>
<li>Open DevTools (<code>F12</code>)</li>
<li>Navigate to Elements tab</li>
<li>Expand relevant HTML section (e.g., <code>&lt;div id="status"&gt;</code>)</li>
<li>Highlight element to show in right panel:
<ul>
<li>Attributes (ARIA roles, labels)</li>
<li>Styles</li>
<li>Accessibility tree (if available)</li>
</ul>
</li>
<li><strong>Crop tightly</strong> to code + right panel (no need for full browser window)</li>
<li>Increase DevTools font size if text is small (DevTools Settings ‚Üí Appearance)</li>
</ul>
<p><strong>Example Filename</strong>: <code>aria-live-region-devtools.png</code></p>
<hr />
<h3 id="c-screen-reader-screenshots-speech-viewer"><a class="header" href="#c-screen-reader-screenshots-speech-viewer">C. Screen Reader Screenshots (Speech Viewer)</a></h3>
<p><strong>Purpose</strong>: Show what screen reader announces</p>
<p><strong>NVDA (Windows)</strong>:</p>
<ol>
<li>Enable Speech Viewer: <code>NVDA menu ‚Üí Tools ‚Üí Speech Viewer</code></li>
<li>Navigate through interface with <code>Tab</code> or <code>Down Arrow</code></li>
<li>Speech Viewer window shows announced text</li>
<li>Screenshot Speech Viewer window (crop to just that window)</li>
<li><strong>Blur any personal info</strong> in background windows</li>
</ol>
<p><strong>VoiceOver (macOS)</strong>:</p>
<ol>
<li>Enable Caption Panel: VoiceOver Utility ‚Üí Visuals ‚Üí Show Caption Panel</li>
<li>Navigate with <code>VO + Right Arrow</code> (where VO = <code>Ctrl + Option</code>)</li>
<li>Caption Panel shows announced text</li>
<li>Screenshot Caption Panel</li>
<li><strong>Blur any personal info</strong> in background</li>
</ol>
<p><strong>Example Filename</strong>: <code>nvda-task-added-announcement.png</code></p>
<hr />
<h3 id="d-network-timing-screenshots-performance-evidence"><a class="header" href="#d-network-timing-screenshots-performance-evidence">D. Network Timing Screenshots (Performance Evidence)</a></h3>
<p><strong>Purpose</strong>: Show request duration (for Task 1 metrics analysis)</p>
<p><strong>Best Practices</strong>:</p>
<ul>
<li>Open DevTools (<code>F12</code>) ‚Üí Network tab</li>
<li>Perform action (e.g., add task)</li>
<li>Look for POST request to <code>/tasks</code></li>
<li>Click request ‚Üí Timing tab shows duration</li>
<li><strong>Crop to show</strong>:
<ul>
<li>Request URL (<code>/tasks</code>)</li>
<li>Status code (200, 400, etc.)</li>
<li><strong>Duration</strong> (e.g., <code>234ms</code>)</li>
<li>Request headers showing <code>HX-Request: true</code> (if HTMX mode)</li>
</ul>
</li>
<li><strong>Crop out</strong>:
<ul>
<li>Session cookies (in Cookies tab)</li>
<li>Other unrelated requests</li>
</ul>
</li>
</ul>
<p><strong>Example Filename</strong>: <code>add-task-timing-234ms.png</code></p>
<hr />
<h2 id="7-organizing-screenshots-for-submission"><a class="header" href="#7-organizing-screenshots-for-submission">7. Organizing Screenshots for Submission</a></h2>
<h3 id="directory-structure"><a class="header" href="#directory-structure">Directory Structure</a></h3>
<pre><code>wk09/evidence/screenshots/
‚îú‚îÄ‚îÄ 01-baseline/
‚îÇ   ‚îú‚îÄ‚îÄ task-list-full-page.png
‚îÇ   ‚îú‚îÄ‚îÄ add-form-validation-error.png
‚îÇ   ‚îî‚îÄ‚îÄ aria-live-region-devtools.png
‚îú‚îÄ‚îÄ 02-screen-reader/
‚îÇ   ‚îú‚îÄ‚îÄ nvda-task-added.png
‚îÇ   ‚îú‚îÄ‚îÄ nvda-validation-error.png
‚îÇ   ‚îî‚îÄ‚îÄ voiceover-delete-confirmation.png
‚îú‚îÄ‚îÄ 03-network-timing/
‚îÇ   ‚îú‚îÄ‚îÄ add-task-timing.png
‚îÇ   ‚îú‚îÄ‚îÄ delete-task-timing.png
‚îÇ   ‚îî‚îÄ‚îÄ filter-task-timing.png
‚îî‚îÄ‚îÄ 04-after-redesign/
    ‚îú‚îÄ‚îÄ improved-error-message.png
    ‚îú‚îÄ‚îÄ aria-alert-devtools.png
    ‚îî‚îÄ‚îÄ nvda-improved-announcement.png
</code></pre>
<h3 id="naming-convention"><a class="header" href="#naming-convention">Naming Convention</a></h3>
<p>Use <strong>descriptive, searchable filenames</strong>:</p>
<p><strong>Good</strong> ‚úÖ:</p>
<ul>
<li><code>task-list-before-redesign.png</code></li>
<li><code>nvda-announcement-validation-error.png</code></li>
<li><code>devtools-aria-live-region-status.png</code></li>
<li><code>network-timing-add-task-567ms.png</code></li>
</ul>
<p><strong>Bad</strong> ‚ùå:</p>
<ul>
<li><code>Screenshot1.png</code></li>
<li><code>IMG_2024_10_14.png</code></li>
<li><code>Capture.png</code></li>
<li><code>untitled.png</code></li>
</ul>
<hr />
<h2 id="8-privacy-scrubbing-tools"><a class="header" href="#8-privacy-scrubbing-tools">8. Privacy Scrubbing Tools</a></h2>
<h3 id="built-in-most-tools"><a class="header" href="#built-in-most-tools">Built-In (Most Tools)</a></h3>
<ul>
<li><strong>Blur Tool</strong>: Flameshot, Greenshot, Snip &amp; Sketch</li>
<li><strong>Rectangle/Box</strong>: Draw solid box over sensitive area (use same color as background)</li>
<li><strong>Crop</strong>: Remove edges with sensitive info</li>
</ul>
<h3 id="external-if-needed"><a class="header" href="#external-if-needed">External (If Needed)</a></h3>
<ul>
<li>
<p><strong>ImageMagick</strong> (command-line):</p>
<pre><code class="language-bash"># Blur region (x, y, width, height)
convert input.png -region 100x50+10+10 -blur 0x8 output.png
</code></pre>
</li>
<li>
<p><strong>GIMP</strong> (free GUI editor):</p>
<ol>
<li>Open image</li>
<li>Select region (Rectangle Select tool)</li>
<li>Filters ‚Üí Blur ‚Üí Pixelize (or Gaussian Blur)</li>
<li>Export as PNG</li>
</ol>
</li>
</ul>
<h3 id="quick-check-metadata-removal"><a class="header" href="#quick-check-metadata-removal">Quick Check: Metadata Removal</a></h3>
<p>Some screenshot tools embed metadata (creation date, device name). Remove with:</p>
<p><strong>ExifTool</strong> (all platforms):</p>
<pre><code class="language-bash">exiftool -all= screenshot.png
</code></pre>
<p><strong>Or</strong>: Most screenshot tools don't embed EXIF data by default (unlike phone cameras), but verify if submitting to external sites.</p>
<hr />
<h2 id="9-annotation-best-practices"><a class="header" href="#9-annotation-best-practices">9. Annotation Best Practices</a></h2>
<p>When adding <strong>arrows, boxes, or text</strong> to explain screenshots:</p>
<h3 id="good-annotations-"><a class="header" href="#good-annotations-">Good Annotations ‚úÖ</a></h3>
<ul>
<li><strong>Red boxes/arrows</strong>: Highlight relevant code/UI element</li>
<li><strong>Text labels</strong>: Short (1-3 words), clear font (Arial 14pt+)</li>
<li><strong>Contrast</strong>: Red/yellow on light backgrounds, white/yellow on dark</li>
<li><strong>Purpose</strong>: Point to specific ARIA attribute, error message, focus indicator</li>
</ul>
<p><strong>Example</strong>: Red arrow pointing to <code>role="status"</code> in DevTools with label "Live region"</p>
<h3 id="bad-annotations-"><a class="header" href="#bad-annotations-">Bad Annotations ‚ùå</a></h3>
<ul>
<li><strong>Too many arrows</strong>: Cluttered, confusing</li>
<li><strong>Tiny text</strong>: Labels must be 14pt+ to read in PDF</li>
<li><strong>Vague labels</strong>: "This part" instead of "ARIA live region"</li>
<li><strong>Covering content</strong>: Arrow/box blocks the code you're highlighting</li>
</ul>
<hr />
<h2 id="10-testing-screenshot-readability"><a class="header" href="#10-testing-screenshot-readability">10. Testing Screenshot Readability</a></h2>
<p>Before submitting, test if screenshots are readable:</p>
<ol>
<li><strong>Export to PDF</strong> (as you will for submission)</li>
<li><strong>View at 100% zoom</strong> (not zoomed in)</li>
<li><strong>Check text is legible</strong>:
<ul>
<li>Code in DevTools should be readable without squinting</li>
<li>ARIA attributes should be clear</li>
<li>Error messages should be sharp (not blurry JPG artifacts)</li>
</ul>
</li>
<li><strong>If too small</strong>: Retake at higher resolution or crop tighter</li>
</ol>
<p><strong>Rule of thumb</strong>: If you need to zoom to 150%+ to read text, screenshot is too small/blurry.</p>
<hr />
<h2 id="11-common-mistakes--fixes"><a class="header" href="#11-common-mistakes--fixes">11. Common Mistakes &amp; Fixes</a></h2>
<h3 id="mistake-1-full-desktop-screenshot-too-much-context"><a class="header" href="#mistake-1-full-desktop-screenshot-too-much-context">Mistake 1: Full Desktop Screenshot (Too Much Context)</a></h3>
<p><strong>Problem</strong>: Screenshot shows taskbar, desktop icons, unrelated windows
<strong>Fix</strong>: Crop to <strong>browser window only</strong> or <strong>DevTools panel only</strong></p>
<hr />
<h3 id="mistake-2-text-too-small-low-resolution"><a class="header" href="#mistake-2-text-too-small-low-resolution">Mistake 2: Text Too Small (Low Resolution)</a></h3>
<p><strong>Problem</strong>: Took screenshot on 4K monitor but text is tiny in PDF
<strong>Fix</strong>: Increase browser zoom to 125-150% before screenshot, OR use higher DPI export</p>
<hr />
<h3 id="mistake-3-personal-bookmarks-visible"><a class="header" href="#mistake-3-personal-bookmarks-visible">Mistake 3: Personal Bookmarks Visible</a></h3>
<p><strong>Problem</strong>: Bookmark bar shows "Personal Email", "Work Project", "Bank Login"
<strong>Fix</strong>: Hide bookmark bar (<code>Ctrl + Shift + B</code>) OR crop it out OR blur it</p>
<hr />
<h3 id="mistake-4-username-in-file-path"><a class="header" href="#mistake-4-username-in-file-path">Mistake 4: Username in File Path</a></h3>
<p><strong>Problem</strong>: Screenshot shows <code>C:\Users\JohnSmith\IdeaProjects\comp2850\...</code>
<strong>Fix</strong>:</p>
<ul>
<li>Option A: Crop file path out</li>
<li>Option B: Blur username portion</li>
<li>Option C: Use environment variable in terminal: <code>~/IdeaProjects/...</code> instead of full path</li>
</ul>
<hr />
<h3 id="mistake-5-dark-mode-code-unreadable"><a class="header" href="#mistake-5-dark-mode-code-unreadable">Mistake 5: Dark Mode Code Unreadable</a></h3>
<p><strong>Problem</strong>: White text on black background exports as low-contrast gray in PDF
<strong>Fix</strong>:</p>
<ul>
<li>Use <strong>light theme</strong> in DevTools (Settings ‚Üí Appearance ‚Üí Light)</li>
<li>OR export as PNG (not JPG which loses contrast)</li>
</ul>
<hr />
<h2 id="12-accessibility-of-screenshots-for-your-portfolio"><a class="header" href="#12-accessibility-of-screenshots-for-your-portfolio">12. Accessibility of Screenshots (For Your Portfolio)</a></h2>
<p>When preparing your <strong>final portfolio</strong>, ensure screenshots are accessible:</p>
<h3 id="add-alt-text-if-embedding-in-web-portfolio"><a class="header" href="#add-alt-text-if-embedding-in-web-portfolio">Add Alt Text (If Embedding in Web Portfolio)</a></h3>
<pre><code class="language-html">&lt;img src="aria-live-region.png"
     alt="Chrome DevTools showing div element with id='status', role='status', and aria-live='polite' attributes"&gt;
</code></pre>
<h3 id="provide-captions-in-pdf-submission"><a class="header" href="#provide-captions-in-pdf-submission">Provide Captions (In PDF Submission)</a></h3>
<p><strong>Example</strong>:</p>
<pre><code>Figure 1: ARIA live region in DevTools
The status div has role="status" and aria-live="polite", ensuring screen readers announce task additions without interrupting the user.
</code></pre>
<h3 id="use-high-contrast"><a class="header" href="#use-high-contrast">Use High Contrast</a></h3>
<ul>
<li>Avoid light gray text on white backgrounds</li>
<li>Annotations should be <strong>red</strong> (high contrast) not light pink</li>
<li>Ensure focus indicators are visible (3:1 contrast minimum)</li>
</ul>
<hr />
<h2 id="13-quick-reference-screenshot-workflow"><a class="header" href="#13-quick-reference-screenshot-workflow">13. Quick Reference: Screenshot Workflow</a></h2>
<ol>
<li><strong>Before</strong>: Hide bookmark bar, close extra tabs, use test data</li>
<li><strong>Capture</strong>: Use tool's region select (not full screen)</li>
<li><strong>Inspect</strong>: Check for PII (usernames, emails, file paths)</li>
<li><strong>Scrub</strong>: Blur or crop sensitive areas</li>
<li><strong>Annotate</strong> (if needed): Add red arrows/boxes to highlight</li>
<li><strong>Save</strong>: PNG format, descriptive filename</li>
<li><strong>Organize</strong>: Move to appropriate evidence subfolder</li>
<li><strong>Verify</strong>: Open in PDF viewer at 100% zoom, check readability</li>
</ol>
<hr />
<h2 id="14-example-evidence-package"><a class="header" href="#14-example-evidence-package">14. Example Evidence Package</a></h2>
<p>Here's what a complete screenshot evidence folder might look like for <strong>Task 1 (Week 9)</strong>:</p>
<pre><code>wk09/evidence/screenshots/
‚îú‚îÄ‚îÄ 01-baseline-interface/
‚îÇ   ‚îú‚îÄ‚îÄ task-list-full-view.png              (1280x720, 156KB)
‚îÇ   ‚îú‚îÄ‚îÄ add-task-form-validation-error.png   (800x600, 89KB)
‚îÇ   ‚îî‚îÄ‚îÄ filter-results-no-announcement.png   (1280x720, 142KB)
‚îÇ
‚îú‚îÄ‚îÄ 02-html-structure/
‚îÇ   ‚îú‚îÄ‚îÄ aria-live-region-status-devtools.png (1024x768, 203KB)
‚îÇ   ‚îú‚îÄ‚îÄ form-labels-aria-describedby.png     (800x600, 134KB)
‚îÇ   ‚îî‚îÄ‚îÄ skip-link-html-structure.png         (800x600, 98KB)
‚îÇ
‚îú‚îÄ‚îÄ 03-screen-reader-testing/
‚îÇ   ‚îú‚îÄ‚îÄ nvda-task-added-success.png          (600x400, 45KB)
‚îÇ   ‚îú‚îÄ‚îÄ nvda-validation-error-not-announced.png (600x400, 52KB)
‚îÇ   ‚îî‚îÄ‚îÄ voiceover-delete-button-label.png    (700x300, 67KB)
‚îÇ
‚îú‚îÄ‚îÄ 04-network-performance/
‚îÇ   ‚îú‚îÄ‚îÄ add-task-post-timing-234ms.png       (900x700, 178KB)
‚îÇ   ‚îú‚îÄ‚îÄ delete-task-post-timing-187ms.png    (900x700, 165KB)
‚îÇ   ‚îî‚îÄ‚îÄ filter-get-timing-1847ms.png         (900x700, 189KB)
‚îÇ
‚îî‚îÄ‚îÄ 05-after-redesign/
    ‚îú‚îÄ‚îÄ improved-error-aria-alert.png        (1280x720, 156KB)
    ‚îú‚îÄ‚îÄ nvda-now-announces-error.png         (600x400, 48KB)
    ‚îî‚îÄ‚îÄ devtools-role-alert-added.png        (800x600, 145KB)
</code></pre>
<p><strong>Total</strong>: ~20 screenshots, ~2MB compressed (well within Gradescope limits)</p>
<hr />
<h2 id="resources-4"><a class="header" href="#resources-4">Resources</a></h2>
<ul>
<li><strong>WCAG 2.2 Images of Text</strong>: https://www.w3.org/WAI/WCAG22/Understanding/images-of-text</li>
<li><strong>UK GDPR Compliance</strong>: https://ico.org.uk/for-organisations/guide-to-data-protection/</li>
<li><strong>Screenshot Tools Comparison</strong>: https://alternativeto.net/software/snipping-tool/</li>
</ul>
<hr />
<p><strong>Guide Version</strong>: 1.0
<strong>Last Updated</strong>: 2025-10-14
<strong>Module</strong>: COMP2850 HCI
<strong>Contact</strong>: See module Minerva page for help with evidence submission</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="process-visuals"><a class="header" href="#process-visuals">Process Visuals</a></h1>
<p>High-level diagrams that map the Week 6-11 journey, evidence pipelines, component structure, and critique loop. Each figure renders via Mermaid; follow the anchor links from labs or the index to revisit them.</p>
<h2 id="semester-flow"><a class="header" href="#semester-flow">Semester Flow</a></h2>
<pre class="mermaid">graph LR
  W6[Week 6&lt;br/&gt;Server-first&lt;br/&gt;Needs-finding]
  W7[Week 7&lt;br/&gt;Ethics&lt;br/&gt;Accessibility]
  W8[Week 8&lt;br/&gt;Prototyping&lt;br/&gt;Constraints]
  W9[Week 9&lt;br/&gt;Evaluation&lt;br/&gt;Pilots]
  W10[Week 10&lt;br/&gt;Analysis&lt;br/&gt;Redesign]
  W11[Week 11&lt;br/&gt;Studio Crit&lt;br/&gt;Portfolio]

  W6 --&gt; W7
  W7 --&gt; W8
  W8 --&gt; W9
  W9 --&gt; W10
  W10 --&gt; W11
</pre>
<p><strong>What it shows:</strong> the six-week arc from observation to wrap-up, one swimlane per theme.</p>
<h2 id="evidence-map"><a class="header" href="#evidence-map">Evidence Map</a></h2>
<pre class="mermaid">graph TD
  A[Needs-finding stories] --&gt; B[Inclusive backlog]
  B --&gt; C[WCAG &amp; heuristic audit]
  C --&gt; D[Pilots &amp; metrics]
  D --&gt; E[Analysis &amp; prioritisation]
  E --&gt; F[Inclusive redesign]
  F --&gt; G[Task 2 evidence pack]
  G --&gt; H[Studio crit &amp; wrap-up]
  H --&gt;|Carry forward| B
</pre>
<p><strong>What it shows:</strong> how artefacts produced in each lab feed Task 1 and Task 2, ensuring evidence chains stay intact.</p>
<h2 id="template-hierarchy"><a class="header" href="#template-hierarchy">Template Hierarchy</a></h2>
<pre class="mermaid">graph TD
  Base[_layout/base.peb&lt;br/&gt;skip link, live region, Pico.css]
  Base --&gt; Index[tasks/index.peb]
  Index --&gt; List[tasks/_list.peb]
  List --&gt; Item[tasks/_item.peb]
  Index --&gt; Pager[tasks/_pager.peb]
  Item --&gt;|Forms| Routes[(Ktor routes)]
  Pager --&gt;|Links| Routes
  Routes --&gt; HTMX[HTMX fragment responses]
  Routes --&gt; PRG[Full-page PRG responses]
</pre>
<p><strong>What it shows:</strong> relationships between the Pebble layout, task partials, and Ktor routes used in Week 8's partial refactor.</p>
<h2 id="crit-loop"><a class="header" href="#crit-loop">Crit Loop</a></h2>
<pre class="mermaid">graph TD
  Present[Evidence-led demo]
  Present --&gt; Feedback[Peer &amp; staff critique]
  Feedback --&gt; Notes[Crit notes &amp; backlog updates]
  Notes --&gt; Portfolio[Portfolio &amp; wrap-up]
  Portfolio --&gt; Plan[Semester 2 planning]
  Plan --&gt; Present
</pre>
<p><strong>What it shows:</strong> the continuous feedback cycle students should follow during the Week 11 studio critique and portfolio wrap-up.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->
        <script src="mermaid.min.js"></script>
        <script src="mermaid-init.js"></script>

        <script>
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>


    </div>
    </body>
</html>
