<!DOCTYPE HTML>
<html lang="en" class="navy sidebar-visible" dir="ltr">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Lab 2: Pilots, debrief, Task 1 draft pack - COMP2850 ‚Ä¢ Human-Computer Interaction</title>


        <!-- Custom HTML head -->

        <meta name="description" content="HCI module covering server-first architecture, accessibility, privacy by design, and evaluation (Weeks 6-11)">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff">

        <link rel="icon" href="../favicon.svg">
        <link rel="shortcut icon" href="../favicon.png">
        <link rel="stylesheet" href="../css/variables.css">
        <link rel="stylesheet" href="../css/general.css">
        <link rel="stylesheet" href="../css/chrome.css">
        <link rel="stylesheet" href="../css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="../FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="../fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" id="highlight-css" href="../highlight.css">
        <link rel="stylesheet" id="tomorrow-night-css" href="../tomorrow-night.css">
        <link rel="stylesheet" id="ayu-highlight-css" href="../ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        <link rel="stylesheet" href="../css/admonish.css">
        <link rel="stylesheet" href="../css/custom.css">
        <link rel="stylesheet" href="../css/retro-theme.css">
        <link rel="stylesheet" href=".././mdbook-admonish.css">


        <!-- Provide site root and default themes to javascript -->
        <script>
            const path_to_root = "../";
            const default_light_theme = "navy";
            const default_dark_theme = "navy";
            window.path_to_searchindex_js = "../searchindex.js";
        </script>
        <!-- Start loading toc.js asap -->
        <script src="../toc.js"></script>
    </head>
    <body>
    <div id="mdbook-help-container">
        <div id="mdbook-help-popup">
            <h2 class="mdbook-help-title">Keyboard shortcuts</h2>
            <div>
                <p>Press <kbd>‚Üê</kbd> or <kbd>‚Üí</kbd> to navigate between chapters</p>
                <p>Press <kbd>S</kbd> or <kbd>/</kbd> to search in the book</p>
                <p>Press <kbd>?</kbd> to show this help</p>
                <p>Press <kbd>Esc</kbd> to hide this help</p>
            </div>
        </div>
    </div>
    <div id="body-container">
        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                let theme = localStorage.getItem('mdbook-theme');
                let sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            const default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? default_dark_theme : default_light_theme;
            let theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            const html = document.documentElement;
            html.classList.remove('navy')
            html.classList.add(theme);
            html.classList.add("js");
        </script>

        <input type="checkbox" id="sidebar-toggle-anchor" class="hidden">

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            let sidebar = null;
            const sidebar_toggle = document.getElementById("sidebar-toggle-anchor");
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
                sidebar_toggle.checked = false;
            }
            if (sidebar === 'visible') {
                sidebar_toggle.checked = true;
            } else {
                html.classList.remove('sidebar-visible');
            }
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <!-- populated by js -->
            <mdbook-sidebar-scrollbox class="sidebar-scrollbox"></mdbook-sidebar-scrollbox>
            <noscript>
                <iframe class="sidebar-iframe-outer" src="../toc.html"></iframe>
            </noscript>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle">
                <div class="sidebar-resize-indicator"></div>
            </div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <label id="sidebar-toggle" class="icon-button" for="sidebar-toggle-anchor" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </label>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="default_theme">Auto</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search (`/`)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="/ s" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">COMP2850 ‚Ä¢ Human-Computer Interaction</h1>

                    <div class="right-buttons">
                        <a href="../print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <div class="search-wrapper">
                            <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                            <div class="spinner-wrapper">
                                <i class="fa fa-spinner fa-spin"></i>
                            </div>
                        </div>
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="week-9--lab-2--peer-pilots-debrief-and-task-1-draft-pack"><a class="header" href="#week-9--lab-2--peer-pilots-debrief-and-task-1-draft-pack">Week 9 ‚Ä¢ Lab 2 ‚Äî Peer Pilots, Debrief, and Task 1 Draft Pack</a></h1>
<p><img src="https://img.shields.io/badge/COMP2850-HCI-blue" alt="COMP2850" />
<img src="https://img.shields.io/badge/Week-9-orange" alt="Week 9" />
<img src="https://img.shields.io/badge/Lab-2-green" alt="Lab 2" />
<img src="https://img.shields.io/badge/Status-Draft-yellow" alt="Status" /></p>
<hr />
<h2 id="before-lab-required-reading-10-mins"><a class="header" href="#before-lab-required-reading-10-mins">Before Lab: Required Reading (10 mins)</a></h2>
<p>üìñ <strong>Essential</strong>:</p>
<ul>
<li>Push/log Week 9 starter repo instrumentation before pilots</li>
<li>Review your Week 9 Lab 1 protocol (<code>wk09/lab-wk9/research/protocol.md</code>)</li>
<li>Review <code>references/consent-pii-faq.md</code></li>
<li><a href="https://www.nngroup.com/articles/how-many-test-users/">Nielsen: How Many Test Users in Usability Studies?</a></li>
</ul>
<p>üìñ <strong>Quick reference</strong>:</p>
<ul>
<li><a href="../references/evaluation-metrics-quickref.html">Evaluation Metrics Quick Reference</a></li>
<li><a href="../references/assistive-testing-checklist.html">Assistive Testing Checklist</a></li>
<li><a href="../references/screenshot-guide.html">Screenshot Evidence Guide</a></li>
</ul>
<hr />
<h2 id="introduction-from-plan-to-data"><a class="header" href="#introduction-from-plan-to-data">Introduction: From Plan to Data</a></h2>
<p>Week 9 Lab 1 built the evaluation infrastructure. <strong>Today you execute</strong>.</p>
<p>Running peer pilots is <strong>the most critical empirical HCI activity</strong> in this module:</p>
<ul>
<li><strong>Data collection</strong>: Objective metrics (time, errors, completion) + subjective (confidence, satisfaction)</li>
<li><strong>Qualitative insights</strong>: Observe real struggles, accessibility barriers, unexpected behaviours</li>
<li><strong>Evidence generation</strong>: Logs, notes, screenshots for Gradescope Task 1 and Week 11 portfolio</li>
</ul>
<p><strong>Why this matters</strong>:</p>
<ul>
<li>Week 10 redesign <strong>depends on</strong> identifying real problems (not assumed ones)</li>
<li>Task 1 grade depends on evidence quality (traceability from raw data ‚Üí findings ‚Üí mitigations)</li>
<li>Professional practice: Decisions backed by data, not opinions</li>
</ul>
<p><strong>Ethical imperative</strong>: Participants are peers, not research subjects. Treat them respectfully, honour consent, protect privacy.</p>
<hr />
<h2 id="learning-focus"><a class="header" href="#learning-focus">Learning Focus</a></h2>
<h3 id="lab-objectives"><a class="header" href="#lab-objectives">Lab Objectives</a></h3>
<blockquote>
<p><strong>Staff reference</strong>: Sample data + completed pilot pack available in the <a href="../../resources/code-resources.html#week-9">solution repository</a>.
By the end of this session, you will have:</p>
</blockquote>
<ul>
<li>Conducted 4 peer pilots following ethical protocol</li>
<li>Collected quantitative data (time-on-task, errors, SUS) and qualitative observations</li>
<li>Taken observer notes (quotes, errors, time-on-task)</li>
<li>Debriefed with participants and synthesised findings</li>
<li>Documented findings with evidence chains (raw data ‚Üí issue ‚Üí backlog item)</li>
<li>Assembled draft Task 1 evidence pack</li>
</ul>
<h3 id="learning-outcomes-addressed"><a class="header" href="#learning-outcomes-addressed">Learning Outcomes Addressed</a></h3>
<p>This lab contributes to the following module Learning Outcomes (<a href="../references/learning-outcomes.html">full definitions</a>):</p>
<ul>
<li><strong>LO6</strong>: Apply iterative design ‚Äî evidenced by pilot data ‚Üí findings synthesis</li>
<li><strong>LO8</strong>: Design and execute evaluation ‚Äî evidenced by 4 pilot sessions + data</li>
<li><strong>LO11</strong>: Collaborate in teams ‚Äî evidenced by peer pilot facilitation + observer role</li>
<li><strong>LO12</strong>: Demonstrate professionalism ‚Äî evidenced by consent adherence + respectful facilitation</li>
</ul>
<hr />
<h2 id="key-concepts"><a class="header" href="#key-concepts">Key Concepts</a></h2>
<h3 id="pilot-study"><a class="header" href="#pilot-study">Pilot Study</a></h3>
<blockquote>
<p><strong>Pilot Study</strong> [GLOSSARY]</p>
<p>Small-scale preliminary study to test evaluation protocol and gather initial data. <strong>Formative</strong> (improve design) vs <strong>Summative</strong> (final quality assessment).</p>
<p><strong>This module uses formative pilots</strong>: Identify issues to fix in Week 10, not measure final quality.</p>
<p><strong>Characteristics</strong>:</p>
<ul>
<li>Small sample (5‚Äì10 participants typical for qualitative insights)</li>
<li>Controlled tasks (defined in Week 9 Lab 1)</li>
<li>Mixed methods (quantitative metrics + qualitative observation)</li>
<li>Iterative (findings inform redesign)</li>
</ul>
<p><strong>Nielsen's 5-user rule</strong>: 5 participants find ~85% of usability issues. Diminishing returns after that for formative testing.</p>
<p><strong>HCI Connection</strong>: Empirical HCI requires <strong>ecological validity</strong>‚Äîtest with real people doing realistic tasks, not just hypothetical analysis.</p>
<p>üîó <a href="https://www.nngroup.com/articles/why-you-only-need-to-test-with-5-users/">Nielsen: Why You Only Need to Test with 5 Users</a></p>
</blockquote>
<h3 id="qualitative-vs-quantitative-data"><a class="header" href="#qualitative-vs-quantitative-data">Qualitative vs Quantitative Data</a></h3>
<blockquote>
<p><strong>Quantitative Data</strong> [GLOSSARY]</p>
<p>Numerical measurements: times, counts, percentages. <strong>Objective</strong>, statistically analysable.</p>
<p><strong>Examples from this module</strong>:</p>
<ul>
<li>Task completion time: Median 24s (MAD 6s)</li>
<li>Error rate: 2/5 = 40%</li>
<li>Completion rate: 4/5 = 80%</li>
</ul>
<p><strong>Strengths</strong>: Comparable, repeatable, supports statistical tests
<strong>Limitations</strong>: Doesn't explain "why"‚Äîneed qualitative data to interpret</p>
<hr />
<p><strong>Qualitative Data</strong> [GLOSSARY]</p>
<p>Non-numerical observations: quotes, behaviours, patterns. <strong>Subjective</strong>, interpretive.</p>
<p><strong>Examples from this module</strong>:</p>
<ul>
<li>"Participant paused 10s, said 'I'm not sure if it saved'"</li>
<li>"Screen reader did not announce filter result count"</li>
<li>"Participant used Ctrl+F instead of built-in filter"</li>
</ul>
<p><strong>Strengths</strong>: Reveals "why" issues occur, uncovers unexpected problems
<strong>Limitations</strong>: Varies by participant, researcher bias, harder to generalize</p>
<p><strong>HCI Connection</strong>: Best practice = <strong>mixed methods</strong> (both quant + qual). Numbers show <em>what</em> happened, observations show <em>why</em>.</p>
<p>üîó <a href="https://dl.acm.org/doi/book/10.5555/2737875">Lazar et al.: Research Methods in HCI</a> ‚Äî Chapter 9</p>
</blockquote>
<h3 id="think-aloud-protocol"><a class="header" href="#think-aloud-protocol">Think-Aloud Protocol</a></h3>
<blockquote>
<p><strong>Think-Aloud Protocol</strong> [GLOSSARY]</p>
<p>Participants verbalize their thoughts while completing tasks. Reveals cognitive process, confusion points, expectations.</p>
<p><strong>Types</strong>:</p>
<ul>
<li><strong>Concurrent</strong>: Talk while doing task (can be distracting, slower)</li>
<li><strong>Retrospective</strong>: Explain after completing (less disruptive but memory decay)</li>
</ul>
<p><strong>For this module</strong>: <strong>Optional concurrent</strong> (invite, don't force). Some participants find it natural, others find it intrusive.</p>
<p><strong>Example quote captured</strong>:</p>
<blockquote>
<p>"I'm looking for a filter... is this the search box? I'll try typing here."</p>
</blockquote>
<p><strong>HCI Connection</strong>: Think-aloud reveals <strong>mental models</strong>‚Äîhow people understand the interface vs how it actually works.</p>
<p><strong>Accessibility note</strong>: Think-aloud can be difficult for screen reader users (talking competes with SR audio). Allow silence.</p>
<p>üîó <a href="https://www.nngroup.com/articles/thinking-aloud-the-1-usability-tool/">Nielsen: Thinking Aloud: The #1 Usability Tool</a></p>
</blockquote>
<h3 id="evidence-chain"><a class="header" href="#evidence-chain">Evidence Chain</a></h3>
<blockquote>
<p><strong>Evidence Chain</strong> [GLOSSARY]</p>
<p>Traceability from raw data ‚Üí finding ‚Üí backlog item ‚Üí fix ‚Üí verification. Critical for academic rigour and professional practice.</p>
<p><strong>Example chain</strong>:</p>
<ol>
<li><strong>Raw data</strong>: <code>metrics.csv</code> shows <code>T2_edit, validation_error, blank_title</code> for session <code>WK9A03</code></li>
<li><strong>Observation</strong>: Pilot notes say "Participant didn't notice error message, submitted blank again"</li>
<li><strong>Finding</strong>: "Error messages not accessible to screen readers (WCAG 4.1.3 violation)"</li>
<li><strong>Backlog item</strong>: <code>wk9-05: Add role=alert to validation errors</code></li>
<li><strong>Fix</strong> (Week 10): Update template with <code>&lt;p role="alert"&gt;</code></li>
<li><strong>Verification</strong>: Retest with screen reader, confirm announcement</li>
</ol>
<p><strong>Why this matters</strong>:</p>
<ul>
<li><strong>Gradescope Task 1</strong>: Markers check evidence chains (no evidence = no marks)</li>
<li><strong>Professional practice</strong>: Design decisions require justification</li>
<li><strong>Accreditation</strong>: External panels expect rigorous HCI process</li>
</ul>
<p><strong>HCI Connection</strong>: Evidence chains demonstrate <strong>systematic design process</strong>, not ad-hoc changes.</p>
<p>üîó <a href="https://www.gov.uk/service-manual/measuring-success/using-data-to-improve-your-service">GOV.UK Service Manual: Using data in service design</a></p>
</blockquote>
<h3 id="thematic-coding"><a class="header" href="#thematic-coding">Thematic Coding</a></h3>
<blockquote>
<p><strong>Thematic Coding</strong> [GLOSSARY]</p>
<p>Systematic process of identifying patterns (themes) in qualitative data. Used to analyse pilot notes.</p>
<p><strong>Process</strong>:</p>
<ol>
<li><strong>Read notes</strong>: Familiarize yourself with all observations</li>
<li><strong>Code</strong>: Label each observation with tags (e.g., "sr-announcement", "validation-error", "focus-management")</li>
<li><strong>Group</strong>: Cluster similar codes into themes (e.g., all "sr-announcement" issues ‚Üí theme: "Status feedback")</li>
<li><strong>Interpret</strong>: What do these themes tell us about usability/accessibility?</li>
</ol>
<p><strong>Example</strong> (simplified):</p>
<pre><code>Observation: "Participant didn't notice success message" ‚Üí Code: feedback-timing
Observation: "SR didn't announce deletion" ‚Üí Code: sr-announcement
Observation: "Participant asked 'did it save?'" ‚Üí Code: feedback-clarity

Theme: "Success feedback insufficient" (3 codes)
Priority: High (affects confidence, inclusion)
</code></pre>
<p><strong>This module</strong>: Light-touch thematic coding in Week 10. Full formal coding (inter-rater reliability, etc.) is postgraduate-level.</p>
<p>üîó <a href="https://www.tandfonline.com/doi/abs/10.1191/1478088706qp063oa">Braun &amp; Clarke: Thematic Analysis</a> ‚Äî Academic reference</p>
</blockquote>
<hr />
<h2 id="activity-a-pilot-preparation-10-min"><a class="header" href="#activity-a-pilot-preparation-10-min">Activity A: Pilot Preparation (10 min)</a></h2>
<p><strong>Goal</strong>: Ensure everything is ready before first participant arrives.</p>
<h3 id="step-1-technical-setup-5-min"><a class="header" href="#step-1-technical-setup-5-min">Step 1: Technical setup (5 min)</a></h3>
<ol>
<li><strong>Start server</strong>: <code>./gradlew run</code> (or IDE run configuration)</li>
<li><strong>Test routes</strong>: Visit <code>/tasks</code>, confirm prototype works (add/edit/filter/delete)</li>
<li><strong>Clear old data</strong> (optional): If <code>data/metrics.csv</code> contains dry-run rows, either delete them or note the starting row number so you know which rows are real pilot data</li>
</ol>
<p><strong>Verify instrumentation</strong>:</p>
<ul>
<li>Submit a test task ‚Üí check <code>metrics.csv</code> for new row</li>
<li>Submit empty form ‚Üí check for <code>validation_error</code> row</li>
<li>Disable JS, repeat ‚Üí check <code>js_mode=off</code> appears</li>
</ul>
<p>If anything's broken, <strong>fix it now</strong> (don't waste participants' time).</p>
<h3 id="step-2-materials-ready-3-min"><a class="header" href="#step-2-materials-ready-3-min">Step 2: Materials ready (3 min)</a></h3>
<p><strong>Physical/digital checklists</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Protocol document (<code>wk09/lab-wk9/research/protocol.md</code>) printed or on second screen</li>
<li><input disabled="" type="checkbox"/>
Task scenarios ready to read aloud</li>
<li><input disabled="" type="checkbox"/>
Consent script ready (memorize or have visible)</li>
<li><input disabled="" type="checkbox"/>
<code>pilot-notes.md</code> template open in editor</li>
<li><input disabled="" type="checkbox"/>
Stopwatch/timer (backup for server timing)</li>
<li><input disabled="" type="checkbox"/>
Post-task questions printed (confidence rating 1‚Äì5)</li>
</ul>
<p><strong>Participant setup</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Clean browser session (clear cookies, cache)</li>
<li><input disabled="" type="checkbox"/>
Navigate to prototype homepage</li>
<li><input disabled="" type="checkbox"/>
DevTools closed (don't intimidate participant with console)</li>
</ul>
<h3 id="step-3-role-allocation-2-min"><a class="header" href="#step-3-role-allocation-2-min">Step 3: Role allocation (2 min)</a></h3>
<p><strong>Work in pairs or triads</strong>:</p>
<ul>
<li><strong>Facilitator</strong>: Reads scenarios, asks questions, manages timing</li>
<li><strong>Note-taker</strong>: Records observations, direct quotes, timestamps</li>
<li><strong>Participant</strong>: Completes tasks</li>
</ul>
<p><strong>Rotate roles</strong> after each pilot (everyone gets experience facilitating and participating).</p>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Server running, prototype functional</li>
<li><input disabled="" type="checkbox"/>
metrics.csv logging correctly</li>
<li><input disabled="" type="checkbox"/>
Protocol and materials ready</li>
<li><input disabled="" type="checkbox"/>
Roles assigned</li>
</ul>
<hr />
<h2 id="activity-b-run-pilot-sessions-6080-min"><a class="header" href="#activity-b-run-pilot-sessions-6080-min">Activity B: Run Pilot Sessions (60‚Äì80 min)</a></h2>
<p><strong>Goal</strong>: Conduct 5‚Äì6 peer pilots following your ethical protocol.</p>
<p><strong>Timing</strong>:</p>
<ul>
<li>~15 minutes per pilot (4 tasks + debrief)</li>
<li>~5 minutes between pilots (swap roles, generate new session ID)</li>
<li>Total: 5 pilots √ó 20 min = ~100 min</li>
</ul>
<p><strong>If time is tight</strong>: Minimum 3 pilots (one with keyboard-only, one with JS-off, one standard).</p>
<h3 id="pilot-1-standard-htmx-mouse-js-on"><a class="header" href="#pilot-1-standard-htmx-mouse-js-on">Pilot 1: Standard (HTMX, mouse, JS-on)</a></h3>
<h4 id="setup-3-min"><a class="header" href="#setup-3-min">Setup (3 min)</a></h4>
<ol>
<li>
<p><strong>Generate session ID</strong>:</p>
<pre><code class="language-bash">openssl rand -hex 3  # Example output: 7a9f2c
</code></pre>
<p>Or use: <code>https://www.random.org/strings/</code> (6 chars, alphanumeric)</p>
</li>
<li>
<p><strong>Set cookie</strong> in participant browser (DevTools Console):</p>
<pre><code class="language-javascript">document.cookie = "sid=P1_7a9f; path=/";
</code></pre>
</li>
<li>
<p><strong>Record in consent log</strong> (<code>wk09/lab-wk9/research/consent-log.md</code>):</p>
<pre><code class="language-markdown">## Pilot 1
Date: 2025-10-15
Participant code: P1
Session ID: P1_7a9f
Variant: Standard (HTMX, mouse, JS-on)
Consent: Verbal consent given at 14:15
Notes: None
</code></pre>
</li>
</ol>
<h4 id="consent-process-2-min"><a class="header" href="#consent-process-2-min">Consent process (2 min)</a></h4>
<p><strong>Read script</strong> (from protocol.md):</p>
<blockquote>
<p>"Thanks for agreeing to pilot our prototype. This is a quick usability test‚Äîabout 15 minutes. I'll ask you to complete 4 tasks while I observe and take notes. I'm testing the interface, not you, so there are no wrong answers.</p>
<p><strong>What we're collecting</strong>: task times, whether you complete successfully, any errors, your confidence ratings, and my notes on any issues.</p>
<p><strong>What we're NOT collecting</strong>: your name, email, student ID, or any recordings.</p>
<p>Your session code is <code>P1_7a9f</code>. You can request data deletion anytime.</p>
<p><strong>You can stop at any time.</strong> Do you have questions?"</p>
</blockquote>
<p><strong>Wait for verbal consent</strong>: "Are you happy to proceed?"</p>
<p>If participant declines or seems uncertain, thank them and find another volunteer.</p>
<h4 id="warm-up-2-min-not-timed"><a class="header" href="#warm-up-2-min-not-timed">Warm-up (2 min, not timed)</a></h4>
<p>"Take a minute to browse the task list. Click around, get familiar. Think aloud if you're comfortable‚Äîsay what you're thinking‚Äîbut no pressure. Let me know when you're ready for the first task."</p>
<p><strong>Note-taker observes</strong>: Initial reactions, confusion points, do they notice key UI elements?</p>
<h4 id="task-t3-add-task-60s-limit"><a class="header" href="#task-t3-add-task-60s-limit">Task T3: Add Task (60s limit)</a></h4>
<p><strong>Facilitator reads</strong>:</p>
<blockquote>
<p>"You need to remember to 'Call supplier about delivery'. Add this as a new task."</p>
</blockquote>
<p><strong>Start timing</strong>: When participant focuses in input or begins typing.</p>
<p><strong>Note-taker records</strong>:</p>
<ul>
<li>Timestamp (e.g., <code>14:18</code>)</li>
<li>Did they find form immediately?</li>
<li>Did they hesitate or look confused?</li>
<li>Did they submit blank by mistake?</li>
<li>Did they notice success confirmation?</li>
</ul>
<p><strong>Post-task question</strong>:</p>
<blockquote>
<p>"On a scale of 1 to 5, how confident are you that you completed that correctly?"</p>
</blockquote>
<p>Record answer: <code>Confidence: 5</code></p>
<p><strong>Check logs</strong>: Open <code>data/metrics.csv</code>, verify new row with <code>task_code=T3_add, step=success, session_id=P1_7a9f</code>.</p>
<hr />
<h4 id="task-t1-filter-tasks-120s-limit"><a class="header" href="#task-t1-filter-tasks-120s-limit">Task T1: Filter Tasks (120s limit)</a></h4>
<p><strong>Facilitator reads</strong>:</p>
<blockquote>
<p>"You've been asked to find all tasks containing the word 'report'. Use the filter to show only matching tasks, then count how many remain."</p>
</blockquote>
<p><strong>Note-taker records</strong>:</p>
<ul>
<li>How long to find filter box?</li>
<li>Did they type "report" or "Report" (case sensitivity)?</li>
<li>Did they notice result count indicator?</li>
<li>Did they manually count items vs read count?</li>
</ul>
<p><strong>Post-task question</strong>: Confidence (1‚Äì5)</p>
<hr />
<h4 id="task-t2-edit-task-90s-limit"><a class="header" href="#task-t2-edit-task-90s-limit">Task T2: Edit Task (90s limit)</a></h4>
<p><strong>Facilitator reads</strong>:</p>
<blockquote>
<p>"The task 'Submit invoices' has a typo. Change it to 'Submit invoices by Friday' and save the change."</p>
</blockquote>
<p><strong>Note-taker records</strong>:</p>
<ul>
<li>How quickly did they find Edit button?</li>
<li>Any validation errors triggered?</li>
<li>Did they verify edit saved?</li>
<li>Any confusion about inline vs full-page edit?</li>
</ul>
<p><strong>Post-task question</strong>: Confidence (1‚Äì5)</p>
<hr />
<h4 id="task-t4-delete-task-45s-limit"><a class="header" href="#task-t4-delete-task-45s-limit">Task T4: Delete Task (45s limit)</a></h4>
<p><strong>Facilitator reads</strong>:</p>
<blockquote>
<p>"The task 'Test entry' is no longer needed. Delete it."</p>
</blockquote>
<p><strong>Note-taker records</strong>:</p>
<ul>
<li>Confirmation dialog appeared? (HTMX)</li>
<li>Did they expect confirmation?</li>
<li>Did they verify deletion succeeded?</li>
</ul>
<p><strong>Post-task question</strong>: Confidence (1‚Äì5)</p>
<hr />
<h4 id="debrief-3-min"><a class="header" href="#debrief-3-min">Debrief (3 min)</a></h4>
<p><strong>Facilitator asks</strong>:</p>
<ol>
<li>"Which task felt most difficult?"</li>
<li>"Did anything surprise you or not work as expected?"</li>
<li>"Were there any points where you weren't sure if something had worked?"</li>
</ol>
<p><strong>Record verbatim quotes</strong> in notes:</p>
<pre><code>Debrief P1:
- "T2 edit was hardest‚ÄîI wasn't sure if it saved"
- "T1 filter was easy once I found the box"
- "Success messages were subtle, I had to look for them"
</code></pre>
<p><strong>Thank participant</strong>:</p>
<blockquote>
<p>"That's really helpful, thank you. Your feedback will directly improve the prototype."</p>
</blockquote>
<hr />
<h3 id="pilot-2-keyboard-only-variant"><a class="header" href="#pilot-2-keyboard-only-variant">Pilot 2: Keyboard-Only Variant</a></h3>
<p>Repeat entire process with new participant, <strong>new session ID</strong> (e.g., <code>P2_4d8e</code>).</p>
<p><strong>Key difference</strong>: Participant uses <strong>Tab, Enter, Space only</strong> (no mouse).</p>
<p><strong>Record variant</strong> in consent log: <code>Variant: Keyboard-only, JS-on</code></p>
<p><strong>Additional observations to capture</strong>:</p>
<ul>
<li>Tab order logical?</li>
<li>All interactive elements reachable?</li>
<li>Focus visible on all stops?</li>
<li>Any keyboard traps?</li>
<li>Skip link working?</li>
</ul>
<p><strong>Expected</strong>: May be slower (tabbing takes time). Note accessibility issues (missing focus indicators, unreachable buttons).</p>
<hr />
<h3 id="pilot-3-no-js-variant"><a class="header" href="#pilot-3-no-js-variant">Pilot 3: No-JS Variant</a></h3>
<p><strong>Key difference</strong>: Disable JavaScript before starting.</p>
<p><strong>Setup</strong>:</p>
<ol>
<li>Chrome DevTools ‚Üí Settings ‚Üí Preferences ‚Üí Disable JavaScript (checkbox)</li>
<li>Hard refresh (Ctrl+Shift+R / Cmd+Shift+R)</li>
</ol>
<p><strong>Record variant</strong>: <code>Variant: No-JS (JS-off)</code></p>
<p><strong>Additional observations</strong>:</p>
<ul>
<li>Full page reloads on every form submit?</li>
<li>Error messages visible after redirect?</li>
<li>PRG pattern working (refresh doesn't duplicate submission)?</li>
<li>Confirmation missing for delete? (expected trade-off)</li>
</ul>
<p><strong>Expected</strong>: Slower task times (full page reloads). Verify <code>metrics.csv</code> shows <code>js_mode=off</code>.</p>
<hr />
<h3 id="pilots-46-standard-or-screen-reader"><a class="header" href="#pilots-46-standard-or-screen-reader">Pilots 4‚Äì6: Standard or Screen Reader</a></h3>
<p><strong>Standard</strong>: Repeat Pilot 1 process with new participants for more data points.</p>
<p><strong>Screen Reader</strong> (if time permits):</p>
<ul>
<li>Participant uses NVDA (Windows) or Orca (Linux)</li>
<li>Allow 2√ó time (SR navigation slower)</li>
<li>Facilitator <strong>silent</strong> unless participant asks questions (talking competes with SR audio)</li>
</ul>
<p><strong>SR-specific observations</strong>:</p>
<ul>
<li>Are labels announced correctly?</li>
<li>Are status messages announced (<code>role="status"</code>)?</li>
<li>Are error messages linked to inputs (<code>aria-describedby</code>)?</li>
<li>Can participant complete tasks independently?</li>
</ul>
<p><strong>Record variant</strong>: <code>Variant: Screen reader (NVDA), keyboard-only, JS-on</code></p>
<hr />
<h3 id="between-pilots-5-min-each"><a class="header" href="#between-pilots-5-min-each">Between Pilots (5 min each)</a></h3>
<ol>
<li><strong>Save notes</strong>: Copy notes to <code>wk09/lab-wk9/research/pilots/P1-notes.md</code> (or keep in single file with headings)</li>
<li><strong>Check logs</strong>: Verify <code>metrics.csv</code> has rows for all completed tasks</li>
<li><strong>Swap roles</strong>: Next person facilitates, previous facilitator becomes note-taker or participant</li>
<li><strong>Generate new session ID</strong>: Never reuse (contaminates data)</li>
<li><strong>Clear browser state</strong>: Delete cookies, close tabs, fresh start</li>
</ol>
<hr />
<h3 id="facilitator-guidelines-reference"><a class="header" href="#facilitator-guidelines-reference">Facilitator Guidelines (Reference)</a></h3>
<p><strong>Do</strong>:</p>
<ul>
<li>Stay neutral (tone, facial expressions)</li>
<li>Allow silence (don't fill pauses‚Äîpeople think quietly)</li>
<li>Record exact quotes when possible</li>
<li>Note timestamps for key events</li>
</ul>
<p><strong>Don't</strong>:</p>
<ul>
<li>Explain interface ("The filter is at the top")</li>
<li>Justify design ("It's supposed to work like this")</li>
<li>Lead participant ("Did you see the success message?")</li>
<li>Show impatience (sighs, tapping, checking watch)</li>
</ul>
<p><strong>If participant stuck (&gt;3 min)</strong>:</p>
<ol>
<li>Ask diagnostic question: "What are you looking for?"</li>
<li>If still stuck: "Let's move to the next task"</li>
<li>Mark task as <code>completion=0</code>, note reason in pilot-notes</li>
</ol>
<p><strong>If participant becomes frustrated</strong>:</p>
<ul>
<li>Reassure: "This is really helpful feedback‚Äîit's the interface, not you."</li>
<li>Offer break or stop session</li>
<li>Never pressure to continue</li>
</ul>
<hr />
<p>‚úã <strong>Stop and check</strong> (after completing pilots):</p>
<ul>
<li><input disabled="" type="checkbox"/>
3‚Äì6 pilots completed with different variants</li>
<li><input disabled="" type="checkbox"/>
Consent logged for each participant</li>
<li><input disabled="" type="checkbox"/>
metrics.csv contains rows for all tasks (check session_ids)</li>
<li><input disabled="" type="checkbox"/>
Pilot notes saved with timestamps, quotes, observations</li>
<li><input disabled="" type="checkbox"/>
Subjective ratings captured (confidence 1‚Äì5)</li>
</ul>
<hr />
<h2 id="activity-c-data-verification-and-initial-analysis-15-min"><a class="header" href="#activity-c-data-verification-and-initial-analysis-15-min">Activity C: Data Verification and Initial Analysis (15 min)</a></h2>
<p><strong>Goal</strong>: Ensure collected data is complete and usable before leaving lab.</p>
<h3 id="step-1-check-metricscsv-completeness-5-min"><a class="header" href="#step-1-check-metricscsv-completeness-5-min">Step 1: Check metrics.csv completeness (5 min)</a></h3>
<p>Open <code>data/metrics.csv</code> and verify:</p>
<p><strong>Expected structure</strong>:</p>
<pre><code class="language-csv">ts_iso,session_id,request_id,task_code,step,outcome,ms,http_status,js_mode
2025-10-15T14:18:23.456Z,P1_7a9f,r001,T3_add,success,,567,200,on
2025-10-15T14:19:45.789Z,P1_7a9f,r002,T1_filter,success,,1847,200,on
2025-10-15T14:21:12.123Z,P1_7a9f,r003,T2_edit,validation_error,blank_title,0,400,on
2025-10-15T14:21:34.456Z,P1_7a9f,r004,T2_edit,success,,1234,200,on
2025-10-15T14:22:10.789Z,P1_7a9f,r005,T4_delete,success,,210,200,on
</code></pre>
<p><strong>Checklist</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
All session_ids present (P1, P2, P3, ...)</li>
<li><input disabled="" type="checkbox"/>
All task_codes present (T1, T2, T3, T4) per session</li>
<li><input disabled="" type="checkbox"/>
<code>step</code> values valid (success, validation_error, fail)</li>
<li><input disabled="" type="checkbox"/>
Timestamps in chronological order</li>
<li><input disabled="" type="checkbox"/>
<code>js_mode</code> matches variant (off for Pilot 3)</li>
<li><input disabled="" type="checkbox"/>
Durations plausible (not negative, not absurdly high like 999999ms)</li>
</ul>
<p><strong>If data missing</strong>:</p>
<ul>
<li>Note in <code>wk09/lab-wk9/research/data-notes.md</code>:
<pre><code>Pilot 2 (P2_4d8e): Task T4 not logged due to server restart. Used facilitator stopwatch time: 38s.
</code></pre>
</li>
</ul>
<h3 id="step-2-calculate-quick-summary-stats-5-min"><a class="header" href="#step-2-calculate-quick-summary-stats-5-min">Step 2: Calculate quick summary stats (5 min)</a></h3>
<p><strong>Use spreadsheet or manual calculation</strong>:</p>
<p><strong>Completion rates</strong> (per task):</p>
<pre><code>T1 (Filter):    5 success / 5 attempts = 100%
T2 (Edit):      4 success / 5 attempts = 80% (1 participant gave up)
T3 (Add):       5 success / 5 attempts = 100%
T4 (Delete):    5 success / 5 attempts = 100%
</code></pre>
<p><strong>Median times</strong> (from <code>ms</code> column, filter <code>step=success</code>):</p>
<pre><code>T1: [1847, 2103, 1654, 2345, 1899] ‚Üí Median = 1899ms (~19s)
T2: [1234, 1567, 1123, 1890] ‚Üí Median = 1400ms (~14s)
T3: [567, 432, 689, 543, 601] ‚Üí Median = 567ms (~6s)
T4: [210, 198, 234, 221, 205] ‚Üí Median = 210ms (~2s)
</code></pre>
<p><strong>Error rates</strong>:</p>
<pre><code>T2: 2 validation_error events / 6 total attempts = 33%
T3: 1 validation_error / 5 attempts = 20%
</code></pre>
<p><strong>Record in <code>wk09/lab-wk9/research/summary-stats.md</code></strong>:</p>
<pre><code class="language-markdown"># Pilot Summary Stats (n=5)

## Completion Rates
| Task | Completion | Notes |
|------|-----------|-------|
| T1 (Filter) | 5/5 (100%) | All participants successful |
| T2 (Edit) | 4/5 (80%) | P3 gave up after 2 validation errors |
| T3 (Add) | 5/5 (100%) | 1 validation error (P2 submitted blank) |
| T4 (Delete) | 5/5 (100%) | No issues |

## Median Times (success only)
| Task | Median (ms) | Median (s) | Range |
|------|------------|------------|-------|
| T1 | 1899 | 19s | 16s‚Äì23s |
| T2 | 1400 | 14s | 11s‚Äì19s |
| T3 | 567 | 6s | 4s‚Äì7s |
| T4 | 210 | 2s | 2s‚Äì2.3s |

## Error Rates
| Task | Validation Errors | Rate | Notes |
|------|------------------|------|-------|
| T2 | 2 errors (P2, P3) | 33% | Blank title submitted |
| T3 | 1 error (P2) | 20% | Blank title submitted |

## JS-On vs JS-Off (T3 comparison)
- JS-on (n=4): Median 567ms
- JS-off (n=1, P3): 3456ms (full page reload)
- **Difference**: ~6√ó slower without JS (expected)
</code></pre>
<h3 id="step-3-flag-anomalies-5-min"><a class="header" href="#step-3-flag-anomalies-5-min">Step 3: Flag anomalies (5 min)</a></h3>
<p><strong>Look for</strong>:</p>
<ul>
<li>Outliers: Times &gt;3√ó median (distraction? confusion? technical issue?)</li>
<li>Missing data: Tasks with no log entries</li>
<li>Impossible values: Negative times, empty session_ids</li>
<li>Inconsistencies: <code>js_mode=on</code> for Pilot 3 (should be <code>off</code>)</li>
</ul>
<p><strong>Document in data-notes.md</strong>:</p>
<pre><code class="language-markdown"># Data Quality Notes

## Anomalies
- Pilot 1, T1: Duration 1847ms is within normal range ‚úì
- Pilot 3, T3: Duration 3456ms (no-JS) is expected (full page reload) ‚úì
- Pilot 4, T2: Missing log entry‚Äîserver crashed, used stopwatch: 17s

## Exclusions
- None (all data usable)

## Notes
- P3 (no-JS) consistently slower‚Äîconfirms dual-path performance difference
- P2 triggered 2 validation errors (blank submissions)‚Äîpossible focus management issue
</code></pre>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
metrics.csv verified complete</li>
<li><input disabled="" type="checkbox"/>
Summary stats calculated (completion, median times, error rates)</li>
<li><input disabled="" type="checkbox"/>
Anomalies documented</li>
<li><input disabled="" type="checkbox"/>
Data quality acceptable for Week 10 analysis</li>
</ul>
<hr />
<h2 id="activity-d-translate-findings-to-backlog-20-min"><a class="header" href="#activity-d-translate-findings-to-backlog-20-min">Activity D: Translate Findings to Backlog (20 min)</a></h2>
<p><strong>Goal</strong>: Create evidence chains from pilot observations to actionable backlog items.</p>
<h3 id="step-1-review-pilot-notes-5-min"><a class="header" href="#step-1-review-pilot-notes-5-min">Step 1: Review pilot notes (5 min)</a></h3>
<p><strong>Read through all pilot notes</strong> (<code>pilots/P1-notes.md</code>, etc.) and highlight:</p>
<ul>
<li><strong>Accessibility issues</strong>: SR didn't announce, keyboard trap, missing label</li>
<li><strong>Usability issues</strong>: Confusion, hesitation, unexpected behaviour</li>
<li><strong>Error patterns</strong>: Multiple participants hit same validation error</li>
<li><strong>Positive observations</strong>: What worked well (keep in redesign)</li>
</ul>
<p><strong>Example notes</strong>:</p>
<pre><code class="language-markdown">## Pilot 1 (P1_7a9f)
- 14:18 T3: Participant hesitated before clicking "Add Task" button‚Äîunsure if Enter would work
- 14:19 T1: Typed "report", waited, then said "is it filtering automatically?"‚Äîexpected to click button
- 14:21 T2: Validation error (blank submission), participant said "I didn't see an error message"
- 14:22 T4: Delete confirmation dialog appeared, participant confirmed without hesitation ‚úì

## Pilot 2 (P2_4d8e, keyboard-only)
- 14:35 T3: Tab order correct, focus visible ‚úì
- 14:37 T1: Result count not announced by screen reader (tested with NVDA for demo) ‚úó
- 14:39 T2: Blank submission error‚ÄîSR didn't announce error message ‚úó
- 14:40 T4: Delete button accessible, confirmation worked ‚úì

## Pilot 3 (P3_1f2a, no-JS)
- 15:00 T3: Full page reload after submit‚Äîslower but functional ‚úì
- 15:02 T1: Filter worked with form submit‚Äîno issues ‚úì
- 15:04 T2: Gave up after 2 validation errors‚Äîerror summary not focusable ‚úó
- 15:05 T4: No confirmation dialog (expected trade-off), task completed ‚úì
</code></pre>
<h3 id="step-2-identify-themes-5-min"><a class="header" href="#step-2-identify-themes-5-min">Step 2: Identify themes (5 min)</a></h3>
<p><strong>Group similar issues</strong>:</p>
<div class="table-wrapper"><table><thead><tr><th>Theme</th><th>Code</th><th>Observations</th></tr></thead><tbody>
<tr><td><strong>Status feedback</strong></td><td>sr-announcement</td><td>P1: "didn't see error", P2: SR didn't announce, P3: error not focusable</td></tr>
<tr><td><strong>Filter expectations</strong></td><td>ux-expectation</td><td>P1: expected button, not auto-filter</td></tr>
<tr><td><strong>Validation errors</strong></td><td>error-handling</td><td>P2, P3: blank submissions frequent</td></tr>
<tr><td><strong>Keyboard accessibility</strong></td><td>a11y-keyboard</td><td>P2: tab order good ‚úì</td></tr>
<tr><td><strong>No-JS parity</strong></td><td>parity-nojs</td><td>P3: slower but functional ‚úì</td></tr>
</tbody></table>
</div>
<h3 id="step-3-create-backlog-items-10-min"><a class="header" href="#step-3-create-backlog-items-10-min">Step 3: Create backlog items (10 min)</a></h3>
<p><strong>Open <code>backlog/backlog.csv</code></strong> and add entries for significant issues.</p>
<p><strong>Template</strong>:</p>
<pre><code class="language-csv">id,week,priority,category,description,wcag,status,evidence,mitigation,candidate_fix
</code></pre>
<p><strong>Example entries</strong>:</p>
<pre><code class="language-csv">wk9-01,9,high,a11y,"Validation errors not announced by screen readers",4.1.3,open,"data/metrics.csv#P2_4d8e T2 validation_error; pilots/P2-notes.md L12; pilots/P3-notes.md L8","Add role=alert to error messages, aria-describedby for input association",true

wk9-02,9,medium,ux,"Filter auto-search confuses some participants (expected button)",,"open","pilots/P1-notes.md L6","Consider adding visible 'Apply' button or help text",false

wk9-03,9,high,a11y,"Error summary not keyboard-focusable in no-JS mode",3.2.1,open,"pilots/P3-notes.md L10; data/metrics.csv#P3_1f2a T2 fail","Add tabindex=-1 to error summary, focus on page load",true

wk9-04,9,low,ux,"Delete confirmation missing in no-JS (documented trade-off)",3.3.4,open,"pilots/P3-notes.md L12; wk08/docs/prototyping-constraints.md L78","Consider adding /tasks/{id}/delete/confirm page",false

wk9-05,9,high,a11y,"Result count after filter not announced to SR",4.1.3,open,"pilots/P2-notes.md L8","Move result count into live region (role=status)",true
</code></pre>
<p><strong>Key fields</strong>:</p>
<ul>
<li><strong>id</strong>: Unique identifier (wk9-01, wk9-02, ...)</li>
<li><strong>priority</strong>: high (blocks task completion or WCAG A/AA violation), medium (impacts efficiency), low (nice-to-have)</li>
<li><strong>wcag</strong>: Reference if applicable (3.3.1, 4.1.3, etc.)</li>
<li><strong>evidence</strong>: Direct links to data sources (file paths, line numbers, session IDs)</li>
<li><strong>mitigation</strong>: Proposed fix (specific, actionable)</li>
<li><strong>candidate_fix</strong>: <code>true</code> if you plan to implement in Week 10 (limit to 2-3)</li>
</ul>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Pilot notes reviewed and themes identified</li>
<li><input disabled="" type="checkbox"/>
backlog.csv updated with evidence-linked items</li>
<li><input disabled="" type="checkbox"/>
Priority set based on inclusion impact + frequency</li>
<li><input disabled="" type="checkbox"/>
2-3 items marked as candidate fixes for Week 10</li>
</ul>
<hr />
<h2 id="activity-e-assemble-task-1-draft-pack-20-min"><a class="header" href="#activity-e-assemble-task-1-draft-pack-20-min">Activity E: Assemble Task 1 Draft Pack (20 min)</a></h2>
<p><strong>Goal</strong>: Create a complete evidence pack for Gradescope Task 1 submission (will be refined in Week 11).</p>
<p><strong>Directory structure</strong>: <code>wk09/lab-wk9/submission/task1-draft/</code></p>
<h3 id="step-1-copy-evaluation-plan-materials-5-min"><a class="header" href="#step-1-copy-evaluation-plan-materials-5-min">Step 1: Copy evaluation plan materials (5 min)</a></h3>
<p><strong>Files to include</strong>:</p>
<ol>
<li>
<p><strong><code>01-evaluation-plan.md</code></strong>: Copy from <code>wk09/lab-wk9/research/tasks.md</code> + <code>measures.md</code></p>
<ul>
<li>Task definitions</li>
<li>Metrics definitions</li>
<li>Success criteria</li>
</ul>
</li>
<li>
<p><strong><code>02-protocol.md</code></strong>: Copy from <code>wk09/lab-wk9/research/protocol.md</code></p>
<ul>
<li>Consent process</li>
<li>Session flow</li>
<li>Facilitator guidelines</li>
<li>Ethical considerations</li>
</ul>
</li>
<li>
<p><strong><code>03-consent-log.md</code></strong>: Copy from <code>wk09/lab-wk9/research/consent-log.md</code></p>
<ul>
<li>Participant codes</li>
<li>Session IDs</li>
<li>Variants tested</li>
<li>Consent confirmation</li>
</ul>
</li>
</ol>
<h3 id="step-2-include-quantitative-data-5-min"><a class="header" href="#step-2-include-quantitative-data-5-min">Step 2: Include quantitative data (5 min)</a></h3>
<p><strong>Create <code>04-results.csv</code></strong>:</p>
<p>Option A: Copy relevant rows from <code>data/metrics.csv</code>:</p>
<pre><code class="language-bash">grep -E "P1_|P2_|P3_|P4_|P5_" data/metrics.csv &gt; wk09/lab-wk9/submission/task1-draft/04-results.csv
</code></pre>
<p>Option B: Symbolic link (keeps data in one place):</p>
<pre><code class="language-bash">ln -s ../../../data/metrics.csv wk09/lab-wk9/submission/task1-draft/04-results.csv
</code></pre>
<p><strong>Include README.md</strong> explaining columns:</p>
<pre><code class="language-markdown"># Results Data

**File**: `04-results.csv`

**Columns**:
- `ts_iso`: Event timestamp (ISO 8601 UTC)
- `session_id`: Anonymous participant identifier (P1_7a9f, etc.)
- `request_id`: Request trace ID
- `task_code`: Task identifier (T1_filter, T2_edit, T3_add, T4_delete)
- `step`: Event type (success, validation_error, fail)
- `outcome`: Specific error type (blank_title, max_length, etc.)
- `ms`: Duration in milliseconds
- `http_status`: HTTP response code (200, 400, 500)
- `js_mode`: JavaScript availability (on, off)

**Sessions**:
- P1_7a9f: Standard (HTMX, mouse, JS-on)
- P2_4d8e: Keyboard-only (JS-on)
- P3_1f2a: No-JS (JS-off)
- P4_8c3b: Standard (HTMX, mouse, JS-on)
- P5_2a7d: Standard (HTMX, mouse, JS-on)

**Analysis**: See `05-findings.md` for summary statistics and interpretation.
</code></pre>
<h3 id="step-3-document-findings-5-min"><a class="header" href="#step-3-document-findings-5-min">Step 3: Document findings (5 min)</a></h3>
<p><strong>Create <code>05-findings.md</code></strong> summarizing key issues with evidence chains and WCAG references (see Week 9 Lab 1 for detailed example format).</p>
<h3 id="step-4-collect-evidence-artefacts-5-min"><a class="header" href="#step-4-collect-evidence-artefacts-5-min">Step 4: Collect evidence artefacts (5 min)</a></h3>
<p><strong>Create <code>06-evidence/</code> directory</strong>:</p>
<pre><code>wk09/lab-wk9/submission/task1-draft/06-evidence/
‚îú‚îÄ‚îÄ screenshots/
‚îÇ   ‚îú‚îÄ‚îÄ t2-validation-error-nojs.png
‚îÇ   ‚îú‚îÄ‚îÄ t1-filter-results.png
‚îÇ   ‚îî‚îÄ‚îÄ annotations.md (descriptions + alt text)
‚îú‚îÄ‚îÄ pilot-notes/
‚îÇ   ‚îú‚îÄ‚îÄ P1-notes.md
‚îÇ   ‚îú‚îÄ‚îÄ P2-notes.md
‚îÇ   ‚îî‚îÄ‚îÄ P3-notes.md
‚îî‚îÄ‚îÄ consent-log.md
</code></pre>
<p><strong>Remove any PII</strong> from screenshots and notes.</p>
<p>‚úã <strong>Stop and check</strong>:</p>
<ul>
<li><input disabled="" type="checkbox"/>
Evaluation plan + protocol copied to task1-draft/</li>
<li><input disabled="" type="checkbox"/>
Quantitative data (metrics.csv) included or linked</li>
<li><input disabled="" type="checkbox"/>
Findings document complete with statistics + evidence chains</li>
<li><input disabled="" type="checkbox"/>
Evidence artefacts collected (screenshots, notes)</li>
<li><input disabled="" type="checkbox"/>
All files sanitized (no PII)</li>
</ul>
<hr />
<h2 id="commit--reflect-10-min"><a class="header" href="#commit--reflect-10-min">Commit &amp; Reflect (10 min)</a></h2>
<h3 id="commit-message"><a class="header" href="#commit-message">Commit message</a></h3>
<pre><code class="language-bash">git add data/metrics.csv backlog/backlog.csv wk09/lab-wk9/research wk09/lab-wk9/submission

git commit -m "$(cat &lt;&lt;'EOF'
wk9s2: completed peer pilots (n=5), assembled Task 1 draft pack

- Conducted 5 peer pilots: 3 standard (HTMX), 1 keyboard-only, 1 no-JS
- Collected quantitative data: completion rates (80-100%), median times (2s‚Äì19s), error rates (20-33% for T2/T3)
- Captured qualitative observations: validation error accessibility issues, status feedback insufficient, filter UX expectations
- Verified no-JS parity: functional but 6√ó slower (expected)
- Created evidence chains: raw data ‚Üí findings ‚Üí backlog items (wk9-01 to wk9-05)
- Assembled Task 1 draft pack: plan, protocol, results.csv, findings.md, evidence artefacts
- Identified Priority 1 fixes for Week 10: validation error accessibility (role=alert, aria-describedby, focusable summary)

Key findings:
- Validation errors not accessible to SR users (WCAG 4.1.3 violation)
- Error summary not keyboard-focusable in no-JS mode (WCAG 3.2.1)
- Status messages too subtle (affects confidence)
- High error rate on T2 edit (33%‚Äîblank submissions due to focus management)

Ready for Week 10 analysis and redesign.

ü§ñ Generated with [Claude Code](https://claude.com/claude-code)

Co-Authored-By: Claude &lt;noreply@anthropic.com&gt;
EOF
)"
</code></pre>
<h3 id="reflection-questions"><a class="header" href="#reflection-questions">Reflection questions</a></h3>
<p><strong>Answer in <code>wk09/reflection.md</code></strong>:</p>
<ol>
<li>
<p><strong>Pilot experience</strong>: What surprised you most during pilots? Did participants struggle where you expected, or were there unexpected issues?</p>
</li>
<li>
<p><strong>Ethical practice</strong>: How comfortable were participants? Did consent process feel sufficient? Any near-misses on PII collection?</p>
</li>
<li>
<p><strong>Data quality</strong>: How confident are you in the quantitative data (metrics.csv)? Any concerns about accuracy, completeness, or bias?</p>
</li>
<li>
<p><strong>Qualitative insights</strong>: What did observation reveal that logs couldn't capture? How valuable was think-aloud (if used)?</p>
</li>
<li>
<p><strong>Accessibility impact</strong>: Which findings have highest inclusion impact? How would you prioritize fixes if you could only do one?</p>
</li>
<li>
<p><strong>Week 10 readiness</strong>: What are your Priority 1 fixes? How will you verify they worked?</p>
</li>
</ol>
<hr />
<h2 id="looking-ahead-week-10-analysis--redesign"><a class="header" href="#looking-ahead-week-10-analysis--redesign">Looking Ahead: Week 10 Analysis &amp; Redesign</a></h2>
<p>Next week:</p>
<ul>
<li><strong>Lab 1</strong>: Analyse metrics in depth (median, MAD, error rates), prioritize backlog with inclusion √ó impact scores, plan redesign</li>
<li><strong>Lab 2</strong>: Implement Priority 1-2 fixes, re-verify accessibility, update backlog, prepare Task 2 evidence pack</li>
</ul>
<p><strong>Before Week 10</strong>:</p>
<ul>
<li>Review <a href="../references/evaluation-metrics-quickref.html">Evaluation Metrics Quick Reference</a> for analysis formulas</li>
<li>Refresh WCAG 2.2 guidelines for fixes (3.3.1, 4.1.3)</li>
<li>Think about trade-offs: which fixes are quick wins vs major refactors?</li>
</ul>
<hr />
<h2 id="further-reading--resources"><a class="header" href="#further-reading--resources">Further Reading &amp; Resources</a></h2>
<h3 id="essential"><a class="header" href="#essential">Essential</a></h3>
<ul>
<li>Review Week 9 Lab 1 (evaluation planning) for context</li>
<li><a href="../references/evaluation-metrics-quickref.html">Evaluation Metrics Quick Reference</a> ‚Äî Median, MAD, error rate formulas</li>
<li><a href="https://www.gov.uk/service-manual/user-research/analyse-a-research-session">GOV.UK: Analysing user research</a></li>
</ul>
<h3 id="hci-evaluation"><a class="header" href="#hci-evaluation">HCI Evaluation</a></h3>
<ul>
<li><a href="https://www.nngroup.com/articles/usability-testing-101/">Nielsen: How to Conduct a Usability Test</a></li>
<li><a href="https://dl.acm.org/doi/book/10.5555/2737875">Lazar et al.: Research Methods in HCI</a> ‚Äî Chapters 9-10 (qualitative methods)</li>
<li><a href="https://measuringux.com/">Measuring UX</a> ‚Äî Quantitative analysis techniques</li>
</ul>
<h3 id="qualitative-analysis"><a class="header" href="#qualitative-analysis">Qualitative Analysis</a></h3>
<ul>
<li><a href="https://www.tandfonline.com/doi/abs/10.1191/1478088706qp063oa">Braun &amp; Clarke: Thematic Analysis</a></li>
<li><a href="https://www.gov.uk/service-manual/user-research/analyse-a-research-session">GOV.UK: Analysing qualitative data</a></li>
</ul>
<h3 id="ethics"><a class="header" href="#ethics">Ethics</a></h3>
<ul>
<li>Review <code>references/consent-pii-faq.md</code></li>
<li><a href="https://www.bps.org.uk/guideline/code-ethics-and-conduct">BPS Code of Ethics</a></li>
</ul>
<hr />
<h2 id="glossary-summary"><a class="header" href="#glossary-summary">Glossary Summary</a></h2>
<div class="table-wrapper"><table><thead><tr><th>Term</th><th>One-line definition</th></tr></thead><tbody>
<tr><td><strong>Pilot study</strong></td><td>Small-scale preliminary study to test protocol and gather initial data</td></tr>
<tr><td><strong>Quantitative data</strong></td><td>Numerical measurements (times, counts, percentages); objective, statistical</td></tr>
<tr><td><strong>Qualitative data</strong></td><td>Non-numerical observations (quotes, behaviours, patterns); subjective, interpretive</td></tr>
<tr><td><strong>Think-aloud protocol</strong></td><td>Participants verbalize thoughts while completing tasks; reveals mental models</td></tr>
<tr><td><strong>Evidence chain</strong></td><td>Traceability from raw data ‚Üí finding ‚Üí backlog item ‚Üí fix ‚Üí verification</td></tr>
<tr><td><strong>Thematic coding</strong></td><td>Systematic process of identifying patterns (themes) in qualitative data</td></tr>
<tr><td><strong>Median</strong></td><td>Middle value in sorted dataset; resistant to outliers</td></tr>
<tr><td><strong>MAD</strong></td><td>Median Absolute Deviation; robust measure of spread</td></tr>
<tr><td><strong>Completion rate</strong></td><td>Proportion of participants who successfully complete a task</td></tr>
<tr><td><strong>Error rate</strong></td><td>Proportion of attempts that trigger validation errors</td></tr>
</tbody></table>
</div>
<hr />
<p><strong>Lab complete!</strong> You have real pilot data, evidence chains, and a draft Task 1 pack. Week 10 will analyse this data rigorously and implement prioritised fixes.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                            <a rel="prev" href="../wk09/wk9-lab1-eval-plan-instrumentation.html" class="mobile-nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                                <i class="fa fa-angle-left"></i>
                            </a>

                            <a rel="next prefetch" href="../resources/code-resources.html" class="mobile-nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                                <i class="fa fa-angle-right"></i>
                            </a>

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                    <a rel="prev" href="../wk09/wk9-lab1-eval-plan-instrumentation.html" class="nav-chapters previous" title="Previous chapter" aria-label="Previous chapter" aria-keyshortcuts="Left">
                        <i class="fa fa-angle-left"></i>
                    </a>

                    <a rel="next prefetch" href="../resources/code-resources.html" class="nav-chapters next" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right">
                        <i class="fa fa-angle-right"></i>
                    </a>
            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="../elasticlunr.min.js"></script>
        <script src="../mark.min.js"></script>
        <script src="../searcher.js"></script>

        <script src="../clipboard.min.js"></script>
        <script src="../highlight.js"></script>
        <script src="../book.js"></script>

        <!-- Custom JS scripts -->
        <script src="../mermaid.min.js"></script>
        <script src="../mermaid-init.js"></script>



    </div>
    </body>
</html>
